{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "414f139d-1690-4a6a-8a9b-bc9abcc54dbb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Constants\n",
    "DATA_PATH   = \"../Data/Processed/3_engineered_df.pkl\"\n",
    "\n",
    "TECH_JOBS = ['Techjobs']\n",
    "\n",
    "CORE_COLS = ['VersionControlSystem',\n",
    "             'Languages',\n",
    "             'Databases',\n",
    "             'Platforms',\n",
    "             'WebFrameworks',\n",
    "             'MiscTech',\n",
    "             'ToolsTech',\n",
    "             'CollabTools'\n",
    "]\n",
    "\n",
    "\n",
    "MLFLOW_TRACKING_URI = '../models/mlruns'\n",
    "MLFLOW_EXPERIMENT_NAME = \"tech_jobs_predictions\"\n",
    "\n",
    "LOG_PATH = \"../models/temp/\"\n",
    "LOG_DATA_PKL    =  \"data.pkl\"\n",
    "LOG_MODEL_PKL   =  \"model.pkl\"\n",
    "LOG_METRICS_PKL =  \"metrics.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "479545cb-df3d-4d79-b24a-f12d1945d453",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load packages\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    " \n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler,RobustScaler\n",
    "\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import auc, accuracy_score, confusion_matrix, f1_score, precision_score, recall_score,ConfusionMatrixDisplay,classification_report\n",
    "from sklearn.model_selection import train_test_split,cross_val_score, cross_validate,cross_val_predict, GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "pd.options.display.max_rows = 1000\n",
    "pd.options.display.max_columns = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8796ec-a3a5-4ce6-aa68-5489f03d4364",
   "metadata": {},
   "source": [
    "_____"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b303da-94c0-4c3c-81a6-4ede2d19d9c4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d025650b-bca6-408e-b551-8bbd87b15859",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Functions to calculate metric functions across all columns in a multi-label dataset\n",
    "def calculate_metric(truth, pred, metric_function):\n",
    "    if metric_function == accuracy_score:\n",
    "        metric_score = round(metric_function(truth, pred) * 100, 2)\n",
    "    else: \n",
    "        metric_score = round(metric_function(truth, pred,zero_division=0,average='macro') * 100, 2)\n",
    "    return metric_score\n",
    "\n",
    "def predictions_per_col(predictions, y, metric_function):\n",
    "    metric_scores = {}\n",
    "    for col in predictions.columns:\n",
    "        truth = y[col].copy()\n",
    "        pred  = predictions[col].copy()\n",
    "        \n",
    "        metric_scores[col] = calculate_metric(truth, pred, metric_function)\n",
    "\n",
    "    metric_scores = pd.Series(metric_scores.values(), index=metric_scores.keys())\n",
    "    \n",
    "    return metric_scores\n",
    "\n",
    "def calculate_metrics(clf, x, y, metrics=[accuracy_score, precision_score, recall_score, f1_score]):\n",
    "    #create a dataframe contains the predictions \n",
    "    predictions =  pd.DataFrame(clf.predict(x),\n",
    "                                columns=y.columns)\n",
    "    \n",
    "    #create a dict for each type of metric contains a dicts of each label and its value \n",
    "    final_scores = {metric.__name__: predictions_per_col(predictions, y, metric) \n",
    "            for metric in metrics}\n",
    "    \n",
    "    #Convert the dict to dataframe\n",
    "    final_scores = pd.concat(final_scores,axis=1)\n",
    "    mean_final_scores = final_scores.mean()\n",
    "    \n",
    "    return final_scores, mean_final_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5aee1817-0500-4631-adf9-64dcc67f2e7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function that calculate all metrics for a cross_validate function for multiclass classification\n",
    "def calculate_scores(clf, x, y):\n",
    "    y_pred = clf.predict(x)\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    precision = precision_score(y, y_pred, average='macro',zero_division=0.0)\n",
    "    recall = recall_score(y, y_pred, average='macro',zero_division=0.0)\n",
    "    f1 = f1_score(y, y_pred, average='macro',zero_division=0.0)\n",
    "    \n",
    "    return {'accuracy': accuracy,\n",
    "            'precision':precision,\n",
    "            'recall': recall,\n",
    "           'f1' : f1}\n",
    "\n",
    "def calculate_scores_multi_label(clf, x, y, metrics=[accuracy_score, precision_score, recall_score, f1_score]):\n",
    "    #create a dataframe contains the predictions \n",
    "    predictions =  pd.DataFrame(clf.predict(x),\n",
    "                                columns=y.columns)\n",
    "    \n",
    "    #create a dict for each type of metric contains a dicts of each label and its value \n",
    "    final_scores = {metric.__name__: predictions_per_col(predictions, y, metric) \n",
    "            for metric in metrics}\n",
    "    \n",
    "    #Convert the dict to dataframe\n",
    "    final_scores = pd.concat(final_scores,axis=1)\n",
    "    mean_final_scores = final_scores.mean()\n",
    "    \n",
    "    return {'accuracy': mean_final_scores[0],\n",
    "            'precision':mean_final_scores[1],\n",
    "            'recall': mean_final_scores[2],\n",
    "           'f1' : mean_final_scores[3]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38d203ad-1aa0-4110-b7ff-4a735985c905",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function responisble for Grid_search wtih multi_label dataset\n",
    "def f1_score_multi_label(clf, x, y):\n",
    "    quality_scores = {}\n",
    "    predictions =  pd.DataFrame(clf.predict(x),\n",
    "                            columns=y.columns)\n",
    "    \n",
    "    for col in predictions.columns:\n",
    "        job_pred  = predictions[col].copy()\n",
    "        job_truth = y[col].copy()\n",
    "\n",
    "        quality_scores[col] = round(f1_score(job_truth, job_pred,zero_division=0,average='macro') * 100, 2)\n",
    "        \n",
    "    quality_scores = pd.Series(quality_scores.values(), index=quality_scores.keys())\n",
    "    \n",
    "    # train_scores = pd.concat(train_scores,axis=1)\n",
    "    mean_f1_score = quality_scores.mean()\n",
    "    return mean_f1_score\n",
    "\n",
    "def precision_score_multi_label(clf, x, y):\n",
    "    quality_scores = {}\n",
    "    predictions =  pd.DataFrame(clf.predict(x),\n",
    "                            columns=y.columns)\n",
    "    \n",
    "    for col in predictions.columns:\n",
    "        job_pred  = predictions[col].copy()\n",
    "        job_truth = y[col].copy()\n",
    "\n",
    "        quality_scores[col] = round(precision_score(job_truth, job_pred,zero_division=0,average='macro') * 100, 2)\n",
    "        \n",
    "    quality_scores = pd.Series(quality_scores.values(), index=quality_scores.keys())\n",
    "    \n",
    "    # train_scores = pd.concat(train_scores,axis=1)\n",
    "    mean_f1_score = quality_scores.mean()\n",
    "    return mean_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd630a5c-eb8f-4e6c-97d0-e56a2109894f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def log_data(x_train,y_train,x_test,y_test):\n",
    "    # Save the model's dataset trained on\n",
    "    data_details = {\n",
    "    #For multilabel Dataset\n",
    "                    \"data_path\": DATA_PATH,\n",
    "                    \"training_set\": x_train.index.tolist(),\n",
    "                    \"test_indices\":     x_test.index.tolist(), \n",
    "                    \"features_names\":   x_train.columns.tolist(),\n",
    "                    \"targets_names\":    y_train.columns.tolist()\n",
    "    #For multiclass Dataset    \n",
    "                    # \"x_train\": x_train,\n",
    "                    # \"x_test\":x_test,\n",
    "                    # \"y_train\":y_train,\n",
    "                    # \"y_test\": y_test\n",
    "    }\n",
    "\n",
    "    with open(os.path.join(LOG_PATH, LOG_DATA_PKL), \"wb\") as output_file:\n",
    "        pickle.dump(data_details, output_file)\n",
    "        \n",
    "        \n",
    "def log_model(clf,model_description=''):\n",
    "    # save the model, model details and model's description\n",
    "    model = {\"model_description\": model_description,\n",
    "             \"model_details\": str(clf),\n",
    "             \"model_object\": clf} \n",
    "\n",
    "    with open(os.path.join(LOG_PATH, LOG_MODEL_PKL), \"wb\") as output_file:\n",
    "        pickle.dump(model, output_file)\n",
    "        \n",
    "    return model\n",
    "        \n",
    "def log_metrics(train_scores, test_scores):\n",
    "    # save the model metrics\n",
    "    classes_metrics = {\"train_scores\": train_scores,\n",
    "                        \"test_scores\" : test_scores} \n",
    "\n",
    "\n",
    "    with open(os.path.join(LOG_PATH, LOG_METRICS_PKL), \"wb\") as output_file:\n",
    "        pickle.dump(classes_metrics, output_file)\n",
    "\n",
    "def track_model(model, scores):\n",
    "    # Start a run in the experiment and track current model\n",
    "    with mlflow.start_run(experiment_id=exp.experiment_id, run_name=model[\"model_description\"]):\n",
    "        # Track pickle files\n",
    "        mlflow.log_artifacts(LOG_PATH)\n",
    "\n",
    "        # Track metrics \n",
    "        for metric, score in scores.items():\n",
    "            mlflow.log_metric(metric, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571b17b8-74c5-4506-872e-3fd7f4c83cdd",
   "metadata": {},
   "source": [
    "_____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6a14ea2-0e58-4a2d-8fd8-90adfd22c3c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load dataset and make a copy\n",
    "eng_df = pd.read_pickle(DATA_PATH)\n",
    "df = eng_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3aaf3f6-1a80-401a-a9d9-dbabdcd58898",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"19\" halign=\"left\">Techjobs</th>\n",
       "      <th colspan=\"3\" halign=\"left\">VersionControlSystem</th>\n",
       "      <th colspan=\"42\" halign=\"left\">Languages</th>\n",
       "      <th colspan=\"17\" halign=\"left\">Databases</th>\n",
       "      <th colspan=\"14\" halign=\"left\">Platforms</th>\n",
       "      <th colspan=\"25\" halign=\"left\">WebFrameworks</th>\n",
       "      <th colspan=\"23\" halign=\"left\">MiscTech</th>\n",
       "      <th colspan=\"13\" halign=\"left\">ToolsTech</th>\n",
       "      <th colspan=\"27\" halign=\"left\">CollabTools</th>\n",
       "      <th colspan=\"38\" halign=\"left\">Skills_Clusters</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Data scientist or machine learning specialist</th>\n",
       "      <th>Engineer, data</th>\n",
       "      <th>Data or business analyst</th>\n",
       "      <th>Developer, back-end</th>\n",
       "      <th>Database administrator</th>\n",
       "      <th>Developer, mobile</th>\n",
       "      <th>Developer, full-stack</th>\n",
       "      <th>Cloud infrastructure engineer</th>\n",
       "      <th>Developer, embedded applications or devices</th>\n",
       "      <th>Developer, QA or test</th>\n",
       "      <th>System administrator</th>\n",
       "      <th>Scientist</th>\n",
       "      <th>Security professional</th>\n",
       "      <th>Developer, game or graphics</th>\n",
       "      <th>Developer, front-end</th>\n",
       "      <th>Blockchain</th>\n",
       "      <th>Developer, desktop or enterprise applications</th>\n",
       "      <th>DevOps specialist</th>\n",
       "      <th>Academic researcher</th>\n",
       "      <th>Git</th>\n",
       "      <th>Mercurial</th>\n",
       "      <th>SVN</th>\n",
       "      <th>APL</th>\n",
       "      <th>Assembly</th>\n",
       "      <th>Bash/Shell</th>\n",
       "      <th>C</th>\n",
       "      <th>C#</th>\n",
       "      <th>C++</th>\n",
       "      <th>COBOL</th>\n",
       "      <th>Clojure</th>\n",
       "      <th>Crystal</th>\n",
       "      <th>Dart</th>\n",
       "      <th>Delphi</th>\n",
       "      <th>Elixir</th>\n",
       "      <th>Erlang</th>\n",
       "      <th>F#</th>\n",
       "      <th>Fortran</th>\n",
       "      <th>Go</th>\n",
       "      <th>Groovy</th>\n",
       "      <th>HTML/CSS</th>\n",
       "      <th>Haskell</th>\n",
       "      <th>Java</th>\n",
       "      <th>JavaScript</th>\n",
       "      <th>Julia</th>\n",
       "      <th>Kotlin</th>\n",
       "      <th>LISP</th>\n",
       "      <th>Lua</th>\n",
       "      <th>MATLAB</th>\n",
       "      <th>OCaml</th>\n",
       "      <th>Objective-C</th>\n",
       "      <th>PHP</th>\n",
       "      <th>Perl</th>\n",
       "      <th>PowerShell</th>\n",
       "      <th>Python</th>\n",
       "      <th>R</th>\n",
       "      <th>Ruby</th>\n",
       "      <th>Rust</th>\n",
       "      <th>SAS</th>\n",
       "      <th>SQL</th>\n",
       "      <th>Scala</th>\n",
       "      <th>Solidity</th>\n",
       "      <th>Swift</th>\n",
       "      <th>TypeScript</th>\n",
       "      <th>VBA</th>\n",
       "      <th>Cassandra</th>\n",
       "      <th>Cloud Firestore</th>\n",
       "      <th>CouchDB</th>\n",
       "      <th>Couchbase</th>\n",
       "      <th>DynamoDB</th>\n",
       "      <th>Elasticsearch</th>\n",
       "      <th>Firebase Realtime Database</th>\n",
       "      <th>IBM DB2</th>\n",
       "      <th>MariaDB</th>\n",
       "      <th>Microsoft SQL Server</th>\n",
       "      <th>MongoDB</th>\n",
       "      <th>MySQL</th>\n",
       "      <th>Neo4j</th>\n",
       "      <th>Oracle</th>\n",
       "      <th>PostgreSQL</th>\n",
       "      <th>Redis</th>\n",
       "      <th>SQLite</th>\n",
       "      <th>AWS</th>\n",
       "      <th>Colocation</th>\n",
       "      <th>DigitalOcean</th>\n",
       "      <th>Firebase</th>\n",
       "      <th>Google Cloud</th>\n",
       "      <th>Heroku</th>\n",
       "      <th>IBM Cloud or Watson</th>\n",
       "      <th>Linode</th>\n",
       "      <th>Managed Hosting</th>\n",
       "      <th>Microsoft Azure</th>\n",
       "      <th>OVH</th>\n",
       "      <th>OpenStack</th>\n",
       "      <th>Oracle Cloud Infrastructure</th>\n",
       "      <th>VMware</th>\n",
       "      <th>ASP.NET</th>\n",
       "      <th>ASP.NET Core</th>\n",
       "      <th>Angular</th>\n",
       "      <th>Angular.js</th>\n",
       "      <th>Blazor</th>\n",
       "      <th>Deno</th>\n",
       "      <th>Django</th>\n",
       "      <th>Drupal</th>\n",
       "      <th>Express</th>\n",
       "      <th>FastAPI</th>\n",
       "      <th>Fastify</th>\n",
       "      <th>Flask</th>\n",
       "      <th>Gatsby</th>\n",
       "      <th>Laravel</th>\n",
       "      <th>Next.js</th>\n",
       "      <th>Node.js</th>\n",
       "      <th>Nuxt.js</th>\n",
       "      <th>Phoenix</th>\n",
       "      <th>Play Framework</th>\n",
       "      <th>React.js</th>\n",
       "      <th>Ruby on Rails</th>\n",
       "      <th>Svelte</th>\n",
       "      <th>Symfony</th>\n",
       "      <th>Vue.js</th>\n",
       "      <th>jQuery</th>\n",
       "      <th>.NET</th>\n",
       "      <th>Apache Kafka</th>\n",
       "      <th>Apache Spark</th>\n",
       "      <th>Capacitor</th>\n",
       "      <th>Cordova</th>\n",
       "      <th>Electron</th>\n",
       "      <th>Flutter</th>\n",
       "      <th>GTK</th>\n",
       "      <th>Hadoop</th>\n",
       "      <th>Hugging Face Transformers</th>\n",
       "      <th>Ionic</th>\n",
       "      <th>Keras</th>\n",
       "      <th>NumPy</th>\n",
       "      <th>Pandas</th>\n",
       "      <th>Qt</th>\n",
       "      <th>React Native</th>\n",
       "      <th>Scikit-learn</th>\n",
       "      <th>Spring</th>\n",
       "      <th>TensorFlow</th>\n",
       "      <th>Tidyverse</th>\n",
       "      <th>Torch/PyTorch</th>\n",
       "      <th>Uno Platform</th>\n",
       "      <th>Xamarin</th>\n",
       "      <th>Ansible</th>\n",
       "      <th>Chef</th>\n",
       "      <th>Docker</th>\n",
       "      <th>Flow</th>\n",
       "      <th>Homebrew</th>\n",
       "      <th>Kubernetes</th>\n",
       "      <th>Pulumi</th>\n",
       "      <th>Puppet</th>\n",
       "      <th>Terraform</th>\n",
       "      <th>Unity 3D</th>\n",
       "      <th>Unreal Engine</th>\n",
       "      <th>Yarn</th>\n",
       "      <th>npm</th>\n",
       "      <th>Android Studio</th>\n",
       "      <th>Atom</th>\n",
       "      <th>CLion</th>\n",
       "      <th>Eclipse</th>\n",
       "      <th>Emacs</th>\n",
       "      <th>GoLand</th>\n",
       "      <th>IPython/Jupyter</th>\n",
       "      <th>IntelliJ</th>\n",
       "      <th>Nano</th>\n",
       "      <th>Neovim</th>\n",
       "      <th>NetBeans</th>\n",
       "      <th>Notepad++</th>\n",
       "      <th>PhpStorm</th>\n",
       "      <th>PyCharm</th>\n",
       "      <th>Qt Creator</th>\n",
       "      <th>RAD Studio (Delphi, C++ Builder)</th>\n",
       "      <th>RStudio</th>\n",
       "      <th>Rider</th>\n",
       "      <th>RubyMine</th>\n",
       "      <th>Spyder</th>\n",
       "      <th>Sublime Text</th>\n",
       "      <th>TextMate</th>\n",
       "      <th>Vim</th>\n",
       "      <th>Visual Studio</th>\n",
       "      <th>Visual Studio Code</th>\n",
       "      <th>Webstorm</th>\n",
       "      <th>Xcode</th>\n",
       "      <th>skills_group_0</th>\n",
       "      <th>skills_group_1</th>\n",
       "      <th>skills_group_10</th>\n",
       "      <th>skills_group_11</th>\n",
       "      <th>skills_group_12</th>\n",
       "      <th>skills_group_13</th>\n",
       "      <th>skills_group_14</th>\n",
       "      <th>skills_group_15</th>\n",
       "      <th>skills_group_16</th>\n",
       "      <th>skills_group_17</th>\n",
       "      <th>skills_group_18</th>\n",
       "      <th>skills_group_19</th>\n",
       "      <th>skills_group_2</th>\n",
       "      <th>skills_group_20</th>\n",
       "      <th>skills_group_21</th>\n",
       "      <th>skills_group_22</th>\n",
       "      <th>skills_group_23</th>\n",
       "      <th>skills_group_24</th>\n",
       "      <th>skills_group_25</th>\n",
       "      <th>skills_group_26</th>\n",
       "      <th>skills_group_27</th>\n",
       "      <th>skills_group_28</th>\n",
       "      <th>skills_group_29</th>\n",
       "      <th>skills_group_3</th>\n",
       "      <th>skills_group_30</th>\n",
       "      <th>skills_group_31</th>\n",
       "      <th>skills_group_32</th>\n",
       "      <th>skills_group_33</th>\n",
       "      <th>skills_group_34</th>\n",
       "      <th>skills_group_35</th>\n",
       "      <th>skills_group_36</th>\n",
       "      <th>skills_group_37</th>\n",
       "      <th>skills_group_4</th>\n",
       "      <th>skills_group_5</th>\n",
       "      <th>skills_group_6</th>\n",
       "      <th>skills_group_7</th>\n",
       "      <th>skills_group_8</th>\n",
       "      <th>skills_group_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73262</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73263</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73264</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73265</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73266</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42246 rows  221 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Techjobs                 \\\n",
       "      Data scientist or machine learning specialist Engineer, data   \n",
       "2                                                 1              1   \n",
       "3                                                 0              0   \n",
       "9                                                 0              0   \n",
       "10                                                0              0   \n",
       "12                                                0              0   \n",
       "...                                             ...            ...   \n",
       "73262                                             0              0   \n",
       "73263                                             0              0   \n",
       "73264                                             1              0   \n",
       "73265                                             0              0   \n",
       "73266                                             0              0   \n",
       "\n",
       "                                                                           \\\n",
       "      Data or business analyst Developer, back-end Database administrator   \n",
       "2                            0                   0                      0   \n",
       "3                            0                   0                      0   \n",
       "9                            0                   0                      0   \n",
       "10                           0                   1                      0   \n",
       "12                           0                   0                      0   \n",
       "...                        ...                 ...                    ...   \n",
       "73262                        0                   0                      0   \n",
       "73263                        0                   1                      0   \n",
       "73264                        0                   0                      0   \n",
       "73265                        0                   0                      0   \n",
       "73266                        0                   0                      0   \n",
       "\n",
       "                                                                             \\\n",
       "      Developer, mobile Developer, full-stack Cloud infrastructure engineer   \n",
       "2                     0                     0                             0   \n",
       "3                     0                     1                             0   \n",
       "9                     1                     0                             0   \n",
       "10                    0                     1                             0   \n",
       "12                    0                     1                             0   \n",
       "...                 ...                   ...                           ...   \n",
       "73262                 0                     0                             0   \n",
       "73263                 0                     0                             0   \n",
       "73264                 0                     0                             0   \n",
       "73265                 0                     1                             0   \n",
       "73266                 0                     0                             0   \n",
       "\n",
       "                                                                         \\\n",
       "      Developer, embedded applications or devices Developer, QA or test   \n",
       "2                                               0                     0   \n",
       "3                                               0                     0   \n",
       "9                                               0                     0   \n",
       "10                                              0                     0   \n",
       "12                                              0                     0   \n",
       "...                                           ...                   ...   \n",
       "73262                                           0                     0   \n",
       "73263                                           0                     0   \n",
       "73264                                           0                     0   \n",
       "73265                                           0                     0   \n",
       "73266                                           0                     0   \n",
       "\n",
       "                                                            \\\n",
       "      System administrator Scientist Security professional   \n",
       "2                        0         0                     0   \n",
       "3                        0         0                     0   \n",
       "9                        0         0                     0   \n",
       "10                       0         0                     0   \n",
       "12                       0         0                     0   \n",
       "...                    ...       ...                   ...   \n",
       "73262                    0         0                     0   \n",
       "73263                    0         0                     0   \n",
       "73264                    0         0                     0   \n",
       "73265                    1         0                     0   \n",
       "73266                    0         0                     0   \n",
       "\n",
       "                                                                   \\\n",
       "      Developer, game or graphics Developer, front-end Blockchain   \n",
       "2                               0                    1          0   \n",
       "3                               0                    0          0   \n",
       "9                               0                    0          0   \n",
       "10                              0                    0          0   \n",
       "12                              0                    0          0   \n",
       "...                           ...                  ...        ...   \n",
       "73262                           0                    1          0   \n",
       "73263                           0                    0          0   \n",
       "73264                           0                    0          0   \n",
       "73265                           0                    0          0   \n",
       "73266                           0                    1          0   \n",
       "\n",
       "                                                                       \\\n",
       "      Developer, desktop or enterprise applications DevOps specialist   \n",
       "2                                                 0                 0   \n",
       "3                                                 0                 0   \n",
       "9                                                 1                 0   \n",
       "10                                                0                 0   \n",
       "12                                                0                 0   \n",
       "...                                             ...               ...   \n",
       "73262                                             0                 0   \n",
       "73263                                             0                 0   \n",
       "73264                                             0                 0   \n",
       "73265                                             1                 0   \n",
       "73266                                             1                 0   \n",
       "\n",
       "                          VersionControlSystem               Languages  \\\n",
       "      Academic researcher                  Git Mercurial SVN       APL   \n",
       "2                       0                    1         0   0         0   \n",
       "3                       0                    1         0   0         0   \n",
       "9                       0                    1         0   0         0   \n",
       "10                      0                    1         0   0         0   \n",
       "12                      0                    1         0   0         0   \n",
       "...                   ...                  ...       ...  ..       ...   \n",
       "73262                   0                    1         0   0         0   \n",
       "73263                   0                    1         0   0         0   \n",
       "73264                   0                    1         0   0         0   \n",
       "73265                   0                    1         0   0         0   \n",
       "73266                   0                    0         0   1         0   \n",
       "\n",
       "                                                                              \\\n",
       "      Assembly Bash/Shell  C C# C++ COBOL Clojure Crystal Dart Delphi Elixir   \n",
       "2            0          0  0  1   1     0       0       0    0      0      0   \n",
       "3            0          0  0  1   0     0       0       0    0      0      0   \n",
       "9            0          0  0  0   0     0       0       0    0      1      0   \n",
       "10           0          1  0  1   0     0       0       0    0      0      0   \n",
       "12           0          0  1  0   0     0       0       0    0      0      0   \n",
       "...        ...        ... .. ..  ..   ...     ...     ...  ...    ...    ...   \n",
       "73262        1          0  1  0   1     0       0       0    0      0      0   \n",
       "73263        0          1  0  0   0     0       0       0    1      0      0   \n",
       "73264        0          1  0  0   0     0       0       0    0      0      0   \n",
       "73265        0          0  0  1   0     0       0       0    0      0      0   \n",
       "73266        0          0  0  1   0     0       0       0    0      1      0   \n",
       "\n",
       "                                                                          \\\n",
       "      Erlang F# Fortran Go Groovy HTML/CSS Haskell Java JavaScript Julia   \n",
       "2          0  0       0  0      0        1       0    0          1     0   \n",
       "3          0  0       0  0      0        0       0    0          1     0   \n",
       "9          0  0       0  0      0        0       0    1          0     0   \n",
       "10         0  0       0  1      0        1       0    0          1     0   \n",
       "12         0  0       0  0      0        1       1    0          0     0   \n",
       "...      ... ..     ... ..    ...      ...     ...  ...        ...   ...   \n",
       "73262      0  0       0  0      0        0       0    1          0     0   \n",
       "73263      0  0       0  1      0        0       0    0          1     0   \n",
       "73264      0  0       0  0      0        1       0    0          1     0   \n",
       "73265      0  0       0  0      0        1       0    0          1     0   \n",
       "73266      0  0       0  0      0        0       0    0          0     0   \n",
       "\n",
       "                                                                              \\\n",
       "      Kotlin LISP Lua MATLAB OCaml Objective-C PHP Perl PowerShell Python  R   \n",
       "2          0    0   0      0     0           0   0    0          0      1  0   \n",
       "3          0    0   0      0     0           0   0    0          0      0  0   \n",
       "9          0    0   0      0     0           0   0    0          0      0  0   \n",
       "10         0    0   0      0     0           0   0    0          1      0  0   \n",
       "12         0    0   0      0     0           0   0    0          0      0  0   \n",
       "...      ...  ...  ..    ...   ...         ...  ..  ...        ...    ... ..   \n",
       "73262      0    0   0      0     0           0   0    0          0      0  0   \n",
       "73263      0    0   0      0     0           0   1    0          0      1  0   \n",
       "73264      0    0   0      0     0           0   0    0          0      1  0   \n",
       "73265      0    0   0      0     0           0   1    0          0      1  0   \n",
       "73266      0    0   0      0     0           0   0    0          0      0  0   \n",
       "\n",
       "                                                            Databases  \\\n",
       "      Ruby Rust SAS SQL Scala Solidity Swift TypeScript VBA Cassandra   \n",
       "2        0    0   0   0     0        0     0          1   0         0   \n",
       "3        0    0   0   1     0        0     0          1   0         0   \n",
       "9        0    0   0   0     0        0     1          0   0         0   \n",
       "10       0    0   0   1     0        0     0          0   0         0   \n",
       "12       0    1   0   1     0        0     1          1   0         0   \n",
       "...    ...  ...  ..  ..   ...      ...   ...        ...  ..       ...   \n",
       "73262    0    0   0   0     0        0     0          1   0         0   \n",
       "73263    0    0   0   1     0        0     0          1   0         0   \n",
       "73264    0    0   0   1     0        0     0          0   0         0   \n",
       "73265    0    0   0   1     0        0     0          0   0         0   \n",
       "73266    0    0   0   0     0        0     0          0   1         0   \n",
       "\n",
       "                                                                \\\n",
       "      Cloud Firestore CouchDB Couchbase DynamoDB Elasticsearch   \n",
       "2                   0       0         0        0             0   \n",
       "3                   0       0         0        0             0   \n",
       "9                   0       0         0        0             0   \n",
       "10                  0       0         0        0             0   \n",
       "12                  0       0         0        0             1   \n",
       "...               ...     ...       ...      ...           ...   \n",
       "73262               0       0         0        0             0   \n",
       "73263               0       0         0        0             1   \n",
       "73264               0       0         0        0             1   \n",
       "73265               0       0         0        0             0   \n",
       "73266               0       0         0        0             0   \n",
       "\n",
       "                                                                               \\\n",
       "      Firebase Realtime Database IBM DB2 MariaDB Microsoft SQL Server MongoDB   \n",
       "2                              0       0       0                    1       0   \n",
       "3                              0       0       0                    1       0   \n",
       "9                              0       0       0                    0       0   \n",
       "10                             0       0       0                    1       0   \n",
       "12                             0       0       0                    0       0   \n",
       "...                          ...     ...     ...                  ...     ...   \n",
       "73262                          0       0       0                    0       0   \n",
       "73263                          0       0       0                    0       0   \n",
       "73264                          0       0       0                    0       1   \n",
       "73265                          0       0       1                    1       0   \n",
       "73266                          0       0       0                    1       1   \n",
       "\n",
       "                                                 Platforms             \\\n",
       "      MySQL Neo4j Oracle PostgreSQL Redis SQLite       AWS Colocation   \n",
       "2         0     0      0          0     0      0         0          0   \n",
       "3         0     0      0          0     0      0         0          0   \n",
       "9         0     0      0          0     0      0         0          0   \n",
       "10        0     0      0          0     0      0         1          0   \n",
       "12        0     0      0          1     1      0         1          0   \n",
       "...     ...   ...    ...        ...   ...    ...       ...        ...   \n",
       "73262     0     0      0          0     0      0         0          0   \n",
       "73263     1     0      0          1     1      0         1          0   \n",
       "73264     0     1      1          0     0      1         0          0   \n",
       "73265     1     0      0          1     0      1         0          0   \n",
       "73266     0     0      1          0     0      0         0          0   \n",
       "\n",
       "                                                                            \\\n",
       "      DigitalOcean Firebase Google Cloud Heroku IBM Cloud or Watson Linode   \n",
       "2                0        0            0      0                   0      0   \n",
       "3                0        0            0      0                   0      0   \n",
       "9                1        1            0      0                   0      0   \n",
       "10               0        0            0      0                   0      0   \n",
       "12               0        0            0      0                   0      0   \n",
       "...            ...      ...          ...    ...                 ...    ...   \n",
       "73262            0        0            0      0                   0      0   \n",
       "73263            1        0            1      0                   0      0   \n",
       "73264            0        0            0      0                   0      0   \n",
       "73265            0        1            0      0                   0      1   \n",
       "73266            0        0            0      0                   0      0   \n",
       "\n",
       "                                                     \\\n",
       "      Managed Hosting Microsoft Azure OVH OpenStack   \n",
       "2                   0               0   0         0   \n",
       "3                   0               0   0         0   \n",
       "9                   0               0   0         0   \n",
       "10                  0               1   0         0   \n",
       "12                  0               0   0         0   \n",
       "...               ...             ...  ..       ...   \n",
       "73262               0               0   0         0   \n",
       "73263               0               0   0         0   \n",
       "73264               0               0   0         0   \n",
       "73265               1               1   0         0   \n",
       "73266               0               0   0         0   \n",
       "\n",
       "                                         WebFrameworks                        \\\n",
       "      Oracle Cloud Infrastructure VMware       ASP.NET ASP.NET Core  Angular   \n",
       "2                               0      0             0             0       1   \n",
       "3                               0      0             1             1       0   \n",
       "9                               0      0             0             0       0   \n",
       "10                              0      0             1             1       0   \n",
       "12                              0      0             0             0       0   \n",
       "...                           ...    ...           ...           ...     ...   \n",
       "73262                           0      0             0             0       0   \n",
       "73263                           0      0             0             0       0   \n",
       "73264                           0      0             0             0       0   \n",
       "73265                           0      1             1             1       0   \n",
       "73266                           0      0             0             0       0   \n",
       "\n",
       "                                                                          \\\n",
       "      Angular.js Blazor Deno Django Drupal Express FastAPI Fastify Flask   \n",
       "2              1      0    0      0      0       0       0       0     0   \n",
       "3              0      0    0      0      0       0       0       0     0   \n",
       "9              0      0    0      0      0       0       0       0     0   \n",
       "10             0      1    0      0      0       0       0       0     0   \n",
       "12             0      0    0      0      0       0       0       0     0   \n",
       "...          ...    ...  ...    ...    ...     ...     ...     ...   ...   \n",
       "73262          0      0    0      0      0       0       0       0     0   \n",
       "73263          0      0    0      0      0       1       1       0     0   \n",
       "73264          0      0    0      0      0       0       1       0     1   \n",
       "73265          0      1    0      0      0       0       0       0     0   \n",
       "73266          0      0    0      0      0       0       0       0     0   \n",
       "\n",
       "                                                                              \\\n",
       "      Gatsby Laravel Next.js Node.js Nuxt.js Phoenix Play Framework React.js   \n",
       "2          0       0       0       0       0       0              0        0   \n",
       "3          0       0       0       0       0       0              0        0   \n",
       "9          0       0       0       0       0       0              0        0   \n",
       "10         0       0       0       0       0       0              0        0   \n",
       "12         0       0       0       0       0       0              0        1   \n",
       "...      ...     ...     ...     ...     ...     ...            ...      ...   \n",
       "73262      0       0       0       1       0       0              0        0   \n",
       "73263      0       0       0       1       0       0              0        0   \n",
       "73264      0       0       0       0       0       0              0        1   \n",
       "73265      0       1       1       0       0       0              0        1   \n",
       "73266      0       0       0       0       0       0              0        0   \n",
       "\n",
       "                                                 MiscTech               \\\n",
       "      Ruby on Rails Svelte Symfony Vue.js jQuery     .NET Apache Kafka   \n",
       "2                 0      0       0      0      0        1            0   \n",
       "3                 0      0       0      0      0        1            0   \n",
       "9                 0      0       0      0      0        0            0   \n",
       "10                0      0       0      1      0        1            0   \n",
       "12                0      0       0      0      0        0            0   \n",
       "...             ...    ...     ...    ...    ...      ...          ...   \n",
       "73262             0      0       0      0      0        0            0   \n",
       "73263             0      0       0      0      0        0            0   \n",
       "73264             0      0       0      0      0        0            0   \n",
       "73265             0      1       0      0      0        1            0   \n",
       "73266             0      0       0      0      0        0            0   \n",
       "\n",
       "                                                                  \\\n",
       "      Apache Spark Capacitor Cordova Electron Flutter GTK Hadoop   \n",
       "2                0         0       0        0       0   0      0   \n",
       "3                0         0       0        0       0   0      0   \n",
       "9                0         0       0        0       0   0      0   \n",
       "10               0         0       0        0       0   0      0   \n",
       "12               0         0       0        0       0   0      0   \n",
       "...            ...       ...     ...      ...     ...  ..    ...   \n",
       "73262            0         0       0        0       0   0      0   \n",
       "73263            0         0       0        0       1   0      0   \n",
       "73264            0         0       0        0       0   0      0   \n",
       "73265            0         0       1        0       0   0      0   \n",
       "73266            0         0       0        0       0   0      0   \n",
       "\n",
       "                                                                          \\\n",
       "      Hugging Face Transformers Ionic Keras NumPy Pandas Qt React Native   \n",
       "2                             0     0     0     0      1  0            0   \n",
       "3                             0     0     0     0      0  0            0   \n",
       "9                             0     0     0     0      0  0            0   \n",
       "10                            0     0     0     0      0  0            0   \n",
       "12                            0     0     0     0      0  0            0   \n",
       "...                         ...   ...   ...   ...    ... ..          ...   \n",
       "73262                         0     0     0     0      0  0            0   \n",
       "73263                         0     0     0     0      0  0            0   \n",
       "73264                         1     0     1     1      1  0            0   \n",
       "73265                         0     1     0     0      1  0            1   \n",
       "73266                         0     0     0     0      0  0            0   \n",
       "\n",
       "                                                                           \\\n",
       "      Scikit-learn Spring TensorFlow Tidyverse Torch/PyTorch Uno Platform   \n",
       "2                0      0          0         0             0            0   \n",
       "3                0      0          0         0             0            0   \n",
       "9                0      0          0         0             0            0   \n",
       "10               0      0          0         0             0            0   \n",
       "12               0      0          0         0             1            0   \n",
       "...            ...    ...        ...       ...           ...          ...   \n",
       "73262            0      0          0         0             0            0   \n",
       "73263            0      0          0         0             0            0   \n",
       "73264            1      0          1         0             1            0   \n",
       "73265            0      0          0         0             0            0   \n",
       "73266            0      0          0         0             0            0   \n",
       "\n",
       "              ToolsTech                                                     \\\n",
       "      Xamarin   Ansible Chef Docker Flow Homebrew Kubernetes Pulumi Puppet   \n",
       "2           0         0    0      0    0        0          0      0      0   \n",
       "3           0         0    0      0    0        0          0      0      0   \n",
       "9           0         0    0      0    0        0          0      0      0   \n",
       "10          0         0    0      1    0        0          0      0      0   \n",
       "12          0         0    0      1    0        0          0      0      0   \n",
       "...       ...       ...  ...    ...  ...      ...        ...    ...    ...   \n",
       "73262       0         0    0      0    0        0          0      0      0   \n",
       "73263       0         0    0      1    0        1          1      0      0   \n",
       "73264       0         0    0      0    0        0          0      0      0   \n",
       "73265       1         0    0      0    0        0          0      0      0   \n",
       "73266       0         0    0      0    0        0          0      0      0   \n",
       "\n",
       "                                                   CollabTools             \\\n",
       "      Terraform Unity 3D Unreal Engine Yarn npm Android Studio Atom CLion   \n",
       "2             0        0             0    0   0              0    0     0   \n",
       "3             0        0             0    0   0              0    0     0   \n",
       "9             0        0             0    0   0              1    0     0   \n",
       "10            1        0             0    0   1              0    0     0   \n",
       "12            0        0             0    0   0              0    0     0   \n",
       "...         ...      ...           ...  ...  ..            ...  ...   ...   \n",
       "73262         0        0             0    0   1              1    0     0   \n",
       "73263         0        0             0    0   1              0    0     0   \n",
       "73264         0        0             0    0   0              0    0     0   \n",
       "73265         0        0             1    0   1              0    0     0   \n",
       "73266         0        0             0    0   0              0    0     0   \n",
       "\n",
       "                                                                          \\\n",
       "      Eclipse Emacs GoLand IPython/Jupyter IntelliJ Nano Neovim NetBeans   \n",
       "2           0     0      0               0        0    0      0        0   \n",
       "3           0     0      0               0        0    0      0        0   \n",
       "9           0     0      0               0        0    0      0        0   \n",
       "10          0     0      0               0        0    0      0        0   \n",
       "12          0     0      0               0        0    0      0        0   \n",
       "...       ...   ...    ...             ...      ...  ...    ...      ...   \n",
       "73262       1     0      0               0        0    0      0        0   \n",
       "73263       0     0      0               1        0    0      0        0   \n",
       "73264       0     0      0               1        0    0      0        0   \n",
       "73265       0     0      0               0        0    0      0        0   \n",
       "73266       0     0      0               0        0    0      0        0   \n",
       "\n",
       "                                                                              \\\n",
       "      Notepad++ PhpStorm PyCharm Qt Creator RAD Studio (Delphi, C++ Builder)   \n",
       "2             1        0       0          0                                0   \n",
       "3             1        0       0          0                                0   \n",
       "9             0        0       0          0                                1   \n",
       "10            0        0       0          0                                0   \n",
       "12            0        0       0          0                                0   \n",
       "...         ...      ...     ...        ...                              ...   \n",
       "73262         0        0       0          0                                0   \n",
       "73263         0        0       0          0                                0   \n",
       "73264         1        0       0          0                                0   \n",
       "73265         0        0       0          0                                0   \n",
       "73266         0        0       0          0                                1   \n",
       "\n",
       "                                                                             \\\n",
       "      RStudio Rider RubyMine Spyder Sublime Text TextMate Vim Visual Studio   \n",
       "2           0     0        0      0            0        0   0             1   \n",
       "3           0     0        0      0            0        0   0             1   \n",
       "9           0     0        0      0            0        0   0             0   \n",
       "10          0     1        0      0            0        0   0             1   \n",
       "12          0     0        0      0            0        0   1             1   \n",
       "...       ...   ...      ...    ...          ...      ...  ..           ...   \n",
       "73262       0     0        0      0            0        0   0             0   \n",
       "73263       0     0        0      0            1        0   1             0   \n",
       "73264       0     0        0      1            0        0   1             0   \n",
       "73265       0     0        0      1            0        0   0             1   \n",
       "73266       0     0        0      0            0        0   0             1   \n",
       "\n",
       "                                        Skills_Clusters                 \\\n",
       "      Visual Studio Code Webstorm Xcode  skills_group_0 skills_group_1   \n",
       "2                      0        0     0               1              0   \n",
       "3                      1        0     0               0              0   \n",
       "9                      1        0     1               0              0   \n",
       "10                     1        0     0               0              0   \n",
       "12                     0        0     0               1              0   \n",
       "...                  ...      ...   ...             ...            ...   \n",
       "73262                  1        0     0               0              0   \n",
       "73263                  1        0     0               1              2   \n",
       "73264                  1        0     0               9              0   \n",
       "73265                  1        0     0               2              4   \n",
       "73266                  0        0     0               0              0   \n",
       "\n",
       "                                                                       \\\n",
       "      skills_group_10 skills_group_11 skills_group_12 skills_group_13   \n",
       "2                   0               3               0               1   \n",
       "3                   0               3               0               0   \n",
       "9                   0               1               2               0   \n",
       "10                  0               4               0               0   \n",
       "12                  0               3               1               1   \n",
       "...               ...             ...             ...             ...   \n",
       "73262               0               3               0               3   \n",
       "73263               0               4               1               0   \n",
       "73264               1               4               0               0   \n",
       "73265               0               5               0               0   \n",
       "73266               1               0               0               0   \n",
       "\n",
       "                                                                       \\\n",
       "      skills_group_14 skills_group_15 skills_group_16 skills_group_17   \n",
       "2                   1               0               0               0   \n",
       "3                   1               0               0               0   \n",
       "9                   1               0               0               0   \n",
       "10                  3               0               0               0   \n",
       "12                  2               1               0               1   \n",
       "...               ...             ...             ...             ...   \n",
       "73262               1               0               1               0   \n",
       "73263               3               0               1               0   \n",
       "73264               1               0               0               0   \n",
       "73265               1               0               0               0   \n",
       "73266               0               0               0               0   \n",
       "\n",
       "                                                                      \\\n",
       "      skills_group_18 skills_group_19 skills_group_2 skills_group_20   \n",
       "2                   0               0              0               0   \n",
       "3                   0               0              0               0   \n",
       "9                   0               0              0               0   \n",
       "10                  0               0              0               0   \n",
       "12                  0               0              0               0   \n",
       "...               ...             ...            ...             ...   \n",
       "73262               0               0              0               0   \n",
       "73263               0               0              0               0   \n",
       "73264               0               0              1               0   \n",
       "73265               1               2              0               1   \n",
       "73266               0               0              0               0   \n",
       "\n",
       "                                                                       \\\n",
       "      skills_group_21 skills_group_22 skills_group_23 skills_group_24   \n",
       "2                   0               0               0               1   \n",
       "3                   0               0               0               0   \n",
       "9                   2               0               0               0   \n",
       "10                  0               0               1               0   \n",
       "12                  0               0               1               0   \n",
       "...               ...             ...             ...             ...   \n",
       "73262               0               0               0               0   \n",
       "73263               0               0               2               2   \n",
       "73264               0               0               0               3   \n",
       "73265               0               0               0               1   \n",
       "73266               3               0               0               0   \n",
       "\n",
       "                                                                       \\\n",
       "      skills_group_25 skills_group_26 skills_group_27 skills_group_28   \n",
       "2                   0               0               0               0   \n",
       "3                   0               0               0               0   \n",
       "9                   0               1               0               0   \n",
       "10                  0               0               0               0   \n",
       "12                  0               0               0               0   \n",
       "...               ...             ...             ...             ...   \n",
       "73262               0               0               0               1   \n",
       "73263               0               1               0               2   \n",
       "73264               0               0               0               1   \n",
       "73265               1               1               0               1   \n",
       "73266               0               0               0               1   \n",
       "\n",
       "                                                                      \\\n",
       "      skills_group_29 skills_group_3 skills_group_30 skills_group_31   \n",
       "2                   0              0               0               0   \n",
       "3                   0              0               0               0   \n",
       "9                   1              0               0               1   \n",
       "10                  0              0               0               0   \n",
       "12                  0              0               0               0   \n",
       "...               ...            ...             ...             ...   \n",
       "73262               1              0               0               0   \n",
       "73263               0              0               0               0   \n",
       "73264               0              0               0               0   \n",
       "73265               0              2               0               1   \n",
       "73266               0              0               0               0   \n",
       "\n",
       "                                                                       \\\n",
       "      skills_group_32 skills_group_33 skills_group_34 skills_group_35   \n",
       "2                   0               0               2               0   \n",
       "3                   0               0               0               0   \n",
       "9                   0               0               0               0   \n",
       "10                  1               1               0               0   \n",
       "12                  0               1               0               3   \n",
       "...               ...             ...             ...             ...   \n",
       "73262               0               0               0               0   \n",
       "73263               0               2               0               3   \n",
       "73264               0               2               0               1   \n",
       "73265               0               0               0               1   \n",
       "73266               0               0               0               0   \n",
       "\n",
       "                                                                     \\\n",
       "      skills_group_36 skills_group_37 skills_group_4 skills_group_5   \n",
       "2                   0               0              3              2   \n",
       "3                   0               0              5              3   \n",
       "9                   0               0              0              0   \n",
       "10                  0               1              7              4   \n",
       "12                  0               0              1              1   \n",
       "...               ...             ...            ...            ...   \n",
       "73262               0               0              0              0   \n",
       "73263               0               1              0              1   \n",
       "73264               0               0              0              2   \n",
       "73265               0               0              7              3   \n",
       "73266               0               0              2              2   \n",
       "\n",
       "                                                                   \n",
       "      skills_group_6 skills_group_7 skills_group_8 skills_group_9  \n",
       "2                  0              0              0              0  \n",
       "3                  0              0              0              0  \n",
       "9                  0              1              0              0  \n",
       "10                 0              0              0              0  \n",
       "12                 0              0              0              0  \n",
       "...              ...            ...            ...            ...  \n",
       "73262              0              1              0              0  \n",
       "73263              0              2              0              0  \n",
       "73264              0              1              0              0  \n",
       "73265              0              1              0              0  \n",
       "73266              0              0              0              0  \n",
       "\n",
       "[42246 rows x 221 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52187dcd-5537-48f9-bd88-92467bdc88a8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create a Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "456e9c3f-1dd0-4f03-bcba-702746ff49aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = df.drop(df[TECH_JOBS],axis = 1).droplevel(0,axis=1).copy()\n",
    "y = df[TECH_JOBS].droplevel(0,axis = 1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91689354-70c2-435d-b47a-cdf6272d18fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We will split using traditional train_test_split because we are dealing with multilabel data\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y,test_size=0.20,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc54c52e-8d70-4e11-8df4-f99ae2e240ce",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Deal with Imbalanced Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c84cf9-bd58-4304-8fdf-a19f3e7eb66e",
   "metadata": {},
   "source": [
    "- **To deal with imbalance, I tried different methods to see which one performs the best**\n",
    "    - **Didn't apply any modifications to the Dataset both as multilabel or as multiclass.**\n",
    "    - **SMOTE by converting the Dataset to multiclass insted of mutilabel by taking rows that have only 1 value.**\n",
    "    - **Using random sample method by pandas that returns random samples to try to balance the dataset.** `Best Performer`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9529b49d-3acf-43d7-8a68-f34d81408ff6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1-Random Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f36d07fe-80b2-4f1b-b956-debfe08b7760",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Blockchain                                         447\n",
       "Security professional                              485\n",
       "Developer, game or graphics                        640\n",
       "Scientist                                          736\n",
       "Developer, QA or test                              807\n",
       "Database administrator                             831\n",
       "Data or business analyst                          1009\n",
       "System administrator                              1170\n",
       "Academic researcher                               1243\n",
       "Engineer, data                                    1329\n",
       "Developer, embedded applications or devices       1484\n",
       "Data scientist or machine learning specialist     1546\n",
       "Cloud infrastructure engineer                     1655\n",
       "DevOps specialist                                 1985\n",
       "Developer, mobile                                 2994\n",
       "Developer, desktop or enterprise applications     3452\n",
       "Developer, front-end                              6392\n",
       "Developer, back-end                              12785\n",
       "Developer, full-stack                            14183\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.sum(axis=0).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f3bb8d1-6760-411e-b32a-d8d7884f92c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DownSample majority classes and OverSample minority Classes of training set\n",
    "samples_per_class = 600\n",
    "resampled_jobs = []\n",
    "\n",
    "for job in y_train.columns:\n",
    "    sub_df = y_train.loc[y_train[job] == 1].copy()\n",
    "    \n",
    "    if len(sub_df) < samples_per_class:\n",
    "        # Upsample\n",
    "        sub_df = sub_df.sample(samples_per_class, replace=True, random_state=42)\n",
    "    else:\n",
    "        # Downsample\n",
    "        sub_df = sub_df.sample(samples_per_class, random_state=42) \n",
    "    \n",
    "    resampled_jobs.append(sub_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70dd4b2f-4bac-48a7-933c-7ae6d502507b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Blockchain                                        700\n",
       "Developer, game or graphics                       747\n",
       "Security professional                             757\n",
       "Developer, QA or test                             770\n",
       "Database administrator                            888\n",
       "Developer, embedded applications or devices       960\n",
       "Scientist                                         980\n",
       "Data or business analyst                          982\n",
       "Developer, mobile                                1035\n",
       "Engineer, data                                   1036\n",
       "System administrator                             1061\n",
       "Cloud infrastructure engineer                    1134\n",
       "Academic researcher                              1219\n",
       "Data scientist or machine learning specialist    1227\n",
       "DevOps specialist                                1265\n",
       "Developer, front-end                             1365\n",
       "Developer, desktop or enterprise applications    1445\n",
       "Developer, full-stack                            3117\n",
       "Developer, back-end                              3405\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = pd.concat(resampled_jobs)\n",
    "x_train = x_train.loc[y_train.index].copy()\n",
    "y_train.sum(axis=0).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3237488-3bb8-416b-b43c-cfce73593814",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DownSample majority classes and OverSample minority Classes of training set\n",
    "samples_per_class = 300\n",
    "resampled_jobs = []\n",
    "\n",
    "for job in y_test.columns:\n",
    "    sub_df = y_test.loc[y_test[job] == 1].copy()\n",
    "    \n",
    "    if len(sub_df) < samples_per_class:\n",
    "        # Upsample\n",
    "        sub_df = sub_df.sample(samples_per_class, replace=True, random_state=42)\n",
    "    else:\n",
    "        # Downsample\n",
    "        sub_df = sub_df.sample(samples_per_class, random_state=42) \n",
    "    \n",
    "    resampled_jobs.append(sub_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a446c4b-8181-4608-957b-686eb15d2529",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Blockchain                                        366\n",
       "Developer, game or graphics                       372\n",
       "Security professional                             392\n",
       "Developer, QA or test                             400\n",
       "Developer, embedded applications or devices       437\n",
       "Database administrator                            462\n",
       "Scientist                                         470\n",
       "Data or business analyst                          491\n",
       "Developer, mobile                                 505\n",
       "Engineer, data                                    527\n",
       "System administrator                              543\n",
       "Cloud infrastructure engineer                     593\n",
       "Data scientist or machine learning specialist     609\n",
       "DevOps specialist                                 616\n",
       "Academic researcher                               629\n",
       "Developer, front-end                              680\n",
       "Developer, desktop or enterprise applications     742\n",
       "Developer, full-stack                            1531\n",
       "Developer, back-end                              1537\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = pd.concat(resampled_jobs)\n",
    "x_test = x_test.loc[y_test.index].copy()\n",
    "y_test.sum(axis=0).sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641ed3a9-09f3-4e22-ac2d-eeb6d5f92165",
   "metadata": {},
   "source": [
    "### 2- MultiClass with SMOTE"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2dc7da9e-a3d1-477c-8ced-4449b939f14d",
   "metadata": {
    "tags": []
   },
   "source": [
    "one_job_df = df[df['Techjobs'].sum(axis=1) ==1]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3853fcdd-21b4-4dee-8a22-3f4200a167d7",
   "metadata": {
    "tags": []
   },
   "source": [
    "one_job_df[TECH_JOBS].sum(axis=0).sort_values()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b1be3b91-e571-488b-b0b0-3f89a9cc4910",
   "metadata": {
    "tags": []
   },
   "source": [
    "X = one_job_df.drop(one_job_df[TECH_JOBS],axis = 1).droplevel(0,axis=1).reset_index(drop=True)\n",
    "y = one_job_df[TECH_JOBS].droplevel(0,axis = 1).copy()\n",
    "y = pd.from_dummies(y)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "51b1312a-e0fd-4bec-b5c7-589150d6d09b",
   "metadata": {
    "tags": []
   },
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "# Create StratifiedKFold object.\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    x_train, x_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7320a1cd-8f26-433f-8bcd-acae093329fc",
   "metadata": {
    "tags": []
   },
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6227e701-ac01-45c3-b7b7-b2b3a5286faf",
   "metadata": {
    "tags": []
   },
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dfa26f32-d5bc-4936-8f6c-1fa5d6438515",
   "metadata": {
    "tags": []
   },
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "over = SMOTE(random_state=42, k_neighbors=5)\n",
    "under= RandomUnderSampler(random_state=42 ,sampling_strategy={'Developer, full-stack':1000,'Developer, back-end':1000,'Developer, front-end':1000,'Developer, mobile':1000})\n",
    "x_under, y_under= under.fit_resample(x_train, y_train)\n",
    "x_over, y_over = over.fit_resample(x_under, y_under)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "affadf2e-6a21-47f8-9c6b-0ca3aa74bd1e",
   "metadata": {
    "tags": []
   },
   "source": [
    "y_over.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f7d168-c648-4a29-a9d9-4e56a951ebe2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Intialize MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a0716b2-2897-4136-acd0-8c39e16d4fcf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create Directories\n",
    "Path(MLFLOW_TRACKING_URI).mkdir(parents=True, exist_ok=True)\n",
    "Path(LOG_PATH).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2acd1b21-0876-4bf8-9d0c-4e3f795a9226",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize client and experiment\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "client = MlflowClient()\n",
    "mlflow.set_experiment(MLFLOW_EXPERIMENT_NAME)\n",
    "exp = client.get_experiment_by_name(MLFLOW_EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413ed77a-59a6-4187-927c-ffc4bd28497f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Create a Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c2b0d967-8f29-41df-b4a2-06f57582e5a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),\n",
       "                (&#x27;multioutputclassifier&#x27;,\n",
       "                 MultiOutputClassifier(estimator=LogisticRegression(max_iter=1000)))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),\n",
       "                (&#x27;multioutputclassifier&#x27;,\n",
       "                 MultiOutputClassifier(estimator=LogisticRegression(max_iter=1000)))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">multioutputclassifier: MultiOutputClassifier</label><div class=\"sk-toggleable__content\"><pre>MultiOutputClassifier(estimator=LogisticRegression(max_iter=1000))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('multioutputclassifier',\n",
       "                 MultiOutputClassifier(estimator=LogisticRegression(max_iter=1000)))])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a Logistic Regression Classifier, Used StandardScaler because logistic Regression uses l2 regression by default\n",
    "log_clf = make_pipeline(StandardScaler(),\n",
    "                    MultiOutputClassifier(LogisticRegression(max_iter=1000)))\n",
    "log_clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe68e04-4f72-4085-a57a-bb7060d2e475",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Evaluating the multilabel dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "959e35f5-e1a0-4868-b954-58b9c1ee6f07",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score     90.765263\n",
      "precision_score    78.838947\n",
      "recall_score       63.910526\n",
      "f1_score           67.053684\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Developer, back-end</th>\n",
       "      <td>75.00</td>\n",
       "      <td>70.70</td>\n",
       "      <td>64.08</td>\n",
       "      <td>65.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Database administrator</th>\n",
       "      <td>92.24</td>\n",
       "      <td>71.95</td>\n",
       "      <td>53.31</td>\n",
       "      <td>54.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Security professional</th>\n",
       "      <td>93.38</td>\n",
       "      <td>72.33</td>\n",
       "      <td>53.81</td>\n",
       "      <td>55.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, full-stack</th>\n",
       "      <td>79.43</td>\n",
       "      <td>74.45</td>\n",
       "      <td>70.84</td>\n",
       "      <td>72.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>System administrator</th>\n",
       "      <td>91.23</td>\n",
       "      <td>76.57</td>\n",
       "      <td>57.36</td>\n",
       "      <td>60.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Engineer, data</th>\n",
       "      <td>91.65</td>\n",
       "      <td>77.65</td>\n",
       "      <td>59.35</td>\n",
       "      <td>62.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, desktop or enterprise applications</th>\n",
       "      <td>88.72</td>\n",
       "      <td>77.82</td>\n",
       "      <td>60.56</td>\n",
       "      <td>63.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data or business analyst</th>\n",
       "      <td>92.31</td>\n",
       "      <td>78.67</td>\n",
       "      <td>61.53</td>\n",
       "      <td>65.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DevOps specialist</th>\n",
       "      <td>90.57</td>\n",
       "      <td>78.91</td>\n",
       "      <td>64.57</td>\n",
       "      <td>68.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, embedded applications or devices</th>\n",
       "      <td>92.67</td>\n",
       "      <td>78.92</td>\n",
       "      <td>63.98</td>\n",
       "      <td>68.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cloud infrastructure engineer</th>\n",
       "      <td>91.65</td>\n",
       "      <td>79.25</td>\n",
       "      <td>66.03</td>\n",
       "      <td>70.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, QA or test</th>\n",
       "      <td>93.26</td>\n",
       "      <td>79.97</td>\n",
       "      <td>50.25</td>\n",
       "      <td>48.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scientist</th>\n",
       "      <td>92.89</td>\n",
       "      <td>80.78</td>\n",
       "      <td>65.83</td>\n",
       "      <td>70.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, front-end</th>\n",
       "      <td>90.51</td>\n",
       "      <td>81.09</td>\n",
       "      <td>66.89</td>\n",
       "      <td>71.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Academic researcher</th>\n",
       "      <td>91.50</td>\n",
       "      <td>81.28</td>\n",
       "      <td>67.15</td>\n",
       "      <td>71.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data scientist or machine learning specialist</th>\n",
       "      <td>92.38</td>\n",
       "      <td>81.97</td>\n",
       "      <td>74.55</td>\n",
       "      <td>77.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blockchain</th>\n",
       "      <td>94.89</td>\n",
       "      <td>82.21</td>\n",
       "      <td>64.83</td>\n",
       "      <td>69.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, game or graphics</th>\n",
       "      <td>95.22</td>\n",
       "      <td>85.09</td>\n",
       "      <td>70.24</td>\n",
       "      <td>75.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, mobile</th>\n",
       "      <td>95.04</td>\n",
       "      <td>88.33</td>\n",
       "      <td>79.14</td>\n",
       "      <td>82.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               accuracy_score  \\\n",
       "Developer, back-end                                     75.00   \n",
       "Database administrator                                  92.24   \n",
       "Security professional                                   93.38   \n",
       "Developer, full-stack                                   79.43   \n",
       "System administrator                                    91.23   \n",
       "Engineer, data                                          91.65   \n",
       "Developer, desktop or enterprise applications           88.72   \n",
       "Data or business analyst                                92.31   \n",
       "DevOps specialist                                       90.57   \n",
       "Developer, embedded applications or devices             92.67   \n",
       "Cloud infrastructure engineer                           91.65   \n",
       "Developer, QA or test                                   93.26   \n",
       "Scientist                                               92.89   \n",
       "Developer, front-end                                    90.51   \n",
       "Academic researcher                                     91.50   \n",
       "Data scientist or machine learning specialist           92.38   \n",
       "Blockchain                                              94.89   \n",
       "Developer, game or graphics                             95.22   \n",
       "Developer, mobile                                       95.04   \n",
       "\n",
       "                                               precision_score  recall_score  \\\n",
       "Developer, back-end                                      70.70         64.08   \n",
       "Database administrator                                   71.95         53.31   \n",
       "Security professional                                    72.33         53.81   \n",
       "Developer, full-stack                                    74.45         70.84   \n",
       "System administrator                                     76.57         57.36   \n",
       "Engineer, data                                           77.65         59.35   \n",
       "Developer, desktop or enterprise applications            77.82         60.56   \n",
       "Data or business analyst                                 78.67         61.53   \n",
       "DevOps specialist                                        78.91         64.57   \n",
       "Developer, embedded applications or devices              78.92         63.98   \n",
       "Cloud infrastructure engineer                            79.25         66.03   \n",
       "Developer, QA or test                                    79.97         50.25   \n",
       "Scientist                                                80.78         65.83   \n",
       "Developer, front-end                                     81.09         66.89   \n",
       "Academic researcher                                      81.28         67.15   \n",
       "Data scientist or machine learning specialist            81.97         74.55   \n",
       "Blockchain                                               82.21         64.83   \n",
       "Developer, game or graphics                              85.09         70.24   \n",
       "Developer, mobile                                        88.33         79.14   \n",
       "\n",
       "                                               f1_score  \n",
       "Developer, back-end                               65.27  \n",
       "Database administrator                            54.29  \n",
       "Security professional                             55.33  \n",
       "Developer, full-stack                             72.18  \n",
       "System administrator                              60.19  \n",
       "Engineer, data                                    62.88  \n",
       "Developer, desktop or enterprise applications     63.87  \n",
       "Data or business analyst                          65.59  \n",
       "DevOps specialist                                 68.58  \n",
       "Developer, embedded applications or devices       68.23  \n",
       "Cloud infrastructure engineer                     70.13  \n",
       "Developer, QA or test                             48.77  \n",
       "Scientist                                         70.34  \n",
       "Developer, front-end                              71.13  \n",
       "Academic researcher                               71.51  \n",
       "Data scientist or machine learning specialist     77.60  \n",
       "Blockchain                                        69.83  \n",
       "Developer, game or graphics                       75.35  \n",
       "Developer, mobile                                 82.95  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics=[accuracy_score, precision_score, recall_score, f1_score]\n",
    "train_scores, mean_train_score= calculate_metrics(log_clf,x_train,y_train, metrics)\n",
    "\n",
    "print(mean_train_score)\n",
    "train_scores.sort_values(\"precision_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "23983855-a229-4a85-8725-9d7fa2587e53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cross_validate the baseline model on the accuracy, precision, recall and f1\n",
    "log_clf_scores = cross_validate(log_clf,x_train,y_train, cv=5, scoring =calculate_scores_multi_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4c0d23c7-0449-454a-b182-db0bf71ba15e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_accuracy': 89.21,\n",
       " 'test_precision': 67.04,\n",
       " 'test_recall': 61.54,\n",
       " 'test_f1': 61.12}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = ['test_accuracy', 'test_precision','test_recall', 'test_f1']\n",
    "validation_scores = {}\n",
    "for score in scores:\n",
    "    validation_scores[score] = round(log_clf_scores[score].mean(), 2)\n",
    "validation_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7d4998-4a31-42f9-b82c-e6135b04bb99",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Evaluating the multiclass Dataset"
   ]
  },
  {
   "cell_type": "raw",
   "id": "30636f5f-d84e-4d42-8279-c39497262d98",
   "metadata": {
    "tags": []
   },
   "source": [
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_train, predictions))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9b72fdc8-8fcb-4e68-8ccb-a60dade5c1a9",
   "metadata": {
    "tags": []
   },
   "source": [
    "y_train_pred = cross_val_predict(log_clf, x_train, y_train, cv=3)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "279c5eef-2fa9-4fa2-8de3-944a6c7212db",
   "metadata": {
    "tags": []
   },
   "source": [
    "fig, ax = plt.subplots(figsize=(15,10))\n",
    "cmp = ConfusionMatrixDisplay.from_predictions(y_train, predictions,normalize=\"true\", values_format=\".0%\",xticks_rotation=90,ax=ax)\n",
    "plt.rc('font', size=12)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "21c7c373-7f3d-4ae9-8c28-f52980f24f97",
   "metadata": {
    "tags": []
   },
   "source": [
    "# cross_validate the baseline model on the accuracy, precision, recall and f1\n",
    "log_clf_scores = cross_validate(log_clf,x_train,y_train, cv=4, scoring =calculate_scores)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b85f82cb-cc12-42db-8351-9f0b93efd876",
   "metadata": {
    "tags": []
   },
   "source": [
    "scores = ['test_accuracy', 'test_precision','test_recall', 'test_f1']\n",
    "validation_scores = {}\n",
    "for score in scores:\n",
    "    validation_scores[score] = round(log_clf_scores[score].mean()* 100, 2)\n",
    "validation_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11fcaa54-0d6c-435d-adf6-1a66e27a3821",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Log Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "78296fa5-7917-42a4-b861-6317d618932d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Log the model's dataset train and test indices\n",
    "log_data(x_train,y_train,x_test,y_test)\n",
    "# Log the model, model description\n",
    "model = log_model(log_clf,'Baseline model: Logistic Regression, multilabel, Data Resampled ')\n",
    "# Log the model's train and test scores\n",
    "log_metrics(train_scores, validation_scores)\n",
    "# track the model artifacts, validation scores with mlflow\n",
    "track_model(model,validation_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a089c091-e3b4-4e85-bd03-a44b42df1992",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c3313a9a-bd04-4a95-bbb7-13a1fdadb8a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    3.1s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;randomforestclassifier&#x27;,\n",
       "                 RandomForestClassifier(n_jobs=-1, random_state=42,\n",
       "                                        verbose=1))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;randomforestclassifier&#x27;,\n",
       "                 RandomForestClassifier(n_jobs=-1, random_state=42,\n",
       "                                        verbose=1))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_jobs=-1, random_state=42, verbose=1)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('randomforestclassifier',\n",
       "                 RandomForestClassifier(n_jobs=-1, random_state=42,\n",
       "                                        verbose=1))])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a random forest classifier\n",
    "rf_clf = make_pipeline(#StandardScaler(),\n",
    "                       #PCA(n_components=0.95),\n",
    "                       RandomForestClassifier(n_jobs=-1,\n",
    "                                              verbose=1,\n",
    "                                              random_state=42))\n",
    "\n",
    "rf_clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73083653-d9c9-4c55-9ca0-c5e769eaf8d8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Evaluating the multilabel dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9a2b367d-d343-4072-85f4-180025ef02a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score     99.994737\n",
      "precision_score    99.993684\n",
      "recall_score       99.980000\n",
      "f1_score           99.985789\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Security professional</th>\n",
       "      <td>99.99</td>\n",
       "      <td>99.93</td>\n",
       "      <td>100.00</td>\n",
       "      <td>99.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, desktop or enterprise applications</th>\n",
       "      <td>99.98</td>\n",
       "      <td>99.96</td>\n",
       "      <td>99.96</td>\n",
       "      <td>99.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, back-end</th>\n",
       "      <td>99.99</td>\n",
       "      <td>99.99</td>\n",
       "      <td>99.99</td>\n",
       "      <td>99.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data scientist or machine learning specialist</th>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blockchain</th>\n",
       "      <td>99.99</td>\n",
       "      <td>100.00</td>\n",
       "      <td>99.93</td>\n",
       "      <td>99.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, front-end</th>\n",
       "      <td>99.99</td>\n",
       "      <td>100.00</td>\n",
       "      <td>99.96</td>\n",
       "      <td>99.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, game or graphics</th>\n",
       "      <td>99.99</td>\n",
       "      <td>100.00</td>\n",
       "      <td>99.93</td>\n",
       "      <td>99.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scientist</th>\n",
       "      <td>99.99</td>\n",
       "      <td>100.00</td>\n",
       "      <td>99.95</td>\n",
       "      <td>99.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>System administrator</th>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, QA or test</th>\n",
       "      <td>99.99</td>\n",
       "      <td>100.00</td>\n",
       "      <td>99.94</td>\n",
       "      <td>99.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, embedded applications or devices</th>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cloud infrastructure engineer</th>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, full-stack</th>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, mobile</th>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Database administrator</th>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data or business analyst</th>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Engineer, data</th>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DevOps specialist</th>\n",
       "      <td>99.99</td>\n",
       "      <td>100.00</td>\n",
       "      <td>99.96</td>\n",
       "      <td>99.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Academic researcher</th>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               accuracy_score  \\\n",
       "Security professional                                   99.99   \n",
       "Developer, desktop or enterprise applications           99.98   \n",
       "Developer, back-end                                     99.99   \n",
       "Data scientist or machine learning specialist          100.00   \n",
       "Blockchain                                              99.99   \n",
       "Developer, front-end                                    99.99   \n",
       "Developer, game or graphics                             99.99   \n",
       "Scientist                                               99.99   \n",
       "System administrator                                   100.00   \n",
       "Developer, QA or test                                   99.99   \n",
       "Developer, embedded applications or devices            100.00   \n",
       "Cloud infrastructure engineer                          100.00   \n",
       "Developer, full-stack                                  100.00   \n",
       "Developer, mobile                                      100.00   \n",
       "Database administrator                                 100.00   \n",
       "Data or business analyst                               100.00   \n",
       "Engineer, data                                         100.00   \n",
       "DevOps specialist                                       99.99   \n",
       "Academic researcher                                    100.00   \n",
       "\n",
       "                                               precision_score  recall_score  \\\n",
       "Security professional                                    99.93        100.00   \n",
       "Developer, desktop or enterprise applications            99.96         99.96   \n",
       "Developer, back-end                                      99.99         99.99   \n",
       "Data scientist or machine learning specialist           100.00        100.00   \n",
       "Blockchain                                              100.00         99.93   \n",
       "Developer, front-end                                    100.00         99.96   \n",
       "Developer, game or graphics                             100.00         99.93   \n",
       "Scientist                                               100.00         99.95   \n",
       "System administrator                                    100.00        100.00   \n",
       "Developer, QA or test                                   100.00         99.94   \n",
       "Developer, embedded applications or devices             100.00        100.00   \n",
       "Cloud infrastructure engineer                           100.00        100.00   \n",
       "Developer, full-stack                                   100.00        100.00   \n",
       "Developer, mobile                                       100.00        100.00   \n",
       "Database administrator                                  100.00        100.00   \n",
       "Data or business analyst                                100.00        100.00   \n",
       "Engineer, data                                          100.00        100.00   \n",
       "DevOps specialist                                       100.00         99.96   \n",
       "Academic researcher                                     100.00        100.00   \n",
       "\n",
       "                                               f1_score  \n",
       "Security professional                             99.96  \n",
       "Developer, desktop or enterprise applications     99.96  \n",
       "Developer, back-end                               99.99  \n",
       "Data scientist or machine learning specialist    100.00  \n",
       "Blockchain                                        99.96  \n",
       "Developer, front-end                              99.98  \n",
       "Developer, game or graphics                       99.96  \n",
       "Scientist                                         99.97  \n",
       "System administrator                             100.00  \n",
       "Developer, QA or test                             99.97  \n",
       "Developer, embedded applications or devices      100.00  \n",
       "Cloud infrastructure engineer                    100.00  \n",
       "Developer, full-stack                            100.00  \n",
       "Developer, mobile                                100.00  \n",
       "Database administrator                           100.00  \n",
       "Data or business analyst                         100.00  \n",
       "Engineer, data                                   100.00  \n",
       "DevOps specialist                                 99.98  \n",
       "Academic researcher                              100.00  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics=[accuracy_score, precision_score, recall_score, f1_score]\n",
    "train_scores, mean_train_scores= calculate_metrics(rf_clf,x_train,y_train, metrics)\n",
    "\n",
    "print(mean_train_scores)\n",
    "train_scores.sort_values(\"precision_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7ea7fa2d-d319-43c9-8d58-51211e882d96",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    5.7s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    2.5s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    2.5s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    2.5s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done  85 out of 100 | elapsed:    2.5s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    2.7s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.2s finished\n"
     ]
    }
   ],
   "source": [
    "# cross_validate the baseline model on the accuracy, precision, recall and f1\n",
    "rf_clf_scores = cross_validate(rf_clf,x_train,y_train, cv=5, scoring =calculate_scores_multi_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "60f412cd-13b9-49c5-bb6c-e2d926035f79",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_accuracy': 92.15,\n",
       " 'test_precision': 89.16,\n",
       " 'test_recall': 76.29,\n",
       " 'test_f1': 78.92}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = ['test_accuracy', 'test_precision','test_recall', 'test_f1']\n",
    "validation_scores = {}\n",
    "for score in scores:\n",
    "    validation_scores[score] = round(rf_clf_scores[score].mean(), 2)\n",
    "validation_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab07fc61-8005-4f78-bdb0-12b1a770d6ca",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Evaluating the multiclass Dataset"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1cc8faeb-89a4-4fef-980c-1bf2e25bb79b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# cross_validate the baseline model on the accuracy, precision, recall and f1\n",
    "rf_clf_scores = cross_validate(rf_clf,x_train,y_train, cv=4, scoring =calculate_scores)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "489d7fda-b338-42f9-8a1c-3dd1f35ca242",
   "metadata": {
    "tags": []
   },
   "source": [
    "scores = ['test_accuracy', 'test_precision','test_recall', 'test_f1']\n",
    "validation_scores = {}\n",
    "for score in scores:\n",
    "    validation_scores[score] = round(rf_clf_scores[score].mean()* 100, 2)\n",
    "validation_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08be589a-56b8-4afb-85cc-f6a099f27aee",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Log RandomForest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "faecb94d-80e5-4c33-b189-d8133ee5bfa6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Log the model's dataset train and test indices\n",
    "log_data(x_train,y_train,x_test,y_test)\n",
    "# Log the model, model description\n",
    "model = log_model(rf_clf,'Random Forest, multilabel, Data resampled')\n",
    "# Log the model's train and test scores\n",
    "log_metrics(train_scores, validation_scores)\n",
    "# track the model artifacts, validation scores with mlflow\n",
    "track_model(model,validation_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c0cf30-79e5-476e-a5a0-9a4b8d984f6a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6286b3d5-58e6-4cd9-a89a-942400bd0bbe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(random_state=42)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dec_clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "dec_clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8872ee16-c43c-4aca-be72-be55ab63b099",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Evaluating the multilabel dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1285304f-64ad-444f-a587-3372c61f0f96",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score     99.997368\n",
      "precision_score    99.995263\n",
      "recall_score       99.990526\n",
      "f1_score           99.992105\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Security professional</th>\n",
       "      <td>99.99</td>\n",
       "      <td>99.93</td>\n",
       "      <td>100.00</td>\n",
       "      <td>99.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, desktop or enterprise applications</th>\n",
       "      <td>99.99</td>\n",
       "      <td>99.99</td>\n",
       "      <td>99.97</td>\n",
       "      <td>99.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, back-end</th>\n",
       "      <td>99.99</td>\n",
       "      <td>99.99</td>\n",
       "      <td>99.99</td>\n",
       "      <td>99.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data scientist or machine learning specialist</th>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blockchain</th>\n",
       "      <td>99.99</td>\n",
       "      <td>100.00</td>\n",
       "      <td>99.93</td>\n",
       "      <td>99.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, front-end</th>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, game or graphics</th>\n",
       "      <td>99.99</td>\n",
       "      <td>100.00</td>\n",
       "      <td>99.93</td>\n",
       "      <td>99.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scientist</th>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>System administrator</th>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, QA or test</th>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, embedded applications or devices</th>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cloud infrastructure engineer</th>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, full-stack</th>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, mobile</th>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Database administrator</th>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data or business analyst</th>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Engineer, data</th>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DevOps specialist</th>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Academic researcher</th>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               accuracy_score  \\\n",
       "Security professional                                   99.99   \n",
       "Developer, desktop or enterprise applications           99.99   \n",
       "Developer, back-end                                     99.99   \n",
       "Data scientist or machine learning specialist          100.00   \n",
       "Blockchain                                              99.99   \n",
       "Developer, front-end                                   100.00   \n",
       "Developer, game or graphics                             99.99   \n",
       "Scientist                                              100.00   \n",
       "System administrator                                   100.00   \n",
       "Developer, QA or test                                  100.00   \n",
       "Developer, embedded applications or devices            100.00   \n",
       "Cloud infrastructure engineer                          100.00   \n",
       "Developer, full-stack                                  100.00   \n",
       "Developer, mobile                                      100.00   \n",
       "Database administrator                                 100.00   \n",
       "Data or business analyst                               100.00   \n",
       "Engineer, data                                         100.00   \n",
       "DevOps specialist                                      100.00   \n",
       "Academic researcher                                    100.00   \n",
       "\n",
       "                                               precision_score  recall_score  \\\n",
       "Security professional                                    99.93        100.00   \n",
       "Developer, desktop or enterprise applications            99.99         99.97   \n",
       "Developer, back-end                                      99.99         99.99   \n",
       "Data scientist or machine learning specialist           100.00        100.00   \n",
       "Blockchain                                              100.00         99.93   \n",
       "Developer, front-end                                    100.00        100.00   \n",
       "Developer, game or graphics                             100.00         99.93   \n",
       "Scientist                                               100.00        100.00   \n",
       "System administrator                                    100.00        100.00   \n",
       "Developer, QA or test                                   100.00        100.00   \n",
       "Developer, embedded applications or devices             100.00        100.00   \n",
       "Cloud infrastructure engineer                           100.00        100.00   \n",
       "Developer, full-stack                                   100.00        100.00   \n",
       "Developer, mobile                                       100.00        100.00   \n",
       "Database administrator                                  100.00        100.00   \n",
       "Data or business analyst                                100.00        100.00   \n",
       "Engineer, data                                          100.00        100.00   \n",
       "DevOps specialist                                       100.00        100.00   \n",
       "Academic researcher                                     100.00        100.00   \n",
       "\n",
       "                                               f1_score  \n",
       "Security professional                             99.96  \n",
       "Developer, desktop or enterprise applications     99.98  \n",
       "Developer, back-end                               99.99  \n",
       "Data scientist or machine learning specialist    100.00  \n",
       "Blockchain                                        99.96  \n",
       "Developer, front-end                             100.00  \n",
       "Developer, game or graphics                       99.96  \n",
       "Scientist                                        100.00  \n",
       "System administrator                             100.00  \n",
       "Developer, QA or test                            100.00  \n",
       "Developer, embedded applications or devices      100.00  \n",
       "Cloud infrastructure engineer                    100.00  \n",
       "Developer, full-stack                            100.00  \n",
       "Developer, mobile                                100.00  \n",
       "Database administrator                           100.00  \n",
       "Data or business analyst                         100.00  \n",
       "Engineer, data                                   100.00  \n",
       "DevOps specialist                                100.00  \n",
       "Academic researcher                              100.00  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics=[accuracy_score, precision_score, recall_score, f1_score]\n",
    "train_scores, mean_train_scores= calculate_metrics(dec_clf,x_train,y_train, metrics)\n",
    "\n",
    "print(mean_train_scores)\n",
    "train_scores.sort_values(\"precision_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "806d0077-4db9-44cc-ae01-8869a393691d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cross_validate the baseline model on the accuracy, precision, recall and f1\n",
    "dec_clf_scores = cross_validate(dec_clf,x_train,y_train, cv=5, scoring =calculate_scores_multi_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ea4dc513-b85f-49f9-b697-2e6d825e6b8b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_accuracy': 87.78,\n",
       " 'test_precision': 66.54,\n",
       " 'test_recall': 76.8,\n",
       " 'test_f1': 66.7}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = ['test_accuracy', 'test_precision','test_recall', 'test_f1']\n",
    "validation_scores = {}\n",
    "for score in scores:\n",
    "    validation_scores[score] = round(dec_clf_scores[score].mean(), 2)\n",
    "validation_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65361901-8a85-4865-b32b-6dbda4656295",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Log Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8f0c1e1c-9368-4276-8427-addc50cbac31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Log the model's dataset train and test indices\n",
    "log_data(x_train,y_train,x_test,y_test)\n",
    "# Log the model, model description\n",
    "model = log_model(dec_clf,'Decision Tree, multilabel, Data resampled')\n",
    "# Log the model's train and test scores\n",
    "log_metrics(train_scores, validation_scores)\n",
    "# track the model artifacts, validation scores with mlflow \n",
    "track_model(model,validation_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64ac9b1-87a5-40fe-b39e-1355517f9dda",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Evaluating the multiclass Dataset"
   ]
  },
  {
   "cell_type": "raw",
   "id": "474090ba-6ad1-48de-8094-6eacb76ebc1e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# cross_validate the baseline model on the accuracy, precision, recall and f1\n",
    "rf_clf_scores = cross_validate(dec_clf,x_train,y_train, cv=4, scoring =calculate_scores)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0ac6056e-d7ed-4aa5-b45f-019725e7c152",
   "metadata": {
    "tags": []
   },
   "source": [
    "scores = ['test_accuracy', 'test_precision','test_recall', 'test_f1']\n",
    "validation_scores = {}\n",
    "for score in scores:\n",
    "    validation_scores[score] = round(rf_clf_scores[score].mean()* 100, 2)\n",
    "validation_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b70d24-5714-46cf-a29a-6f9df5235005",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c49a5656-c618-439c-8235-4e4a71cfe306",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.6418            0.72s\n",
      "         2           0.6020            0.78s\n",
      "         3           0.5766            0.74s\n",
      "         4           0.5588            0.64s\n",
      "         5           0.5391            0.51s\n",
      "         6           0.5209            0.62s\n",
      "         7           0.5080            0.63s\n",
      "         8           0.4951            0.60s\n",
      "         9           0.4837            0.58s\n",
      "        10           0.4746            0.60s\n",
      "        20           0.4277            0.51s\n",
      "        30           0.4032            0.44s\n",
      "        40           0.3901            0.39s\n",
      "        50           0.3808            0.33s\n",
      "        60           0.3738            0.26s\n",
      "        70           0.3675            0.20s\n",
      "        80           0.3624            0.13s\n",
      "        90           0.3572            0.07s\n",
      "       100           0.3524            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.5917            0.60s\n",
      "         2           0.5817            0.74s\n",
      "         3           0.5729            0.55s\n",
      "         4           0.5627            0.72s\n",
      "         5           0.5570            0.77s\n",
      "         6           0.5487            0.74s\n",
      "         7           0.5418            0.71s\n",
      "         8           0.5388            0.70s\n",
      "         9           0.5306            0.68s\n",
      "        10           0.5265            0.69s\n",
      "        20           0.5012            0.60s\n",
      "        30           0.4832            0.53s\n",
      "        40           0.4729            0.46s\n",
      "        50           0.4622            0.38s\n",
      "        60           0.4546            0.31s\n",
      "        70           0.4486            0.24s\n",
      "        80           0.4436            0.16s\n",
      "        90           0.4385            0.08s\n",
      "       100           0.4340            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.5686            0.61s\n",
      "         2           0.5591            0.55s\n",
      "         3           0.5451            0.69s\n",
      "         4           0.5367            0.65s\n",
      "         5           0.5298            0.64s\n",
      "         6           0.5197            0.65s\n",
      "         7           0.5129            0.67s\n",
      "         8           0.5078            0.65s\n",
      "         9           0.5019            0.62s\n",
      "        10           0.4955            0.62s\n",
      "        20           0.4642            0.53s\n",
      "        30           0.4439            0.45s\n",
      "        40           0.4317            0.40s\n",
      "        50           0.4219            0.33s\n",
      "        60           0.4138            0.26s\n",
      "        70           0.4064            0.19s\n",
      "        80           0.4014            0.13s\n",
      "        90           0.3960            0.06s\n",
      "       100           0.3912            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.2065            0.61s\n",
      "         2           1.1948            0.48s\n",
      "         3           1.1871            0.64s\n",
      "         4           1.1811            0.48s\n",
      "         5           1.1750            0.62s\n",
      "         6           1.1668            0.60s\n",
      "         7           1.1600            0.53s\n",
      "         8           1.1534            0.59s\n",
      "         9           1.1492            0.52s\n",
      "        10           1.1448            0.58s\n",
      "        20           1.1039            0.54s\n",
      "        30           1.0799            0.47s\n",
      "        40           1.0630            0.40s\n",
      "        50           1.0476            0.32s\n",
      "        60           1.0342            0.26s\n",
      "        70           1.0240            0.19s\n",
      "        80           1.0151            0.13s\n",
      "        90           1.0065            0.06s\n",
      "       100           0.9996            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.5427            0.67s\n",
      "         2           0.5379            0.51s\n",
      "         3           0.5347            0.47s\n",
      "         4           0.5314            0.57s\n",
      "         5           0.5231            0.57s\n",
      "         6           0.5206            0.55s\n",
      "         7           0.5170            0.58s\n",
      "         8           0.5143            0.50s\n",
      "         9           0.5080            0.56s\n",
      "        10           0.5017            0.55s\n",
      "        20           0.4775            0.50s\n",
      "        30           0.4620            0.43s\n",
      "        40           0.4530            0.37s\n",
      "        50           0.4443            0.31s\n",
      "        60           0.4380            0.27s\n",
      "        70           0.4313            0.21s\n",
      "        80           0.4263            0.14s\n",
      "        90           0.4220            0.07s\n",
      "       100           0.4171            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.5799            0.65s\n",
      "         2           0.5623            0.71s\n",
      "         3           0.5490            0.68s\n",
      "         4           0.5267            0.63s\n",
      "         5           0.4962            0.74s\n",
      "         6           0.4774            0.71s\n",
      "         7           0.4661            0.71s\n",
      "         8           0.4528            0.69s\n",
      "         9           0.4406            0.67s\n",
      "        10           0.4268            0.59s\n",
      "        20           0.3549            0.54s\n",
      "        30           0.3263            0.46s\n",
      "        40           0.3047            0.39s\n",
      "        50           0.2907            0.32s\n",
      "        60           0.2807            0.27s\n",
      "        70           0.2735            0.20s\n",
      "        80           0.2671            0.13s\n",
      "        90           0.2617            0.06s\n",
      "       100           0.2569            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1518            0.59s\n",
      "         2           1.1299            0.62s\n",
      "         3           1.1097            0.60s\n",
      "         4           1.0881            0.59s\n",
      "         5           1.0669            0.60s\n",
      "         6           1.0516            0.59s\n",
      "         7           1.0337            0.59s\n",
      "         8           1.0218            0.58s\n",
      "         9           1.0141            0.56s\n",
      "        10           1.0025            0.55s\n",
      "        20           0.9303            0.50s\n",
      "        30           0.8956            0.44s\n",
      "        40           0.8754            0.38s\n",
      "        50           0.8625            0.33s\n",
      "        60           0.8533            0.27s\n",
      "        70           0.8457            0.21s\n",
      "        80           0.8391            0.14s\n",
      "        90           0.8328            0.07s\n",
      "       100           0.8274            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.6159            0.00s\n",
      "         2           0.5954            0.37s\n",
      "         3           0.5833            0.58s\n",
      "         4           0.5729            0.56s\n",
      "         5           0.5569            0.53s\n",
      "         6           0.5508            0.51s\n",
      "         7           0.5439            0.50s\n",
      "         8           0.5353            0.55s\n",
      "         9           0.5304            0.54s\n",
      "        10           0.5237            0.52s\n",
      "        20           0.4823            0.48s\n",
      "        30           0.4603            0.41s\n",
      "        40           0.4468            0.36s\n",
      "        50           0.4369            0.30s\n",
      "        60           0.4282            0.25s\n",
      "        70           0.4221            0.19s\n",
      "        80           0.4169            0.13s\n",
      "        90           0.4115            0.06s\n",
      "       100           0.4068            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.5595            0.99s\n",
      "         2           0.5408            0.49s\n",
      "         3           0.5238            0.64s\n",
      "         4           0.5172            0.48s\n",
      "         5           0.5113            0.57s\n",
      "         6           0.5026            0.62s\n",
      "         7           0.4926            0.53s\n",
      "         8           0.4837            0.57s\n",
      "         9           0.4801            0.51s\n",
      "        10           0.4755            0.54s\n",
      "        20           0.4425            0.48s\n",
      "        30           0.4211            0.42s\n",
      "        40           0.4074            0.36s\n",
      "        50           0.3983            0.31s\n",
      "        60           0.3912            0.25s\n",
      "        70           0.3850            0.19s\n",
      "        80           0.3785            0.13s\n",
      "        90           0.3739            0.06s\n",
      "       100           0.3694            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.4928            0.68s\n",
      "         2           0.4912            0.63s\n",
      "         3           0.4887            0.61s\n",
      "         4           0.4870            0.60s\n",
      "         5           0.4850            0.61s\n",
      "         6           0.4836            0.53s\n",
      "         7           0.4815            0.53s\n",
      "         8           0.4801            0.58s\n",
      "         9           0.4786            0.55s\n",
      "        10           0.4769            0.49s\n",
      "        20           0.4655            0.47s\n",
      "        30           0.4571            0.44s\n",
      "        40           0.4498            0.37s\n",
      "        50           0.4437            0.31s\n",
      "        60           0.4388            0.24s\n",
      "        70           0.4331            0.18s\n",
      "        80           0.4286            0.12s\n",
      "        90           0.4243            0.06s\n",
      "       100           0.4198            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.6075            0.60s\n",
      "         2           0.6014            0.60s\n",
      "         3           0.5929            0.59s\n",
      "         4           0.5857            0.58s\n",
      "         5           0.5813            0.58s\n",
      "         6           0.5761            0.51s\n",
      "         7           0.5714            0.55s\n",
      "         8           0.5677            0.55s\n",
      "         9           0.5648            0.48s\n",
      "        10           0.5622            0.51s\n",
      "        20           0.5347            0.47s\n",
      "        30           0.5156            0.41s\n",
      "        40           0.5029            0.35s\n",
      "        50           0.4926            0.29s\n",
      "        60           0.4846            0.24s\n",
      "        70           0.4782            0.18s\n",
      "        80           0.4722            0.12s\n",
      "        90           0.4673            0.06s\n",
      "       100           0.4622            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.5692            0.59s\n",
      "         2           0.5541            0.66s\n",
      "         3           0.5311            0.53s\n",
      "         4           0.5189            0.63s\n",
      "         5           0.5059            0.61s\n",
      "         6           0.4929            0.60s\n",
      "         7           0.4835            0.60s\n",
      "         8           0.4770            0.53s\n",
      "         9           0.4716            0.57s\n",
      "        10           0.4620            0.58s\n",
      "        20           0.4234            0.50s\n",
      "        30           0.4008            0.45s\n",
      "        40           0.3863            0.39s\n",
      "        50           0.3748            0.32s\n",
      "        60           0.3677            0.26s\n",
      "        70           0.3607            0.19s\n",
      "        80           0.3555            0.13s\n",
      "        90           0.3509            0.06s\n",
      "       100           0.3459            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.4810            1.64s\n",
      "         2           0.4753            0.99s\n",
      "         3           0.4694            0.97s\n",
      "         4           0.4648            0.87s\n",
      "         5           0.4614            0.80s\n",
      "         6           0.4576            0.75s\n",
      "         7           0.4550            0.73s\n",
      "         8           0.4517            0.71s\n",
      "         9           0.4488            0.68s\n",
      "        10           0.4461            0.66s\n",
      "        20           0.4275            0.54s\n",
      "        30           0.4134            0.46s\n",
      "        40           0.4011            0.39s\n",
      "        50           0.3925            0.33s\n",
      "        60           0.3862            0.27s\n",
      "        70           0.3791            0.20s\n",
      "        80           0.3729            0.13s\n",
      "        90           0.3667            0.07s\n",
      "       100           0.3600            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.4582            0.57s\n",
      "         2           0.4426            0.57s\n",
      "         3           0.4328            0.60s\n",
      "         4           0.4233            0.58s\n",
      "         5           0.4039            0.59s\n",
      "         6           0.3925            0.58s\n",
      "         7           0.3867            0.57s\n",
      "         8           0.3823            0.56s\n",
      "         9           0.3713            0.56s\n",
      "        10           0.3671            0.53s\n",
      "        20           0.3285            0.48s\n",
      "        30           0.3074            0.39s\n",
      "        40           0.2948            0.37s\n",
      "        50           0.2846            0.31s\n",
      "        60           0.2776            0.25s\n",
      "        70           0.2711            0.19s\n",
      "        80           0.2659            0.13s\n",
      "        90           0.2616            0.06s\n",
      "       100           0.2575            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.7157            0.20s\n",
      "         2           0.7003            0.59s\n",
      "         3           0.6828            0.52s\n",
      "         4           0.6712            0.53s\n",
      "         5           0.6579            0.55s\n",
      "         6           0.6469            0.57s\n",
      "         7           0.6375            0.56s\n",
      "         8           0.6300            0.60s\n",
      "         9           0.6240            0.57s\n",
      "        10           0.6176            0.56s\n",
      "        20           0.5698            0.49s\n",
      "        30           0.5420            0.44s\n",
      "        40           0.5250            0.36s\n",
      "        50           0.5120            0.32s\n",
      "        60           0.5028            0.26s\n",
      "        70           0.4952            0.21s\n",
      "        80           0.4893            0.14s\n",
      "        90           0.4836            0.07s\n",
      "       100           0.4784            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.4515            1.03s\n",
      "         2           0.4439            0.92s\n",
      "         3           0.4348            0.81s\n",
      "         4           0.4083            0.76s\n",
      "         5           0.4038            0.74s\n",
      "         6           0.3975            0.69s\n",
      "         7           0.3941            0.65s\n",
      "         8           0.3911            0.68s\n",
      "         9           0.3808            0.66s\n",
      "        10           0.3775            0.64s\n",
      "        20           0.3463            0.60s\n",
      "        30           0.3289            0.56s\n",
      "        40           0.3170            0.46s\n",
      "        50           0.3057            0.38s\n",
      "        60           0.2978            0.30s\n",
      "        70           0.2893            0.24s\n",
      "        80           0.2831            0.16s\n",
      "        90           0.2774            0.09s\n",
      "       100           0.2728            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.7541            1.17s\n",
      "         2           0.7416            0.99s\n",
      "         3           0.7283            1.02s\n",
      "         4           0.7142            1.01s\n",
      "         5           0.7019            0.93s\n",
      "         6           0.6932            0.86s\n",
      "         7           0.6866            0.87s\n",
      "         8           0.6796            0.88s\n",
      "         9           0.6734            0.87s\n",
      "        10           0.6680            0.86s\n",
      "        20           0.6362            0.73s\n",
      "        30           0.6175            0.58s\n",
      "        40           0.6043            0.47s\n",
      "        50           0.5929            0.40s\n",
      "        60           0.5843            0.30s\n",
      "        70           0.5771            0.22s\n",
      "        80           0.5703            0.15s\n",
      "        90           0.5651            0.07s\n",
      "       100           0.5606            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.6637            0.97s\n",
      "         2           0.6446            0.73s\n",
      "         3           0.6328            0.65s\n",
      "         4           0.6227            0.65s\n",
      "         5           0.6106            0.58s\n",
      "         6           0.6034            0.62s\n",
      "         7           0.5951            0.60s\n",
      "         8           0.5888            0.60s\n",
      "         9           0.5851            0.61s\n",
      "        10           0.5797            0.60s\n",
      "        20           0.5418            0.52s\n",
      "        30           0.5208            0.45s\n",
      "        40           0.5073            0.40s\n",
      "        50           0.4968            0.33s\n",
      "        60           0.4889            0.28s\n",
      "        70           0.4822            0.21s\n",
      "        80           0.4762            0.14s\n",
      "        90           0.4707            0.07s\n",
      "       100           0.4662            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.6608            0.59s\n",
      "         2           0.6444            0.64s\n",
      "         3           0.6184            0.61s\n",
      "         4           0.6062            0.54s\n",
      "         5           0.5935            0.51s\n",
      "         6           0.5793            0.60s\n",
      "         7           0.5709            0.64s\n",
      "         8           0.5640            0.63s\n",
      "         9           0.5578            0.63s\n",
      "        10           0.5471            0.75s\n",
      "        20           0.5042            0.71s\n",
      "        30           0.4774            0.59s\n",
      "        40           0.4602            0.49s\n",
      "        50           0.4486            0.40s\n",
      "        60           0.4395            0.31s\n",
      "        70           0.4321            0.24s\n",
      "        80           0.4262            0.16s\n",
      "        90           0.4205            0.08s\n",
      "       100           0.4158            0.00s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultiOutputClassifier(estimator=GradientBoostingClassifier(max_features=&#x27;sqrt&#x27;,\n",
       "                                                           random_state=42,\n",
       "                                                           verbose=1))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultiOutputClassifier</label><div class=\"sk-toggleable__content\"><pre>MultiOutputClassifier(estimator=GradientBoostingClassifier(max_features=&#x27;sqrt&#x27;,\n",
       "                                                           random_state=42,\n",
       "                                                           verbose=1))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(max_features=&#x27;sqrt&#x27;, random_state=42, verbose=1)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(max_features=&#x27;sqrt&#x27;, random_state=42, verbose=1)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultiOutputClassifier(estimator=GradientBoostingClassifier(max_features='sqrt',\n",
       "                                                           random_state=42,\n",
       "                                                           verbose=1))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a Gradient Boosting Classifier\n",
    "gd_clf = MultiOutputClassifier(estimator=GradientBoostingClassifier(n_estimators=100,max_depth=3,max_features='sqrt',verbose=1,random_state=42))\n",
    "gd_clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57600566-7013-423f-b9df-8b1d9b86df86",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Evaluating the multilabal Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d50ab758-e2c6-4ff2-aa85-8b2757d8c050",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score     91.189474\n",
      "precision_score    85.123684\n",
      "recall_score       63.941053\n",
      "f1_score           67.456842\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Developer, back-end</th>\n",
       "      <td>75.72</td>\n",
       "      <td>73.64</td>\n",
       "      <td>63.12</td>\n",
       "      <td>64.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, full-stack</th>\n",
       "      <td>80.58</td>\n",
       "      <td>76.12</td>\n",
       "      <td>72.36</td>\n",
       "      <td>73.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, desktop or enterprise applications</th>\n",
       "      <td>88.96</td>\n",
       "      <td>80.59</td>\n",
       "      <td>60.07</td>\n",
       "      <td>63.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cloud infrastructure engineer</th>\n",
       "      <td>91.92</td>\n",
       "      <td>81.88</td>\n",
       "      <td>65.24</td>\n",
       "      <td>69.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DevOps specialist</th>\n",
       "      <td>90.84</td>\n",
       "      <td>82.00</td>\n",
       "      <td>63.47</td>\n",
       "      <td>67.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data scientist or machine learning specialist</th>\n",
       "      <td>92.59</td>\n",
       "      <td>82.49</td>\n",
       "      <td>75.49</td>\n",
       "      <td>78.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, front-end</th>\n",
       "      <td>90.68</td>\n",
       "      <td>83.61</td>\n",
       "      <td>65.62</td>\n",
       "      <td>70.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data or business analyst</th>\n",
       "      <td>92.64</td>\n",
       "      <td>84.01</td>\n",
       "      <td>60.60</td>\n",
       "      <td>64.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scientist</th>\n",
       "      <td>93.45</td>\n",
       "      <td>84.08</td>\n",
       "      <td>67.80</td>\n",
       "      <td>72.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Engineer, data</th>\n",
       "      <td>92.24</td>\n",
       "      <td>84.14</td>\n",
       "      <td>60.42</td>\n",
       "      <td>64.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Academic researcher</th>\n",
       "      <td>92.06</td>\n",
       "      <td>84.72</td>\n",
       "      <td>67.90</td>\n",
       "      <td>72.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, embedded applications or devices</th>\n",
       "      <td>92.99</td>\n",
       "      <td>85.44</td>\n",
       "      <td>61.51</td>\n",
       "      <td>66.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, game or graphics</th>\n",
       "      <td>95.38</td>\n",
       "      <td>86.70</td>\n",
       "      <td>70.39</td>\n",
       "      <td>75.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>System administrator</th>\n",
       "      <td>91.88</td>\n",
       "      <td>88.31</td>\n",
       "      <td>57.63</td>\n",
       "      <td>60.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Database administrator</th>\n",
       "      <td>92.60</td>\n",
       "      <td>88.51</td>\n",
       "      <td>52.99</td>\n",
       "      <td>53.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blockchain</th>\n",
       "      <td>95.47</td>\n",
       "      <td>89.10</td>\n",
       "      <td>66.48</td>\n",
       "      <td>72.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, mobile</th>\n",
       "      <td>95.42</td>\n",
       "      <td>90.88</td>\n",
       "      <td>79.26</td>\n",
       "      <td>83.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Security professional</th>\n",
       "      <td>93.84</td>\n",
       "      <td>94.46</td>\n",
       "      <td>53.82</td>\n",
       "      <td>55.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, QA or test</th>\n",
       "      <td>93.34</td>\n",
       "      <td>96.67</td>\n",
       "      <td>50.71</td>\n",
       "      <td>49.68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               accuracy_score  \\\n",
       "Developer, back-end                                     75.72   \n",
       "Developer, full-stack                                   80.58   \n",
       "Developer, desktop or enterprise applications           88.96   \n",
       "Cloud infrastructure engineer                           91.92   \n",
       "DevOps specialist                                       90.84   \n",
       "Data scientist or machine learning specialist           92.59   \n",
       "Developer, front-end                                    90.68   \n",
       "Data or business analyst                                92.64   \n",
       "Scientist                                               93.45   \n",
       "Engineer, data                                          92.24   \n",
       "Academic researcher                                     92.06   \n",
       "Developer, embedded applications or devices             92.99   \n",
       "Developer, game or graphics                             95.38   \n",
       "System administrator                                    91.88   \n",
       "Database administrator                                  92.60   \n",
       "Blockchain                                              95.47   \n",
       "Developer, mobile                                       95.42   \n",
       "Security professional                                   93.84   \n",
       "Developer, QA or test                                   93.34   \n",
       "\n",
       "                                               precision_score  recall_score  \\\n",
       "Developer, back-end                                      73.64         63.12   \n",
       "Developer, full-stack                                    76.12         72.36   \n",
       "Developer, desktop or enterprise applications            80.59         60.07   \n",
       "Cloud infrastructure engineer                            81.88         65.24   \n",
       "DevOps specialist                                        82.00         63.47   \n",
       "Data scientist or machine learning specialist            82.49         75.49   \n",
       "Developer, front-end                                     83.61         65.62   \n",
       "Data or business analyst                                 84.01         60.60   \n",
       "Scientist                                                84.08         67.80   \n",
       "Engineer, data                                           84.14         60.42   \n",
       "Academic researcher                                      84.72         67.90   \n",
       "Developer, embedded applications or devices              85.44         61.51   \n",
       "Developer, game or graphics                              86.70         70.39   \n",
       "System administrator                                     88.31         57.63   \n",
       "Database administrator                                   88.51         52.99   \n",
       "Blockchain                                               89.10         66.48   \n",
       "Developer, mobile                                        90.88         79.26   \n",
       "Security professional                                    94.46         53.82   \n",
       "Developer, QA or test                                    96.67         50.71   \n",
       "\n",
       "                                               f1_score  \n",
       "Developer, back-end                               64.21  \n",
       "Developer, full-stack                             73.78  \n",
       "Developer, desktop or enterprise applications     63.45  \n",
       "Cloud infrastructure engineer                     69.83  \n",
       "DevOps specialist                                 67.86  \n",
       "Data scientist or machine learning specialist     78.42  \n",
       "Developer, front-end                              70.28  \n",
       "Data or business analyst                          64.99  \n",
       "Scientist                                         72.82  \n",
       "Engineer, data                                    64.69  \n",
       "Academic researcher                               72.86  \n",
       "Developer, embedded applications or devices       66.26  \n",
       "Developer, game or graphics                       75.85  \n",
       "System administrator                              60.99  \n",
       "Database administrator                            53.74  \n",
       "Blockchain                                        72.60  \n",
       "Developer, mobile                                 83.88  \n",
       "Security professional                             55.49  \n",
       "Developer, QA or test                             49.68  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics=[accuracy_score, precision_score, recall_score, f1_score]\n",
    "train_scores, mean_train_scores= calculate_metrics(gd_clf,x_train,y_train, metrics)\n",
    "\n",
    "print(mean_train_scores)\n",
    "train_scores.sort_values(\"precision_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2e33c81e-a828-4f6d-bd62-c47065b7dc6f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.3265            0.00s\n",
      "         2           0.3053            0.53s\n",
      "         3           0.2928            0.48s\n",
      "         4           0.2838            0.48s\n",
      "         5           0.2749            0.56s\n",
      "         6           0.2675            0.54s\n",
      "         7           0.2612            0.53s\n",
      "         8           0.2553            0.52s\n",
      "         9           0.2515            0.51s\n",
      "        10           0.2470            0.50s\n",
      "        20           0.2218            0.40s\n",
      "        30           0.2080            0.36s\n",
      "        40           0.2003            0.32s\n",
      "        50           0.1953            0.26s\n",
      "        60           0.1907            0.21s\n",
      "        70           0.1860            0.15s\n",
      "        80           0.1822            0.10s\n",
      "        90           0.1784            0.05s\n",
      "       100           0.1751            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.2232            0.37s\n",
      "         2           0.2196            0.50s\n",
      "         3           0.2167            0.46s\n",
      "         4           0.2129            0.52s\n",
      "         5           0.2115            0.51s\n",
      "         6           0.2086            0.53s\n",
      "         7           0.2063            0.46s\n",
      "         8           0.2051            0.48s\n",
      "         9           0.2020            0.42s\n",
      "        10           0.2004            0.47s\n",
      "        20           0.1877            0.41s\n",
      "        30           0.1790            0.37s\n",
      "        40           0.1724            0.32s\n",
      "        50           0.1672            0.27s\n",
      "        60           0.1639            0.22s\n",
      "        70           0.1593            0.16s\n",
      "        80           0.1548            0.11s\n",
      "        90           0.1516            0.05s\n",
      "       100           0.1489            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.2082            0.61s\n",
      "         2           0.2049            0.30s\n",
      "         3           0.2014            0.50s\n",
      "         4           0.1972            0.58s\n",
      "         5           0.1944            0.53s\n",
      "         6           0.1914            0.55s\n",
      "         7           0.1886            0.57s\n",
      "         8           0.1871            0.56s\n",
      "         9           0.1846            0.49s\n",
      "        10           0.1821            0.55s\n",
      "        20           0.1684            0.42s\n",
      "        30           0.1592            0.36s\n",
      "        40           0.1525            0.31s\n",
      "        50           0.1471            0.26s\n",
      "        60           0.1427            0.20s\n",
      "        70           0.1393            0.15s\n",
      "        80           0.1352            0.10s\n",
      "        90           0.1320            0.05s\n",
      "       100           0.1294            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1625            0.00s\n",
      "         2           1.1514            0.54s\n",
      "         3           1.1462            0.65s\n",
      "         4           1.1407            0.61s\n",
      "         5           1.1350            0.57s\n",
      "         6           1.1270            0.55s\n",
      "         7           1.1207            0.53s\n",
      "         8           1.1151            0.46s\n",
      "         9           1.1104            0.47s\n",
      "        10           1.1062            0.45s\n",
      "        20           1.0671            0.43s\n",
      "        30           1.0420            0.35s\n",
      "        40           1.0256            0.31s\n",
      "        50           1.0104            0.25s\n",
      "        60           0.9967            0.20s\n",
      "        70           0.9859            0.15s\n",
      "        80           0.9758            0.10s\n",
      "        90           0.9665            0.05s\n",
      "       100           0.9593            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.5753            0.58s\n",
      "         2           0.5695            0.62s\n",
      "         3           0.5653            0.61s\n",
      "         4           0.5617            0.61s\n",
      "         5           0.5514            0.58s\n",
      "         6           0.5450            0.57s\n",
      "         7           0.5411            0.56s\n",
      "         8           0.5380            0.55s\n",
      "         9           0.5310            0.55s\n",
      "        10           0.5237            0.53s\n",
      "        20           0.4978            0.50s\n",
      "        30           0.4785            0.43s\n",
      "        40           0.4683            0.34s\n",
      "        50           0.4582            0.28s\n",
      "        60           0.4509            0.22s\n",
      "        70           0.4426            0.16s\n",
      "        80           0.4374            0.11s\n",
      "        90           0.4322            0.05s\n",
      "       100           0.4266            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.6615            1.02s\n",
      "         2           0.6423            0.50s\n",
      "         3           0.6218            0.68s\n",
      "         4           0.5984            0.51s\n",
      "         5           0.5648            0.57s\n",
      "         6           0.5420            0.50s\n",
      "         7           0.5298            0.55s\n",
      "         8           0.5157            0.57s\n",
      "         9           0.5028            0.58s\n",
      "        10           0.4878            0.59s\n",
      "        20           0.4076            0.45s\n",
      "        30           0.3734            0.38s\n",
      "        40           0.3481            0.30s\n",
      "        50           0.3314            0.25s\n",
      "        60           0.3190            0.20s\n",
      "        70           0.3099            0.15s\n",
      "        80           0.3032            0.10s\n",
      "        90           0.2958            0.05s\n",
      "       100           0.2904            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.2013            0.51s\n",
      "         2           1.1795            0.47s\n",
      "         3           1.1605            0.48s\n",
      "         4           1.1388            0.36s\n",
      "         5           1.1168            0.48s\n",
      "         6           1.1052            0.39s\n",
      "         7           1.0869            0.47s\n",
      "         8           1.0726            0.46s\n",
      "         9           1.0643            0.45s\n",
      "        10           1.0546            0.40s\n",
      "        20           0.9749            0.38s\n",
      "        30           0.9379            0.34s\n",
      "        40           0.9165            0.29s\n",
      "        50           0.9013            0.24s\n",
      "        60           0.8909            0.19s\n",
      "        70           0.8817            0.14s\n",
      "        80           0.8741            0.10s\n",
      "        90           0.8674            0.05s\n",
      "       100           0.8601            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.6822            0.11s\n",
      "         2           0.6574            0.06s\n",
      "         3           0.6428            0.36s\n",
      "         4           0.6307            0.27s\n",
      "         5           0.6116            0.40s\n",
      "         6           0.6043            0.41s\n",
      "         7           0.5955            0.41s\n",
      "         8           0.5850            0.36s\n",
      "         9           0.5780            0.42s\n",
      "        10           0.5699            0.37s\n",
      "        20           0.5210            0.40s\n",
      "        30           0.4968            0.35s\n",
      "        40           0.4814            0.30s\n",
      "        50           0.4684            0.25s\n",
      "        60           0.4568            0.19s\n",
      "        70           0.4502            0.15s\n",
      "        80           0.4437            0.10s\n",
      "        90           0.4376            0.05s\n",
      "       100           0.4315            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.6353            0.96s\n",
      "         2           0.6147            0.47s\n",
      "         3           0.5961            0.65s\n",
      "         4           0.5884            0.48s\n",
      "         5           0.5815            0.60s\n",
      "         6           0.5734            0.50s\n",
      "         7           0.5621            0.53s\n",
      "         8           0.5528            0.53s\n",
      "         9           0.5493            0.51s\n",
      "        10           0.5443            0.50s\n",
      "        20           0.5062            0.40s\n",
      "        30           0.4809            0.35s\n",
      "        40           0.4660            0.30s\n",
      "        50           0.4553            0.25s\n",
      "        60           0.4473            0.19s\n",
      "        70           0.4398            0.15s\n",
      "        80           0.4328            0.10s\n",
      "        90           0.4269            0.05s\n",
      "       100           0.4216            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.5606            0.11s\n",
      "         2           0.5587            0.40s\n",
      "         3           0.5561            0.27s\n",
      "         4           0.5538            0.43s\n",
      "         5           0.5516            0.34s\n",
      "         6           0.5497            0.44s\n",
      "         7           0.5476            0.38s\n",
      "         8           0.5458            0.44s\n",
      "         9           0.5441            0.46s\n",
      "        10           0.5416            0.47s\n",
      "        20           0.5303            0.41s\n",
      "        30           0.5210            0.35s\n",
      "        40           0.5129            0.31s\n",
      "        50           0.5057            0.26s\n",
      "        60           0.4993            0.21s\n",
      "        70           0.4925            0.16s\n",
      "        80           0.4874            0.10s\n",
      "        90           0.4819            0.05s\n",
      "       100           0.4771            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.6850            0.50s\n",
      "         2           0.6772            0.45s\n",
      "         3           0.6685            0.46s\n",
      "         4           0.6603            0.46s\n",
      "         5           0.6556            0.46s\n",
      "         6           0.6496            0.46s\n",
      "         7           0.6441            0.45s\n",
      "         8           0.6400            0.45s\n",
      "         9           0.6373            0.45s\n",
      "        10           0.6346            0.44s\n",
      "        20           0.6038            0.36s\n",
      "        30           0.5825            0.34s\n",
      "        40           0.5689            0.29s\n",
      "        50           0.5579            0.24s\n",
      "        60           0.5487            0.19s\n",
      "        70           0.5408            0.14s\n",
      "        80           0.5336            0.10s\n",
      "        90           0.5278            0.05s\n",
      "       100           0.5220            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.6027            1.11s\n",
      "         2           0.5855            0.55s\n",
      "         3           0.5546            0.65s\n",
      "         4           0.5386            0.48s\n",
      "         5           0.5234            0.69s\n",
      "         6           0.5078            0.68s\n",
      "         7           0.4949            0.66s\n",
      "         8           0.4864            0.63s\n",
      "         9           0.4803            0.60s\n",
      "        10           0.4695            0.58s\n",
      "        20           0.4232            0.44s\n",
      "        30           0.3981            0.35s\n",
      "        40           0.3813            0.30s\n",
      "        50           0.3689            0.25s\n",
      "        60           0.3605            0.20s\n",
      "        70           0.3532            0.15s\n",
      "        80           0.3480            0.10s\n",
      "        90           0.3429            0.05s\n",
      "       100           0.3377            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.5572            0.90s\n",
      "         2           0.5509            0.70s\n",
      "         3           0.5454            0.61s\n",
      "         4           0.5399            0.58s\n",
      "         5           0.5358            0.55s\n",
      "         6           0.5312            0.46s\n",
      "         7           0.5281            0.53s\n",
      "         8           0.5246            0.46s\n",
      "         9           0.5214            0.50s\n",
      "        10           0.5188            0.44s\n",
      "        20           0.4969            0.42s\n",
      "        30           0.4810            0.35s\n",
      "        40           0.4674            0.30s\n",
      "        50           0.4570            0.25s\n",
      "        60           0.4483            0.20s\n",
      "        70           0.4408            0.15s\n",
      "        80           0.4337            0.10s\n",
      "        90           0.4266            0.05s\n",
      "       100           0.4199            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.5333            0.50s\n",
      "         2           0.5161            0.50s\n",
      "         3           0.5061            0.33s\n",
      "         4           0.4950            0.24s\n",
      "         5           0.4732            0.38s\n",
      "         6           0.4643            0.39s\n",
      "         7           0.4573            0.48s\n",
      "         8           0.4523            0.49s\n",
      "         9           0.4385            0.51s\n",
      "        10           0.4337            0.51s\n",
      "        20           0.3869            0.41s\n",
      "        30           0.3635            0.37s\n",
      "        40           0.3481            0.30s\n",
      "        50           0.3360            0.25s\n",
      "        60           0.3273            0.20s\n",
      "        70           0.3207            0.15s\n",
      "        80           0.3138            0.10s\n",
      "        90           0.3087            0.05s\n",
      "       100           0.3035            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.7805            1.03s\n",
      "         2           0.7650            0.74s\n",
      "         3           0.7471            0.65s\n",
      "         4           0.7348            0.60s\n",
      "         5           0.7209            0.59s\n",
      "         6           0.7091            0.49s\n",
      "         7           0.6995            0.53s\n",
      "         8           0.6922            0.46s\n",
      "         9           0.6862            0.51s\n",
      "        10           0.6817            0.45s\n",
      "        20           0.6262            0.40s\n",
      "        30           0.5938            0.35s\n",
      "        40           0.5748            0.31s\n",
      "        50           0.5619            0.26s\n",
      "        60           0.5518            0.20s\n",
      "        70           0.5424            0.15s\n",
      "        80           0.5350            0.10s\n",
      "        90           0.5286            0.05s\n",
      "       100           0.5222            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.5207            0.00s\n",
      "         2           0.5130            0.46s\n",
      "         3           0.5084            0.59s\n",
      "         4           0.4748            0.60s\n",
      "         5           0.4697            0.59s\n",
      "         6           0.4618            0.51s\n",
      "         7           0.4577            0.58s\n",
      "         8           0.4541            0.56s\n",
      "         9           0.4414            0.54s\n",
      "        10           0.4375            0.52s\n",
      "        20           0.4000            0.42s\n",
      "        30           0.3788            0.35s\n",
      "        40           0.3647            0.30s\n",
      "        50           0.3518            0.25s\n",
      "        60           0.3422            0.20s\n",
      "        70           0.3323            0.15s\n",
      "        80           0.3244            0.10s\n",
      "        90           0.3173            0.05s\n",
      "       100           0.3107            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.8134            1.02s\n",
      "         2           0.8002            0.75s\n",
      "         3           0.7876            0.65s\n",
      "         4           0.7729            0.60s\n",
      "         5           0.7608            0.57s\n",
      "         6           0.7516            0.47s\n",
      "         7           0.7441            0.53s\n",
      "         8           0.7368            0.46s\n",
      "         9           0.7300            0.51s\n",
      "        10           0.7241            0.50s\n",
      "        20           0.6903            0.42s\n",
      "        30           0.6698            0.35s\n",
      "        40           0.6556            0.30s\n",
      "        50           0.6425            0.25s\n",
      "        60           0.6340            0.20s\n",
      "        70           0.6254            0.15s\n",
      "        80           0.6181            0.10s\n",
      "        90           0.6110            0.05s\n",
      "       100           0.6053            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.7403            0.01s\n",
      "         2           0.7186            0.00s\n",
      "         3           0.7046            0.36s\n",
      "         4           0.6932            0.27s\n",
      "         5           0.6793            0.38s\n",
      "         6           0.6708            0.39s\n",
      "         7           0.6609            0.47s\n",
      "         8           0.6539            0.49s\n",
      "         9           0.6495            0.43s\n",
      "        10           0.6428            0.48s\n",
      "        20           0.5997            0.41s\n",
      "        30           0.5754            0.35s\n",
      "        40           0.5593            0.30s\n",
      "        50           0.5472            0.25s\n",
      "        60           0.5385            0.20s\n",
      "        70           0.5310            0.15s\n",
      "        80           0.5244            0.10s\n",
      "        90           0.5180            0.05s\n",
      "       100           0.5128            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.6934            0.41s\n",
      "         2           0.6636            0.20s\n",
      "         3           0.6310            0.45s\n",
      "         4           0.6172            0.33s\n",
      "         5           0.6025            0.46s\n",
      "         6           0.5864            0.38s\n",
      "         7           0.5764            0.45s\n",
      "         8           0.5682            0.39s\n",
      "         9           0.5618            0.46s\n",
      "        10           0.5491            0.44s\n",
      "        20           0.4981            0.40s\n",
      "        30           0.4688            0.34s\n",
      "        40           0.4496            0.29s\n",
      "        50           0.4365            0.23s\n",
      "        60           0.4268            0.19s\n",
      "        70           0.4186            0.15s\n",
      "        80           0.4120            0.10s\n",
      "        90           0.4063            0.05s\n",
      "       100           0.4012            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.7322            0.00s\n",
      "         2           0.6896            0.49s\n",
      "         3           0.6624            0.65s\n",
      "         4           0.6416            0.60s\n",
      "         5           0.6199            0.57s\n",
      "         6           0.5993            0.55s\n",
      "         7           0.5852            0.53s\n",
      "         8           0.5710            0.51s\n",
      "         9           0.5582            0.50s\n",
      "        10           0.5481            0.49s\n",
      "        20           0.4954            0.40s\n",
      "        30           0.4671            0.34s\n",
      "        40           0.4517            0.29s\n",
      "        50           0.4413            0.25s\n",
      "        60           0.4331            0.19s\n",
      "        70           0.4259            0.15s\n",
      "        80           0.4202            0.10s\n",
      "        90           0.4142            0.05s\n",
      "       100           0.4100            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.6626            0.00s\n",
      "         2           0.6521            0.44s\n",
      "         3           0.6433            0.61s\n",
      "         4           0.6329            0.45s\n",
      "         5           0.6244            0.45s\n",
      "         6           0.6156            0.45s\n",
      "         7           0.6082            0.47s\n",
      "         8           0.6043            0.45s\n",
      "         9           0.5955            0.44s\n",
      "        10           0.5904            0.44s\n",
      "        20           0.5625            0.40s\n",
      "        30           0.5435            0.35s\n",
      "        40           0.5321            0.30s\n",
      "        50           0.5194            0.25s\n",
      "        60           0.5107            0.20s\n",
      "        70           0.5032            0.15s\n",
      "        80           0.4965            0.10s\n",
      "        90           0.4906            0.05s\n",
      "       100           0.4848            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.6276            0.22s\n",
      "         2           0.6196            0.48s\n",
      "         3           0.6042            0.48s\n",
      "         4           0.5952            0.48s\n",
      "         5           0.5871            0.47s\n",
      "         6           0.5756            0.47s\n",
      "         7           0.5679            0.40s\n",
      "         8           0.5620            0.40s\n",
      "         9           0.5552            0.42s\n",
      "        10           0.5477            0.37s\n",
      "        20           0.5139            0.38s\n",
      "        30           0.4886            0.35s\n",
      "        40           0.4748            0.29s\n",
      "        50           0.4634            0.24s\n",
      "        60           0.4539            0.19s\n",
      "        70           0.4455            0.15s\n",
      "        80           0.4393            0.10s\n",
      "        90           0.4331            0.05s\n",
      "       100           0.4276            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1949            0.37s\n",
      "         2           1.1819            0.43s\n",
      "         3           1.1729            0.45s\n",
      "         4           1.1649            0.45s\n",
      "         5           1.1583            0.45s\n",
      "         6           1.1491            0.45s\n",
      "         7           1.1413            0.45s\n",
      "         8           1.1347            0.39s\n",
      "         9           1.1282            0.44s\n",
      "        10           1.1238            0.44s\n",
      "        20           1.0812            0.39s\n",
      "        30           1.0563            0.34s\n",
      "        40           1.0386            0.29s\n",
      "        50           1.0208            0.24s\n",
      "        60           1.0067            0.20s\n",
      "        70           0.9960            0.14s\n",
      "        80           0.9857            0.10s\n",
      "        90           0.9769            0.05s\n",
      "       100           0.9692            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.2515            0.61s\n",
      "         2           0.2476            0.30s\n",
      "         3           0.2455            0.48s\n",
      "         4           0.2436            0.48s\n",
      "         5           0.2395            0.48s\n",
      "         6           0.2378            0.47s\n",
      "         7           0.2348            0.47s\n",
      "         8           0.2330            0.46s\n",
      "         9           0.2298            0.46s\n",
      "        10           0.2264            0.41s\n",
      "        20           0.2112            0.38s\n",
      "        30           0.2010            0.34s\n",
      "        40           0.1948            0.29s\n",
      "        50           0.1897            0.24s\n",
      "        60           0.1852            0.19s\n",
      "        70           0.1799            0.14s\n",
      "        80           0.1755            0.10s\n",
      "        90           0.1723            0.05s\n",
      "       100           0.1689            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.3282            0.00s\n",
      "         2           0.3156            0.47s\n",
      "         3           0.3055            0.44s\n",
      "         4           0.2972            0.45s\n",
      "         5           0.2845            0.36s\n",
      "         6           0.2762            0.45s\n",
      "         7           0.2708            0.45s\n",
      "         8           0.2619            0.44s\n",
      "         9           0.2548            0.44s\n",
      "        10           0.2488            0.45s\n",
      "        20           0.2152            0.38s\n",
      "        30           0.2022            0.33s\n",
      "        40           0.1900            0.28s\n",
      "        50           0.1812            0.25s\n",
      "        60           0.1742            0.20s\n",
      "        70           0.1683            0.15s\n",
      "        80           0.1630            0.10s\n",
      "        90           0.1589            0.05s\n",
      "       100           0.1543            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.0341            0.47s\n",
      "         2           1.0146            0.48s\n",
      "         3           0.9969            0.48s\n",
      "         4           0.9790            0.36s\n",
      "         5           0.9575            0.47s\n",
      "         6           0.9447            0.47s\n",
      "         7           0.9304            0.47s\n",
      "         8           0.9187            0.46s\n",
      "         9           0.9121            0.45s\n",
      "        10           0.9035            0.45s\n",
      "        20           0.8451            0.38s\n",
      "        30           0.8163            0.34s\n",
      "        40           0.7996            0.29s\n",
      "        50           0.7868            0.24s\n",
      "        60           0.7783            0.19s\n",
      "        70           0.7705            0.14s\n",
      "        80           0.7643            0.09s\n",
      "        90           0.7588            0.05s\n",
      "       100           0.7522            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.5081            0.45s\n",
      "         2           0.4908            0.48s\n",
      "         3           0.4804            0.48s\n",
      "         4           0.4719            0.48s\n",
      "         5           0.4585            0.47s\n",
      "         6           0.4529            0.52s\n",
      "         7           0.4471            0.48s\n",
      "         8           0.4411            0.46s\n",
      "         9           0.4372            0.45s\n",
      "        10           0.4308            0.45s\n",
      "        20           0.3944            0.40s\n",
      "        30           0.3757            0.34s\n",
      "        40           0.3631            0.28s\n",
      "        50           0.3541            0.24s\n",
      "        60           0.3459            0.20s\n",
      "        70           0.3397            0.15s\n",
      "        80           0.3338            0.10s\n",
      "        90           0.3289            0.05s\n",
      "       100           0.3242            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.6355            0.55s\n",
      "         2           0.6162            0.49s\n",
      "         3           0.5980            0.48s\n",
      "         4           0.5905            0.48s\n",
      "         5           0.5841            0.48s\n",
      "         6           0.5744            0.47s\n",
      "         7           0.5629            0.46s\n",
      "         8           0.5558            0.46s\n",
      "         9           0.5516            0.45s\n",
      "        10           0.5465            0.45s\n",
      "        20           0.5046            0.38s\n",
      "        30           0.4797            0.33s\n",
      "        40           0.4619            0.28s\n",
      "        50           0.4507            0.24s\n",
      "        60           0.4413            0.19s\n",
      "        70           0.4322            0.14s\n",
      "        80           0.4240            0.10s\n",
      "        90           0.4171            0.05s\n",
      "       100           0.4120            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.5537            0.50s\n",
      "         2           0.5520            0.50s\n",
      "         3           0.5485            0.48s\n",
      "         4           0.5459            0.52s\n",
      "         5           0.5430            0.41s\n",
      "         6           0.5410            0.47s\n",
      "         7           0.5380            0.47s\n",
      "         8           0.5357            0.47s\n",
      "         9           0.5338            0.42s\n",
      "        10           0.5321            0.45s\n",
      "        20           0.5172            0.40s\n",
      "        30           0.5067            0.34s\n",
      "        40           0.4975            0.29s\n",
      "        50           0.4892            0.24s\n",
      "        60           0.4825            0.20s\n",
      "        70           0.4765            0.15s\n",
      "        80           0.4701            0.10s\n",
      "        90           0.4646            0.05s\n",
      "       100           0.4598            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.6311            0.30s\n",
      "         2           0.6237            0.35s\n",
      "         3           0.6161            0.38s\n",
      "         4           0.6076            0.40s\n",
      "         5           0.6034            0.42s\n",
      "         6           0.5975            0.38s\n",
      "         7           0.5918            0.42s\n",
      "         8           0.5878            0.42s\n",
      "         9           0.5848            0.42s\n",
      "        10           0.5819            0.38s\n",
      "        20           0.5519            0.37s\n",
      "        30           0.5313            0.32s\n",
      "        40           0.5169            0.27s\n",
      "        50           0.5063            0.23s\n",
      "        60           0.4969            0.19s\n",
      "        70           0.4897            0.14s\n",
      "        80           0.4820            0.09s\n",
      "        90           0.4769            0.05s\n",
      "       100           0.4704            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.6611            0.50s\n",
      "         2           0.6458            0.50s\n",
      "         3           0.6224            0.33s\n",
      "         4           0.6085            0.53s\n",
      "         5           0.5946            0.53s\n",
      "         6           0.5815            0.52s\n",
      "         7           0.5713            0.50s\n",
      "         8           0.5647            0.49s\n",
      "         9           0.5593            0.47s\n",
      "        10           0.5488            0.47s\n",
      "        20           0.5063            0.38s\n",
      "        30           0.4802            0.34s\n",
      "        40           0.4629            0.29s\n",
      "        50           0.4493            0.24s\n",
      "        60           0.4401            0.20s\n",
      "        70           0.4323            0.15s\n",
      "        80           0.4256            0.10s\n",
      "        90           0.4203            0.05s\n",
      "       100           0.4135            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.5544            0.51s\n",
      "         2           0.5482            0.50s\n",
      "         3           0.5431            0.48s\n",
      "         4           0.5374            0.48s\n",
      "         5           0.5318            0.48s\n",
      "         6           0.5275            0.47s\n",
      "         7           0.5243            0.46s\n",
      "         8           0.5205            0.46s\n",
      "         9           0.5176            0.46s\n",
      "        10           0.5143            0.45s\n",
      "        20           0.4916            0.38s\n",
      "        30           0.4748            0.34s\n",
      "        40           0.4610            0.28s\n",
      "        50           0.4500            0.24s\n",
      "        60           0.4414            0.19s\n",
      "        70           0.4329            0.14s\n",
      "        80           0.4257            0.09s\n",
      "        90           0.4177            0.05s\n",
      "       100           0.4120            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.5160            0.50s\n",
      "         2           0.4992            0.55s\n",
      "         3           0.4872            0.48s\n",
      "         4           0.4762            0.48s\n",
      "         5           0.4556            0.47s\n",
      "         6           0.4423            0.50s\n",
      "         7           0.4356            0.42s\n",
      "         8           0.4245            0.46s\n",
      "         9           0.4130            0.45s\n",
      "        10           0.4085            0.45s\n",
      "        20           0.3642            0.40s\n",
      "        30           0.3375            0.34s\n",
      "        40           0.3232            0.29s\n",
      "        50           0.3116            0.24s\n",
      "        60           0.3026            0.20s\n",
      "        70           0.2951            0.15s\n",
      "        80           0.2878            0.10s\n",
      "        90           0.2823            0.05s\n",
      "       100           0.2770            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.7120            0.50s\n",
      "         2           0.6919            0.49s\n",
      "         3           0.6709            0.49s\n",
      "         4           0.6570            0.48s\n",
      "         5           0.6413            0.49s\n",
      "         6           0.6282            0.47s\n",
      "         7           0.6172            0.47s\n",
      "         8           0.6085            0.46s\n",
      "         9           0.6019            0.46s\n",
      "        10           0.5961            0.45s\n",
      "        20           0.5430            0.40s\n",
      "        30           0.5101            0.35s\n",
      "        40           0.4920            0.29s\n",
      "        50           0.4785            0.24s\n",
      "        60           0.4669            0.19s\n",
      "        70           0.4582            0.15s\n",
      "        80           0.4504            0.10s\n",
      "        90           0.4440            0.05s\n",
      "       100           0.4374            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.5170            0.48s\n",
      "         2           0.5080            0.51s\n",
      "         3           0.4964            0.49s\n",
      "         4           0.4665            0.47s\n",
      "         5           0.4596            0.47s\n",
      "         6           0.4517            0.44s\n",
      "         7           0.4479            0.46s\n",
      "         8           0.4437            0.46s\n",
      "         9           0.4319            0.47s\n",
      "        10           0.4279            0.41s\n",
      "        20           0.3904            0.40s\n",
      "        30           0.3710            0.35s\n",
      "        40           0.3549            0.29s\n",
      "        50           0.3426            0.24s\n",
      "        60           0.3329            0.20s\n",
      "        70           0.3234            0.15s\n",
      "        80           0.3147            0.10s\n",
      "        90           0.3086            0.05s\n",
      "       100           0.3015            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.7900            0.50s\n",
      "         2           0.7764            0.50s\n",
      "         3           0.7611            0.51s\n",
      "         4           0.7473            0.48s\n",
      "         5           0.7353            0.48s\n",
      "         6           0.7259            0.47s\n",
      "         7           0.7193            0.48s\n",
      "         8           0.7122            0.46s\n",
      "         9           0.7057            0.41s\n",
      "        10           0.6996            0.45s\n",
      "        20           0.6659            0.38s\n",
      "        30           0.6438            0.34s\n",
      "        40           0.6292            0.29s\n",
      "        50           0.6154            0.24s\n",
      "        60           0.6056            0.19s\n",
      "        70           0.5975            0.14s\n",
      "        80           0.5898            0.10s\n",
      "        90           0.5839            0.05s\n",
      "       100           0.5786            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.6911            0.46s\n",
      "         2           0.6708            0.23s\n",
      "         3           0.6592            0.49s\n",
      "         4           0.6483            0.50s\n",
      "         5           0.6354            0.48s\n",
      "         6           0.6271            0.46s\n",
      "         7           0.6177            0.46s\n",
      "         8           0.6116            0.46s\n",
      "         9           0.6067            0.45s\n",
      "        10           0.6007            0.45s\n",
      "        20           0.5578            0.39s\n",
      "        30           0.5337            0.33s\n",
      "        40           0.5193            0.28s\n",
      "        50           0.5082            0.24s\n",
      "        60           0.4993            0.20s\n",
      "        70           0.4916            0.15s\n",
      "        80           0.4843            0.10s\n",
      "        90           0.4790            0.05s\n",
      "       100           0.4733            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.7598            0.50s\n",
      "         2           0.7439            0.47s\n",
      "         3           0.7181            0.48s\n",
      "         4           0.7048            0.51s\n",
      "         5           0.6909            0.41s\n",
      "         6           0.6760            0.47s\n",
      "         7           0.6660            0.47s\n",
      "         8           0.6584            0.46s\n",
      "         9           0.6526            0.45s\n",
      "        10           0.6404            0.45s\n",
      "        20           0.5918            0.40s\n",
      "        30           0.5616            0.34s\n",
      "        40           0.5415            0.29s\n",
      "        50           0.5290            0.24s\n",
      "        60           0.5183            0.20s\n",
      "        70           0.5096            0.15s\n",
      "        80           0.5023            0.10s\n",
      "        90           0.4945            0.05s\n",
      "       100           0.4892            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.7059            0.91s\n",
      "         2           0.6620            0.88s\n",
      "         3           0.6329            0.58s\n",
      "         4           0.6115            0.55s\n",
      "         5           0.5897            0.53s\n",
      "         6           0.5698            0.53s\n",
      "         7           0.5547            0.54s\n",
      "         8           0.5404            0.58s\n",
      "         9           0.5274            0.51s\n",
      "        10           0.5172            0.54s\n",
      "        20           0.4634            0.47s\n",
      "        30           0.4357            0.40s\n",
      "        40           0.4206            0.34s\n",
      "        50           0.4101            0.27s\n",
      "        60           0.4023            0.22s\n",
      "        70           0.3957            0.17s\n",
      "        80           0.3899            0.11s\n",
      "        90           0.3851            0.05s\n",
      "       100           0.3795            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.6629            0.51s\n",
      "         2           0.6516            0.50s\n",
      "         3           0.6419            0.39s\n",
      "         4           0.6298            0.48s\n",
      "         5           0.6207            0.48s\n",
      "         6           0.6114            0.39s\n",
      "         7           0.6040            0.40s\n",
      "         8           0.5999            0.40s\n",
      "         9           0.5908            0.41s\n",
      "        10           0.5861            0.36s\n",
      "        20           0.5564            0.37s\n",
      "        30           0.5373            0.34s\n",
      "        40           0.5259            0.29s\n",
      "        50           0.5139            0.24s\n",
      "        60           0.5057            0.19s\n",
      "        70           0.4986            0.14s\n",
      "        80           0.4921            0.10s\n",
      "        90           0.4868            0.05s\n",
      "       100           0.4805            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.6431            0.55s\n",
      "         2           0.6316            0.57s\n",
      "         3           0.6159            0.54s\n",
      "         4           0.6061            0.52s\n",
      "         5           0.5981            0.43s\n",
      "         6           0.5864            0.44s\n",
      "         7           0.5789            0.44s\n",
      "         8           0.5731            0.44s\n",
      "         9           0.5661            0.39s\n",
      "        10           0.5590            0.47s\n",
      "        20           0.5239            0.39s\n",
      "        30           0.4993            0.35s\n",
      "        40           0.4853            0.29s\n",
      "        50           0.4733            0.24s\n",
      "        60           0.4620            0.19s\n",
      "        70           0.4539            0.14s\n",
      "        80           0.4476            0.10s\n",
      "        90           0.4420            0.05s\n",
      "       100           0.4366            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.2339            0.45s\n",
      "         2           1.2213            0.48s\n",
      "         3           1.2120            0.56s\n",
      "         4           1.2052            0.55s\n",
      "         5           1.1979            0.44s\n",
      "         6           1.1883            0.46s\n",
      "         7           1.1801            0.47s\n",
      "         8           1.1747            0.46s\n",
      "         9           1.1697            0.45s\n",
      "        10           1.1644            0.47s\n",
      "        20           1.1151            0.40s\n",
      "        30           1.0878            0.34s\n",
      "        40           1.0691            0.29s\n",
      "        50           1.0535            0.24s\n",
      "        60           1.0407            0.19s\n",
      "        70           1.0296            0.15s\n",
      "        80           1.0199            0.10s\n",
      "        90           1.0104            0.05s\n",
      "       100           1.0025            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.5903            0.51s\n",
      "         2           0.5857            0.25s\n",
      "         3           0.5822            0.49s\n",
      "         4           0.5793            0.36s\n",
      "         5           0.5701            0.38s\n",
      "         6           0.5632            0.40s\n",
      "         7           0.5597            0.34s\n",
      "         8           0.5573            0.41s\n",
      "         9           0.5514            0.36s\n",
      "        10           0.5450            0.44s\n",
      "        20           0.5193            0.38s\n",
      "        30           0.5027            0.34s\n",
      "        40           0.4927            0.28s\n",
      "        50           0.4827            0.24s\n",
      "        60           0.4753            0.19s\n",
      "        70           0.4677            0.14s\n",
      "        80           0.4609            0.09s\n",
      "        90           0.4553            0.05s\n",
      "       100           0.4499            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.6319            0.00s\n",
      "         2           0.6128            0.28s\n",
      "         3           0.5974            0.18s\n",
      "         4           0.5735            0.38s\n",
      "         5           0.5405            0.38s\n",
      "         6           0.5195            0.40s\n",
      "         7           0.5069            0.41s\n",
      "         8           0.4922            0.41s\n",
      "         9           0.4782            0.41s\n",
      "        10           0.4621            0.42s\n",
      "        20           0.3809            0.39s\n",
      "        30           0.3493            0.33s\n",
      "        40           0.3251            0.29s\n",
      "        50           0.3093            0.24s\n",
      "        60           0.2977            0.19s\n",
      "        70           0.2889            0.14s\n",
      "        80           0.2828            0.10s\n",
      "        90           0.2765            0.05s\n",
      "       100           0.2703            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1798            0.62s\n",
      "         2           1.1579            0.51s\n",
      "         3           1.1363            0.48s\n",
      "         4           1.1135            0.48s\n",
      "         5           1.0910            0.48s\n",
      "         6           1.0749            0.47s\n",
      "         7           1.0560            0.46s\n",
      "         8           1.0441            0.46s\n",
      "         9           1.0358            0.46s\n",
      "        10           1.0283            0.45s\n",
      "        20           0.9491            0.38s\n",
      "        30           0.9112            0.34s\n",
      "        40           0.8893            0.28s\n",
      "        50           0.8752            0.24s\n",
      "        60           0.8655            0.19s\n",
      "        70           0.8561            0.15s\n",
      "        80           0.8491            0.10s\n",
      "        90           0.8427            0.05s\n",
      "       100           0.8369            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.5653            0.57s\n",
      "         2           0.5477            0.49s\n",
      "         3           0.5384            0.49s\n",
      "         4           0.5291            0.48s\n",
      "         5           0.5151            0.48s\n",
      "         6           0.5101            0.47s\n",
      "         7           0.5033            0.46s\n",
      "         8           0.4972            0.46s\n",
      "         9           0.4924            0.40s\n",
      "        10           0.4864            0.45s\n",
      "        20           0.4487            0.38s\n",
      "        30           0.4275            0.34s\n",
      "        40           0.4143            0.30s\n",
      "        50           0.4043            0.24s\n",
      "        60           0.3949            0.19s\n",
      "        70           0.3875            0.15s\n",
      "        80           0.3817            0.10s\n",
      "        90           0.3751            0.05s\n",
      "       100           0.3699            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.2820            0.46s\n",
      "         2           0.2742            0.48s\n",
      "         3           0.2666            0.35s\n",
      "         4           0.2642            0.36s\n",
      "         5           0.2616            0.37s\n",
      "         6           0.2590            0.39s\n",
      "         7           0.2545            0.40s\n",
      "         8           0.2510            0.40s\n",
      "         9           0.2493            0.40s\n",
      "        10           0.2472            0.40s\n",
      "        20           0.2299            0.38s\n",
      "        30           0.2185            0.33s\n",
      "        40           0.2117            0.28s\n",
      "        50           0.2069            0.24s\n",
      "        60           0.2031            0.19s\n",
      "        70           0.1982            0.14s\n",
      "        80           0.1949            0.09s\n",
      "        90           0.1916            0.05s\n",
      "       100           0.1882            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.1608            0.50s\n",
      "         2           0.1578            0.49s\n",
      "         3           0.1569            0.49s\n",
      "         4           0.1545            0.49s\n",
      "         5           0.1536            0.48s\n",
      "         6           0.1529            0.49s\n",
      "         7           0.1520            0.47s\n",
      "         8           0.1508            0.46s\n",
      "         9           0.1501            0.46s\n",
      "        10           0.1492            0.46s\n",
      "        20           0.1420            0.38s\n",
      "        30           0.1362            0.34s\n",
      "        40           0.1300            0.29s\n",
      "        50           0.1261            0.24s\n",
      "        60           0.1225            0.19s\n",
      "        70           0.1182            0.14s\n",
      "        80           0.1150            0.10s\n",
      "        90           0.1116            0.05s\n",
      "       100           0.1091            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.3578            0.52s\n",
      "         2           0.3530            0.50s\n",
      "         3           0.3483            0.50s\n",
      "         4           0.3432            0.48s\n",
      "         5           0.3400            0.48s\n",
      "         6           0.3361            0.47s\n",
      "         7           0.3336            0.47s\n",
      "         8           0.3309            0.46s\n",
      "         9           0.3290            0.46s\n",
      "        10           0.3271            0.45s\n",
      "        20           0.3100            0.38s\n",
      "        30           0.2968            0.33s\n",
      "        40           0.2875            0.29s\n",
      "        50           0.2801            0.24s\n",
      "        60           0.2732            0.19s\n",
      "        70           0.2685            0.14s\n",
      "        80           0.2643            0.10s\n",
      "        90           0.2615            0.05s\n",
      "       100           0.2571            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.5320            0.50s\n",
      "         2           0.5176            0.49s\n",
      "         3           0.4973            0.49s\n",
      "         4           0.4855            0.49s\n",
      "         5           0.4739            0.48s\n",
      "         6           0.4619            0.46s\n",
      "         7           0.4529            0.47s\n",
      "         8           0.4437            0.46s\n",
      "         9           0.4375            0.41s\n",
      "        10           0.4295            0.41s\n",
      "        20           0.3945            0.38s\n",
      "        30           0.3723            0.33s\n",
      "        40           0.3575            0.29s\n",
      "        50           0.3464            0.24s\n",
      "        60           0.3381            0.19s\n",
      "        70           0.3305            0.14s\n",
      "        80           0.3257            0.10s\n",
      "        90           0.3201            0.05s\n",
      "       100           0.3153            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.5298            0.50s\n",
      "         2           0.5231            0.50s\n",
      "         3           0.5157            0.46s\n",
      "         4           0.5100            0.49s\n",
      "         5           0.5051            0.47s\n",
      "         6           0.5003            0.49s\n",
      "         7           0.4968            0.46s\n",
      "         8           0.4924            0.46s\n",
      "         9           0.4889            0.45s\n",
      "        10           0.4853            0.46s\n",
      "        20           0.4592            0.40s\n",
      "        30           0.4415            0.34s\n",
      "        40           0.4272            0.28s\n",
      "        50           0.4159            0.24s\n",
      "        60           0.4057            0.19s\n",
      "        70           0.3981            0.14s\n",
      "        80           0.3904            0.10s\n",
      "        90           0.3836            0.05s\n",
      "       100           0.3774            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.5241            0.48s\n",
      "         2           0.5041            0.48s\n",
      "         3           0.4906            0.32s\n",
      "         4           0.4787            0.39s\n",
      "         5           0.4566            0.31s\n",
      "         6           0.4427            0.39s\n",
      "         7           0.4355            0.40s\n",
      "         8           0.4233            0.40s\n",
      "         9           0.4118            0.40s\n",
      "        10           0.4075            0.40s\n",
      "        20           0.3624            0.38s\n",
      "        30           0.3364            0.33s\n",
      "        40           0.3221            0.30s\n",
      "        50           0.3099            0.26s\n",
      "        60           0.3015            0.20s\n",
      "        70           0.2942            0.15s\n",
      "        80           0.2885            0.10s\n",
      "        90           0.2835            0.05s\n",
      "       100           0.2785            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.7787            0.49s\n",
      "         2           0.7609            0.54s\n",
      "         3           0.7420            0.39s\n",
      "         4           0.7287            0.41s\n",
      "         5           0.7142            0.40s\n",
      "         6           0.7023            0.49s\n",
      "         7           0.6918            0.41s\n",
      "         8           0.6836            0.41s\n",
      "         9           0.6771            0.45s\n",
      "        10           0.6719            0.40s\n",
      "        20           0.6186            0.40s\n",
      "        30           0.5877            0.34s\n",
      "        40           0.5691            0.29s\n",
      "        50           0.5533            0.24s\n",
      "        60           0.5415            0.19s\n",
      "        70           0.5320            0.15s\n",
      "        80           0.5242            0.10s\n",
      "        90           0.5172            0.05s\n",
      "       100           0.5114            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.5218            0.35s\n",
      "         2           0.5133            0.42s\n",
      "         3           0.5032            0.44s\n",
      "         4           0.4744            0.49s\n",
      "         5           0.4682            0.52s\n",
      "         6           0.4608            0.51s\n",
      "         7           0.4565            0.50s\n",
      "         8           0.4527            0.51s\n",
      "         9           0.4403            0.49s\n",
      "        10           0.4360            0.50s\n",
      "        20           0.3976            0.41s\n",
      "        30           0.3763            0.36s\n",
      "        40           0.3619            0.30s\n",
      "        50           0.3500            0.25s\n",
      "        60           0.3393            0.20s\n",
      "        70           0.3287            0.15s\n",
      "        80           0.3212            0.10s\n",
      "        90           0.3148            0.05s\n",
      "       100           0.3084            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.7655            0.46s\n",
      "         2           0.7523            0.60s\n",
      "         3           0.7384            0.48s\n",
      "         4           0.7236            0.48s\n",
      "         5           0.7099            0.47s\n",
      "         6           0.7005            0.47s\n",
      "         7           0.6926            0.46s\n",
      "         8           0.6851            0.45s\n",
      "         9           0.6782            0.45s\n",
      "        10           0.6724            0.49s\n",
      "        20           0.6382            0.40s\n",
      "        30           0.6172            0.35s\n",
      "        40           0.6023            0.29s\n",
      "        50           0.5897            0.24s\n",
      "        60           0.5804            0.20s\n",
      "        70           0.5720            0.15s\n",
      "        80           0.5647            0.10s\n",
      "        90           0.5582            0.05s\n",
      "       100           0.5530            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.6613            0.40s\n",
      "         2           0.6421            0.50s\n",
      "         3           0.6302            0.33s\n",
      "         4           0.6207            0.49s\n",
      "         5           0.6084            0.39s\n",
      "         6           0.6026            0.48s\n",
      "         7           0.5940            0.41s\n",
      "         8           0.5877            0.47s\n",
      "         9           0.5837            0.42s\n",
      "        10           0.5780            0.44s\n",
      "        20           0.5373            0.37s\n",
      "        30           0.5152            0.34s\n",
      "        40           0.5002            0.29s\n",
      "        50           0.4892            0.24s\n",
      "        60           0.4802            0.19s\n",
      "        70           0.4725            0.15s\n",
      "        80           0.4663            0.10s\n",
      "        90           0.4604            0.05s\n",
      "       100           0.4550            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.6906            0.50s\n",
      "         2           0.6737            0.50s\n",
      "         3           0.6476            0.51s\n",
      "         4           0.6350            0.48s\n",
      "         5           0.6222            0.48s\n",
      "         6           0.6073            0.47s\n",
      "         7           0.5983            0.40s\n",
      "         8           0.5910            0.47s\n",
      "         9           0.5836            0.45s\n",
      "        10           0.5724            0.45s\n",
      "        20           0.5256            0.40s\n",
      "        30           0.4975            0.34s\n",
      "        40           0.4796            0.30s\n",
      "        50           0.4662            0.25s\n",
      "        60           0.4553            0.20s\n",
      "        70           0.4467            0.15s\n",
      "        80           0.4386            0.10s\n",
      "        90           0.4325            0.05s\n",
      "       100           0.4263            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.7001            0.50s\n",
      "         2           0.6579            0.50s\n",
      "         3           0.6300            0.50s\n",
      "         4           0.6097            0.48s\n",
      "         5           0.5880            0.48s\n",
      "         6           0.5671            0.47s\n",
      "         7           0.5525            0.53s\n",
      "         8           0.5382            0.54s\n",
      "         9           0.5258            0.54s\n",
      "        10           0.5161            0.53s\n",
      "        20           0.4642            0.42s\n",
      "        30           0.4361            0.36s\n",
      "        40           0.4208            0.31s\n",
      "        50           0.4093            0.25s\n",
      "        60           0.4018            0.20s\n",
      "        70           0.3951            0.15s\n",
      "        80           0.3896            0.10s\n",
      "        90           0.3835            0.05s\n",
      "       100           0.3785            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.6721            0.51s\n",
      "         2           0.6621            0.48s\n",
      "         3           0.6528            0.49s\n",
      "         4           0.6417            0.48s\n",
      "         5           0.6352            0.47s\n",
      "         6           0.6265            0.47s\n",
      "         7           0.6187            0.47s\n",
      "         8           0.6152            0.46s\n",
      "         9           0.6061            0.45s\n",
      "        10           0.6014            0.45s\n",
      "        20           0.5723            0.38s\n",
      "        30           0.5515            0.34s\n",
      "        40           0.5392            0.28s\n",
      "        50           0.5273            0.24s\n",
      "        60           0.5186            0.19s\n",
      "        70           0.5114            0.14s\n",
      "        80           0.5062            0.10s\n",
      "        90           0.5007            0.05s\n",
      "       100           0.4952            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.6456            0.50s\n",
      "         2           0.6355            0.63s\n",
      "         3           0.6200            0.42s\n",
      "         4           0.6108            0.49s\n",
      "         5           0.6034            0.48s\n",
      "         6           0.5926            0.48s\n",
      "         7           0.5855            0.47s\n",
      "         8           0.5794            0.46s\n",
      "         9           0.5729            0.49s\n",
      "        10           0.5661            0.51s\n",
      "        20           0.5313            0.44s\n",
      "        30           0.5074            0.36s\n",
      "        40           0.4940            0.30s\n",
      "        50           0.4831            0.26s\n",
      "        60           0.4732            0.20s\n",
      "        70           0.4655            0.15s\n",
      "        80           0.4592            0.10s\n",
      "        90           0.4529            0.05s\n",
      "       100           0.4480            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.2334            0.50s\n",
      "         2           1.2217            0.53s\n",
      "         3           1.2135            0.35s\n",
      "         4           1.2066            0.38s\n",
      "         5           1.2002            0.40s\n",
      "         6           1.1915            0.33s\n",
      "         7           1.1842            0.41s\n",
      "         8           1.1775            0.46s\n",
      "         9           1.1730            0.42s\n",
      "        10           1.1682            0.41s\n",
      "        20           1.1264            0.38s\n",
      "        30           1.1005            0.33s\n",
      "        40           1.0820            0.29s\n",
      "        50           1.0650            0.23s\n",
      "        60           1.0528            0.19s\n",
      "        70           1.0422            0.14s\n",
      "        80           1.0319            0.10s\n",
      "        90           1.0236            0.05s\n",
      "       100           1.0160            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.6262            0.45s\n",
      "         2           0.6205            0.48s\n",
      "         3           0.6160            0.51s\n",
      "         4           0.6125            0.48s\n",
      "         5           0.6039            0.47s\n",
      "         6           0.6010            0.46s\n",
      "         7           0.5973            0.49s\n",
      "         8           0.5943            0.48s\n",
      "         9           0.5879            0.46s\n",
      "        10           0.5813            0.47s\n",
      "        20           0.5537            0.40s\n",
      "        30           0.5368            0.35s\n",
      "        40           0.5264            0.30s\n",
      "        50           0.5156            0.25s\n",
      "        60           0.5086            0.20s\n",
      "        70           0.5000            0.15s\n",
      "        80           0.4930            0.10s\n",
      "        90           0.4879            0.05s\n",
      "       100           0.4817            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.5934            0.55s\n",
      "         2           0.5749            0.56s\n",
      "         3           0.5610            0.55s\n",
      "         4           0.5365            0.56s\n",
      "         5           0.5036            0.55s\n",
      "         6           0.4843            0.55s\n",
      "         7           0.4714            0.48s\n",
      "         8           0.4563            0.53s\n",
      "         9           0.4427            0.53s\n",
      "        10           0.4293            0.54s\n",
      "        20           0.3517            0.46s\n",
      "        30           0.3208            0.38s\n",
      "        40           0.2975            0.32s\n",
      "        50           0.2812            0.26s\n",
      "        60           0.2692            0.20s\n",
      "        70           0.2601            0.15s\n",
      "        80           0.2527            0.10s\n",
      "        90           0.2463            0.05s\n",
      "       100           0.2413            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1600            0.34s\n",
      "         2           1.1328            0.17s\n",
      "         3           1.1120            0.36s\n",
      "         4           1.0884            0.49s\n",
      "         5           1.0657            0.50s\n",
      "         6           1.0497            0.56s\n",
      "         7           1.0302            0.59s\n",
      "         8           1.0153            0.60s\n",
      "         9           1.0076            0.58s\n",
      "        10           0.9959            0.57s\n",
      "        20           0.9199            0.48s\n",
      "        30           0.8836            0.40s\n",
      "        40           0.8624            0.34s\n",
      "        50           0.8485            0.27s\n",
      "        60           0.8392            0.22s\n",
      "        70           0.8302            0.16s\n",
      "        80           0.8236            0.10s\n",
      "        90           0.8165            0.05s\n",
      "       100           0.8100            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.6839            0.66s\n",
      "         2           0.6618            0.53s\n",
      "         3           0.6481            0.49s\n",
      "         4           0.6365            0.52s\n",
      "         5           0.6185            0.41s\n",
      "         6           0.6116            0.47s\n",
      "         7           0.6037            0.47s\n",
      "         8           0.5947            0.48s\n",
      "         9           0.5891            0.42s\n",
      "        10           0.5821            0.45s\n",
      "        20           0.5362            0.41s\n",
      "        30           0.5111            0.35s\n",
      "        40           0.4948            0.29s\n",
      "        50           0.4832            0.25s\n",
      "        60           0.4743            0.20s\n",
      "        70           0.4655            0.15s\n",
      "        80           0.4590            0.10s\n",
      "        90           0.4519            0.05s\n",
      "       100           0.4464            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.5942            0.45s\n",
      "         2           0.5718            0.82s\n",
      "         3           0.5514            0.73s\n",
      "         4           0.5437            0.61s\n",
      "         5           0.5362            0.66s\n",
      "         6           0.5265            0.63s\n",
      "         7           0.5171            0.60s\n",
      "         8           0.5061            0.58s\n",
      "         9           0.5015            0.56s\n",
      "        10           0.4958            0.54s\n",
      "        20           0.4539            0.44s\n",
      "        30           0.4309            0.37s\n",
      "        40           0.4153            0.30s\n",
      "        50           0.4044            0.26s\n",
      "        60           0.3965            0.20s\n",
      "        70           0.3885            0.15s\n",
      "        80           0.3827            0.10s\n",
      "        90           0.3773            0.05s\n",
      "       100           0.3720            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.5612            0.86s\n",
      "         2           0.5591            0.67s\n",
      "         3           0.5564            0.61s\n",
      "         4           0.5544            0.53s\n",
      "         5           0.5518            0.54s\n",
      "         6           0.5500            0.53s\n",
      "         7           0.5476            0.52s\n",
      "         8           0.5462            0.46s\n",
      "         9           0.5446            0.49s\n",
      "        10           0.5429            0.44s\n",
      "        20           0.5289            0.40s\n",
      "        30           0.5182            0.35s\n",
      "        40           0.5104            0.29s\n",
      "        50           0.5035            0.25s\n",
      "        60           0.4980            0.20s\n",
      "        70           0.4917            0.15s\n",
      "        80           0.4858            0.10s\n",
      "        90           0.4806            0.05s\n",
      "       100           0.4753            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.6682            0.35s\n",
      "         2           0.6623            0.43s\n",
      "         3           0.6527            0.45s\n",
      "         4           0.6443            0.55s\n",
      "         5           0.6392            0.55s\n",
      "         6           0.6338            0.54s\n",
      "         7           0.6279            0.54s\n",
      "         8           0.6234            0.52s\n",
      "         9           0.6198            0.51s\n",
      "        10           0.6170            0.50s\n",
      "        20           0.5847            0.39s\n",
      "        30           0.5642            0.37s\n",
      "        40           0.5501            0.34s\n",
      "        50           0.5387            0.28s\n",
      "        60           0.5293            0.23s\n",
      "        70           0.5219            0.17s\n",
      "        80           0.5151            0.11s\n",
      "        90           0.5096            0.06s\n",
      "       100           0.5037            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.4663            0.46s\n",
      "         2           0.4545            0.48s\n",
      "         3           0.4342            0.46s\n",
      "         4           0.4242            0.49s\n",
      "         5           0.4122            0.47s\n",
      "         6           0.4023            0.46s\n",
      "         7           0.3950            0.46s\n",
      "         8           0.3898            0.41s\n",
      "         9           0.3843            0.45s\n",
      "        10           0.3770            0.44s\n",
      "        20           0.3447            0.38s\n",
      "        30           0.3252            0.34s\n",
      "        40           0.3122            0.28s\n",
      "        50           0.3023            0.24s\n",
      "        60           0.2953            0.19s\n",
      "        70           0.2893            0.14s\n",
      "        80           0.2838            0.09s\n",
      "        90           0.2788            0.05s\n",
      "       100           0.2746            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.1534            0.50s\n",
      "         2           0.1512            0.50s\n",
      "         3           0.1496            0.33s\n",
      "         4           0.1465            0.37s\n",
      "         5           0.1446            0.38s\n",
      "         6           0.1404            0.31s\n",
      "         7           0.1392            0.46s\n",
      "         8           0.1377            0.43s\n",
      "         9           0.1365            0.41s\n",
      "        10           0.1353            0.41s\n",
      "        20           0.1255            0.38s\n",
      "        30           0.1191            0.33s\n",
      "        40           0.1126            0.29s\n",
      "        50           0.1088            0.24s\n",
      "        60           0.1047            0.19s\n",
      "        70           0.1018            0.14s\n",
      "        80           0.0994            0.10s\n",
      "        90           0.0976            0.05s\n",
      "       100           0.0953            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.1364            0.45s\n",
      "         2           0.1326            0.50s\n",
      "         3           0.1305            0.48s\n",
      "         4           0.1282            0.48s\n",
      "         5           0.1219            0.49s\n",
      "         6           0.1202            0.41s\n",
      "         7           0.1190            0.46s\n",
      "         8           0.1164            0.51s\n",
      "         9           0.1138            0.48s\n",
      "        10           0.1125            0.49s\n",
      "        20           0.1003            0.42s\n",
      "        30           0.0927            0.37s\n",
      "        40           0.0875            0.31s\n",
      "        50           0.0834            0.27s\n",
      "        60           0.0801            0.21s\n",
      "        70           0.0769            0.16s\n",
      "        80           0.0733            0.10s\n",
      "        90           0.0709            0.05s\n",
      "       100           0.0687            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.5124            0.47s\n",
      "         2           0.5019            0.50s\n",
      "         3           0.4919            0.49s\n",
      "         4           0.4845            0.48s\n",
      "         5           0.4769            0.48s\n",
      "         6           0.4708            0.47s\n",
      "         7           0.4649            0.41s\n",
      "         8           0.4599            0.46s\n",
      "         9           0.4566            0.46s\n",
      "        10           0.4529            0.45s\n",
      "        20           0.4245            0.38s\n",
      "        30           0.4067            0.33s\n",
      "        40           0.3948            0.29s\n",
      "        50           0.3856            0.25s\n",
      "        60           0.3791            0.20s\n",
      "        70           0.3729            0.15s\n",
      "        80           0.3675            0.10s\n",
      "        90           0.3625            0.05s\n",
      "       100           0.3583            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.4441            0.50s\n",
      "         2           0.4353            0.55s\n",
      "         3           0.4254            0.36s\n",
      "         4           0.3966            0.49s\n",
      "         5           0.3911            0.47s\n",
      "         6           0.3844            0.48s\n",
      "         7           0.3809            0.47s\n",
      "         8           0.3778            0.46s\n",
      "         9           0.3669            0.46s\n",
      "        10           0.3624            0.45s\n",
      "        20           0.3299            0.42s\n",
      "        30           0.3112            0.36s\n",
      "        40           0.2984            0.30s\n",
      "        50           0.2867            0.25s\n",
      "        60           0.2789            0.20s\n",
      "        70           0.2697            0.15s\n",
      "        80           0.2626            0.10s\n",
      "        90           0.2571            0.05s\n",
      "       100           0.2505            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.7871            0.51s\n",
      "         2           0.7733            0.48s\n",
      "         3           0.7595            0.49s\n",
      "         4           0.7444            0.48s\n",
      "         5           0.7305            0.48s\n",
      "         6           0.7215            0.47s\n",
      "         7           0.7138            0.46s\n",
      "         8           0.7061            0.46s\n",
      "         9           0.6995            0.47s\n",
      "        10           0.6938            0.42s\n",
      "        20           0.6595            0.40s\n",
      "        30           0.6384            0.34s\n",
      "        40           0.6240            0.29s\n",
      "        50           0.6130            0.24s\n",
      "        60           0.6045            0.20s\n",
      "        70           0.5964            0.15s\n",
      "        80           0.5895            0.10s\n",
      "        90           0.5837            0.05s\n",
      "       100           0.5778            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.7333            0.61s\n",
      "         2           0.7125            0.48s\n",
      "         3           0.7002            0.48s\n",
      "         4           0.6886            0.48s\n",
      "         5           0.6753            0.47s\n",
      "         6           0.6693            0.46s\n",
      "         7           0.6596            0.39s\n",
      "         8           0.6524            0.46s\n",
      "         9           0.6485            0.46s\n",
      "        10           0.6424            0.45s\n",
      "        20           0.5970            0.40s\n",
      "        30           0.5725            0.34s\n",
      "        40           0.5572            0.29s\n",
      "        50           0.5457            0.24s\n",
      "        60           0.5378            0.19s\n",
      "        70           0.5300            0.15s\n",
      "        80           0.5227            0.10s\n",
      "        90           0.5159            0.05s\n",
      "       100           0.5102            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.6586            0.51s\n",
      "         2           0.6428            0.49s\n",
      "         3           0.6181            0.48s\n",
      "         4           0.6063            0.36s\n",
      "         5           0.5936            0.47s\n",
      "         6           0.5806            0.46s\n",
      "         7           0.5719            0.39s\n",
      "         8           0.5652            0.40s\n",
      "         9           0.5586            0.41s\n",
      "        10           0.5475            0.40s\n",
      "        20           0.5056            0.38s\n",
      "        30           0.4799            0.34s\n",
      "        40           0.4627            0.29s\n",
      "        50           0.4508            0.24s\n",
      "        60           0.4409            0.19s\n",
      "        70           0.4333            0.14s\n",
      "        80           0.4270            0.10s\n",
      "        90           0.4215            0.05s\n",
      "       100           0.4161            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.6839            0.00s\n",
      "         2           0.6417            0.50s\n",
      "         3           0.6139            0.48s\n",
      "         4           0.5945            0.36s\n",
      "         5           0.5734            0.38s\n",
      "         6           0.5531            0.43s\n",
      "         7           0.5387            0.36s\n",
      "         8           0.5245            0.41s\n",
      "         9           0.5118            0.40s\n",
      "        10           0.5026            0.41s\n",
      "        20           0.4516            0.41s\n",
      "        30           0.4235            0.35s\n",
      "        40           0.4075            0.29s\n",
      "        50           0.3964            0.25s\n",
      "        60           0.3886            0.20s\n",
      "        70           0.3810            0.15s\n",
      "        80           0.3758            0.10s\n",
      "        90           0.3709            0.05s\n",
      "       100           0.3661            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.6580            0.64s\n",
      "         2           0.6463            0.49s\n",
      "         3           0.6361            0.49s\n",
      "         4           0.6246            0.48s\n",
      "         5           0.6179            0.38s\n",
      "         6           0.6086            0.50s\n",
      "         7           0.6006            0.42s\n",
      "         8           0.5966            0.46s\n",
      "         9           0.5873            0.46s\n",
      "        10           0.5809            0.45s\n",
      "        20           0.5530            0.38s\n",
      "        30           0.5326            0.34s\n",
      "        40           0.5210            0.29s\n",
      "        50           0.5105            0.24s\n",
      "        60           0.5015            0.19s\n",
      "        70           0.4937            0.14s\n",
      "        80           0.4891            0.10s\n",
      "        90           0.4841            0.05s\n",
      "       100           0.4788            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.6387            0.45s\n",
      "         2           0.6277            0.48s\n",
      "         3           0.6115            0.48s\n",
      "         4           0.6021            0.48s\n",
      "         5           0.5942            0.40s\n",
      "         6           0.5826            0.47s\n",
      "         7           0.5743            0.46s\n",
      "         8           0.5680            0.49s\n",
      "         9           0.5609            0.43s\n",
      "        10           0.5538            0.45s\n",
      "        20           0.5178            0.43s\n",
      "        30           0.4935            0.36s\n",
      "        40           0.4799            0.31s\n",
      "        50           0.4685            0.26s\n",
      "        60           0.4597            0.20s\n",
      "        70           0.4519            0.15s\n",
      "        80           0.4459            0.10s\n",
      "        90           0.4392            0.05s\n",
      "       100           0.4345            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.2011            0.51s\n",
      "         2           1.1901            0.50s\n",
      "         3           1.1831            0.55s\n",
      "         4           1.1771            0.41s\n",
      "         5           1.1708            0.48s\n",
      "         6           1.1631            0.47s\n",
      "         7           1.1568            0.50s\n",
      "         8           1.1504            0.44s\n",
      "         9           1.1462            0.46s\n",
      "        10           1.1421            0.41s\n",
      "        20           1.1032            0.38s\n",
      "        30           1.0803            0.34s\n",
      "        40           1.0631            0.28s\n",
      "        50           1.0475            0.24s\n",
      "        60           1.0346            0.19s\n",
      "        70           1.0230            0.14s\n",
      "        80           1.0127            0.10s\n",
      "        90           1.0040            0.05s\n",
      "       100           0.9966            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.6129            0.46s\n",
      "         2           0.6075            0.48s\n",
      "         3           0.6040            0.48s\n",
      "         4           0.6005            0.47s\n",
      "         5           0.5913            0.47s\n",
      "         6           0.5841            0.47s\n",
      "         7           0.5801            0.46s\n",
      "         8           0.5780            0.46s\n",
      "         9           0.5715            0.45s\n",
      "        10           0.5652            0.45s\n",
      "        20           0.5419            0.40s\n",
      "        30           0.5224            0.35s\n",
      "        40           0.5109            0.29s\n",
      "        50           0.5003            0.24s\n",
      "        60           0.4932            0.19s\n",
      "        70           0.4843            0.15s\n",
      "        80           0.4787            0.10s\n",
      "        90           0.4734            0.05s\n",
      "       100           0.4679            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.6403            0.96s\n",
      "         2           0.6199            0.48s\n",
      "         3           0.6053            0.58s\n",
      "         4           0.5807            0.55s\n",
      "         5           0.5476            0.53s\n",
      "         6           0.5264            0.51s\n",
      "         7           0.5139            0.50s\n",
      "         8           0.4987            0.51s\n",
      "         9           0.4852            0.48s\n",
      "        10           0.4682            0.48s\n",
      "        20           0.3890            0.39s\n",
      "        30           0.3578            0.35s\n",
      "        40           0.3335            0.29s\n",
      "        50           0.3157            0.24s\n",
      "        60           0.3041            0.19s\n",
      "        70           0.2954            0.14s\n",
      "        80           0.2891            0.10s\n",
      "        90           0.2826            0.05s\n",
      "       100           0.2772            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1627            0.46s\n",
      "         2           1.1391            0.48s\n",
      "         3           1.1176            0.50s\n",
      "         4           1.0951            0.47s\n",
      "         5           1.0740            0.47s\n",
      "         6           1.0588            0.46s\n",
      "         7           1.0403            0.46s\n",
      "         8           1.0275            0.46s\n",
      "         9           1.0194            0.40s\n",
      "        10           1.0106            0.41s\n",
      "        20           0.9314            0.39s\n",
      "        30           0.8958            0.35s\n",
      "        40           0.8744            0.30s\n",
      "        50           0.8618            0.25s\n",
      "        60           0.8516            0.20s\n",
      "        70           0.8425            0.15s\n",
      "        80           0.8360            0.10s\n",
      "        90           0.8293            0.05s\n",
      "       100           0.8234            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.6246            0.61s\n",
      "         2           0.6035            0.30s\n",
      "         3           0.5911            0.48s\n",
      "         4           0.5800            0.48s\n",
      "         5           0.5632            0.48s\n",
      "         6           0.5569            0.47s\n",
      "         7           0.5490            0.46s\n",
      "         8           0.5423            0.46s\n",
      "         9           0.5369            0.46s\n",
      "        10           0.5298            0.45s\n",
      "        20           0.4868            0.38s\n",
      "        30           0.4634            0.34s\n",
      "        40           0.4479            0.29s\n",
      "        50           0.4371            0.24s\n",
      "        60           0.4288            0.19s\n",
      "        70           0.4214            0.15s\n",
      "        80           0.4148            0.10s\n",
      "        90           0.4091            0.05s\n",
      "       100           0.4043            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.5976            0.50s\n",
      "         2           0.5760            0.50s\n",
      "         3           0.5564            0.48s\n",
      "         4           0.5487            0.48s\n",
      "         5           0.5419            0.48s\n",
      "         6           0.5320            0.49s\n",
      "         7           0.5229            0.46s\n",
      "         8           0.5126            0.46s\n",
      "         9           0.5080            0.46s\n",
      "        10           0.5026            0.41s\n",
      "        20           0.4637            0.40s\n",
      "        30           0.4402            0.36s\n",
      "        40           0.4244            0.30s\n",
      "        50           0.4135            0.24s\n",
      "        60           0.4059            0.20s\n",
      "        70           0.3989            0.15s\n",
      "        80           0.3926            0.10s\n",
      "        90           0.3863            0.05s\n",
      "       100           0.3811            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.5557            0.60s\n",
      "         2           0.5537            0.59s\n",
      "         3           0.5508            0.55s\n",
      "         4           0.5487            0.53s\n",
      "         5           0.5462            0.50s\n",
      "         6           0.5445            0.49s\n",
      "         7           0.5424            0.41s\n",
      "         8           0.5406            0.48s\n",
      "         9           0.5388            0.46s\n",
      "        10           0.5366            0.46s\n",
      "        20           0.5243            0.40s\n",
      "        30           0.5138            0.34s\n",
      "        40           0.5064            0.29s\n",
      "        50           0.4992            0.24s\n",
      "        60           0.4929            0.19s\n",
      "        70           0.4866            0.14s\n",
      "        80           0.4803            0.10s\n",
      "        90           0.4758            0.05s\n",
      "       100           0.4721            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.6534            0.50s\n",
      "         2           0.6464            0.64s\n",
      "         3           0.6374            0.49s\n",
      "         4           0.6289            0.36s\n",
      "         5           0.6242            0.48s\n",
      "         6           0.6181            0.48s\n",
      "         7           0.6129            0.47s\n",
      "         8           0.6086            0.46s\n",
      "         9           0.6056            0.47s\n",
      "        10           0.6029            0.47s\n",
      "        20           0.5717            0.38s\n",
      "        30           0.5501            0.35s\n",
      "        40           0.5345            0.29s\n",
      "        50           0.5235            0.25s\n",
      "        60           0.5137            0.19s\n",
      "        70           0.5074            0.15s\n",
      "        80           0.5002            0.10s\n",
      "        90           0.4949            0.05s\n",
      "       100           0.4887            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.5632            0.35s\n",
      "         2           0.5488            0.42s\n",
      "         3           0.5266            0.44s\n",
      "         4           0.5148            0.45s\n",
      "         5           0.5022            0.45s\n",
      "         6           0.4895            0.44s\n",
      "         7           0.4808            0.46s\n",
      "         8           0.4748            0.46s\n",
      "         9           0.4694            0.47s\n",
      "        10           0.4595            0.42s\n",
      "        20           0.4215            0.39s\n",
      "        30           0.3983            0.34s\n",
      "        40           0.3810            0.28s\n",
      "        50           0.3692            0.25s\n",
      "        60           0.3611            0.20s\n",
      "        70           0.3537            0.15s\n",
      "        80           0.3480            0.10s\n",
      "        90           0.3434            0.05s\n",
      "       100           0.3369            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.5386            0.99s\n",
      "         2           0.5318            0.49s\n",
      "         3           0.5245            0.49s\n",
      "         4           0.5191            0.48s\n",
      "         5           0.5146            0.48s\n",
      "         6           0.5100            0.47s\n",
      "         7           0.5065            0.47s\n",
      "         8           0.5029            0.46s\n",
      "         9           0.5002            0.46s\n",
      "        10           0.4967            0.45s\n",
      "        20           0.4755            0.38s\n",
      "        30           0.4591            0.35s\n",
      "        40           0.4454            0.30s\n",
      "        50           0.4339            0.25s\n",
      "        60           0.4236            0.20s\n",
      "        70           0.4153            0.15s\n",
      "        80           0.4076            0.10s\n",
      "        90           0.4005            0.05s\n",
      "       100           0.3946            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.5137            0.51s\n",
      "         2           0.4952            0.50s\n",
      "         3           0.4831            0.48s\n",
      "         4           0.4728            0.35s\n",
      "         5           0.4524            0.38s\n",
      "         6           0.4400            0.47s\n",
      "         7           0.4336            0.46s\n",
      "         8           0.4225            0.46s\n",
      "         9           0.4113            0.40s\n",
      "        10           0.4067            0.41s\n",
      "        20           0.3635            0.40s\n",
      "        30           0.3382            0.34s\n",
      "        40           0.3253            0.30s\n",
      "        50           0.3143            0.24s\n",
      "        60           0.3061            0.20s\n",
      "        70           0.2996            0.15s\n",
      "        80           0.2934            0.10s\n",
      "        90           0.2888            0.05s\n",
      "       100           0.2843            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.7649            0.50s\n",
      "         2           0.7468            0.51s\n",
      "         3           0.7264            0.49s\n",
      "         4           0.7127            0.48s\n",
      "         5           0.6981            0.50s\n",
      "         6           0.6846            0.47s\n",
      "         7           0.6734            0.47s\n",
      "         8           0.6650            0.46s\n",
      "         9           0.6583            0.46s\n",
      "        10           0.6505            0.45s\n",
      "        20           0.5984            0.38s\n",
      "        30           0.5684            0.34s\n",
      "        40           0.5499            0.30s\n",
      "        50           0.5357            0.25s\n",
      "        60           0.5263            0.20s\n",
      "        70           0.5174            0.15s\n",
      "        80           0.5104            0.10s\n",
      "        90           0.5042            0.05s\n",
      "       100           0.4988            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.2100            0.50s\n",
      "         2           0.2079            0.50s\n",
      "         3           0.2053            0.51s\n",
      "         4           0.1906            0.48s\n",
      "         5           0.1887            0.48s\n",
      "         6           0.1867            0.39s\n",
      "         7           0.1853            0.48s\n",
      "         8           0.1840            0.46s\n",
      "         9           0.1804            0.46s\n",
      "        10           0.1790            0.45s\n",
      "        20           0.1646            0.41s\n",
      "        30           0.1555            0.35s\n",
      "        40           0.1488            0.30s\n",
      "        50           0.1431            0.25s\n",
      "        60           0.1386            0.20s\n",
      "        70           0.1346            0.15s\n",
      "        80           0.1314            0.10s\n",
      "        90           0.1280            0.05s\n",
      "       100           0.1245            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.5830            0.45s\n",
      "         2           0.5741            0.47s\n",
      "         3           0.5641            0.49s\n",
      "         4           0.5528            0.47s\n",
      "         5           0.5429            0.47s\n",
      "         6           0.5361            0.47s\n",
      "         7           0.5303            0.46s\n",
      "         8           0.5244            0.46s\n",
      "         9           0.5196            0.45s\n",
      "        10           0.5153            0.45s\n",
      "        20           0.4887            0.40s\n",
      "        30           0.4732            0.36s\n",
      "        40           0.4621            0.30s\n",
      "        50           0.4529            0.25s\n",
      "        60           0.4464            0.20s\n",
      "        70           0.4392            0.15s\n",
      "        80           0.4341            0.10s\n",
      "        90           0.4293            0.05s\n",
      "       100           0.4250            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.4619            0.50s\n",
      "         2           0.4480            0.47s\n",
      "         3           0.4392            0.48s\n",
      "         4           0.4317            0.48s\n",
      "         5           0.4229            0.47s\n",
      "         6           0.4178            0.47s\n",
      "         7           0.4126            0.46s\n",
      "         8           0.4084            0.46s\n",
      "         9           0.4061            0.45s\n",
      "        10           0.4025            0.45s\n",
      "        20           0.3784            0.40s\n",
      "        30           0.3631            0.35s\n",
      "        40           0.3519            0.29s\n",
      "        50           0.3440            0.24s\n",
      "        60           0.3381            0.19s\n",
      "        70           0.3322            0.15s\n",
      "        80           0.3267            0.10s\n",
      "        90           0.3215            0.05s\n",
      "       100           0.3173            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.4662            0.50s\n",
      "         2           0.4536            0.53s\n",
      "         3           0.4343            0.48s\n",
      "         4           0.4247            0.49s\n",
      "         5           0.4137            0.47s\n",
      "         6           0.4031            0.47s\n",
      "         7           0.3961            0.40s\n",
      "         8           0.3914            0.46s\n",
      "         9           0.3876            0.45s\n",
      "        10           0.3806            0.45s\n",
      "        20           0.3497            0.38s\n",
      "        30           0.3303            0.35s\n",
      "        40           0.3171            0.30s\n",
      "        50           0.3076            0.24s\n",
      "        60           0.2999            0.19s\n",
      "        70           0.2925            0.15s\n",
      "        80           0.2872            0.10s\n",
      "        90           0.2823            0.05s\n",
      "       100           0.2783            0.00s\n"
     ]
    }
   ],
   "source": [
    "# cross_validate the baseline model on the accuracy, precision, recall and f1\n",
    "gd_clf_scores = cross_validate(gd_clf,x_train,y_train, cv=5, scoring =calculate_scores_multi_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "916a2314-3913-4f5e-8f95-dd5dc8097015",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_accuracy': 89.61,\n",
       " 'test_precision': 71.08,\n",
       " 'test_recall': 60.74,\n",
       " 'test_f1': 60.94}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = ['test_accuracy', 'test_precision','test_recall', 'test_f1']\n",
    "validation_scores = {}\n",
    "for score in scores:\n",
    "    validation_scores[score] = round(gd_clf_scores[score].mean(), 2)\n",
    "validation_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec75eb54-9cd0-4628-9623-a5b7bed49266",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Log Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3c4ef00e-1d51-4fbf-94ec-535cadf8732f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Log the model's dataset train and test indices\n",
    "log_data(x_train,y_train,x_test,y_test)\n",
    "# Log the model, model description\n",
    "model = log_model(gd_clf,'Gradient Boost, multilabel, Data resampled')\n",
    "# Log the model's train and test scores\n",
    "log_metrics(train_scores, validation_scores)\n",
    "# track the model artifacts, validation scores with mlflow \n",
    "track_model(model,validation_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a18298-b423-415f-a724-92cb7794ff49",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Cat Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b9577466-a37a-4aec-a789-e8dc7cf1525b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.029123\n",
      "0:\tlearn: 0.1101801\ttotal: 267ms\tremaining: 4m 26s\n",
      "1:\tlearn: 0.1110388\ttotal: 404ms\tremaining: 3m 21s\n",
      "2:\tlearn: 0.1110295\ttotal: 539ms\tremaining: 2m 59s\n",
      "3:\tlearn: 0.1111404\ttotal: 683ms\tremaining: 2m 50s\n",
      "4:\tlearn: 0.1111911\ttotal: 830ms\tremaining: 2m 45s\n",
      "5:\tlearn: 0.1112004\ttotal: 974ms\tremaining: 2m 41s\n",
      "6:\tlearn: 0.1111357\ttotal: 1.13s\tremaining: 2m 39s\n",
      "7:\tlearn: 0.1111450\ttotal: 1.32s\tremaining: 2m 43s\n",
      "8:\tlearn: 0.1112050\ttotal: 1.47s\tremaining: 2m 42s\n",
      "9:\tlearn: 0.1111958\ttotal: 1.62s\tremaining: 2m 40s\n",
      "10:\tlearn: 0.1111773\ttotal: 1.77s\tremaining: 2m 39s\n",
      "11:\tlearn: 0.1111588\ttotal: 1.92s\tremaining: 2m 37s\n",
      "12:\tlearn: 0.1111588\ttotal: 2.06s\tremaining: 2m 36s\n",
      "13:\tlearn: 0.1111404\ttotal: 2.19s\tremaining: 2m 34s\n",
      "14:\tlearn: 0.1111127\ttotal: 2.32s\tremaining: 2m 32s\n",
      "15:\tlearn: 0.1111404\ttotal: 2.44s\tremaining: 2m 30s\n",
      "16:\tlearn: 0.1111357\ttotal: 2.57s\tremaining: 2m 28s\n",
      "17:\tlearn: 0.1111450\ttotal: 2.7s\tremaining: 2m 27s\n",
      "18:\tlearn: 0.1111542\ttotal: 2.83s\tremaining: 2m 26s\n",
      "19:\tlearn: 0.1111219\ttotal: 2.96s\tremaining: 2m 25s\n",
      "20:\tlearn: 0.1110619\ttotal: 3.1s\tremaining: 2m 24s\n",
      "21:\tlearn: 0.1110526\ttotal: 3.23s\tremaining: 2m 23s\n",
      "22:\tlearn: 0.1109926\ttotal: 3.36s\tremaining: 2m 22s\n",
      "23:\tlearn: 0.1109603\ttotal: 3.5s\tremaining: 2m 22s\n",
      "24:\tlearn: 0.1108910\ttotal: 3.63s\tremaining: 2m 21s\n",
      "25:\tlearn: 0.1109280\ttotal: 3.76s\tremaining: 2m 20s\n",
      "26:\tlearn: 0.1108126\ttotal: 3.89s\tremaining: 2m 20s\n",
      "27:\tlearn: 0.1107202\ttotal: 4.02s\tremaining: 2m 19s\n",
      "28:\tlearn: 0.1106787\ttotal: 4.15s\tremaining: 2m 19s\n",
      "29:\tlearn: 0.1106233\ttotal: 4.28s\tremaining: 2m 18s\n",
      "30:\tlearn: 0.1106325\ttotal: 4.41s\tremaining: 2m 17s\n",
      "31:\tlearn: 0.1104848\ttotal: 4.53s\tremaining: 2m 17s\n",
      "32:\tlearn: 0.1104386\ttotal: 4.66s\tremaining: 2m 16s\n",
      "33:\tlearn: 0.1103601\ttotal: 4.79s\tremaining: 2m 15s\n",
      "34:\tlearn: 0.1103001\ttotal: 4.91s\tremaining: 2m 15s\n",
      "35:\tlearn: 0.1101570\ttotal: 5.04s\tremaining: 2m 14s\n",
      "36:\tlearn: 0.1100139\ttotal: 5.18s\tremaining: 2m 14s\n",
      "37:\tlearn: 0.1099584\ttotal: 5.31s\tremaining: 2m 14s\n",
      "38:\tlearn: 0.1098246\ttotal: 5.44s\tremaining: 2m 13s\n",
      "39:\tlearn: 0.1097553\ttotal: 5.56s\tremaining: 2m 13s\n",
      "40:\tlearn: 0.1097553\ttotal: 5.7s\tremaining: 2m 13s\n",
      "41:\tlearn: 0.1096399\ttotal: 5.83s\tremaining: 2m 12s\n",
      "42:\tlearn: 0.1093490\ttotal: 5.95s\tremaining: 2m 12s\n",
      "43:\tlearn: 0.1092798\ttotal: 6.09s\tremaining: 2m 12s\n",
      "44:\tlearn: 0.1092151\ttotal: 6.22s\tremaining: 2m 12s\n",
      "45:\tlearn: 0.1090443\ttotal: 6.35s\tremaining: 2m 11s\n",
      "46:\tlearn: 0.1087812\ttotal: 6.49s\tremaining: 2m 11s\n",
      "47:\tlearn: 0.1087442\ttotal: 6.62s\tremaining: 2m 11s\n",
      "48:\tlearn: 0.1086288\ttotal: 6.75s\tremaining: 2m 11s\n",
      "49:\tlearn: 0.1085734\ttotal: 6.89s\tremaining: 2m 10s\n",
      "50:\tlearn: 0.1084626\ttotal: 7.03s\tremaining: 2m 10s\n",
      "51:\tlearn: 0.1083102\ttotal: 7.17s\tremaining: 2m 10s\n",
      "52:\tlearn: 0.1082872\ttotal: 7.29s\tremaining: 2m 10s\n",
      "53:\tlearn: 0.1080702\ttotal: 7.42s\tremaining: 2m 10s\n",
      "54:\tlearn: 0.1080471\ttotal: 7.55s\tremaining: 2m 9s\n",
      "55:\tlearn: 0.1079086\ttotal: 7.68s\tremaining: 2m 9s\n",
      "56:\tlearn: 0.1076962\ttotal: 7.85s\tremaining: 2m 9s\n",
      "57:\tlearn: 0.1077054\ttotal: 7.98s\tremaining: 2m 9s\n",
      "58:\tlearn: 0.1077193\ttotal: 8.12s\tremaining: 2m 9s\n",
      "59:\tlearn: 0.1076454\ttotal: 8.25s\tremaining: 2m 9s\n",
      "60:\tlearn: 0.1075115\ttotal: 8.38s\tremaining: 2m 8s\n",
      "61:\tlearn: 0.1073176\ttotal: 8.52s\tremaining: 2m 8s\n",
      "62:\tlearn: 0.1072114\ttotal: 8.65s\tremaining: 2m 8s\n",
      "63:\tlearn: 0.1070822\ttotal: 8.8s\tremaining: 2m 8s\n",
      "64:\tlearn: 0.1069529\ttotal: 8.96s\tremaining: 2m 8s\n",
      "65:\tlearn: 0.1068606\ttotal: 9.1s\tremaining: 2m 8s\n",
      "66:\tlearn: 0.1067036\ttotal: 9.27s\tremaining: 2m 9s\n",
      "67:\tlearn: 0.1066020\ttotal: 9.46s\tremaining: 2m 9s\n",
      "68:\tlearn: 0.1065512\ttotal: 9.63s\tremaining: 2m 9s\n",
      "69:\tlearn: 0.1064497\ttotal: 9.8s\tremaining: 2m 10s\n",
      "70:\tlearn: 0.1063204\ttotal: 9.94s\tremaining: 2m 9s\n",
      "71:\tlearn: 0.1061681\ttotal: 10.1s\tremaining: 2m 9s\n",
      "72:\tlearn: 0.1060480\ttotal: 10.2s\tremaining: 2m 9s\n",
      "73:\tlearn: 0.1059880\ttotal: 10.3s\tremaining: 2m 9s\n",
      "74:\tlearn: 0.1058587\ttotal: 10.5s\tremaining: 2m 9s\n",
      "75:\tlearn: 0.1057018\ttotal: 10.6s\tremaining: 2m 9s\n",
      "76:\tlearn: 0.1056925\ttotal: 10.8s\tremaining: 2m 9s\n",
      "77:\tlearn: 0.1055633\ttotal: 10.9s\tremaining: 2m 9s\n",
      "78:\tlearn: 0.1055540\ttotal: 11.1s\tremaining: 2m 9s\n",
      "79:\tlearn: 0.1054109\ttotal: 11.3s\tremaining: 2m 9s\n",
      "80:\tlearn: 0.1052308\ttotal: 11.4s\tremaining: 2m 9s\n",
      "81:\tlearn: 0.1051062\ttotal: 11.6s\tremaining: 2m 9s\n",
      "82:\tlearn: 0.1049908\ttotal: 11.7s\tremaining: 2m 9s\n",
      "83:\tlearn: 0.1048338\ttotal: 11.9s\tremaining: 2m 9s\n",
      "84:\tlearn: 0.1047091\ttotal: 12.1s\tremaining: 2m 9s\n",
      "85:\tlearn: 0.1045429\ttotal: 12.2s\tremaining: 2m 10s\n",
      "86:\tlearn: 0.1044137\ttotal: 12.4s\tremaining: 2m 10s\n",
      "87:\tlearn: 0.1042428\ttotal: 12.6s\tremaining: 2m 10s\n",
      "88:\tlearn: 0.1041043\ttotal: 12.8s\tremaining: 2m 10s\n",
      "89:\tlearn: 0.1039705\ttotal: 13s\tremaining: 2m 11s\n",
      "90:\tlearn: 0.1039289\ttotal: 13.1s\tremaining: 2m 11s\n",
      "91:\tlearn: 0.1037304\ttotal: 13.3s\tremaining: 2m 11s\n",
      "92:\tlearn: 0.1036473\ttotal: 13.4s\tremaining: 2m 11s\n",
      "93:\tlearn: 0.1035503\ttotal: 13.6s\tremaining: 2m 11s\n",
      "94:\tlearn: 0.1033795\ttotal: 13.7s\tremaining: 2m 10s\n",
      "95:\tlearn: 0.1033149\ttotal: 13.9s\tremaining: 2m 10s\n",
      "96:\tlearn: 0.1032779\ttotal: 14s\tremaining: 2m 10s\n",
      "97:\tlearn: 0.1031856\ttotal: 14.2s\tremaining: 2m 10s\n",
      "98:\tlearn: 0.1030794\ttotal: 14.4s\tremaining: 2m 10s\n",
      "99:\tlearn: 0.1029363\ttotal: 14.6s\tremaining: 2m 10s\n",
      "100:\tlearn: 0.1027147\ttotal: 14.7s\tremaining: 2m 11s\n",
      "101:\tlearn: 0.1027239\ttotal: 14.9s\tremaining: 2m 10s\n",
      "102:\tlearn: 0.1026916\ttotal: 15s\tremaining: 2m 10s\n",
      "103:\tlearn: 0.1025669\ttotal: 15.1s\tremaining: 2m 10s\n",
      "104:\tlearn: 0.1024331\ttotal: 15.3s\tremaining: 2m 10s\n",
      "105:\tlearn: 0.1022807\ttotal: 15.4s\tremaining: 2m 10s\n",
      "106:\tlearn: 0.1020683\ttotal: 15.6s\tremaining: 2m 10s\n",
      "107:\tlearn: 0.1019806\ttotal: 15.7s\tremaining: 2m 9s\n",
      "108:\tlearn: 0.1018329\ttotal: 15.9s\tremaining: 2m 10s\n",
      "109:\tlearn: 0.1017405\ttotal: 16.1s\tremaining: 2m 9s\n",
      "110:\tlearn: 0.1014681\ttotal: 16.2s\tremaining: 2m 9s\n",
      "111:\tlearn: 0.1013435\ttotal: 16.4s\tremaining: 2m 9s\n",
      "112:\tlearn: 0.1012004\ttotal: 16.5s\tremaining: 2m 9s\n",
      "113:\tlearn: 0.1011542\ttotal: 16.7s\tremaining: 2m 9s\n",
      "114:\tlearn: 0.1010896\ttotal: 16.8s\tremaining: 2m 9s\n",
      "115:\tlearn: 0.1010480\ttotal: 17s\tremaining: 2m 9s\n",
      "116:\tlearn: 0.1009418\ttotal: 17.1s\tremaining: 2m 9s\n",
      "117:\tlearn: 0.1008772\ttotal: 17.3s\tremaining: 2m 9s\n",
      "118:\tlearn: 0.1007895\ttotal: 17.4s\tremaining: 2m 9s\n",
      "119:\tlearn: 0.1006694\ttotal: 17.6s\tremaining: 2m 8s\n",
      "120:\tlearn: 0.1006094\ttotal: 17.7s\tremaining: 2m 8s\n",
      "121:\tlearn: 0.1005078\ttotal: 17.9s\tremaining: 2m 8s\n",
      "122:\tlearn: 0.1004386\ttotal: 18s\tremaining: 2m 8s\n",
      "123:\tlearn: 0.1002632\ttotal: 18.2s\tremaining: 2m 8s\n",
      "124:\tlearn: 0.1001708\ttotal: 18.4s\tremaining: 2m 8s\n",
      "125:\tlearn: 0.1001016\ttotal: 18.5s\tremaining: 2m 8s\n",
      "126:\tlearn: 0.1000277\ttotal: 18.6s\tremaining: 2m 8s\n",
      "127:\tlearn: 0.0998384\ttotal: 18.8s\tremaining: 2m 8s\n",
      "128:\tlearn: 0.0998430\ttotal: 19s\tremaining: 2m 7s\n",
      "129:\tlearn: 0.0996999\ttotal: 19.1s\tremaining: 2m 7s\n",
      "130:\tlearn: 0.0995937\ttotal: 19.3s\tremaining: 2m 7s\n",
      "131:\tlearn: 0.0994506\ttotal: 19.4s\tremaining: 2m 7s\n",
      "132:\tlearn: 0.0992982\ttotal: 19.6s\tremaining: 2m 7s\n",
      "133:\tlearn: 0.0991874\ttotal: 19.7s\tremaining: 2m 7s\n",
      "134:\tlearn: 0.0990997\ttotal: 19.9s\tremaining: 2m 7s\n",
      "135:\tlearn: 0.0990212\ttotal: 20s\tremaining: 2m 7s\n",
      "136:\tlearn: 0.0989151\ttotal: 20.2s\tremaining: 2m 7s\n",
      "137:\tlearn: 0.0987996\ttotal: 20.3s\tremaining: 2m 6s\n",
      "138:\tlearn: 0.0987535\ttotal: 20.5s\tremaining: 2m 6s\n",
      "139:\tlearn: 0.0986796\ttotal: 20.6s\tremaining: 2m 6s\n",
      "140:\tlearn: 0.0984949\ttotal: 20.7s\tremaining: 2m 6s\n",
      "141:\tlearn: 0.0984395\ttotal: 20.9s\tremaining: 2m 6s\n",
      "142:\tlearn: 0.0983657\ttotal: 21s\tremaining: 2m 5s\n",
      "143:\tlearn: 0.0983518\ttotal: 21.1s\tremaining: 2m 5s\n",
      "144:\tlearn: 0.0982133\ttotal: 21.3s\tremaining: 2m 5s\n",
      "145:\tlearn: 0.0981071\ttotal: 21.4s\tremaining: 2m 5s\n",
      "146:\tlearn: 0.0980102\ttotal: 21.5s\tremaining: 2m 4s\n",
      "147:\tlearn: 0.0978209\ttotal: 21.7s\tremaining: 2m 4s\n",
      "148:\tlearn: 0.0976962\ttotal: 21.8s\tremaining: 2m 4s\n",
      "149:\tlearn: 0.0976962\ttotal: 22s\tremaining: 2m 4s\n",
      "150:\tlearn: 0.0976177\ttotal: 22.1s\tremaining: 2m 4s\n",
      "151:\tlearn: 0.0975115\ttotal: 22.3s\tremaining: 2m 4s\n",
      "152:\tlearn: 0.0973638\ttotal: 22.4s\tremaining: 2m 4s\n",
      "153:\tlearn: 0.0972392\ttotal: 22.6s\tremaining: 2m 4s\n",
      "154:\tlearn: 0.0971560\ttotal: 22.7s\tremaining: 2m 3s\n",
      "155:\tlearn: 0.0970083\ttotal: 22.9s\tremaining: 2m 3s\n",
      "156:\tlearn: 0.0969114\ttotal: 23s\tremaining: 2m 3s\n",
      "157:\tlearn: 0.0968144\ttotal: 23.2s\tremaining: 2m 3s\n",
      "158:\tlearn: 0.0966805\ttotal: 23.3s\tremaining: 2m 3s\n",
      "159:\tlearn: 0.0966297\ttotal: 23.5s\tremaining: 2m 3s\n",
      "160:\tlearn: 0.0965051\ttotal: 23.6s\tremaining: 2m 3s\n",
      "161:\tlearn: 0.0964220\ttotal: 23.8s\tremaining: 2m 3s\n",
      "162:\tlearn: 0.0963250\ttotal: 23.9s\tremaining: 2m 2s\n",
      "163:\tlearn: 0.0962604\ttotal: 24.1s\tremaining: 2m 2s\n",
      "164:\tlearn: 0.0961588\ttotal: 24.3s\tremaining: 2m 2s\n",
      "165:\tlearn: 0.0960619\ttotal: 24.4s\tremaining: 2m 2s\n",
      "166:\tlearn: 0.0960111\ttotal: 24.5s\tremaining: 2m 2s\n",
      "167:\tlearn: 0.0959788\ttotal: 24.7s\tremaining: 2m 2s\n",
      "168:\tlearn: 0.0958126\ttotal: 24.8s\tremaining: 2m 2s\n",
      "169:\tlearn: 0.0958356\ttotal: 25s\tremaining: 2m 1s\n",
      "170:\tlearn: 0.0957387\ttotal: 25.1s\tremaining: 2m 1s\n",
      "171:\tlearn: 0.0955771\ttotal: 25.3s\tremaining: 2m 1s\n",
      "172:\tlearn: 0.0955863\ttotal: 25.5s\tremaining: 2m 1s\n",
      "173:\tlearn: 0.0954986\ttotal: 25.6s\tremaining: 2m 1s\n",
      "174:\tlearn: 0.0954063\ttotal: 25.8s\tremaining: 2m 1s\n",
      "175:\tlearn: 0.0952585\ttotal: 25.9s\tremaining: 2m 1s\n",
      "176:\tlearn: 0.0952031\ttotal: 26.1s\tremaining: 2m 1s\n",
      "177:\tlearn: 0.0951524\ttotal: 26.2s\tremaining: 2m 1s\n",
      "178:\tlearn: 0.0951708\ttotal: 26.4s\tremaining: 2m\n",
      "179:\tlearn: 0.0950831\ttotal: 26.5s\tremaining: 2m\n",
      "180:\tlearn: 0.0950554\ttotal: 26.7s\tremaining: 2m\n",
      "181:\tlearn: 0.0949861\ttotal: 26.9s\tremaining: 2m\n",
      "182:\tlearn: 0.0948984\ttotal: 27.1s\tremaining: 2m\n",
      "183:\tlearn: 0.0948569\ttotal: 27.3s\tremaining: 2m 1s\n",
      "184:\tlearn: 0.0948384\ttotal: 27.5s\tremaining: 2m 1s\n",
      "185:\tlearn: 0.0946907\ttotal: 27.7s\tremaining: 2m 1s\n",
      "186:\tlearn: 0.0945891\ttotal: 27.9s\tremaining: 2m 1s\n",
      "187:\tlearn: 0.0945199\ttotal: 28s\tremaining: 2m 1s\n",
      "188:\tlearn: 0.0944598\ttotal: 28.2s\tremaining: 2m 1s\n",
      "189:\tlearn: 0.0943813\ttotal: 28.4s\tremaining: 2m\n",
      "190:\tlearn: 0.0943121\ttotal: 28.5s\tremaining: 2m\n",
      "191:\tlearn: 0.0942290\ttotal: 28.7s\tremaining: 2m\n",
      "192:\tlearn: 0.0941367\ttotal: 28.8s\tremaining: 2m\n",
      "193:\tlearn: 0.0939797\ttotal: 28.9s\tremaining: 2m\n",
      "194:\tlearn: 0.0939104\ttotal: 29.1s\tremaining: 2m\n",
      "195:\tlearn: 0.0938504\ttotal: 29.2s\tremaining: 1m 59s\n",
      "196:\tlearn: 0.0937950\ttotal: 29.4s\tremaining: 1m 59s\n",
      "197:\tlearn: 0.0937211\ttotal: 29.5s\tremaining: 1m 59s\n",
      "198:\tlearn: 0.0936288\ttotal: 29.7s\tremaining: 1m 59s\n",
      "199:\tlearn: 0.0935272\ttotal: 29.8s\tremaining: 1m 59s\n",
      "200:\tlearn: 0.0934903\ttotal: 29.9s\tremaining: 1m 59s\n",
      "201:\tlearn: 0.0934349\ttotal: 30.1s\tremaining: 1m 58s\n",
      "202:\tlearn: 0.0933380\ttotal: 30.2s\tremaining: 1m 58s\n",
      "203:\tlearn: 0.0931948\ttotal: 30.4s\tremaining: 1m 58s\n",
      "204:\tlearn: 0.0931764\ttotal: 30.5s\tremaining: 1m 58s\n",
      "205:\tlearn: 0.0931025\ttotal: 30.6s\tremaining: 1m 58s\n",
      "206:\tlearn: 0.0930332\ttotal: 30.8s\tremaining: 1m 57s\n",
      "207:\tlearn: 0.0930102\ttotal: 30.9s\tremaining: 1m 57s\n",
      "208:\tlearn: 0.0929825\ttotal: 31s\tremaining: 1m 57s\n",
      "209:\tlearn: 0.0928855\ttotal: 31.2s\tremaining: 1m 57s\n",
      "210:\tlearn: 0.0928947\ttotal: 31.3s\tremaining: 1m 57s\n",
      "211:\tlearn: 0.0928116\ttotal: 31.4s\tremaining: 1m 56s\n",
      "212:\tlearn: 0.0927054\ttotal: 31.6s\tremaining: 1m 56s\n",
      "213:\tlearn: 0.0926177\ttotal: 31.7s\tremaining: 1m 56s\n",
      "214:\tlearn: 0.0925162\ttotal: 31.8s\tremaining: 1m 56s\n",
      "215:\tlearn: 0.0924746\ttotal: 31.9s\tremaining: 1m 55s\n",
      "216:\tlearn: 0.0924331\ttotal: 32.1s\tremaining: 1m 55s\n",
      "217:\tlearn: 0.0923684\ttotal: 32.2s\tremaining: 1m 55s\n",
      "218:\tlearn: 0.0923176\ttotal: 32.3s\tremaining: 1m 55s\n",
      "219:\tlearn: 0.0922946\ttotal: 32.5s\tremaining: 1m 55s\n",
      "220:\tlearn: 0.0921837\ttotal: 32.6s\tremaining: 1m 54s\n",
      "221:\tlearn: 0.0921653\ttotal: 32.7s\tremaining: 1m 54s\n",
      "222:\tlearn: 0.0920406\ttotal: 32.9s\tremaining: 1m 54s\n",
      "223:\tlearn: 0.0920314\ttotal: 33s\tremaining: 1m 54s\n",
      "224:\tlearn: 0.0919668\ttotal: 33.1s\tremaining: 1m 54s\n",
      "225:\tlearn: 0.0918283\ttotal: 33.2s\tremaining: 1m 53s\n",
      "226:\tlearn: 0.0917729\ttotal: 33.4s\tremaining: 1m 53s\n",
      "227:\tlearn: 0.0916805\ttotal: 33.5s\tremaining: 1m 53s\n",
      "228:\tlearn: 0.0915605\ttotal: 33.6s\tremaining: 1m 53s\n",
      "229:\tlearn: 0.0914912\ttotal: 33.8s\tremaining: 1m 53s\n",
      "230:\tlearn: 0.0913943\ttotal: 33.9s\tremaining: 1m 52s\n",
      "231:\tlearn: 0.0913019\ttotal: 34s\tremaining: 1m 52s\n",
      "232:\tlearn: 0.0912465\ttotal: 34.2s\tremaining: 1m 52s\n",
      "233:\tlearn: 0.0912558\ttotal: 34.3s\tremaining: 1m 52s\n",
      "234:\tlearn: 0.0911219\ttotal: 34.4s\tremaining: 1m 52s\n",
      "235:\tlearn: 0.0911265\ttotal: 34.6s\tremaining: 1m 51s\n",
      "236:\tlearn: 0.0909695\ttotal: 34.7s\tremaining: 1m 51s\n",
      "237:\tlearn: 0.0908633\ttotal: 34.8s\tremaining: 1m 51s\n",
      "238:\tlearn: 0.0908864\ttotal: 34.9s\tremaining: 1m 51s\n",
      "239:\tlearn: 0.0907664\ttotal: 35.1s\tremaining: 1m 51s\n",
      "240:\tlearn: 0.0907756\ttotal: 35.2s\tremaining: 1m 50s\n",
      "241:\tlearn: 0.0907110\ttotal: 35.3s\tremaining: 1m 50s\n",
      "242:\tlearn: 0.0906187\ttotal: 35.5s\tremaining: 1m 50s\n",
      "243:\tlearn: 0.0905633\ttotal: 35.6s\tremaining: 1m 50s\n",
      "244:\tlearn: 0.0905448\ttotal: 35.7s\tremaining: 1m 50s\n",
      "245:\tlearn: 0.0903647\ttotal: 35.9s\tremaining: 1m 49s\n",
      "246:\tlearn: 0.0902678\ttotal: 36s\tremaining: 1m 49s\n",
      "247:\tlearn: 0.0901754\ttotal: 36.1s\tremaining: 1m 49s\n",
      "248:\tlearn: 0.0901570\ttotal: 36.2s\tremaining: 1m 49s\n",
      "249:\tlearn: 0.0900462\ttotal: 36.4s\tremaining: 1m 49s\n",
      "250:\tlearn: 0.0900046\ttotal: 36.5s\tremaining: 1m 48s\n",
      "251:\tlearn: 0.0899123\ttotal: 36.6s\tremaining: 1m 48s\n",
      "252:\tlearn: 0.0898707\ttotal: 36.8s\tremaining: 1m 48s\n",
      "253:\tlearn: 0.0898384\ttotal: 36.9s\tremaining: 1m 48s\n",
      "254:\tlearn: 0.0898707\ttotal: 37s\tremaining: 1m 48s\n",
      "255:\tlearn: 0.0897876\ttotal: 37.2s\tremaining: 1m 47s\n",
      "256:\tlearn: 0.0897692\ttotal: 37.3s\tremaining: 1m 47s\n",
      "257:\tlearn: 0.0896584\ttotal: 37.4s\tremaining: 1m 47s\n",
      "258:\tlearn: 0.0896260\ttotal: 37.5s\tremaining: 1m 47s\n",
      "259:\tlearn: 0.0895291\ttotal: 37.7s\tremaining: 1m 47s\n",
      "260:\tlearn: 0.0895753\ttotal: 37.8s\tremaining: 1m 47s\n",
      "261:\tlearn: 0.0895337\ttotal: 37.9s\tremaining: 1m 46s\n",
      "262:\tlearn: 0.0894321\ttotal: 38.1s\tremaining: 1m 46s\n",
      "263:\tlearn: 0.0894044\ttotal: 38.2s\tremaining: 1m 46s\n",
      "264:\tlearn: 0.0893998\ttotal: 38.3s\tremaining: 1m 46s\n",
      "265:\tlearn: 0.0893259\ttotal: 38.5s\tremaining: 1m 46s\n",
      "266:\tlearn: 0.0893029\ttotal: 38.6s\tremaining: 1m 45s\n",
      "267:\tlearn: 0.0891736\ttotal: 38.7s\tremaining: 1m 45s\n",
      "268:\tlearn: 0.0891413\ttotal: 38.8s\tremaining: 1m 45s\n",
      "269:\tlearn: 0.0890905\ttotal: 39s\tremaining: 1m 45s\n",
      "270:\tlearn: 0.0890766\ttotal: 39.1s\tremaining: 1m 45s\n",
      "271:\tlearn: 0.0889751\ttotal: 39.2s\tremaining: 1m 45s\n",
      "272:\tlearn: 0.0889612\ttotal: 39.4s\tremaining: 1m 44s\n",
      "273:\tlearn: 0.0889381\ttotal: 39.5s\tremaining: 1m 44s\n",
      "274:\tlearn: 0.0888920\ttotal: 39.6s\tremaining: 1m 44s\n",
      "275:\tlearn: 0.0888273\ttotal: 39.8s\tremaining: 1m 44s\n",
      "276:\tlearn: 0.0887442\ttotal: 39.9s\tremaining: 1m 44s\n",
      "277:\tlearn: 0.0886519\ttotal: 40s\tremaining: 1m 43s\n",
      "278:\tlearn: 0.0886242\ttotal: 40.1s\tremaining: 1m 43s\n",
      "279:\tlearn: 0.0885365\ttotal: 40.3s\tremaining: 1m 43s\n",
      "280:\tlearn: 0.0885226\ttotal: 40.4s\tremaining: 1m 43s\n",
      "281:\tlearn: 0.0885042\ttotal: 40.5s\tremaining: 1m 43s\n",
      "282:\tlearn: 0.0884857\ttotal: 40.7s\tremaining: 1m 43s\n",
      "283:\tlearn: 0.0884164\ttotal: 40.8s\tremaining: 1m 42s\n",
      "284:\tlearn: 0.0883010\ttotal: 40.9s\tremaining: 1m 42s\n",
      "285:\tlearn: 0.0882502\ttotal: 41s\tremaining: 1m 42s\n",
      "286:\tlearn: 0.0882364\ttotal: 41.2s\tremaining: 1m 42s\n",
      "287:\tlearn: 0.0880886\ttotal: 41.3s\tremaining: 1m 42s\n",
      "288:\tlearn: 0.0880794\ttotal: 41.4s\tremaining: 1m 41s\n",
      "289:\tlearn: 0.0879963\ttotal: 41.6s\tremaining: 1m 41s\n",
      "290:\tlearn: 0.0879640\ttotal: 41.7s\tremaining: 1m 41s\n",
      "291:\tlearn: 0.0879132\ttotal: 41.8s\tremaining: 1m 41s\n",
      "292:\tlearn: 0.0879040\ttotal: 42s\tremaining: 1m 41s\n",
      "293:\tlearn: 0.0878163\ttotal: 42.1s\tremaining: 1m 41s\n",
      "294:\tlearn: 0.0877562\ttotal: 42.2s\tremaining: 1m 40s\n",
      "295:\tlearn: 0.0877147\ttotal: 42.3s\tremaining: 1m 40s\n",
      "296:\tlearn: 0.0877054\ttotal: 42.5s\tremaining: 1m 40s\n",
      "297:\tlearn: 0.0877008\ttotal: 42.6s\tremaining: 1m 40s\n",
      "298:\tlearn: 0.0876454\ttotal: 42.7s\tremaining: 1m 40s\n",
      "299:\tlearn: 0.0875946\ttotal: 42.9s\tremaining: 1m 40s\n",
      "300:\tlearn: 0.0875485\ttotal: 43s\tremaining: 1m 39s\n",
      "301:\tlearn: 0.0874284\ttotal: 43.1s\tremaining: 1m 39s\n",
      "302:\tlearn: 0.0873453\ttotal: 43.3s\tremaining: 1m 39s\n",
      "303:\tlearn: 0.0872715\ttotal: 43.4s\tremaining: 1m 39s\n",
      "304:\tlearn: 0.0872807\ttotal: 43.5s\tremaining: 1m 39s\n",
      "305:\tlearn: 0.0871884\ttotal: 43.7s\tremaining: 1m 39s\n",
      "306:\tlearn: 0.0871237\ttotal: 43.8s\tremaining: 1m 38s\n",
      "307:\tlearn: 0.0871191\ttotal: 43.9s\tremaining: 1m 38s\n",
      "308:\tlearn: 0.0870545\ttotal: 44s\tremaining: 1m 38s\n",
      "309:\tlearn: 0.0869898\ttotal: 44.2s\tremaining: 1m 38s\n",
      "310:\tlearn: 0.0869529\ttotal: 44.3s\tremaining: 1m 38s\n",
      "311:\tlearn: 0.0869575\ttotal: 44.5s\tremaining: 1m 38s\n",
      "312:\tlearn: 0.0868698\ttotal: 44.6s\tremaining: 1m 37s\n",
      "313:\tlearn: 0.0867452\ttotal: 44.7s\tremaining: 1m 37s\n",
      "314:\tlearn: 0.0866805\ttotal: 44.8s\tremaining: 1m 37s\n",
      "315:\tlearn: 0.0866205\ttotal: 45s\tremaining: 1m 37s\n",
      "316:\tlearn: 0.0865928\ttotal: 45.1s\tremaining: 1m 37s\n",
      "317:\tlearn: 0.0865420\ttotal: 45.2s\tremaining: 1m 37s\n",
      "318:\tlearn: 0.0864589\ttotal: 45.4s\tremaining: 1m 36s\n",
      "319:\tlearn: 0.0864035\ttotal: 45.5s\tremaining: 1m 36s\n",
      "320:\tlearn: 0.0862927\ttotal: 45.7s\tremaining: 1m 36s\n",
      "321:\tlearn: 0.0862604\ttotal: 45.8s\tremaining: 1m 36s\n",
      "322:\tlearn: 0.0862096\ttotal: 46s\tremaining: 1m 36s\n",
      "323:\tlearn: 0.0861542\ttotal: 46.1s\tremaining: 1m 36s\n",
      "324:\tlearn: 0.0861357\ttotal: 46.2s\tremaining: 1m 36s\n",
      "325:\tlearn: 0.0860711\ttotal: 46.4s\tremaining: 1m 35s\n",
      "326:\tlearn: 0.0860203\ttotal: 46.5s\tremaining: 1m 35s\n",
      "327:\tlearn: 0.0860295\ttotal: 46.6s\tremaining: 1m 35s\n",
      "328:\tlearn: 0.0858864\ttotal: 46.7s\tremaining: 1m 35s\n",
      "329:\tlearn: 0.0858218\ttotal: 46.9s\tremaining: 1m 35s\n",
      "330:\tlearn: 0.0856925\ttotal: 47s\tremaining: 1m 35s\n",
      "331:\tlearn: 0.0856510\ttotal: 47.2s\tremaining: 1m 34s\n",
      "332:\tlearn: 0.0855540\ttotal: 47.3s\tremaining: 1m 34s\n",
      "333:\tlearn: 0.0855125\ttotal: 47.5s\tremaining: 1m 34s\n",
      "334:\tlearn: 0.0854201\ttotal: 47.6s\tremaining: 1m 34s\n",
      "335:\tlearn: 0.0854340\ttotal: 47.7s\tremaining: 1m 34s\n",
      "336:\tlearn: 0.0853463\ttotal: 47.9s\tremaining: 1m 34s\n",
      "337:\tlearn: 0.0852355\ttotal: 48s\tremaining: 1m 33s\n",
      "338:\tlearn: 0.0851708\ttotal: 48.1s\tremaining: 1m 33s\n",
      "339:\tlearn: 0.0851431\ttotal: 48.3s\tremaining: 1m 33s\n",
      "340:\tlearn: 0.0850970\ttotal: 48.4s\tremaining: 1m 33s\n",
      "341:\tlearn: 0.0849861\ttotal: 48.5s\tremaining: 1m 33s\n",
      "342:\tlearn: 0.0849908\ttotal: 48.6s\tremaining: 1m 33s\n",
      "343:\tlearn: 0.0849261\ttotal: 48.8s\tremaining: 1m 32s\n",
      "344:\tlearn: 0.0848384\ttotal: 48.9s\tremaining: 1m 32s\n",
      "345:\tlearn: 0.0848015\ttotal: 49s\tremaining: 1m 32s\n",
      "346:\tlearn: 0.0847692\ttotal: 49.2s\tremaining: 1m 32s\n",
      "347:\tlearn: 0.0847461\ttotal: 49.3s\tremaining: 1m 32s\n",
      "348:\tlearn: 0.0846353\ttotal: 49.4s\tremaining: 1m 32s\n",
      "349:\tlearn: 0.0847045\ttotal: 49.5s\tremaining: 1m 32s\n",
      "350:\tlearn: 0.0846537\ttotal: 49.7s\tremaining: 1m 31s\n",
      "351:\tlearn: 0.0845937\ttotal: 49.8s\tremaining: 1m 31s\n",
      "352:\tlearn: 0.0845476\ttotal: 49.9s\tremaining: 1m 31s\n",
      "353:\tlearn: 0.0844875\ttotal: 50.1s\tremaining: 1m 31s\n",
      "354:\tlearn: 0.0844137\ttotal: 50.2s\tremaining: 1m 31s\n",
      "355:\tlearn: 0.0843306\ttotal: 50.3s\tremaining: 1m 31s\n",
      "356:\tlearn: 0.0842428\ttotal: 50.5s\tremaining: 1m 30s\n",
      "357:\tlearn: 0.0841921\ttotal: 50.6s\tremaining: 1m 30s\n",
      "358:\tlearn: 0.0841136\ttotal: 50.7s\tremaining: 1m 30s\n",
      "359:\tlearn: 0.0840443\ttotal: 50.8s\tremaining: 1m 30s\n",
      "360:\tlearn: 0.0840351\ttotal: 51s\tremaining: 1m 30s\n",
      "361:\tlearn: 0.0839797\ttotal: 51.1s\tremaining: 1m 30s\n",
      "362:\tlearn: 0.0838781\ttotal: 51.2s\tremaining: 1m 29s\n",
      "363:\tlearn: 0.0838735\ttotal: 51.4s\tremaining: 1m 29s\n",
      "364:\tlearn: 0.0838042\ttotal: 51.5s\tremaining: 1m 29s\n",
      "365:\tlearn: 0.0837304\ttotal: 51.6s\tremaining: 1m 29s\n",
      "366:\tlearn: 0.0837211\ttotal: 51.8s\tremaining: 1m 29s\n",
      "367:\tlearn: 0.0836473\ttotal: 51.9s\tremaining: 1m 29s\n",
      "368:\tlearn: 0.0836103\ttotal: 52s\tremaining: 1m 28s\n",
      "369:\tlearn: 0.0834580\ttotal: 52.1s\tremaining: 1m 28s\n",
      "370:\tlearn: 0.0834349\ttotal: 52.3s\tremaining: 1m 28s\n",
      "371:\tlearn: 0.0833749\ttotal: 52.4s\tremaining: 1m 28s\n",
      "372:\tlearn: 0.0833287\ttotal: 52.5s\tremaining: 1m 28s\n",
      "373:\tlearn: 0.0833010\ttotal: 52.7s\tremaining: 1m 28s\n",
      "374:\tlearn: 0.0832595\ttotal: 52.8s\tremaining: 1m 27s\n",
      "375:\tlearn: 0.0831994\ttotal: 52.9s\tremaining: 1m 27s\n",
      "376:\tlearn: 0.0831533\ttotal: 53s\tremaining: 1m 27s\n",
      "377:\tlearn: 0.0831163\ttotal: 53.2s\tremaining: 1m 27s\n",
      "378:\tlearn: 0.0830425\ttotal: 53.3s\tremaining: 1m 27s\n",
      "379:\tlearn: 0.0829548\ttotal: 53.4s\tremaining: 1m 27s\n",
      "380:\tlearn: 0.0828670\ttotal: 53.6s\tremaining: 1m 27s\n",
      "381:\tlearn: 0.0828440\ttotal: 53.7s\tremaining: 1m 26s\n",
      "382:\tlearn: 0.0827978\ttotal: 53.8s\tremaining: 1m 26s\n",
      "383:\tlearn: 0.0826962\ttotal: 54s\tremaining: 1m 26s\n",
      "384:\tlearn: 0.0826824\ttotal: 54.1s\tremaining: 1m 26s\n",
      "385:\tlearn: 0.0825392\ttotal: 54.2s\tremaining: 1m 26s\n",
      "386:\tlearn: 0.0825162\ttotal: 54.4s\tremaining: 1m 26s\n",
      "387:\tlearn: 0.0824007\ttotal: 54.5s\tremaining: 1m 25s\n",
      "388:\tlearn: 0.0824054\ttotal: 54.6s\tremaining: 1m 25s\n",
      "389:\tlearn: 0.0822669\ttotal: 54.7s\tremaining: 1m 25s\n",
      "390:\tlearn: 0.0821976\ttotal: 54.9s\tremaining: 1m 25s\n",
      "391:\tlearn: 0.0821607\ttotal: 55s\tremaining: 1m 25s\n",
      "392:\tlearn: 0.0820822\ttotal: 55.1s\tremaining: 1m 25s\n",
      "393:\tlearn: 0.0820729\ttotal: 55.3s\tremaining: 1m 25s\n",
      "394:\tlearn: 0.0819206\ttotal: 55.4s\tremaining: 1m 24s\n",
      "395:\tlearn: 0.0818744\ttotal: 55.5s\tremaining: 1m 24s\n",
      "396:\tlearn: 0.0817959\ttotal: 55.7s\tremaining: 1m 24s\n",
      "397:\tlearn: 0.0816343\ttotal: 55.8s\tremaining: 1m 24s\n",
      "398:\tlearn: 0.0815882\ttotal: 55.9s\tremaining: 1m 24s\n",
      "399:\tlearn: 0.0815189\ttotal: 56s\tremaining: 1m 24s\n",
      "400:\tlearn: 0.0814866\ttotal: 56.2s\tremaining: 1m 23s\n",
      "401:\tlearn: 0.0814312\ttotal: 56.3s\tremaining: 1m 23s\n",
      "402:\tlearn: 0.0813804\ttotal: 56.4s\tremaining: 1m 23s\n",
      "403:\tlearn: 0.0813573\ttotal: 56.6s\tremaining: 1m 23s\n",
      "404:\tlearn: 0.0812696\ttotal: 56.7s\tremaining: 1m 23s\n",
      "405:\tlearn: 0.0812604\ttotal: 56.8s\tremaining: 1m 23s\n",
      "406:\tlearn: 0.0812050\ttotal: 57s\tremaining: 1m 22s\n",
      "407:\tlearn: 0.0811865\ttotal: 57.1s\tremaining: 1m 22s\n",
      "408:\tlearn: 0.0810572\ttotal: 57.2s\tremaining: 1m 22s\n",
      "409:\tlearn: 0.0810018\ttotal: 57.4s\tremaining: 1m 22s\n",
      "410:\tlearn: 0.0809141\ttotal: 57.5s\tremaining: 1m 22s\n",
      "411:\tlearn: 0.0809187\ttotal: 57.6s\tremaining: 1m 22s\n",
      "412:\tlearn: 0.0808541\ttotal: 57.7s\tremaining: 1m 22s\n",
      "413:\tlearn: 0.0807341\ttotal: 57.9s\tremaining: 1m 21s\n",
      "414:\tlearn: 0.0807664\ttotal: 58s\tremaining: 1m 21s\n",
      "415:\tlearn: 0.0807248\ttotal: 58.1s\tremaining: 1m 21s\n",
      "416:\tlearn: 0.0807064\ttotal: 58.3s\tremaining: 1m 21s\n",
      "417:\tlearn: 0.0807202\ttotal: 58.4s\tremaining: 1m 21s\n",
      "418:\tlearn: 0.0806325\ttotal: 58.5s\tremaining: 1m 21s\n",
      "419:\tlearn: 0.0805771\ttotal: 58.6s\tremaining: 1m 20s\n",
      "420:\tlearn: 0.0805540\ttotal: 58.8s\tremaining: 1m 20s\n",
      "421:\tlearn: 0.0804848\ttotal: 58.9s\tremaining: 1m 20s\n",
      "422:\tlearn: 0.0804109\ttotal: 59s\tremaining: 1m 20s\n",
      "423:\tlearn: 0.0803370\ttotal: 59.2s\tremaining: 1m 20s\n",
      "424:\tlearn: 0.0803047\ttotal: 59.3s\tremaining: 1m 20s\n",
      "425:\tlearn: 0.0802447\ttotal: 59.4s\tremaining: 1m 20s\n",
      "426:\tlearn: 0.0802308\ttotal: 59.6s\tremaining: 1m 19s\n",
      "427:\tlearn: 0.0801662\ttotal: 59.7s\tremaining: 1m 19s\n",
      "428:\tlearn: 0.0801108\ttotal: 59.8s\tremaining: 1m 19s\n",
      "429:\tlearn: 0.0800462\ttotal: 59.9s\tremaining: 1m 19s\n",
      "430:\tlearn: 0.0800462\ttotal: 1m\tremaining: 1m 19s\n",
      "431:\tlearn: 0.0800139\ttotal: 1m\tremaining: 1m 19s\n",
      "432:\tlearn: 0.0799169\ttotal: 1m\tremaining: 1m 19s\n",
      "433:\tlearn: 0.0798153\ttotal: 1m\tremaining: 1m 18s\n",
      "434:\tlearn: 0.0797507\ttotal: 1m\tremaining: 1m 18s\n",
      "435:\tlearn: 0.0796584\ttotal: 1m\tremaining: 1m 18s\n",
      "436:\tlearn: 0.0795614\ttotal: 1m\tremaining: 1m 18s\n",
      "437:\tlearn: 0.0795060\ttotal: 1m 1s\tremaining: 1m 18s\n",
      "438:\tlearn: 0.0794367\ttotal: 1m 1s\tremaining: 1m 18s\n",
      "439:\tlearn: 0.0794460\ttotal: 1m 1s\tremaining: 1m 18s\n",
      "440:\tlearn: 0.0794137\ttotal: 1m 1s\tremaining: 1m 17s\n",
      "441:\tlearn: 0.0793029\ttotal: 1m 1s\tremaining: 1m 17s\n",
      "442:\tlearn: 0.0793075\ttotal: 1m 1s\tremaining: 1m 17s\n",
      "443:\tlearn: 0.0792567\ttotal: 1m 1s\tremaining: 1m 17s\n",
      "444:\tlearn: 0.0792290\ttotal: 1m 1s\tremaining: 1m 17s\n",
      "445:\tlearn: 0.0791644\ttotal: 1m 2s\tremaining: 1m 17s\n",
      "446:\tlearn: 0.0791505\ttotal: 1m 2s\tremaining: 1m 16s\n",
      "447:\tlearn: 0.0791274\ttotal: 1m 2s\tremaining: 1m 16s\n",
      "448:\tlearn: 0.0790397\ttotal: 1m 2s\tremaining: 1m 16s\n",
      "449:\tlearn: 0.0789335\ttotal: 1m 2s\tremaining: 1m 16s\n",
      "450:\tlearn: 0.0788504\ttotal: 1m 2s\tremaining: 1m 16s\n",
      "451:\tlearn: 0.0788366\ttotal: 1m 2s\tremaining: 1m 16s\n",
      "452:\tlearn: 0.0787673\ttotal: 1m 3s\tremaining: 1m 16s\n",
      "453:\tlearn: 0.0786519\ttotal: 1m 3s\tremaining: 1m 15s\n",
      "454:\tlearn: 0.0786150\ttotal: 1m 3s\tremaining: 1m 15s\n",
      "455:\tlearn: 0.0785873\ttotal: 1m 3s\tremaining: 1m 15s\n",
      "456:\tlearn: 0.0785919\ttotal: 1m 3s\tremaining: 1m 15s\n",
      "457:\tlearn: 0.0785042\ttotal: 1m 3s\tremaining: 1m 15s\n",
      "458:\tlearn: 0.0784488\ttotal: 1m 3s\tremaining: 1m 15s\n",
      "459:\tlearn: 0.0784303\ttotal: 1m 3s\tremaining: 1m 15s\n",
      "460:\tlearn: 0.0783887\ttotal: 1m 4s\tremaining: 1m 14s\n",
      "461:\tlearn: 0.0783333\ttotal: 1m 4s\tremaining: 1m 14s\n",
      "462:\tlearn: 0.0782687\ttotal: 1m 4s\tremaining: 1m 14s\n",
      "463:\tlearn: 0.0782225\ttotal: 1m 4s\tremaining: 1m 14s\n",
      "464:\tlearn: 0.0782087\ttotal: 1m 4s\tremaining: 1m 14s\n",
      "465:\tlearn: 0.0781394\ttotal: 1m 4s\tremaining: 1m 14s\n",
      "466:\tlearn: 0.0780933\ttotal: 1m 4s\tremaining: 1m 14s\n",
      "467:\tlearn: 0.0780286\ttotal: 1m 4s\tremaining: 1m 13s\n",
      "468:\tlearn: 0.0779871\ttotal: 1m 5s\tremaining: 1m 13s\n",
      "469:\tlearn: 0.0778717\ttotal: 1m 5s\tremaining: 1m 13s\n",
      "470:\tlearn: 0.0778440\ttotal: 1m 5s\tremaining: 1m 13s\n",
      "471:\tlearn: 0.0778532\ttotal: 1m 5s\tremaining: 1m 13s\n",
      "472:\tlearn: 0.0777701\ttotal: 1m 5s\tremaining: 1m 13s\n",
      "473:\tlearn: 0.0777193\ttotal: 1m 5s\tremaining: 1m 12s\n",
      "474:\tlearn: 0.0777101\ttotal: 1m 5s\tremaining: 1m 12s\n",
      "475:\tlearn: 0.0776500\ttotal: 1m 6s\tremaining: 1m 12s\n",
      "476:\tlearn: 0.0776500\ttotal: 1m 6s\tremaining: 1m 12s\n",
      "477:\tlearn: 0.0775346\ttotal: 1m 6s\tremaining: 1m 12s\n",
      "478:\tlearn: 0.0774561\ttotal: 1m 6s\tremaining: 1m 12s\n",
      "479:\tlearn: 0.0773777\ttotal: 1m 6s\tremaining: 1m 12s\n",
      "480:\tlearn: 0.0773869\ttotal: 1m 6s\tremaining: 1m 12s\n",
      "481:\tlearn: 0.0774007\ttotal: 1m 6s\tremaining: 1m 11s\n",
      "482:\tlearn: 0.0772576\ttotal: 1m 7s\tremaining: 1m 11s\n",
      "483:\tlearn: 0.0772438\ttotal: 1m 7s\tremaining: 1m 11s\n",
      "484:\tlearn: 0.0771468\ttotal: 1m 7s\tremaining: 1m 11s\n",
      "485:\tlearn: 0.0771422\ttotal: 1m 7s\tremaining: 1m 11s\n",
      "486:\tlearn: 0.0770776\ttotal: 1m 7s\tremaining: 1m 11s\n",
      "487:\tlearn: 0.0770960\ttotal: 1m 7s\tremaining: 1m 10s\n",
      "488:\tlearn: 0.0770314\ttotal: 1m 7s\tremaining: 1m 10s\n",
      "489:\tlearn: 0.0770314\ttotal: 1m 7s\tremaining: 1m 10s\n",
      "490:\tlearn: 0.0769483\ttotal: 1m 8s\tremaining: 1m 10s\n",
      "491:\tlearn: 0.0769160\ttotal: 1m 8s\tremaining: 1m 10s\n",
      "492:\tlearn: 0.0768744\ttotal: 1m 8s\tremaining: 1m 10s\n",
      "493:\tlearn: 0.0768052\ttotal: 1m 8s\tremaining: 1m 10s\n",
      "494:\tlearn: 0.0767867\ttotal: 1m 8s\tremaining: 1m 9s\n",
      "495:\tlearn: 0.0767128\ttotal: 1m 8s\tremaining: 1m 9s\n",
      "496:\tlearn: 0.0766759\ttotal: 1m 8s\tremaining: 1m 9s\n",
      "497:\tlearn: 0.0766713\ttotal: 1m 8s\tremaining: 1m 9s\n",
      "498:\tlearn: 0.0766620\ttotal: 1m 9s\tremaining: 1m 9s\n",
      "499:\tlearn: 0.0766205\ttotal: 1m 9s\tremaining: 1m 9s\n",
      "500:\tlearn: 0.0765605\ttotal: 1m 9s\tremaining: 1m 9s\n",
      "501:\tlearn: 0.0765189\ttotal: 1m 9s\tremaining: 1m 8s\n",
      "502:\tlearn: 0.0764866\ttotal: 1m 9s\tremaining: 1m 8s\n",
      "503:\tlearn: 0.0764497\ttotal: 1m 9s\tremaining: 1m 8s\n",
      "504:\tlearn: 0.0764035\ttotal: 1m 9s\tremaining: 1m 8s\n",
      "505:\tlearn: 0.0763620\ttotal: 1m 9s\tremaining: 1m 8s\n",
      "506:\tlearn: 0.0763573\ttotal: 1m 10s\tremaining: 1m 8s\n",
      "507:\tlearn: 0.0762927\ttotal: 1m 10s\tremaining: 1m 8s\n",
      "508:\tlearn: 0.0762281\ttotal: 1m 10s\tremaining: 1m 7s\n",
      "509:\tlearn: 0.0762419\ttotal: 1m 10s\tremaining: 1m 7s\n",
      "510:\tlearn: 0.0762096\ttotal: 1m 10s\tremaining: 1m 7s\n",
      "511:\tlearn: 0.0761496\ttotal: 1m 10s\tremaining: 1m 7s\n",
      "512:\tlearn: 0.0760988\ttotal: 1m 10s\tremaining: 1m 7s\n",
      "513:\tlearn: 0.0760342\ttotal: 1m 11s\tremaining: 1m 7s\n",
      "514:\tlearn: 0.0759880\ttotal: 1m 11s\tremaining: 1m 7s\n",
      "515:\tlearn: 0.0759095\ttotal: 1m 11s\tremaining: 1m 6s\n",
      "516:\tlearn: 0.0758218\ttotal: 1m 11s\tremaining: 1m 6s\n",
      "517:\tlearn: 0.0757572\ttotal: 1m 11s\tremaining: 1m 6s\n",
      "518:\tlearn: 0.0757341\ttotal: 1m 11s\tremaining: 1m 6s\n",
      "519:\tlearn: 0.0756925\ttotal: 1m 11s\tremaining: 1m 6s\n",
      "520:\tlearn: 0.0756787\ttotal: 1m 11s\tremaining: 1m 6s\n",
      "521:\tlearn: 0.0756140\ttotal: 1m 12s\tremaining: 1m 5s\n",
      "522:\tlearn: 0.0756048\ttotal: 1m 12s\tremaining: 1m 5s\n",
      "523:\tlearn: 0.0755355\ttotal: 1m 12s\tremaining: 1m 5s\n",
      "524:\tlearn: 0.0754709\ttotal: 1m 12s\tremaining: 1m 5s\n",
      "525:\tlearn: 0.0754386\ttotal: 1m 12s\tremaining: 1m 5s\n",
      "526:\tlearn: 0.0753740\ttotal: 1m 12s\tremaining: 1m 5s\n",
      "527:\tlearn: 0.0752031\ttotal: 1m 12s\tremaining: 1m 5s\n",
      "528:\tlearn: 0.0751939\ttotal: 1m 13s\tremaining: 1m 4s\n",
      "529:\tlearn: 0.0751247\ttotal: 1m 13s\tremaining: 1m 4s\n",
      "530:\tlearn: 0.0750323\ttotal: 1m 13s\tremaining: 1m 4s\n",
      "531:\tlearn: 0.0749954\ttotal: 1m 13s\tremaining: 1m 4s\n",
      "532:\tlearn: 0.0749492\ttotal: 1m 13s\tremaining: 1m 4s\n",
      "533:\tlearn: 0.0748707\ttotal: 1m 13s\tremaining: 1m 4s\n",
      "534:\tlearn: 0.0747922\ttotal: 1m 13s\tremaining: 1m 4s\n",
      "535:\tlearn: 0.0747830\ttotal: 1m 13s\tremaining: 1m 3s\n",
      "536:\tlearn: 0.0747322\ttotal: 1m 14s\tremaining: 1m 3s\n",
      "537:\tlearn: 0.0747322\ttotal: 1m 14s\tremaining: 1m 3s\n",
      "538:\tlearn: 0.0746630\ttotal: 1m 14s\tremaining: 1m 3s\n",
      "539:\tlearn: 0.0745706\ttotal: 1m 14s\tremaining: 1m 3s\n",
      "540:\tlearn: 0.0745152\ttotal: 1m 14s\tremaining: 1m 3s\n",
      "541:\tlearn: 0.0744968\ttotal: 1m 14s\tremaining: 1m 3s\n",
      "542:\tlearn: 0.0744367\ttotal: 1m 14s\tremaining: 1m 2s\n",
      "543:\tlearn: 0.0743813\ttotal: 1m 14s\tremaining: 1m 2s\n",
      "544:\tlearn: 0.0743398\ttotal: 1m 15s\tremaining: 1m 2s\n",
      "545:\tlearn: 0.0743629\ttotal: 1m 15s\tremaining: 1m 2s\n",
      "546:\tlearn: 0.0743444\ttotal: 1m 15s\tremaining: 1m 2s\n",
      "547:\tlearn: 0.0743121\ttotal: 1m 15s\tremaining: 1m 2s\n",
      "548:\tlearn: 0.0741967\ttotal: 1m 15s\tremaining: 1m 2s\n",
      "549:\tlearn: 0.0740628\ttotal: 1m 15s\tremaining: 1m 2s\n",
      "550:\tlearn: 0.0740443\ttotal: 1m 15s\tremaining: 1m 1s\n",
      "551:\tlearn: 0.0739982\ttotal: 1m 16s\tremaining: 1m 1s\n",
      "552:\tlearn: 0.0740120\ttotal: 1m 16s\tremaining: 1m 1s\n",
      "553:\tlearn: 0.0739104\ttotal: 1m 16s\tremaining: 1m 1s\n",
      "554:\tlearn: 0.0738273\ttotal: 1m 16s\tremaining: 1m 1s\n",
      "555:\tlearn: 0.0737904\ttotal: 1m 16s\tremaining: 1m 1s\n",
      "556:\tlearn: 0.0737258\ttotal: 1m 16s\tremaining: 1m 1s\n",
      "557:\tlearn: 0.0737165\ttotal: 1m 16s\tremaining: 1m\n",
      "558:\tlearn: 0.0736750\ttotal: 1m 17s\tremaining: 1m\n",
      "559:\tlearn: 0.0735734\ttotal: 1m 17s\tremaining: 1m\n",
      "560:\tlearn: 0.0735272\ttotal: 1m 17s\tremaining: 1m\n",
      "561:\tlearn: 0.0735549\ttotal: 1m 17s\tremaining: 1m\n",
      "562:\tlearn: 0.0735642\ttotal: 1m 17s\tremaining: 1m\n",
      "563:\tlearn: 0.0734903\ttotal: 1m 17s\tremaining: 1m\n",
      "564:\tlearn: 0.0734303\ttotal: 1m 17s\tremaining: 59.9s\n",
      "565:\tlearn: 0.0733795\ttotal: 1m 17s\tremaining: 59.7s\n",
      "566:\tlearn: 0.0733333\ttotal: 1m 18s\tremaining: 59.6s\n",
      "567:\tlearn: 0.0733380\ttotal: 1m 18s\tremaining: 59.5s\n",
      "568:\tlearn: 0.0732595\ttotal: 1m 18s\tremaining: 59.3s\n",
      "569:\tlearn: 0.0732133\ttotal: 1m 18s\tremaining: 59.2s\n",
      "570:\tlearn: 0.0731717\ttotal: 1m 18s\tremaining: 59s\n",
      "571:\tlearn: 0.0731440\ttotal: 1m 18s\tremaining: 58.9s\n",
      "572:\tlearn: 0.0731256\ttotal: 1m 18s\tremaining: 58.7s\n",
      "573:\tlearn: 0.0730656\ttotal: 1m 18s\tremaining: 58.6s\n",
      "574:\tlearn: 0.0730379\ttotal: 1m 19s\tremaining: 58.5s\n",
      "575:\tlearn: 0.0729825\ttotal: 1m 19s\tremaining: 58.3s\n",
      "576:\tlearn: 0.0729224\ttotal: 1m 19s\tremaining: 58.2s\n",
      "577:\tlearn: 0.0728624\ttotal: 1m 19s\tremaining: 58s\n",
      "578:\tlearn: 0.0728393\ttotal: 1m 19s\tremaining: 57.9s\n",
      "579:\tlearn: 0.0727562\ttotal: 1m 19s\tremaining: 57.8s\n",
      "580:\tlearn: 0.0726223\ttotal: 1m 19s\tremaining: 57.6s\n",
      "581:\tlearn: 0.0725716\ttotal: 1m 20s\tremaining: 57.5s\n",
      "582:\tlearn: 0.0725808\ttotal: 1m 20s\tremaining: 57.3s\n",
      "583:\tlearn: 0.0725577\ttotal: 1m 20s\tremaining: 57.2s\n",
      "584:\tlearn: 0.0725115\ttotal: 1m 20s\tremaining: 57s\n",
      "585:\tlearn: 0.0724885\ttotal: 1m 20s\tremaining: 56.9s\n",
      "586:\tlearn: 0.0724469\ttotal: 1m 20s\tremaining: 56.7s\n",
      "587:\tlearn: 0.0723869\ttotal: 1m 20s\tremaining: 56.6s\n",
      "588:\tlearn: 0.0722899\ttotal: 1m 20s\tremaining: 56.5s\n",
      "589:\tlearn: 0.0722853\ttotal: 1m 21s\tremaining: 56.3s\n",
      "590:\tlearn: 0.0722576\ttotal: 1m 21s\tremaining: 56.2s\n",
      "591:\tlearn: 0.0722253\ttotal: 1m 21s\tremaining: 56s\n",
      "592:\tlearn: 0.0721468\ttotal: 1m 21s\tremaining: 55.9s\n",
      "593:\tlearn: 0.0721145\ttotal: 1m 21s\tremaining: 55.8s\n",
      "594:\tlearn: 0.0720822\ttotal: 1m 21s\tremaining: 55.6s\n",
      "595:\tlearn: 0.0720683\ttotal: 1m 21s\tremaining: 55.5s\n",
      "596:\tlearn: 0.0720083\ttotal: 1m 21s\tremaining: 55.3s\n",
      "597:\tlearn: 0.0719621\ttotal: 1m 22s\tremaining: 55.2s\n",
      "598:\tlearn: 0.0719391\ttotal: 1m 22s\tremaining: 55s\n",
      "599:\tlearn: 0.0718929\ttotal: 1m 22s\tremaining: 54.9s\n",
      "600:\tlearn: 0.0719021\ttotal: 1m 22s\tremaining: 54.8s\n",
      "601:\tlearn: 0.0718652\ttotal: 1m 22s\tremaining: 54.6s\n",
      "602:\tlearn: 0.0718052\ttotal: 1m 22s\tremaining: 54.5s\n",
      "603:\tlearn: 0.0717729\ttotal: 1m 22s\tremaining: 54.3s\n",
      "604:\tlearn: 0.0717082\ttotal: 1m 22s\tremaining: 54.2s\n",
      "605:\tlearn: 0.0716620\ttotal: 1m 23s\tremaining: 54s\n",
      "606:\tlearn: 0.0716205\ttotal: 1m 23s\tremaining: 53.9s\n",
      "607:\tlearn: 0.0716066\ttotal: 1m 23s\tremaining: 53.8s\n",
      "608:\tlearn: 0.0715512\ttotal: 1m 23s\tremaining: 53.6s\n",
      "609:\tlearn: 0.0715559\ttotal: 1m 23s\tremaining: 53.5s\n",
      "610:\tlearn: 0.0715374\ttotal: 1m 23s\tremaining: 53.3s\n",
      "611:\tlearn: 0.0714912\ttotal: 1m 23s\tremaining: 53.2s\n",
      "612:\tlearn: 0.0714635\ttotal: 1m 24s\tremaining: 53s\n",
      "613:\tlearn: 0.0713758\ttotal: 1m 24s\tremaining: 52.9s\n",
      "614:\tlearn: 0.0713112\ttotal: 1m 24s\tremaining: 52.8s\n",
      "615:\tlearn: 0.0712835\ttotal: 1m 24s\tremaining: 52.6s\n",
      "616:\tlearn: 0.0712419\ttotal: 1m 24s\tremaining: 52.5s\n",
      "617:\tlearn: 0.0712235\ttotal: 1m 24s\tremaining: 52.3s\n",
      "618:\tlearn: 0.0711404\ttotal: 1m 24s\tremaining: 52.2s\n",
      "619:\tlearn: 0.0711034\ttotal: 1m 24s\tremaining: 52.1s\n",
      "620:\tlearn: 0.0710526\ttotal: 1m 25s\tremaining: 51.9s\n",
      "621:\tlearn: 0.0709788\ttotal: 1m 25s\tremaining: 51.8s\n",
      "622:\tlearn: 0.0709926\ttotal: 1m 25s\tremaining: 51.6s\n",
      "623:\tlearn: 0.0709741\ttotal: 1m 25s\tremaining: 51.5s\n",
      "624:\tlearn: 0.0709141\ttotal: 1m 25s\tremaining: 51.4s\n",
      "625:\tlearn: 0.0709141\ttotal: 1m 25s\tremaining: 51.2s\n",
      "626:\tlearn: 0.0708957\ttotal: 1m 25s\tremaining: 51.1s\n",
      "627:\tlearn: 0.0708818\ttotal: 1m 25s\tremaining: 50.9s\n",
      "628:\tlearn: 0.0707941\ttotal: 1m 26s\tremaining: 50.8s\n",
      "629:\tlearn: 0.0706787\ttotal: 1m 26s\tremaining: 50.7s\n",
      "630:\tlearn: 0.0706048\ttotal: 1m 26s\tremaining: 50.5s\n",
      "631:\tlearn: 0.0706094\ttotal: 1m 26s\tremaining: 50.4s\n",
      "632:\tlearn: 0.0705771\ttotal: 1m 26s\tremaining: 50.2s\n",
      "633:\tlearn: 0.0705633\ttotal: 1m 26s\tremaining: 50.1s\n",
      "634:\tlearn: 0.0704340\ttotal: 1m 26s\tremaining: 49.9s\n",
      "635:\tlearn: 0.0704017\ttotal: 1m 27s\tremaining: 49.8s\n",
      "636:\tlearn: 0.0703693\ttotal: 1m 27s\tremaining: 49.7s\n",
      "637:\tlearn: 0.0703139\ttotal: 1m 27s\tremaining: 49.5s\n",
      "638:\tlearn: 0.0701985\ttotal: 1m 27s\tremaining: 49.4s\n",
      "639:\tlearn: 0.0701754\ttotal: 1m 27s\tremaining: 49.3s\n",
      "640:\tlearn: 0.0701570\ttotal: 1m 27s\tremaining: 49.1s\n",
      "641:\tlearn: 0.0701477\ttotal: 1m 27s\tremaining: 49s\n",
      "642:\tlearn: 0.0701524\ttotal: 1m 27s\tremaining: 48.8s\n",
      "643:\tlearn: 0.0700185\ttotal: 1m 28s\tremaining: 48.7s\n",
      "644:\tlearn: 0.0699723\ttotal: 1m 28s\tremaining: 48.6s\n",
      "645:\tlearn: 0.0699261\ttotal: 1m 28s\tremaining: 48.4s\n",
      "646:\tlearn: 0.0699030\ttotal: 1m 28s\tremaining: 48.3s\n",
      "647:\tlearn: 0.0698800\ttotal: 1m 28s\tremaining: 48.1s\n",
      "648:\tlearn: 0.0698430\ttotal: 1m 28s\tremaining: 48s\n",
      "649:\tlearn: 0.0697599\ttotal: 1m 28s\tremaining: 47.9s\n",
      "650:\tlearn: 0.0697507\ttotal: 1m 28s\tremaining: 47.7s\n",
      "651:\tlearn: 0.0696907\ttotal: 1m 29s\tremaining: 47.6s\n",
      "652:\tlearn: 0.0695845\ttotal: 1m 29s\tremaining: 47.4s\n",
      "653:\tlearn: 0.0695152\ttotal: 1m 29s\tremaining: 47.3s\n",
      "654:\tlearn: 0.0694275\ttotal: 1m 29s\tremaining: 47.2s\n",
      "655:\tlearn: 0.0693721\ttotal: 1m 29s\tremaining: 47s\n",
      "656:\tlearn: 0.0693583\ttotal: 1m 29s\tremaining: 46.9s\n",
      "657:\tlearn: 0.0693167\ttotal: 1m 29s\tremaining: 46.7s\n",
      "658:\tlearn: 0.0692936\ttotal: 1m 30s\tremaining: 46.6s\n",
      "659:\tlearn: 0.0692798\ttotal: 1m 30s\tremaining: 46.5s\n",
      "660:\tlearn: 0.0692844\ttotal: 1m 30s\tremaining: 46.3s\n",
      "661:\tlearn: 0.0692105\ttotal: 1m 30s\tremaining: 46.2s\n",
      "662:\tlearn: 0.0691874\ttotal: 1m 30s\tremaining: 46.1s\n",
      "663:\tlearn: 0.0691597\ttotal: 1m 30s\tremaining: 45.9s\n",
      "664:\tlearn: 0.0691136\ttotal: 1m 30s\tremaining: 45.8s\n",
      "665:\tlearn: 0.0690720\ttotal: 1m 31s\tremaining: 45.6s\n",
      "666:\tlearn: 0.0690305\ttotal: 1m 31s\tremaining: 45.5s\n",
      "667:\tlearn: 0.0690120\ttotal: 1m 31s\tremaining: 45.4s\n",
      "668:\tlearn: 0.0689566\ttotal: 1m 31s\tremaining: 45.2s\n",
      "669:\tlearn: 0.0689289\ttotal: 1m 31s\tremaining: 45.1s\n",
      "670:\tlearn: 0.0688873\ttotal: 1m 31s\tremaining: 45s\n",
      "671:\tlearn: 0.0688458\ttotal: 1m 31s\tremaining: 44.8s\n",
      "672:\tlearn: 0.0688458\ttotal: 1m 32s\tremaining: 44.7s\n",
      "673:\tlearn: 0.0688319\ttotal: 1m 32s\tremaining: 44.6s\n",
      "674:\tlearn: 0.0688089\ttotal: 1m 32s\tremaining: 44.4s\n",
      "675:\tlearn: 0.0687165\ttotal: 1m 32s\tremaining: 44.3s\n",
      "676:\tlearn: 0.0686842\ttotal: 1m 32s\tremaining: 44.2s\n",
      "677:\tlearn: 0.0686888\ttotal: 1m 32s\tremaining: 44s\n",
      "678:\tlearn: 0.0685457\ttotal: 1m 32s\tremaining: 43.9s\n",
      "679:\tlearn: 0.0685134\ttotal: 1m 32s\tremaining: 43.7s\n",
      "680:\tlearn: 0.0684349\ttotal: 1m 33s\tremaining: 43.6s\n",
      "681:\tlearn: 0.0684395\ttotal: 1m 33s\tremaining: 43.5s\n",
      "682:\tlearn: 0.0683610\ttotal: 1m 33s\tremaining: 43.3s\n",
      "683:\tlearn: 0.0683195\ttotal: 1m 33s\tremaining: 43.2s\n",
      "684:\tlearn: 0.0682410\ttotal: 1m 33s\tremaining: 43.1s\n",
      "685:\tlearn: 0.0681856\ttotal: 1m 33s\tremaining: 42.9s\n",
      "686:\tlearn: 0.0681348\ttotal: 1m 33s\tremaining: 42.8s\n",
      "687:\tlearn: 0.0680517\ttotal: 1m 34s\tremaining: 42.6s\n",
      "688:\tlearn: 0.0679963\ttotal: 1m 34s\tremaining: 42.5s\n",
      "689:\tlearn: 0.0679409\ttotal: 1m 34s\tremaining: 42.4s\n",
      "690:\tlearn: 0.0678901\ttotal: 1m 34s\tremaining: 42.2s\n",
      "691:\tlearn: 0.0678763\ttotal: 1m 34s\tremaining: 42.1s\n",
      "692:\tlearn: 0.0678440\ttotal: 1m 34s\tremaining: 42s\n",
      "693:\tlearn: 0.0677932\ttotal: 1m 34s\tremaining: 41.8s\n",
      "694:\tlearn: 0.0678347\ttotal: 1m 34s\tremaining: 41.7s\n",
      "695:\tlearn: 0.0677793\ttotal: 1m 35s\tremaining: 41.5s\n",
      "696:\tlearn: 0.0677886\ttotal: 1m 35s\tremaining: 41.4s\n",
      "697:\tlearn: 0.0677378\ttotal: 1m 35s\tremaining: 41.3s\n",
      "698:\tlearn: 0.0677470\ttotal: 1m 35s\tremaining: 41.1s\n",
      "699:\tlearn: 0.0677147\ttotal: 1m 35s\tremaining: 41s\n",
      "700:\tlearn: 0.0676916\ttotal: 1m 35s\tremaining: 40.8s\n",
      "701:\tlearn: 0.0675900\ttotal: 1m 35s\tremaining: 40.7s\n",
      "702:\tlearn: 0.0675300\ttotal: 1m 35s\tremaining: 40.6s\n",
      "703:\tlearn: 0.0674654\ttotal: 1m 36s\tremaining: 40.4s\n",
      "704:\tlearn: 0.0674377\ttotal: 1m 36s\tremaining: 40.3s\n",
      "705:\tlearn: 0.0673961\ttotal: 1m 36s\tremaining: 40.1s\n",
      "706:\tlearn: 0.0672853\ttotal: 1m 36s\tremaining: 40s\n",
      "707:\tlearn: 0.0672438\ttotal: 1m 36s\tremaining: 39.9s\n",
      "708:\tlearn: 0.0671976\ttotal: 1m 36s\tremaining: 39.7s\n",
      "709:\tlearn: 0.0671745\ttotal: 1m 36s\tremaining: 39.6s\n",
      "710:\tlearn: 0.0671607\ttotal: 1m 37s\tremaining: 39.4s\n",
      "711:\tlearn: 0.0671053\ttotal: 1m 37s\tremaining: 39.3s\n",
      "712:\tlearn: 0.0670822\ttotal: 1m 37s\tremaining: 39.2s\n",
      "713:\tlearn: 0.0670683\ttotal: 1m 37s\tremaining: 39s\n",
      "714:\tlearn: 0.0670222\ttotal: 1m 37s\tremaining: 38.9s\n",
      "715:\tlearn: 0.0669621\ttotal: 1m 37s\tremaining: 38.7s\n",
      "716:\tlearn: 0.0669760\ttotal: 1m 37s\tremaining: 38.6s\n",
      "717:\tlearn: 0.0669252\ttotal: 1m 37s\tremaining: 38.5s\n",
      "718:\tlearn: 0.0669206\ttotal: 1m 38s\tremaining: 38.4s\n",
      "719:\tlearn: 0.0669021\ttotal: 1m 38s\tremaining: 38.2s\n",
      "720:\tlearn: 0.0668098\ttotal: 1m 38s\tremaining: 38.1s\n",
      "721:\tlearn: 0.0668006\ttotal: 1m 38s\tremaining: 38s\n",
      "722:\tlearn: 0.0667313\ttotal: 1m 38s\tremaining: 37.8s\n",
      "723:\tlearn: 0.0666851\ttotal: 1m 38s\tremaining: 37.7s\n",
      "724:\tlearn: 0.0666297\ttotal: 1m 39s\tremaining: 37.6s\n",
      "725:\tlearn: 0.0666066\ttotal: 1m 39s\tremaining: 37.4s\n",
      "726:\tlearn: 0.0665836\ttotal: 1m 39s\tremaining: 37.3s\n",
      "727:\tlearn: 0.0664912\ttotal: 1m 39s\tremaining: 37.2s\n",
      "728:\tlearn: 0.0664635\ttotal: 1m 39s\tremaining: 37.1s\n",
      "729:\tlearn: 0.0664081\ttotal: 1m 39s\tremaining: 36.9s\n",
      "730:\tlearn: 0.0663389\ttotal: 1m 39s\tremaining: 36.8s\n",
      "731:\tlearn: 0.0663389\ttotal: 1m 40s\tremaining: 36.7s\n",
      "732:\tlearn: 0.0662973\ttotal: 1m 40s\tremaining: 36.5s\n",
      "733:\tlearn: 0.0662558\ttotal: 1m 40s\tremaining: 36.4s\n",
      "734:\tlearn: 0.0662327\ttotal: 1m 40s\tremaining: 36.3s\n",
      "735:\tlearn: 0.0662096\ttotal: 1m 40s\tremaining: 36.1s\n",
      "736:\tlearn: 0.0661542\ttotal: 1m 40s\tremaining: 36s\n",
      "737:\tlearn: 0.0661496\ttotal: 1m 41s\tremaining: 35.9s\n",
      "738:\tlearn: 0.0660619\ttotal: 1m 41s\tremaining: 35.7s\n",
      "739:\tlearn: 0.0660065\ttotal: 1m 41s\tremaining: 35.6s\n",
      "740:\tlearn: 0.0659372\ttotal: 1m 41s\tremaining: 35.5s\n",
      "741:\tlearn: 0.0659234\ttotal: 1m 41s\tremaining: 35.3s\n",
      "742:\tlearn: 0.0659095\ttotal: 1m 41s\tremaining: 35.2s\n",
      "743:\tlearn: 0.0658910\ttotal: 1m 41s\tremaining: 35.1s\n",
      "744:\tlearn: 0.0658310\ttotal: 1m 42s\tremaining: 34.9s\n",
      "745:\tlearn: 0.0657802\ttotal: 1m 42s\tremaining: 34.8s\n",
      "746:\tlearn: 0.0657295\ttotal: 1m 42s\tremaining: 34.7s\n",
      "747:\tlearn: 0.0656510\ttotal: 1m 42s\tremaining: 34.5s\n",
      "748:\tlearn: 0.0656002\ttotal: 1m 42s\tremaining: 34.4s\n",
      "749:\tlearn: 0.0655863\ttotal: 1m 42s\tremaining: 34.3s\n",
      "750:\tlearn: 0.0655217\ttotal: 1m 43s\tremaining: 34.2s\n",
      "751:\tlearn: 0.0654986\ttotal: 1m 43s\tremaining: 34s\n",
      "752:\tlearn: 0.0654017\ttotal: 1m 43s\tremaining: 33.9s\n",
      "753:\tlearn: 0.0653601\ttotal: 1m 43s\tremaining: 33.8s\n",
      "754:\tlearn: 0.0653232\ttotal: 1m 43s\tremaining: 33.7s\n",
      "755:\tlearn: 0.0653186\ttotal: 1m 43s\tremaining: 33.6s\n",
      "756:\tlearn: 0.0652632\ttotal: 1m 44s\tremaining: 33.5s\n",
      "757:\tlearn: 0.0652632\ttotal: 1m 44s\tremaining: 33.3s\n",
      "758:\tlearn: 0.0651939\ttotal: 1m 44s\tremaining: 33.2s\n",
      "759:\tlearn: 0.0651754\ttotal: 1m 44s\tremaining: 33.1s\n",
      "760:\tlearn: 0.0651616\ttotal: 1m 44s\tremaining: 32.9s\n",
      "761:\tlearn: 0.0651339\ttotal: 1m 45s\tremaining: 32.8s\n",
      "762:\tlearn: 0.0650508\ttotal: 1m 45s\tremaining: 32.7s\n",
      "763:\tlearn: 0.0650139\ttotal: 1m 45s\tremaining: 32.5s\n",
      "764:\tlearn: 0.0649631\ttotal: 1m 45s\tremaining: 32.4s\n",
      "765:\tlearn: 0.0649307\ttotal: 1m 45s\tremaining: 32.3s\n",
      "766:\tlearn: 0.0649261\ttotal: 1m 45s\tremaining: 32.1s\n",
      "767:\tlearn: 0.0649307\ttotal: 1m 45s\tremaining: 32s\n",
      "768:\tlearn: 0.0648984\ttotal: 1m 46s\tremaining: 31.9s\n",
      "769:\tlearn: 0.0649077\ttotal: 1m 46s\tremaining: 31.7s\n",
      "770:\tlearn: 0.0648846\ttotal: 1m 46s\tremaining: 31.6s\n",
      "771:\tlearn: 0.0648338\ttotal: 1m 46s\tremaining: 31.4s\n",
      "772:\tlearn: 0.0648384\ttotal: 1m 46s\tremaining: 31.3s\n",
      "773:\tlearn: 0.0647553\ttotal: 1m 46s\tremaining: 31.2s\n",
      "774:\tlearn: 0.0646861\ttotal: 1m 46s\tremaining: 31s\n",
      "775:\tlearn: 0.0646814\ttotal: 1m 46s\tremaining: 30.9s\n",
      "776:\tlearn: 0.0646353\ttotal: 1m 47s\tremaining: 30.7s\n",
      "777:\tlearn: 0.0645891\ttotal: 1m 47s\tremaining: 30.6s\n",
      "778:\tlearn: 0.0645476\ttotal: 1m 47s\tremaining: 30.4s\n",
      "779:\tlearn: 0.0644829\ttotal: 1m 47s\tremaining: 30.3s\n",
      "780:\tlearn: 0.0644552\ttotal: 1m 47s\tremaining: 30.2s\n",
      "781:\tlearn: 0.0643813\ttotal: 1m 47s\tremaining: 30s\n",
      "782:\tlearn: 0.0643767\ttotal: 1m 47s\tremaining: 29.9s\n",
      "783:\tlearn: 0.0643583\ttotal: 1m 48s\tremaining: 29.8s\n",
      "784:\tlearn: 0.0643075\ttotal: 1m 48s\tremaining: 29.6s\n",
      "785:\tlearn: 0.0642705\ttotal: 1m 48s\tremaining: 29.5s\n",
      "786:\tlearn: 0.0642382\ttotal: 1m 48s\tremaining: 29.4s\n",
      "787:\tlearn: 0.0642613\ttotal: 1m 48s\tremaining: 29.2s\n",
      "788:\tlearn: 0.0641828\ttotal: 1m 48s\tremaining: 29.1s\n",
      "789:\tlearn: 0.0641320\ttotal: 1m 48s\tremaining: 28.9s\n",
      "790:\tlearn: 0.0641136\ttotal: 1m 48s\tremaining: 28.8s\n",
      "791:\tlearn: 0.0640766\ttotal: 1m 49s\tremaining: 28.7s\n",
      "792:\tlearn: 0.0640351\ttotal: 1m 49s\tremaining: 28.5s\n",
      "793:\tlearn: 0.0640120\ttotal: 1m 49s\tremaining: 28.4s\n",
      "794:\tlearn: 0.0639843\ttotal: 1m 49s\tremaining: 28.2s\n",
      "795:\tlearn: 0.0639335\ttotal: 1m 49s\tremaining: 28.1s\n",
      "796:\tlearn: 0.0639058\ttotal: 1m 49s\tremaining: 27.9s\n",
      "797:\tlearn: 0.0638689\ttotal: 1m 49s\tremaining: 27.8s\n",
      "798:\tlearn: 0.0638504\ttotal: 1m 49s\tremaining: 27.7s\n",
      "799:\tlearn: 0.0637950\ttotal: 1m 50s\tremaining: 27.5s\n",
      "800:\tlearn: 0.0637442\ttotal: 1m 50s\tremaining: 27.4s\n",
      "801:\tlearn: 0.0637027\ttotal: 1m 50s\tremaining: 27.3s\n",
      "802:\tlearn: 0.0636750\ttotal: 1m 50s\tremaining: 27.1s\n",
      "803:\tlearn: 0.0636842\ttotal: 1m 50s\tremaining: 27s\n",
      "804:\tlearn: 0.0636427\ttotal: 1m 50s\tremaining: 26.8s\n",
      "805:\tlearn: 0.0635457\ttotal: 1m 50s\tremaining: 26.7s\n",
      "806:\tlearn: 0.0634811\ttotal: 1m 51s\tremaining: 26.6s\n",
      "807:\tlearn: 0.0634857\ttotal: 1m 51s\tremaining: 26.4s\n",
      "808:\tlearn: 0.0634257\ttotal: 1m 51s\tremaining: 26.3s\n",
      "809:\tlearn: 0.0633980\ttotal: 1m 51s\tremaining: 26.1s\n",
      "810:\tlearn: 0.0634072\ttotal: 1m 51s\tremaining: 26s\n",
      "811:\tlearn: 0.0633380\ttotal: 1m 51s\tremaining: 25.9s\n",
      "812:\tlearn: 0.0632918\ttotal: 1m 51s\tremaining: 25.7s\n",
      "813:\tlearn: 0.0632779\ttotal: 1m 51s\tremaining: 25.6s\n",
      "814:\tlearn: 0.0631856\ttotal: 1m 52s\tremaining: 25.4s\n",
      "815:\tlearn: 0.0631579\ttotal: 1m 52s\tremaining: 25.3s\n",
      "816:\tlearn: 0.0630332\ttotal: 1m 52s\tremaining: 25.2s\n",
      "817:\tlearn: 0.0629963\ttotal: 1m 52s\tremaining: 25s\n",
      "818:\tlearn: 0.0629917\ttotal: 1m 52s\tremaining: 24.9s\n",
      "819:\tlearn: 0.0629825\ttotal: 1m 52s\tremaining: 24.7s\n",
      "820:\tlearn: 0.0629317\ttotal: 1m 52s\tremaining: 24.6s\n",
      "821:\tlearn: 0.0628624\ttotal: 1m 52s\tremaining: 24.5s\n",
      "822:\tlearn: 0.0628255\ttotal: 1m 53s\tremaining: 24.3s\n",
      "823:\tlearn: 0.0628070\ttotal: 1m 53s\tremaining: 24.2s\n",
      "824:\tlearn: 0.0628024\ttotal: 1m 53s\tremaining: 24s\n",
      "825:\tlearn: 0.0627562\ttotal: 1m 53s\tremaining: 23.9s\n",
      "826:\tlearn: 0.0627424\ttotal: 1m 53s\tremaining: 23.8s\n",
      "827:\tlearn: 0.0627424\ttotal: 1m 53s\tremaining: 23.6s\n",
      "828:\tlearn: 0.0627008\ttotal: 1m 53s\tremaining: 23.5s\n",
      "829:\tlearn: 0.0626547\ttotal: 1m 53s\tremaining: 23.3s\n",
      "830:\tlearn: 0.0625531\ttotal: 1m 54s\tremaining: 23.2s\n",
      "831:\tlearn: 0.0624700\ttotal: 1m 54s\tremaining: 23.1s\n",
      "832:\tlearn: 0.0624331\ttotal: 1m 54s\tremaining: 22.9s\n",
      "833:\tlearn: 0.0624100\ttotal: 1m 54s\tremaining: 22.8s\n",
      "834:\tlearn: 0.0623638\ttotal: 1m 54s\tremaining: 22.7s\n",
      "835:\tlearn: 0.0623453\ttotal: 1m 54s\tremaining: 22.5s\n",
      "836:\tlearn: 0.0622484\ttotal: 1m 54s\tremaining: 22.4s\n",
      "837:\tlearn: 0.0621884\ttotal: 1m 55s\tremaining: 22.2s\n",
      "838:\tlearn: 0.0621514\ttotal: 1m 55s\tremaining: 22.1s\n",
      "839:\tlearn: 0.0621006\ttotal: 1m 55s\tremaining: 22s\n",
      "840:\tlearn: 0.0621006\ttotal: 1m 55s\tremaining: 21.8s\n",
      "841:\tlearn: 0.0620822\ttotal: 1m 55s\tremaining: 21.7s\n",
      "842:\tlearn: 0.0620683\ttotal: 1m 55s\tremaining: 21.5s\n",
      "843:\tlearn: 0.0620452\ttotal: 1m 55s\tremaining: 21.4s\n",
      "844:\tlearn: 0.0620222\ttotal: 1m 55s\tremaining: 21.3s\n",
      "845:\tlearn: 0.0619945\ttotal: 1m 56s\tremaining: 21.1s\n",
      "846:\tlearn: 0.0619714\ttotal: 1m 56s\tremaining: 21s\n",
      "847:\tlearn: 0.0619160\ttotal: 1m 56s\tremaining: 20.9s\n",
      "848:\tlearn: 0.0618606\ttotal: 1m 56s\tremaining: 20.7s\n",
      "849:\tlearn: 0.0618421\ttotal: 1m 56s\tremaining: 20.6s\n",
      "850:\tlearn: 0.0618236\ttotal: 1m 56s\tremaining: 20.4s\n",
      "851:\tlearn: 0.0617544\ttotal: 1m 56s\tremaining: 20.3s\n",
      "852:\tlearn: 0.0617082\ttotal: 1m 56s\tremaining: 20.2s\n",
      "853:\tlearn: 0.0616713\ttotal: 1m 57s\tremaining: 20s\n",
      "854:\tlearn: 0.0616759\ttotal: 1m 57s\tremaining: 19.9s\n",
      "855:\tlearn: 0.0616667\ttotal: 1m 57s\tremaining: 19.7s\n",
      "856:\tlearn: 0.0615974\ttotal: 1m 57s\tremaining: 19.6s\n",
      "857:\tlearn: 0.0615374\ttotal: 1m 57s\tremaining: 19.5s\n",
      "858:\tlearn: 0.0615051\ttotal: 1m 57s\tremaining: 19.3s\n",
      "859:\tlearn: 0.0613943\ttotal: 1m 57s\tremaining: 19.2s\n",
      "860:\tlearn: 0.0613666\ttotal: 1m 58s\tremaining: 19.1s\n",
      "861:\tlearn: 0.0613250\ttotal: 1m 58s\tremaining: 18.9s\n",
      "862:\tlearn: 0.0613112\ttotal: 1m 58s\tremaining: 18.8s\n",
      "863:\tlearn: 0.0612558\ttotal: 1m 58s\tremaining: 18.6s\n",
      "864:\tlearn: 0.0612142\ttotal: 1m 58s\tremaining: 18.5s\n",
      "865:\tlearn: 0.0611634\ttotal: 1m 58s\tremaining: 18.4s\n",
      "866:\tlearn: 0.0611173\ttotal: 1m 58s\tremaining: 18.2s\n",
      "867:\tlearn: 0.0610849\ttotal: 1m 58s\tremaining: 18.1s\n",
      "868:\tlearn: 0.0610526\ttotal: 1m 59s\tremaining: 17.9s\n",
      "869:\tlearn: 0.0610111\ttotal: 1m 59s\tremaining: 17.8s\n",
      "870:\tlearn: 0.0609372\ttotal: 1m 59s\tremaining: 17.7s\n",
      "871:\tlearn: 0.0609095\ttotal: 1m 59s\tremaining: 17.5s\n",
      "872:\tlearn: 0.0609234\ttotal: 1m 59s\tremaining: 17.4s\n",
      "873:\tlearn: 0.0608449\ttotal: 1m 59s\tremaining: 17.3s\n",
      "874:\tlearn: 0.0607572\ttotal: 1m 59s\tremaining: 17.1s\n",
      "875:\tlearn: 0.0607387\ttotal: 1m 59s\tremaining: 17s\n",
      "876:\tlearn: 0.0607525\ttotal: 2m\tremaining: 16.8s\n",
      "877:\tlearn: 0.0607387\ttotal: 2m\tremaining: 16.7s\n",
      "878:\tlearn: 0.0606741\ttotal: 2m\tremaining: 16.6s\n",
      "879:\tlearn: 0.0606417\ttotal: 2m\tremaining: 16.4s\n",
      "880:\tlearn: 0.0606094\ttotal: 2m\tremaining: 16.3s\n",
      "881:\tlearn: 0.0605633\ttotal: 2m\tremaining: 16.2s\n",
      "882:\tlearn: 0.0605402\ttotal: 2m\tremaining: 16s\n",
      "883:\tlearn: 0.0604755\ttotal: 2m 1s\tremaining: 15.9s\n",
      "884:\tlearn: 0.0604109\ttotal: 2m 1s\tremaining: 15.7s\n",
      "885:\tlearn: 0.0603970\ttotal: 2m 1s\tremaining: 15.6s\n",
      "886:\tlearn: 0.0603093\ttotal: 2m 1s\tremaining: 15.5s\n",
      "887:\tlearn: 0.0603139\ttotal: 2m 1s\tremaining: 15.3s\n",
      "888:\tlearn: 0.0602170\ttotal: 2m 1s\tremaining: 15.2s\n",
      "889:\tlearn: 0.0601801\ttotal: 2m 1s\tremaining: 15.1s\n",
      "890:\tlearn: 0.0601062\ttotal: 2m 1s\tremaining: 14.9s\n",
      "891:\tlearn: 0.0600693\ttotal: 2m 2s\tremaining: 14.8s\n",
      "892:\tlearn: 0.0600785\ttotal: 2m 2s\tremaining: 14.6s\n",
      "893:\tlearn: 0.0600185\ttotal: 2m 2s\tremaining: 14.5s\n",
      "894:\tlearn: 0.0600000\ttotal: 2m 2s\tremaining: 14.4s\n",
      "895:\tlearn: 0.0599677\ttotal: 2m 2s\tremaining: 14.2s\n",
      "896:\tlearn: 0.0599307\ttotal: 2m 2s\tremaining: 14.1s\n",
      "897:\tlearn: 0.0598384\ttotal: 2m 2s\tremaining: 14s\n",
      "898:\tlearn: 0.0597461\ttotal: 2m 2s\tremaining: 13.8s\n",
      "899:\tlearn: 0.0597138\ttotal: 2m 3s\tremaining: 13.7s\n",
      "900:\tlearn: 0.0597322\ttotal: 2m 3s\tremaining: 13.5s\n",
      "901:\tlearn: 0.0596814\ttotal: 2m 3s\tremaining: 13.4s\n",
      "902:\tlearn: 0.0596399\ttotal: 2m 3s\tremaining: 13.3s\n",
      "903:\tlearn: 0.0595614\ttotal: 2m 3s\tremaining: 13.1s\n",
      "904:\tlearn: 0.0595845\ttotal: 2m 3s\tremaining: 13s\n",
      "905:\tlearn: 0.0595476\ttotal: 2m 3s\tremaining: 12.9s\n",
      "906:\tlearn: 0.0594875\ttotal: 2m 4s\tremaining: 12.7s\n",
      "907:\tlearn: 0.0594875\ttotal: 2m 4s\tremaining: 12.6s\n",
      "908:\tlearn: 0.0594598\ttotal: 2m 4s\tremaining: 12.4s\n",
      "909:\tlearn: 0.0594783\ttotal: 2m 4s\tremaining: 12.3s\n",
      "910:\tlearn: 0.0594645\ttotal: 2m 4s\tremaining: 12.2s\n",
      "911:\tlearn: 0.0594137\ttotal: 2m 4s\tremaining: 12s\n",
      "912:\tlearn: 0.0594137\ttotal: 2m 4s\tremaining: 11.9s\n",
      "913:\tlearn: 0.0593952\ttotal: 2m 4s\tremaining: 11.8s\n",
      "914:\tlearn: 0.0593629\ttotal: 2m 5s\tremaining: 11.6s\n",
      "915:\tlearn: 0.0593167\ttotal: 2m 5s\tremaining: 11.5s\n",
      "916:\tlearn: 0.0593029\ttotal: 2m 5s\tremaining: 11.3s\n",
      "917:\tlearn: 0.0592936\ttotal: 2m 5s\tremaining: 11.2s\n",
      "918:\tlearn: 0.0592475\ttotal: 2m 5s\tremaining: 11.1s\n",
      "919:\tlearn: 0.0592705\ttotal: 2m 5s\tremaining: 10.9s\n",
      "920:\tlearn: 0.0591874\ttotal: 2m 5s\tremaining: 10.8s\n",
      "921:\tlearn: 0.0591182\ttotal: 2m 5s\tremaining: 10.7s\n",
      "922:\tlearn: 0.0591090\ttotal: 2m 6s\tremaining: 10.5s\n",
      "923:\tlearn: 0.0590997\ttotal: 2m 6s\tremaining: 10.4s\n",
      "924:\tlearn: 0.0590536\ttotal: 2m 6s\tremaining: 10.2s\n",
      "925:\tlearn: 0.0590166\ttotal: 2m 6s\tremaining: 10.1s\n",
      "926:\tlearn: 0.0589843\ttotal: 2m 6s\tremaining: 9.97s\n",
      "927:\tlearn: 0.0589751\ttotal: 2m 6s\tremaining: 9.84s\n",
      "928:\tlearn: 0.0589335\ttotal: 2m 6s\tremaining: 9.7s\n",
      "929:\tlearn: 0.0589335\ttotal: 2m 7s\tremaining: 9.56s\n",
      "930:\tlearn: 0.0588966\ttotal: 2m 7s\tremaining: 9.42s\n",
      "931:\tlearn: 0.0588735\ttotal: 2m 7s\tremaining: 9.29s\n",
      "932:\tlearn: 0.0588643\ttotal: 2m 7s\tremaining: 9.15s\n",
      "933:\tlearn: 0.0588550\ttotal: 2m 7s\tremaining: 9.01s\n",
      "934:\tlearn: 0.0588319\ttotal: 2m 7s\tremaining: 8.88s\n",
      "935:\tlearn: 0.0587442\ttotal: 2m 7s\tremaining: 8.74s\n",
      "936:\tlearn: 0.0587119\ttotal: 2m 7s\tremaining: 8.6s\n",
      "937:\tlearn: 0.0586934\ttotal: 2m 8s\tremaining: 8.46s\n",
      "938:\tlearn: 0.0586842\ttotal: 2m 8s\tremaining: 8.33s\n",
      "939:\tlearn: 0.0586750\ttotal: 2m 8s\tremaining: 8.19s\n",
      "940:\tlearn: 0.0586288\ttotal: 2m 8s\tremaining: 8.05s\n",
      "941:\tlearn: 0.0586334\ttotal: 2m 8s\tremaining: 7.92s\n",
      "942:\tlearn: 0.0586380\ttotal: 2m 8s\tremaining: 7.78s\n",
      "943:\tlearn: 0.0586334\ttotal: 2m 8s\tremaining: 7.64s\n",
      "944:\tlearn: 0.0586473\ttotal: 2m 8s\tremaining: 7.51s\n",
      "945:\tlearn: 0.0586196\ttotal: 2m 9s\tremaining: 7.37s\n",
      "946:\tlearn: 0.0585873\ttotal: 2m 9s\tremaining: 7.23s\n",
      "947:\tlearn: 0.0585365\ttotal: 2m 9s\tremaining: 7.1s\n",
      "948:\tlearn: 0.0585134\ttotal: 2m 9s\tremaining: 6.96s\n",
      "949:\tlearn: 0.0584857\ttotal: 2m 9s\tremaining: 6.82s\n",
      "950:\tlearn: 0.0584395\ttotal: 2m 9s\tremaining: 6.68s\n",
      "951:\tlearn: 0.0584072\ttotal: 2m 9s\tremaining: 6.55s\n",
      "952:\tlearn: 0.0583472\ttotal: 2m 9s\tremaining: 6.41s\n",
      "953:\tlearn: 0.0583056\ttotal: 2m 10s\tremaining: 6.27s\n",
      "954:\tlearn: 0.0583056\ttotal: 2m 10s\tremaining: 6.14s\n",
      "955:\tlearn: 0.0582641\ttotal: 2m 10s\tremaining: 6s\n",
      "956:\tlearn: 0.0582502\ttotal: 2m 10s\tremaining: 5.86s\n",
      "957:\tlearn: 0.0582179\ttotal: 2m 10s\tremaining: 5.73s\n",
      "958:\tlearn: 0.0582041\ttotal: 2m 10s\tremaining: 5.59s\n",
      "959:\tlearn: 0.0581671\ttotal: 2m 10s\tremaining: 5.45s\n",
      "960:\tlearn: 0.0581348\ttotal: 2m 11s\tremaining: 5.32s\n",
      "961:\tlearn: 0.0581071\ttotal: 2m 11s\tremaining: 5.18s\n",
      "962:\tlearn: 0.0581302\ttotal: 2m 11s\tremaining: 5.04s\n",
      "963:\tlearn: 0.0580517\ttotal: 2m 11s\tremaining: 4.91s\n",
      "964:\tlearn: 0.0580379\ttotal: 2m 11s\tremaining: 4.77s\n",
      "965:\tlearn: 0.0579963\ttotal: 2m 11s\tremaining: 4.63s\n",
      "966:\tlearn: 0.0579594\ttotal: 2m 11s\tremaining: 4.5s\n",
      "967:\tlearn: 0.0579548\ttotal: 2m 11s\tremaining: 4.36s\n",
      "968:\tlearn: 0.0579778\ttotal: 2m 12s\tremaining: 4.22s\n",
      "969:\tlearn: 0.0578809\ttotal: 2m 12s\tremaining: 4.09s\n",
      "970:\tlearn: 0.0578670\ttotal: 2m 12s\tremaining: 3.95s\n",
      "971:\tlearn: 0.0578440\ttotal: 2m 12s\tremaining: 3.81s\n",
      "972:\tlearn: 0.0577562\ttotal: 2m 12s\tremaining: 3.68s\n",
      "973:\tlearn: 0.0577424\ttotal: 2m 12s\tremaining: 3.54s\n",
      "974:\tlearn: 0.0577285\ttotal: 2m 12s\tremaining: 3.41s\n",
      "975:\tlearn: 0.0577239\ttotal: 2m 12s\tremaining: 3.27s\n",
      "976:\tlearn: 0.0576593\ttotal: 2m 13s\tremaining: 3.13s\n",
      "977:\tlearn: 0.0576454\ttotal: 2m 13s\tremaining: 3s\n",
      "978:\tlearn: 0.0576500\ttotal: 2m 13s\tremaining: 2.86s\n",
      "979:\tlearn: 0.0576039\ttotal: 2m 13s\tremaining: 2.72s\n",
      "980:\tlearn: 0.0575623\ttotal: 2m 13s\tremaining: 2.59s\n",
      "981:\tlearn: 0.0575808\ttotal: 2m 13s\tremaining: 2.45s\n",
      "982:\tlearn: 0.0575254\ttotal: 2m 13s\tremaining: 2.31s\n",
      "983:\tlearn: 0.0575208\ttotal: 2m 14s\tremaining: 2.18s\n",
      "984:\tlearn: 0.0574792\ttotal: 2m 14s\tremaining: 2.04s\n",
      "985:\tlearn: 0.0574007\ttotal: 2m 14s\tremaining: 1.91s\n",
      "986:\tlearn: 0.0573823\ttotal: 2m 14s\tremaining: 1.77s\n",
      "987:\tlearn: 0.0573223\ttotal: 2m 14s\tremaining: 1.63s\n",
      "988:\tlearn: 0.0572946\ttotal: 2m 14s\tremaining: 1.5s\n",
      "989:\tlearn: 0.0572622\ttotal: 2m 14s\tremaining: 1.36s\n",
      "990:\tlearn: 0.0572438\ttotal: 2m 14s\tremaining: 1.23s\n",
      "991:\tlearn: 0.0571791\ttotal: 2m 15s\tremaining: 1.09s\n",
      "992:\tlearn: 0.0571053\ttotal: 2m 15s\tremaining: 953ms\n",
      "993:\tlearn: 0.0570683\ttotal: 2m 15s\tremaining: 817ms\n",
      "994:\tlearn: 0.0570591\ttotal: 2m 15s\tremaining: 681ms\n",
      "995:\tlearn: 0.0570314\ttotal: 2m 15s\tremaining: 545ms\n",
      "996:\tlearn: 0.0569806\ttotal: 2m 15s\tremaining: 409ms\n",
      "997:\tlearn: 0.0569298\ttotal: 2m 15s\tremaining: 272ms\n",
      "998:\tlearn: 0.0569252\ttotal: 2m 16s\tremaining: 136ms\n",
      "999:\tlearn: 0.0568698\ttotal: 2m 16s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x2a52795b790>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_clf = CatBoostClassifier(loss_function='MultiLogloss',\n",
    "                            eval_metric='HammingLoss',\n",
    "                            verbose=1)\n",
    "cat_clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745d4a43-e133-41b2-a3bc-855887037771",
   "metadata": {},
   "source": [
    "### Evaluate Cat Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5413b161-26df-48e3-9a5b-745b617b3862",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.026476\n",
      "0:\tlearn: 0.1098107\ttotal: 131ms\tremaining: 2m 11s\n",
      "1:\tlearn: 0.1106994\ttotal: 260ms\tremaining: 2m 9s\n",
      "2:\tlearn: 0.1109245\ttotal: 385ms\tremaining: 2m 7s\n",
      "3:\tlearn: 0.1113689\ttotal: 484ms\tremaining: 2m\n",
      "4:\tlearn: 0.1118594\ttotal: 613ms\tremaining: 2m 1s\n",
      "5:\tlearn: 0.1118536\ttotal: 754ms\tremaining: 2m 4s\n",
      "6:\tlearn: 0.1117671\ttotal: 891ms\tremaining: 2m 6s\n",
      "7:\tlearn: 0.1118190\ttotal: 1.02s\tremaining: 2m 6s\n",
      "8:\tlearn: 0.1119171\ttotal: 1.15s\tremaining: 2m 6s\n",
      "9:\tlearn: 0.1118306\ttotal: 1.28s\tremaining: 2m 6s\n",
      "10:\tlearn: 0.1118363\ttotal: 1.41s\tremaining: 2m 6s\n",
      "11:\tlearn: 0.1117382\ttotal: 1.54s\tremaining: 2m 6s\n",
      "12:\tlearn: 0.1116921\ttotal: 1.68s\tremaining: 2m 7s\n",
      "13:\tlearn: 0.1114843\ttotal: 1.81s\tremaining: 2m 7s\n",
      "14:\tlearn: 0.1116170\ttotal: 1.94s\tremaining: 2m 7s\n",
      "15:\tlearn: 0.1115362\ttotal: 2.06s\tremaining: 2m 7s\n",
      "16:\tlearn: 0.1112823\ttotal: 2.19s\tremaining: 2m 6s\n",
      "17:\tlearn: 0.1113689\ttotal: 2.33s\tremaining: 2m 6s\n",
      "18:\tlearn: 0.1112246\ttotal: 2.45s\tremaining: 2m 6s\n",
      "19:\tlearn: 0.1112131\ttotal: 2.59s\tremaining: 2m 6s\n",
      "20:\tlearn: 0.1110630\ttotal: 2.73s\tremaining: 2m 7s\n",
      "21:\tlearn: 0.1108841\ttotal: 2.86s\tremaining: 2m 7s\n",
      "22:\tlearn: 0.1107283\ttotal: 2.99s\tremaining: 2m 6s\n",
      "23:\tlearn: 0.1106879\ttotal: 3.12s\tremaining: 2m 6s\n",
      "24:\tlearn: 0.1106533\ttotal: 3.25s\tremaining: 2m 6s\n",
      "25:\tlearn: 0.1103763\ttotal: 3.38s\tremaining: 2m 6s\n",
      "26:\tlearn: 0.1101570\ttotal: 3.51s\tremaining: 2m 6s\n",
      "27:\tlearn: 0.1100877\ttotal: 3.66s\tremaining: 2m 7s\n",
      "28:\tlearn: 0.1099608\ttotal: 3.79s\tremaining: 2m 7s\n",
      "29:\tlearn: 0.1100012\ttotal: 3.93s\tremaining: 2m 6s\n",
      "30:\tlearn: 0.1098800\ttotal: 4.05s\tremaining: 2m 6s\n",
      "31:\tlearn: 0.1097299\ttotal: 4.18s\tremaining: 2m 6s\n",
      "32:\tlearn: 0.1097761\ttotal: 4.31s\tremaining: 2m 6s\n",
      "33:\tlearn: 0.1094587\ttotal: 4.44s\tremaining: 2m 6s\n",
      "34:\tlearn: 0.1091990\ttotal: 4.57s\tremaining: 2m 6s\n",
      "35:\tlearn: 0.1089970\ttotal: 4.71s\tremaining: 2m 6s\n",
      "36:\tlearn: 0.1088066\ttotal: 4.84s\tremaining: 2m 5s\n",
      "37:\tlearn: 0.1088412\ttotal: 4.97s\tremaining: 2m 5s\n",
      "38:\tlearn: 0.1087027\ttotal: 5.09s\tremaining: 2m 5s\n",
      "39:\tlearn: 0.1085007\ttotal: 5.23s\tremaining: 2m 5s\n",
      "40:\tlearn: 0.1083218\ttotal: 5.36s\tremaining: 2m 5s\n",
      "41:\tlearn: 0.1082410\ttotal: 5.49s\tremaining: 2m 5s\n",
      "42:\tlearn: 0.1081948\ttotal: 5.62s\tremaining: 2m 5s\n",
      "43:\tlearn: 0.1081775\ttotal: 5.76s\tremaining: 2m 5s\n",
      "44:\tlearn: 0.1080275\ttotal: 5.9s\tremaining: 2m 5s\n",
      "45:\tlearn: 0.1078832\ttotal: 6.03s\tremaining: 2m 5s\n",
      "46:\tlearn: 0.1078370\ttotal: 6.16s\tremaining: 2m 4s\n",
      "47:\tlearn: 0.1076466\ttotal: 6.29s\tremaining: 2m 4s\n",
      "48:\tlearn: 0.1076581\ttotal: 6.42s\tremaining: 2m 4s\n",
      "49:\tlearn: 0.1075542\ttotal: 6.55s\tremaining: 2m 4s\n",
      "50:\tlearn: 0.1074331\ttotal: 6.69s\tremaining: 2m 4s\n",
      "51:\tlearn: 0.1073523\ttotal: 6.81s\tremaining: 2m 4s\n",
      "52:\tlearn: 0.1072830\ttotal: 6.95s\tremaining: 2m 4s\n",
      "53:\tlearn: 0.1072484\ttotal: 7.08s\tremaining: 2m 4s\n",
      "54:\tlearn: 0.1072138\ttotal: 7.21s\tremaining: 2m 3s\n",
      "55:\tlearn: 0.1070753\ttotal: 7.34s\tremaining: 2m 3s\n",
      "56:\tlearn: 0.1069310\ttotal: 7.47s\tremaining: 2m 3s\n",
      "57:\tlearn: 0.1069714\ttotal: 7.6s\tremaining: 2m 3s\n",
      "58:\tlearn: 0.1069252\ttotal: 7.74s\tremaining: 2m 3s\n",
      "59:\tlearn: 0.1067232\ttotal: 7.87s\tremaining: 2m 3s\n",
      "60:\tlearn: 0.1065905\ttotal: 8.01s\tremaining: 2m 3s\n",
      "61:\tlearn: 0.1064635\ttotal: 8.14s\tremaining: 2m 3s\n",
      "62:\tlearn: 0.1062731\ttotal: 8.27s\tremaining: 2m 2s\n",
      "63:\tlearn: 0.1061288\ttotal: 8.4s\tremaining: 2m 2s\n",
      "64:\tlearn: 0.1060192\ttotal: 8.53s\tremaining: 2m 2s\n",
      "65:\tlearn: 0.1059095\ttotal: 8.67s\tremaining: 2m 2s\n",
      "66:\tlearn: 0.1058460\ttotal: 8.8s\tremaining: 2m 2s\n",
      "67:\tlearn: 0.1057595\ttotal: 8.94s\tremaining: 2m 2s\n",
      "68:\tlearn: 0.1055863\ttotal: 9.07s\tremaining: 2m 2s\n",
      "69:\tlearn: 0.1054940\ttotal: 9.2s\tremaining: 2m 2s\n",
      "70:\tlearn: 0.1053555\ttotal: 9.32s\tremaining: 2m 2s\n",
      "71:\tlearn: 0.1052458\ttotal: 9.45s\tremaining: 2m 1s\n",
      "72:\tlearn: 0.1052343\ttotal: 9.58s\tremaining: 2m 1s\n",
      "73:\tlearn: 0.1050958\ttotal: 9.73s\tremaining: 2m 1s\n",
      "74:\tlearn: 0.1049111\ttotal: 9.86s\tremaining: 2m 1s\n",
      "75:\tlearn: 0.1048015\ttotal: 10s\tremaining: 2m 1s\n",
      "76:\tlearn: 0.1047207\ttotal: 10.1s\tremaining: 2m 1s\n",
      "77:\tlearn: 0.1046572\ttotal: 10.3s\tremaining: 2m 1s\n",
      "78:\tlearn: 0.1046514\ttotal: 10.4s\tremaining: 2m 1s\n",
      "79:\tlearn: 0.1046053\ttotal: 10.5s\tremaining: 2m 1s\n",
      "80:\tlearn: 0.1044610\ttotal: 10.7s\tremaining: 2m\n",
      "81:\tlearn: 0.1043225\ttotal: 10.8s\tremaining: 2m\n",
      "82:\tlearn: 0.1042071\ttotal: 10.9s\tremaining: 2m\n",
      "83:\tlearn: 0.1040512\ttotal: 11.1s\tremaining: 2m\n",
      "84:\tlearn: 0.1040166\ttotal: 11.2s\tremaining: 2m\n",
      "85:\tlearn: 0.1040166\ttotal: 11.3s\tremaining: 2m\n",
      "86:\tlearn: 0.1039127\ttotal: 11.5s\tremaining: 2m\n",
      "87:\tlearn: 0.1037281\ttotal: 11.6s\tremaining: 2m\n",
      "88:\tlearn: 0.1036415\ttotal: 11.7s\tremaining: 1m 59s\n",
      "89:\tlearn: 0.1037165\ttotal: 11.9s\tremaining: 1m 59s\n",
      "90:\tlearn: 0.1035492\ttotal: 12s\tremaining: 1m 59s\n",
      "91:\tlearn: 0.1034568\ttotal: 12.1s\tremaining: 1m 59s\n",
      "92:\tlearn: 0.1033703\ttotal: 12.2s\tremaining: 1m 59s\n",
      "93:\tlearn: 0.1032548\ttotal: 12.4s\tremaining: 1m 59s\n",
      "94:\tlearn: 0.1029374\ttotal: 12.5s\tremaining: 1m 59s\n",
      "95:\tlearn: 0.1028393\ttotal: 12.6s\tremaining: 1m 58s\n",
      "96:\tlearn: 0.1026777\ttotal: 12.8s\tremaining: 1m 58s\n",
      "97:\tlearn: 0.1025219\ttotal: 12.9s\tremaining: 1m 58s\n",
      "98:\tlearn: 0.1024469\ttotal: 13s\tremaining: 1m 58s\n",
      "99:\tlearn: 0.1023892\ttotal: 13.2s\tremaining: 1m 58s\n",
      "100:\tlearn: 0.1022969\ttotal: 13.3s\tremaining: 1m 58s\n",
      "101:\tlearn: 0.1021988\ttotal: 13.4s\tremaining: 1m 58s\n",
      "102:\tlearn: 0.1021006\ttotal: 13.6s\tremaining: 1m 58s\n",
      "103:\tlearn: 0.1019160\ttotal: 13.7s\tremaining: 1m 58s\n",
      "104:\tlearn: 0.1018063\ttotal: 13.9s\tremaining: 1m 58s\n",
      "105:\tlearn: 0.1017082\ttotal: 14s\tremaining: 1m 58s\n",
      "106:\tlearn: 0.1017602\ttotal: 14.1s\tremaining: 1m 58s\n",
      "107:\tlearn: 0.1016678\ttotal: 14.3s\tremaining: 1m 58s\n",
      "108:\tlearn: 0.1014370\ttotal: 14.4s\tremaining: 1m 57s\n",
      "109:\tlearn: 0.1013273\ttotal: 14.6s\tremaining: 1m 57s\n",
      "110:\tlearn: 0.1012639\ttotal: 14.7s\tremaining: 1m 57s\n",
      "111:\tlearn: 0.1011484\ttotal: 14.8s\tremaining: 1m 57s\n",
      "112:\tlearn: 0.1010330\ttotal: 15s\tremaining: 1m 57s\n",
      "113:\tlearn: 0.1009060\ttotal: 15.1s\tremaining: 1m 57s\n",
      "114:\tlearn: 0.1007387\ttotal: 15.2s\tremaining: 1m 57s\n",
      "115:\tlearn: 0.1005482\ttotal: 15.4s\tremaining: 1m 57s\n",
      "116:\tlearn: 0.1004848\ttotal: 15.5s\tremaining: 1m 56s\n",
      "117:\tlearn: 0.1003924\ttotal: 15.6s\tremaining: 1m 56s\n",
      "118:\tlearn: 0.1002539\ttotal: 15.8s\tremaining: 1m 56s\n",
      "119:\tlearn: 0.1001731\ttotal: 15.9s\tremaining: 1m 56s\n",
      "120:\tlearn: 0.1000404\ttotal: 16s\tremaining: 1m 56s\n",
      "121:\tlearn: 0.0999365\ttotal: 16.2s\tremaining: 1m 56s\n",
      "122:\tlearn: 0.0998615\ttotal: 16.3s\tremaining: 1m 56s\n",
      "123:\tlearn: 0.0996999\ttotal: 16.4s\tremaining: 1m 56s\n",
      "124:\tlearn: 0.0996307\ttotal: 16.6s\tremaining: 1m 56s\n",
      "125:\tlearn: 0.0994691\ttotal: 16.7s\tremaining: 1m 55s\n",
      "126:\tlearn: 0.0993594\ttotal: 16.8s\tremaining: 1m 55s\n",
      "127:\tlearn: 0.0993190\ttotal: 17s\tremaining: 1m 55s\n",
      "128:\tlearn: 0.0992209\ttotal: 17.1s\tremaining: 1m 55s\n",
      "129:\tlearn: 0.0990478\ttotal: 17.2s\tremaining: 1m 55s\n",
      "130:\tlearn: 0.0989728\ttotal: 17.4s\tremaining: 1m 55s\n",
      "131:\tlearn: 0.0988862\ttotal: 17.5s\tremaining: 1m 55s\n",
      "132:\tlearn: 0.0988862\ttotal: 17.7s\tremaining: 1m 55s\n",
      "133:\tlearn: 0.0987996\ttotal: 17.8s\tremaining: 1m 54s\n",
      "134:\tlearn: 0.0985688\ttotal: 17.9s\tremaining: 1m 54s\n",
      "135:\tlearn: 0.0985342\ttotal: 18.1s\tremaining: 1m 54s\n",
      "136:\tlearn: 0.0984072\ttotal: 18.2s\tremaining: 1m 54s\n",
      "137:\tlearn: 0.0982456\ttotal: 18.3s\tremaining: 1m 54s\n",
      "138:\tlearn: 0.0981706\ttotal: 18.5s\tremaining: 1m 54s\n",
      "139:\tlearn: 0.0980667\ttotal: 18.6s\tremaining: 1m 54s\n",
      "140:\tlearn: 0.0979686\ttotal: 18.7s\tremaining: 1m 54s\n",
      "141:\tlearn: 0.0978936\ttotal: 18.9s\tremaining: 1m 53s\n",
      "142:\tlearn: 0.0978301\ttotal: 19s\tremaining: 1m 53s\n",
      "143:\tlearn: 0.0978301\ttotal: 19.1s\tremaining: 1m 53s\n",
      "144:\tlearn: 0.0976916\ttotal: 19.2s\tremaining: 1m 53s\n",
      "145:\tlearn: 0.0975358\ttotal: 19.4s\tremaining: 1m 53s\n",
      "146:\tlearn: 0.0974665\ttotal: 19.5s\tremaining: 1m 53s\n",
      "147:\tlearn: 0.0973569\ttotal: 19.6s\tremaining: 1m 53s\n",
      "148:\tlearn: 0.0972761\ttotal: 19.8s\tremaining: 1m 52s\n",
      "149:\tlearn: 0.0971030\ttotal: 19.9s\tremaining: 1m 52s\n",
      "150:\tlearn: 0.0970799\ttotal: 20s\tremaining: 1m 52s\n",
      "151:\tlearn: 0.0968779\ttotal: 20.2s\tremaining: 1m 52s\n",
      "152:\tlearn: 0.0966470\ttotal: 20.3s\tremaining: 1m 52s\n",
      "153:\tlearn: 0.0965836\ttotal: 20.4s\tremaining: 1m 52s\n",
      "154:\tlearn: 0.0965663\ttotal: 20.6s\tremaining: 1m 52s\n",
      "155:\tlearn: 0.0963758\ttotal: 20.7s\tremaining: 1m 52s\n",
      "156:\tlearn: 0.0963181\ttotal: 20.8s\tremaining: 1m 51s\n",
      "157:\tlearn: 0.0962142\ttotal: 21s\tremaining: 1m 51s\n",
      "158:\tlearn: 0.0961796\ttotal: 21.1s\tremaining: 1m 51s\n",
      "159:\tlearn: 0.0960699\ttotal: 21.2s\tremaining: 1m 51s\n",
      "160:\tlearn: 0.0959430\ttotal: 21.4s\tremaining: 1m 51s\n",
      "161:\tlearn: 0.0958795\ttotal: 21.5s\tremaining: 1m 51s\n",
      "162:\tlearn: 0.0957295\ttotal: 21.6s\tremaining: 1m 51s\n",
      "163:\tlearn: 0.0956775\ttotal: 21.8s\tremaining: 1m 50s\n",
      "164:\tlearn: 0.0955044\ttotal: 21.9s\tremaining: 1m 50s\n",
      "165:\tlearn: 0.0953659\ttotal: 22s\tremaining: 1m 50s\n",
      "166:\tlearn: 0.0953659\ttotal: 22.2s\tremaining: 1m 50s\n",
      "167:\tlearn: 0.0952735\ttotal: 22.3s\tremaining: 1m 50s\n",
      "168:\tlearn: 0.0950427\ttotal: 22.4s\tremaining: 1m 50s\n",
      "169:\tlearn: 0.0949100\ttotal: 22.6s\tremaining: 1m 50s\n",
      "170:\tlearn: 0.0948061\ttotal: 22.7s\tremaining: 1m 50s\n",
      "171:\tlearn: 0.0946618\ttotal: 22.8s\tremaining: 1m 49s\n",
      "172:\tlearn: 0.0946099\ttotal: 23s\tremaining: 1m 49s\n",
      "173:\tlearn: 0.0945175\ttotal: 23.1s\tremaining: 1m 49s\n",
      "174:\tlearn: 0.0944829\ttotal: 23.2s\tremaining: 1m 49s\n",
      "175:\tlearn: 0.0943271\ttotal: 23.4s\tremaining: 1m 49s\n",
      "176:\tlearn: 0.0943271\ttotal: 23.5s\tremaining: 1m 49s\n",
      "177:\tlearn: 0.0942175\ttotal: 23.6s\tremaining: 1m 49s\n",
      "178:\tlearn: 0.0941482\ttotal: 23.8s\tremaining: 1m 49s\n",
      "179:\tlearn: 0.0940386\ttotal: 23.9s\tremaining: 1m 48s\n",
      "180:\tlearn: 0.0940039\ttotal: 24.1s\tremaining: 1m 48s\n",
      "181:\tlearn: 0.0939808\ttotal: 24.2s\tremaining: 1m 48s\n",
      "182:\tlearn: 0.0938596\ttotal: 24.3s\tremaining: 1m 48s\n",
      "183:\tlearn: 0.0937211\ttotal: 24.5s\tremaining: 1m 48s\n",
      "184:\tlearn: 0.0936115\ttotal: 24.6s\tremaining: 1m 48s\n",
      "185:\tlearn: 0.0935711\ttotal: 24.8s\tremaining: 1m 48s\n",
      "186:\tlearn: 0.0934903\ttotal: 24.9s\tremaining: 1m 48s\n",
      "187:\tlearn: 0.0934499\ttotal: 25.1s\tremaining: 1m 48s\n",
      "188:\tlearn: 0.0934499\ttotal: 25.2s\tremaining: 1m 48s\n",
      "189:\tlearn: 0.0933114\ttotal: 25.3s\tremaining: 1m 47s\n",
      "190:\tlearn: 0.0932422\ttotal: 25.4s\tremaining: 1m 47s\n",
      "191:\tlearn: 0.0931036\ttotal: 25.6s\tremaining: 1m 47s\n",
      "192:\tlearn: 0.0930171\ttotal: 25.7s\tremaining: 1m 47s\n",
      "193:\tlearn: 0.0928843\ttotal: 25.8s\tremaining: 1m 47s\n",
      "194:\tlearn: 0.0927574\ttotal: 26s\tremaining: 1m 47s\n",
      "195:\tlearn: 0.0926535\ttotal: 26.1s\tremaining: 1m 47s\n",
      "196:\tlearn: 0.0926131\ttotal: 26.3s\tremaining: 1m 47s\n",
      "197:\tlearn: 0.0925208\ttotal: 26.4s\tremaining: 1m 47s\n",
      "198:\tlearn: 0.0923996\ttotal: 26.5s\tremaining: 1m 46s\n",
      "199:\tlearn: 0.0922899\ttotal: 26.7s\tremaining: 1m 46s\n",
      "200:\tlearn: 0.0922322\ttotal: 26.8s\tremaining: 1m 46s\n",
      "201:\tlearn: 0.0921399\ttotal: 26.9s\tremaining: 1m 46s\n",
      "202:\tlearn: 0.0920880\ttotal: 27.1s\tremaining: 1m 46s\n",
      "203:\tlearn: 0.0919494\ttotal: 27.2s\tremaining: 1m 46s\n",
      "204:\tlearn: 0.0919090\ttotal: 27.3s\tremaining: 1m 46s\n",
      "205:\tlearn: 0.0918398\ttotal: 27.5s\tremaining: 1m 45s\n",
      "206:\tlearn: 0.0917417\ttotal: 27.6s\tremaining: 1m 45s\n",
      "207:\tlearn: 0.0916840\ttotal: 27.7s\tremaining: 1m 45s\n",
      "208:\tlearn: 0.0915974\ttotal: 27.9s\tremaining: 1m 45s\n",
      "209:\tlearn: 0.0915282\ttotal: 28s\tremaining: 1m 45s\n",
      "210:\tlearn: 0.0914012\ttotal: 28.1s\tremaining: 1m 45s\n",
      "211:\tlearn: 0.0913435\ttotal: 28.3s\tremaining: 1m 45s\n",
      "212:\tlearn: 0.0912281\ttotal: 28.4s\tremaining: 1m 44s\n",
      "213:\tlearn: 0.0911761\ttotal: 28.5s\tremaining: 1m 44s\n",
      "214:\tlearn: 0.0910838\ttotal: 28.7s\tremaining: 1m 44s\n",
      "215:\tlearn: 0.0910261\ttotal: 28.8s\tremaining: 1m 44s\n",
      "216:\tlearn: 0.0908934\ttotal: 29s\tremaining: 1m 44s\n",
      "217:\tlearn: 0.0907433\ttotal: 29.1s\tremaining: 1m 44s\n",
      "218:\tlearn: 0.0906971\ttotal: 29.3s\tremaining: 1m 44s\n",
      "219:\tlearn: 0.0906106\ttotal: 29.4s\tremaining: 1m 44s\n",
      "220:\tlearn: 0.0905702\ttotal: 29.6s\tremaining: 1m 44s\n",
      "221:\tlearn: 0.0905067\ttotal: 29.7s\tremaining: 1m 44s\n",
      "222:\tlearn: 0.0904144\ttotal: 29.8s\tremaining: 1m 43s\n",
      "223:\tlearn: 0.0903797\ttotal: 30s\tremaining: 1m 43s\n",
      "224:\tlearn: 0.0903393\ttotal: 30.1s\tremaining: 1m 43s\n",
      "225:\tlearn: 0.0902008\ttotal: 30.2s\tremaining: 1m 43s\n",
      "226:\tlearn: 0.0901951\ttotal: 30.4s\tremaining: 1m 43s\n",
      "227:\tlearn: 0.0900912\ttotal: 30.5s\tremaining: 1m 43s\n",
      "228:\tlearn: 0.0899931\ttotal: 30.6s\tremaining: 1m 43s\n",
      "229:\tlearn: 0.0899411\ttotal: 30.8s\tremaining: 1m 43s\n",
      "230:\tlearn: 0.0898661\ttotal: 30.9s\tremaining: 1m 42s\n",
      "231:\tlearn: 0.0897738\ttotal: 31s\tremaining: 1m 42s\n",
      "232:\tlearn: 0.0897334\ttotal: 31.2s\tremaining: 1m 42s\n",
      "233:\tlearn: 0.0897449\ttotal: 31.3s\tremaining: 1m 42s\n",
      "234:\tlearn: 0.0896237\ttotal: 31.4s\tremaining: 1m 42s\n",
      "235:\tlearn: 0.0896064\ttotal: 31.6s\tremaining: 1m 42s\n",
      "236:\tlearn: 0.0895776\ttotal: 31.7s\tremaining: 1m 42s\n",
      "237:\tlearn: 0.0895487\ttotal: 31.8s\tremaining: 1m 41s\n",
      "238:\tlearn: 0.0894852\ttotal: 32s\tremaining: 1m 41s\n",
      "239:\tlearn: 0.0894333\ttotal: 32.1s\tremaining: 1m 41s\n",
      "240:\tlearn: 0.0893294\ttotal: 32.3s\tremaining: 1m 41s\n",
      "241:\tlearn: 0.0892255\ttotal: 32.4s\tremaining: 1m 41s\n",
      "242:\tlearn: 0.0891967\ttotal: 32.5s\tremaining: 1m 41s\n",
      "243:\tlearn: 0.0890870\ttotal: 32.7s\tremaining: 1m 41s\n",
      "244:\tlearn: 0.0890524\ttotal: 32.8s\tremaining: 1m 41s\n",
      "245:\tlearn: 0.0890178\ttotal: 33s\tremaining: 1m 41s\n",
      "246:\tlearn: 0.0889428\ttotal: 33.1s\tremaining: 1m 40s\n",
      "247:\tlearn: 0.0888158\ttotal: 33.2s\tremaining: 1m 40s\n",
      "248:\tlearn: 0.0886831\ttotal: 33.4s\tremaining: 1m 40s\n",
      "249:\tlearn: 0.0886484\ttotal: 33.5s\tremaining: 1m 40s\n",
      "250:\tlearn: 0.0886369\ttotal: 33.6s\tremaining: 1m 40s\n",
      "251:\tlearn: 0.0885734\ttotal: 33.8s\tremaining: 1m 40s\n",
      "252:\tlearn: 0.0885099\ttotal: 33.9s\tremaining: 1m 40s\n",
      "253:\tlearn: 0.0884811\ttotal: 34s\tremaining: 1m 39s\n",
      "254:\tlearn: 0.0884118\ttotal: 34.2s\tremaining: 1m 39s\n",
      "255:\tlearn: 0.0882964\ttotal: 34.3s\tremaining: 1m 39s\n",
      "256:\tlearn: 0.0883022\ttotal: 34.4s\tremaining: 1m 39s\n",
      "257:\tlearn: 0.0882502\ttotal: 34.6s\tremaining: 1m 39s\n",
      "258:\tlearn: 0.0882098\ttotal: 34.7s\tremaining: 1m 39s\n",
      "259:\tlearn: 0.0881983\ttotal: 34.8s\tremaining: 1m 39s\n",
      "260:\tlearn: 0.0881637\ttotal: 35s\tremaining: 1m 39s\n",
      "261:\tlearn: 0.0880482\ttotal: 35.1s\tremaining: 1m 38s\n",
      "262:\tlearn: 0.0879444\ttotal: 35.2s\tremaining: 1m 38s\n",
      "263:\tlearn: 0.0878751\ttotal: 35.4s\tremaining: 1m 38s\n",
      "264:\tlearn: 0.0877712\ttotal: 35.5s\tremaining: 1m 38s\n",
      "265:\tlearn: 0.0877597\ttotal: 35.6s\tremaining: 1m 38s\n",
      "266:\tlearn: 0.0877135\ttotal: 35.8s\tremaining: 1m 38s\n",
      "267:\tlearn: 0.0876558\ttotal: 35.9s\tremaining: 1m 38s\n",
      "268:\tlearn: 0.0875346\ttotal: 36s\tremaining: 1m 37s\n",
      "269:\tlearn: 0.0875577\ttotal: 36.2s\tremaining: 1m 37s\n",
      "270:\tlearn: 0.0874942\ttotal: 36.3s\tremaining: 1m 37s\n",
      "271:\tlearn: 0.0874711\ttotal: 36.4s\tremaining: 1m 37s\n",
      "272:\tlearn: 0.0874365\ttotal: 36.6s\tremaining: 1m 37s\n",
      "273:\tlearn: 0.0873673\ttotal: 36.7s\tremaining: 1m 37s\n",
      "274:\tlearn: 0.0872807\ttotal: 36.8s\tremaining: 1m 37s\n",
      "275:\tlearn: 0.0871422\ttotal: 37s\tremaining: 1m 36s\n",
      "276:\tlearn: 0.0870729\ttotal: 37.1s\tremaining: 1m 36s\n",
      "277:\tlearn: 0.0871249\ttotal: 37.2s\tremaining: 1m 36s\n",
      "278:\tlearn: 0.0870210\ttotal: 37.4s\tremaining: 1m 36s\n",
      "279:\tlearn: 0.0869864\ttotal: 37.5s\tremaining: 1m 36s\n",
      "280:\tlearn: 0.0869114\ttotal: 37.7s\tremaining: 1m 36s\n",
      "281:\tlearn: 0.0868479\ttotal: 37.9s\tremaining: 1m 36s\n",
      "282:\tlearn: 0.0867959\ttotal: 38s\tremaining: 1m 36s\n",
      "283:\tlearn: 0.0867786\ttotal: 38.2s\tremaining: 1m 36s\n",
      "284:\tlearn: 0.0867094\ttotal: 38.3s\tremaining: 1m 36s\n",
      "285:\tlearn: 0.0866459\ttotal: 38.5s\tremaining: 1m 36s\n",
      "286:\tlearn: 0.0865362\ttotal: 38.6s\tremaining: 1m 35s\n",
      "287:\tlearn: 0.0864497\ttotal: 38.8s\tremaining: 1m 35s\n",
      "288:\tlearn: 0.0864151\ttotal: 38.9s\tremaining: 1m 35s\n",
      "289:\tlearn: 0.0863169\ttotal: 39.1s\tremaining: 1m 35s\n",
      "290:\tlearn: 0.0862419\ttotal: 39.3s\tremaining: 1m 35s\n",
      "291:\tlearn: 0.0860803\ttotal: 39.4s\tremaining: 1m 35s\n",
      "292:\tlearn: 0.0860630\ttotal: 39.6s\tremaining: 1m 35s\n",
      "293:\tlearn: 0.0860515\ttotal: 39.7s\tremaining: 1m 35s\n",
      "294:\tlearn: 0.0859938\ttotal: 39.9s\tremaining: 1m 35s\n",
      "295:\tlearn: 0.0858553\ttotal: 40s\tremaining: 1m 35s\n",
      "296:\tlearn: 0.0858380\ttotal: 40.2s\tremaining: 1m 35s\n",
      "297:\tlearn: 0.0857802\ttotal: 40.3s\tremaining: 1m 34s\n",
      "298:\tlearn: 0.0857283\ttotal: 40.5s\tremaining: 1m 34s\n",
      "299:\tlearn: 0.0857110\ttotal: 40.6s\tremaining: 1m 34s\n",
      "300:\tlearn: 0.0856764\ttotal: 40.8s\tremaining: 1m 34s\n",
      "301:\tlearn: 0.0855840\ttotal: 40.9s\tremaining: 1m 34s\n",
      "302:\tlearn: 0.0855609\ttotal: 41.1s\tremaining: 1m 34s\n",
      "303:\tlearn: 0.0855436\ttotal: 41.2s\tremaining: 1m 34s\n",
      "304:\tlearn: 0.0855090\ttotal: 41.4s\tremaining: 1m 34s\n",
      "305:\tlearn: 0.0854455\ttotal: 41.6s\tremaining: 1m 34s\n",
      "306:\tlearn: 0.0853936\ttotal: 41.8s\tremaining: 1m 34s\n",
      "307:\tlearn: 0.0853243\ttotal: 42s\tremaining: 1m 34s\n",
      "308:\tlearn: 0.0852320\ttotal: 42.2s\tremaining: 1m 34s\n",
      "309:\tlearn: 0.0851512\ttotal: 42.4s\tremaining: 1m 34s\n",
      "310:\tlearn: 0.0851108\ttotal: 42.6s\tremaining: 1m 34s\n",
      "311:\tlearn: 0.0850127\ttotal: 42.8s\tremaining: 1m 34s\n",
      "312:\tlearn: 0.0850012\ttotal: 42.9s\tremaining: 1m 34s\n",
      "313:\tlearn: 0.0848915\ttotal: 43.1s\tremaining: 1m 34s\n",
      "314:\tlearn: 0.0848396\ttotal: 43.2s\tremaining: 1m 34s\n",
      "315:\tlearn: 0.0847241\ttotal: 43.4s\tremaining: 1m 33s\n",
      "316:\tlearn: 0.0847011\ttotal: 43.5s\tremaining: 1m 33s\n",
      "317:\tlearn: 0.0845683\ttotal: 43.7s\tremaining: 1m 33s\n",
      "318:\tlearn: 0.0845279\ttotal: 43.8s\tremaining: 1m 33s\n",
      "319:\tlearn: 0.0845106\ttotal: 44s\tremaining: 1m 33s\n",
      "320:\tlearn: 0.0843837\ttotal: 44.1s\tremaining: 1m 33s\n",
      "321:\tlearn: 0.0844587\ttotal: 44.3s\tremaining: 1m 33s\n",
      "322:\tlearn: 0.0843202\ttotal: 44.4s\tremaining: 1m 33s\n",
      "323:\tlearn: 0.0843029\ttotal: 44.5s\tremaining: 1m 32s\n",
      "324:\tlearn: 0.0842682\ttotal: 44.7s\tremaining: 1m 32s\n",
      "325:\tlearn: 0.0842394\ttotal: 44.8s\tremaining: 1m 32s\n",
      "326:\tlearn: 0.0842048\ttotal: 44.9s\tremaining: 1m 32s\n",
      "327:\tlearn: 0.0841759\ttotal: 45.1s\tremaining: 1m 32s\n",
      "328:\tlearn: 0.0841355\ttotal: 45.2s\tremaining: 1m 32s\n",
      "329:\tlearn: 0.0841009\ttotal: 45.3s\tremaining: 1m 32s\n",
      "330:\tlearn: 0.0840316\ttotal: 45.5s\tremaining: 1m 31s\n",
      "331:\tlearn: 0.0839912\ttotal: 45.6s\tremaining: 1m 31s\n",
      "332:\tlearn: 0.0839970\ttotal: 45.8s\tremaining: 1m 31s\n",
      "333:\tlearn: 0.0839162\ttotal: 45.9s\tremaining: 1m 31s\n",
      "334:\tlearn: 0.0838700\ttotal: 46s\tremaining: 1m 31s\n",
      "335:\tlearn: 0.0837258\ttotal: 46.2s\tremaining: 1m 31s\n",
      "336:\tlearn: 0.0837315\ttotal: 46.3s\tremaining: 1m 31s\n",
      "337:\tlearn: 0.0836450\ttotal: 46.4s\tremaining: 1m 30s\n",
      "338:\tlearn: 0.0835757\ttotal: 46.6s\tremaining: 1m 30s\n",
      "339:\tlearn: 0.0835526\ttotal: 46.7s\tremaining: 1m 30s\n",
      "340:\tlearn: 0.0834314\ttotal: 46.8s\tremaining: 1m 30s\n",
      "341:\tlearn: 0.0834199\ttotal: 47s\tremaining: 1m 30s\n",
      "342:\tlearn: 0.0834084\ttotal: 47.1s\tremaining: 1m 30s\n",
      "343:\tlearn: 0.0833391\ttotal: 47.2s\tremaining: 1m 30s\n",
      "344:\tlearn: 0.0832179\ttotal: 47.4s\tremaining: 1m 29s\n",
      "345:\tlearn: 0.0830967\ttotal: 47.5s\tremaining: 1m 29s\n",
      "346:\tlearn: 0.0830852\ttotal: 47.6s\tremaining: 1m 29s\n",
      "347:\tlearn: 0.0830332\ttotal: 47.8s\tremaining: 1m 29s\n",
      "348:\tlearn: 0.0829467\ttotal: 47.9s\tremaining: 1m 29s\n",
      "349:\tlearn: 0.0828947\ttotal: 48.1s\tremaining: 1m 29s\n",
      "350:\tlearn: 0.0828370\ttotal: 48.2s\tremaining: 1m 29s\n",
      "351:\tlearn: 0.0828082\ttotal: 48.3s\tremaining: 1m 28s\n",
      "352:\tlearn: 0.0827562\ttotal: 48.5s\tremaining: 1m 28s\n",
      "353:\tlearn: 0.0827389\ttotal: 48.6s\tremaining: 1m 28s\n",
      "354:\tlearn: 0.0825485\ttotal: 48.7s\tremaining: 1m 28s\n",
      "355:\tlearn: 0.0825196\ttotal: 48.9s\tremaining: 1m 28s\n",
      "356:\tlearn: 0.0825196\ttotal: 49s\tremaining: 1m 28s\n",
      "357:\tlearn: 0.0824677\ttotal: 49.1s\tremaining: 1m 28s\n",
      "358:\tlearn: 0.0823811\ttotal: 49.2s\tremaining: 1m 27s\n",
      "359:\tlearn: 0.0823119\ttotal: 49.4s\tremaining: 1m 27s\n",
      "360:\tlearn: 0.0822888\ttotal: 49.5s\tremaining: 1m 27s\n",
      "361:\tlearn: 0.0821791\ttotal: 49.6s\tremaining: 1m 27s\n",
      "362:\tlearn: 0.0820522\ttotal: 49.8s\tremaining: 1m 27s\n",
      "363:\tlearn: 0.0820175\ttotal: 49.9s\tremaining: 1m 27s\n",
      "364:\tlearn: 0.0819252\ttotal: 50s\tremaining: 1m 27s\n",
      "365:\tlearn: 0.0819310\ttotal: 50.2s\tremaining: 1m 26s\n",
      "366:\tlearn: 0.0817982\ttotal: 50.3s\tremaining: 1m 26s\n",
      "367:\tlearn: 0.0817290\ttotal: 50.4s\tremaining: 1m 26s\n",
      "368:\tlearn: 0.0816944\ttotal: 50.6s\tremaining: 1m 26s\n",
      "369:\tlearn: 0.0816424\ttotal: 50.7s\tremaining: 1m 26s\n",
      "370:\tlearn: 0.0815559\ttotal: 50.9s\tremaining: 1m 26s\n",
      "371:\tlearn: 0.0815328\ttotal: 51s\tremaining: 1m 26s\n",
      "372:\tlearn: 0.0814635\ttotal: 51.2s\tremaining: 1m 26s\n",
      "373:\tlearn: 0.0813770\ttotal: 51.3s\tremaining: 1m 25s\n",
      "374:\tlearn: 0.0813193\ttotal: 51.5s\tremaining: 1m 25s\n",
      "375:\tlearn: 0.0812615\ttotal: 51.7s\tremaining: 1m 25s\n",
      "376:\tlearn: 0.0812500\ttotal: 51.9s\tremaining: 1m 25s\n",
      "377:\tlearn: 0.0811807\ttotal: 52.1s\tremaining: 1m 25s\n",
      "378:\tlearn: 0.0811404\ttotal: 52.3s\tremaining: 1m 25s\n",
      "379:\tlearn: 0.0810596\ttotal: 52.4s\tremaining: 1m 25s\n",
      "380:\tlearn: 0.0810365\ttotal: 52.6s\tremaining: 1m 25s\n",
      "381:\tlearn: 0.0809499\ttotal: 52.8s\tremaining: 1m 25s\n",
      "382:\tlearn: 0.0809557\ttotal: 52.9s\tremaining: 1m 25s\n",
      "383:\tlearn: 0.0809211\ttotal: 53s\tremaining: 1m 25s\n",
      "384:\tlearn: 0.0808864\ttotal: 53.2s\tremaining: 1m 24s\n",
      "385:\tlearn: 0.0808749\ttotal: 53.3s\tremaining: 1m 24s\n",
      "386:\tlearn: 0.0807999\ttotal: 53.4s\tremaining: 1m 24s\n",
      "387:\tlearn: 0.0807075\ttotal: 53.6s\tremaining: 1m 24s\n",
      "388:\tlearn: 0.0806729\ttotal: 53.7s\tremaining: 1m 24s\n",
      "389:\tlearn: 0.0806152\ttotal: 53.9s\tremaining: 1m 24s\n",
      "390:\tlearn: 0.0805748\ttotal: 54s\tremaining: 1m 24s\n",
      "391:\tlearn: 0.0805633\ttotal: 54.1s\tremaining: 1m 23s\n",
      "392:\tlearn: 0.0804421\ttotal: 54.3s\tremaining: 1m 23s\n",
      "393:\tlearn: 0.0804247\ttotal: 54.4s\tremaining: 1m 23s\n",
      "394:\tlearn: 0.0804767\ttotal: 54.5s\tremaining: 1m 23s\n",
      "395:\tlearn: 0.0803843\ttotal: 54.7s\tremaining: 1m 23s\n",
      "396:\tlearn: 0.0803670\ttotal: 54.8s\tremaining: 1m 23s\n",
      "397:\tlearn: 0.0803324\ttotal: 54.9s\tremaining: 1m 23s\n",
      "398:\tlearn: 0.0802054\ttotal: 55.1s\tremaining: 1m 22s\n",
      "399:\tlearn: 0.0801593\ttotal: 55.2s\tremaining: 1m 22s\n",
      "400:\tlearn: 0.0800554\ttotal: 55.3s\tremaining: 1m 22s\n",
      "401:\tlearn: 0.0799977\ttotal: 55.5s\tremaining: 1m 22s\n",
      "402:\tlearn: 0.0799111\ttotal: 55.6s\tremaining: 1m 22s\n",
      "403:\tlearn: 0.0798996\ttotal: 55.7s\tremaining: 1m 22s\n",
      "404:\tlearn: 0.0798938\ttotal: 55.9s\tremaining: 1m 22s\n",
      "405:\tlearn: 0.0798592\ttotal: 56s\tremaining: 1m 21s\n",
      "406:\tlearn: 0.0798130\ttotal: 56.1s\tremaining: 1m 21s\n",
      "407:\tlearn: 0.0797438\ttotal: 56.3s\tremaining: 1m 21s\n",
      "408:\tlearn: 0.0796687\ttotal: 56.4s\tremaining: 1m 21s\n",
      "409:\tlearn: 0.0796283\ttotal: 56.6s\tremaining: 1m 21s\n",
      "410:\tlearn: 0.0795706\ttotal: 56.7s\tremaining: 1m 21s\n",
      "411:\tlearn: 0.0794379\ttotal: 56.8s\tremaining: 1m 21s\n",
      "412:\tlearn: 0.0794264\ttotal: 57s\tremaining: 1m 20s\n",
      "413:\tlearn: 0.0793802\ttotal: 57.1s\tremaining: 1m 20s\n",
      "414:\tlearn: 0.0792705\ttotal: 57.2s\tremaining: 1m 20s\n",
      "415:\tlearn: 0.0792013\ttotal: 57.4s\tremaining: 1m 20s\n",
      "416:\tlearn: 0.0792013\ttotal: 57.5s\tremaining: 1m 20s\n",
      "417:\tlearn: 0.0791320\ttotal: 57.6s\tremaining: 1m 20s\n",
      "418:\tlearn: 0.0790455\ttotal: 57.8s\tremaining: 1m 20s\n",
      "419:\tlearn: 0.0790051\ttotal: 57.9s\tremaining: 1m 19s\n",
      "420:\tlearn: 0.0789301\ttotal: 58s\tremaining: 1m 19s\n",
      "421:\tlearn: 0.0789416\ttotal: 58.2s\tremaining: 1m 19s\n",
      "422:\tlearn: 0.0788608\ttotal: 58.3s\tremaining: 1m 19s\n",
      "423:\tlearn: 0.0788204\ttotal: 58.4s\tremaining: 1m 19s\n",
      "424:\tlearn: 0.0787916\ttotal: 58.6s\tremaining: 1m 19s\n",
      "425:\tlearn: 0.0786473\ttotal: 58.7s\tremaining: 1m 19s\n",
      "426:\tlearn: 0.0784857\ttotal: 58.9s\tremaining: 1m 18s\n",
      "427:\tlearn: 0.0784626\ttotal: 59s\tremaining: 1m 18s\n",
      "428:\tlearn: 0.0784280\ttotal: 59.2s\tremaining: 1m 18s\n",
      "429:\tlearn: 0.0783703\ttotal: 59.3s\tremaining: 1m 18s\n",
      "430:\tlearn: 0.0783299\ttotal: 59.4s\tremaining: 1m 18s\n",
      "431:\tlearn: 0.0783126\ttotal: 59.6s\tremaining: 1m 18s\n",
      "432:\tlearn: 0.0782952\ttotal: 59.7s\tremaining: 1m 18s\n",
      "433:\tlearn: 0.0782145\ttotal: 59.8s\tremaining: 1m 18s\n",
      "434:\tlearn: 0.0781279\ttotal: 60s\tremaining: 1m 17s\n",
      "435:\tlearn: 0.0780702\ttotal: 1m\tremaining: 1m 17s\n",
      "436:\tlearn: 0.0779894\ttotal: 1m\tremaining: 1m 17s\n",
      "437:\tlearn: 0.0778855\ttotal: 1m\tremaining: 1m 17s\n",
      "438:\tlearn: 0.0778509\ttotal: 1m\tremaining: 1m 17s\n",
      "439:\tlearn: 0.0778336\ttotal: 1m\tremaining: 1m 17s\n",
      "440:\tlearn: 0.0777297\ttotal: 1m\tremaining: 1m 17s\n",
      "441:\tlearn: 0.0776893\ttotal: 1m\tremaining: 1m 16s\n",
      "442:\tlearn: 0.0776489\ttotal: 1m 1s\tremaining: 1m 16s\n",
      "443:\tlearn: 0.0775623\ttotal: 1m 1s\tremaining: 1m 16s\n",
      "444:\tlearn: 0.0775450\ttotal: 1m 1s\tremaining: 1m 16s\n",
      "445:\tlearn: 0.0774065\ttotal: 1m 1s\tremaining: 1m 16s\n",
      "446:\tlearn: 0.0774411\ttotal: 1m 1s\tremaining: 1m 16s\n",
      "447:\tlearn: 0.0774181\ttotal: 1m 1s\tremaining: 1m 16s\n",
      "448:\tlearn: 0.0773603\ttotal: 1m 1s\tremaining: 1m 15s\n",
      "449:\tlearn: 0.0772276\ttotal: 1m 1s\tremaining: 1m 15s\n",
      "450:\tlearn: 0.0772045\ttotal: 1m 2s\tremaining: 1m 15s\n",
      "451:\tlearn: 0.0771064\ttotal: 1m 2s\tremaining: 1m 15s\n",
      "452:\tlearn: 0.0770833\ttotal: 1m 2s\tremaining: 1m 15s\n",
      "453:\tlearn: 0.0769564\ttotal: 1m 2s\tremaining: 1m 15s\n",
      "454:\tlearn: 0.0769217\ttotal: 1m 2s\tremaining: 1m 15s\n",
      "455:\tlearn: 0.0767832\ttotal: 1m 2s\tremaining: 1m 14s\n",
      "456:\tlearn: 0.0767890\ttotal: 1m 2s\tremaining: 1m 14s\n",
      "457:\tlearn: 0.0767082\ttotal: 1m 3s\tremaining: 1m 14s\n",
      "458:\tlearn: 0.0766678\ttotal: 1m 3s\tremaining: 1m 14s\n",
      "459:\tlearn: 0.0766332\ttotal: 1m 3s\tremaining: 1m 14s\n",
      "460:\tlearn: 0.0765928\ttotal: 1m 3s\tremaining: 1m 14s\n",
      "461:\tlearn: 0.0765524\ttotal: 1m 3s\tremaining: 1m 14s\n",
      "462:\tlearn: 0.0764889\ttotal: 1m 3s\tremaining: 1m 13s\n",
      "463:\tlearn: 0.0764831\ttotal: 1m 3s\tremaining: 1m 13s\n",
      "464:\tlearn: 0.0764543\ttotal: 1m 3s\tremaining: 1m 13s\n",
      "465:\tlearn: 0.0763908\ttotal: 1m 4s\tremaining: 1m 13s\n",
      "466:\tlearn: 0.0763620\ttotal: 1m 4s\tremaining: 1m 13s\n",
      "467:\tlearn: 0.0762754\ttotal: 1m 4s\tremaining: 1m 13s\n",
      "468:\tlearn: 0.0762696\ttotal: 1m 4s\tremaining: 1m 13s\n",
      "469:\tlearn: 0.0762696\ttotal: 1m 4s\tremaining: 1m 12s\n",
      "470:\tlearn: 0.0762061\ttotal: 1m 4s\tremaining: 1m 12s\n",
      "471:\tlearn: 0.0761715\ttotal: 1m 4s\tremaining: 1m 12s\n",
      "472:\tlearn: 0.0761600\ttotal: 1m 5s\tremaining: 1m 12s\n",
      "473:\tlearn: 0.0761196\ttotal: 1m 5s\tremaining: 1m 12s\n",
      "474:\tlearn: 0.0760619\ttotal: 1m 5s\tremaining: 1m 12s\n",
      "475:\tlearn: 0.0759464\ttotal: 1m 5s\tremaining: 1m 12s\n",
      "476:\tlearn: 0.0759407\ttotal: 1m 5s\tremaining: 1m 11s\n",
      "477:\tlearn: 0.0759003\ttotal: 1m 5s\tremaining: 1m 11s\n",
      "478:\tlearn: 0.0758657\ttotal: 1m 5s\tremaining: 1m 11s\n",
      "479:\tlearn: 0.0758714\ttotal: 1m 6s\tremaining: 1m 11s\n",
      "480:\tlearn: 0.0758541\ttotal: 1m 6s\tremaining: 1m 11s\n",
      "481:\tlearn: 0.0757964\ttotal: 1m 6s\tremaining: 1m 11s\n",
      "482:\tlearn: 0.0757502\ttotal: 1m 6s\tremaining: 1m 11s\n",
      "483:\tlearn: 0.0756867\ttotal: 1m 6s\tremaining: 1m 10s\n",
      "484:\tlearn: 0.0756175\ttotal: 1m 6s\tremaining: 1m 10s\n",
      "485:\tlearn: 0.0755771\ttotal: 1m 6s\tremaining: 1m 10s\n",
      "486:\tlearn: 0.0754790\ttotal: 1m 7s\tremaining: 1m 10s\n",
      "487:\tlearn: 0.0753751\ttotal: 1m 7s\tremaining: 1m 10s\n",
      "488:\tlearn: 0.0754386\ttotal: 1m 7s\tremaining: 1m 10s\n",
      "489:\tlearn: 0.0753636\ttotal: 1m 7s\tremaining: 1m 10s\n",
      "490:\tlearn: 0.0753059\ttotal: 1m 7s\tremaining: 1m 10s\n",
      "491:\tlearn: 0.0752770\ttotal: 1m 7s\tremaining: 1m 9s\n",
      "492:\tlearn: 0.0751674\ttotal: 1m 7s\tremaining: 1m 9s\n",
      "493:\tlearn: 0.0751731\ttotal: 1m 8s\tremaining: 1m 9s\n",
      "494:\tlearn: 0.0751500\ttotal: 1m 8s\tremaining: 1m 9s\n",
      "495:\tlearn: 0.0750289\ttotal: 1m 8s\tremaining: 1m 9s\n",
      "496:\tlearn: 0.0749885\ttotal: 1m 8s\tremaining: 1m 9s\n",
      "497:\tlearn: 0.0749134\ttotal: 1m 8s\tremaining: 1m 9s\n",
      "498:\tlearn: 0.0748442\ttotal: 1m 8s\tremaining: 1m 9s\n",
      "499:\tlearn: 0.0748211\ttotal: 1m 8s\tremaining: 1m 8s\n",
      "500:\tlearn: 0.0747576\ttotal: 1m 9s\tremaining: 1m 8s\n",
      "501:\tlearn: 0.0747345\ttotal: 1m 9s\tremaining: 1m 8s\n",
      "502:\tlearn: 0.0746595\ttotal: 1m 9s\tremaining: 1m 8s\n",
      "503:\tlearn: 0.0745672\ttotal: 1m 9s\tremaining: 1m 8s\n",
      "504:\tlearn: 0.0745325\ttotal: 1m 9s\tremaining: 1m 8s\n",
      "505:\tlearn: 0.0744806\ttotal: 1m 9s\tremaining: 1m 8s\n",
      "506:\tlearn: 0.0744402\ttotal: 1m 9s\tremaining: 1m 7s\n",
      "507:\tlearn: 0.0743940\ttotal: 1m 9s\tremaining: 1m 7s\n",
      "508:\tlearn: 0.0744633\ttotal: 1m 10s\tremaining: 1m 7s\n",
      "509:\tlearn: 0.0743536\ttotal: 1m 10s\tremaining: 1m 7s\n",
      "510:\tlearn: 0.0742844\ttotal: 1m 10s\tremaining: 1m 7s\n",
      "511:\tlearn: 0.0742613\ttotal: 1m 10s\tremaining: 1m 7s\n",
      "512:\tlearn: 0.0741978\ttotal: 1m 10s\tremaining: 1m 7s\n",
      "513:\tlearn: 0.0741574\ttotal: 1m 10s\tremaining: 1m 6s\n",
      "514:\tlearn: 0.0740593\ttotal: 1m 10s\tremaining: 1m 6s\n",
      "515:\tlearn: 0.0740074\ttotal: 1m 11s\tremaining: 1m 6s\n",
      "516:\tlearn: 0.0739151\ttotal: 1m 11s\tremaining: 1m 6s\n",
      "517:\tlearn: 0.0738689\ttotal: 1m 11s\tremaining: 1m 6s\n",
      "518:\tlearn: 0.0738573\ttotal: 1m 11s\tremaining: 1m 6s\n",
      "519:\tlearn: 0.0737708\ttotal: 1m 11s\tremaining: 1m 6s\n",
      "520:\tlearn: 0.0737015\ttotal: 1m 11s\tremaining: 1m 5s\n",
      "521:\tlearn: 0.0736784\ttotal: 1m 11s\tremaining: 1m 5s\n",
      "522:\tlearn: 0.0736380\ttotal: 1m 11s\tremaining: 1m 5s\n",
      "523:\tlearn: 0.0735630\ttotal: 1m 12s\tremaining: 1m 5s\n",
      "524:\tlearn: 0.0735226\ttotal: 1m 12s\tremaining: 1m 5s\n",
      "525:\tlearn: 0.0734130\ttotal: 1m 12s\tremaining: 1m 5s\n",
      "526:\tlearn: 0.0733553\ttotal: 1m 12s\tremaining: 1m 5s\n",
      "527:\tlearn: 0.0731994\ttotal: 1m 12s\tremaining: 1m 4s\n",
      "528:\tlearn: 0.0732052\ttotal: 1m 12s\tremaining: 1m 4s\n",
      "529:\tlearn: 0.0731937\ttotal: 1m 12s\tremaining: 1m 4s\n",
      "530:\tlearn: 0.0730898\ttotal: 1m 13s\tremaining: 1m 4s\n",
      "531:\tlearn: 0.0730840\ttotal: 1m 13s\tremaining: 1m 4s\n",
      "532:\tlearn: 0.0730667\ttotal: 1m 13s\tremaining: 1m 4s\n",
      "533:\tlearn: 0.0730436\ttotal: 1m 13s\tremaining: 1m 4s\n",
      "534:\tlearn: 0.0730379\ttotal: 1m 13s\tremaining: 1m 3s\n",
      "535:\tlearn: 0.0729975\ttotal: 1m 13s\tremaining: 1m 3s\n",
      "536:\tlearn: 0.0728936\ttotal: 1m 13s\tremaining: 1m 3s\n",
      "537:\tlearn: 0.0728763\ttotal: 1m 13s\tremaining: 1m 3s\n",
      "538:\tlearn: 0.0728359\ttotal: 1m 14s\tremaining: 1m 3s\n",
      "539:\tlearn: 0.0728070\ttotal: 1m 14s\tremaining: 1m 3s\n",
      "540:\tlearn: 0.0727435\ttotal: 1m 14s\tremaining: 1m 3s\n",
      "541:\tlearn: 0.0726223\ttotal: 1m 14s\tremaining: 1m 2s\n",
      "542:\tlearn: 0.0726166\ttotal: 1m 14s\tremaining: 1m 2s\n",
      "543:\tlearn: 0.0725012\ttotal: 1m 14s\tremaining: 1m 2s\n",
      "544:\tlearn: 0.0724146\ttotal: 1m 14s\tremaining: 1m 2s\n",
      "545:\tlearn: 0.0723915\ttotal: 1m 15s\tremaining: 1m 2s\n",
      "546:\tlearn: 0.0722992\ttotal: 1m 15s\tremaining: 1m 2s\n",
      "547:\tlearn: 0.0722415\ttotal: 1m 15s\tremaining: 1m 2s\n",
      "548:\tlearn: 0.0721664\ttotal: 1m 15s\tremaining: 1m 2s\n",
      "549:\tlearn: 0.0722011\ttotal: 1m 15s\tremaining: 1m 1s\n",
      "550:\tlearn: 0.0721376\ttotal: 1m 15s\tremaining: 1m 1s\n",
      "551:\tlearn: 0.0721318\ttotal: 1m 15s\tremaining: 1m 1s\n",
      "552:\tlearn: 0.0721030\ttotal: 1m 16s\tremaining: 1m 1s\n",
      "553:\tlearn: 0.0720222\ttotal: 1m 16s\tremaining: 1m 1s\n",
      "554:\tlearn: 0.0720452\ttotal: 1m 16s\tremaining: 1m 1s\n",
      "555:\tlearn: 0.0720222\ttotal: 1m 16s\tremaining: 1m 1s\n",
      "556:\tlearn: 0.0719356\ttotal: 1m 16s\tremaining: 1m\n",
      "557:\tlearn: 0.0718548\ttotal: 1m 16s\tremaining: 1m\n",
      "558:\tlearn: 0.0718606\ttotal: 1m 16s\tremaining: 1m\n",
      "559:\tlearn: 0.0718086\ttotal: 1m 16s\tremaining: 1m\n",
      "560:\tlearn: 0.0716932\ttotal: 1m 17s\tremaining: 1m\n",
      "561:\tlearn: 0.0716817\ttotal: 1m 17s\tremaining: 1m\n",
      "562:\tlearn: 0.0716124\ttotal: 1m 17s\tremaining: 1m\n",
      "563:\tlearn: 0.0715720\ttotal: 1m 17s\tremaining: 59.9s\n",
      "564:\tlearn: 0.0716240\ttotal: 1m 17s\tremaining: 59.8s\n",
      "565:\tlearn: 0.0715316\ttotal: 1m 17s\tremaining: 59.6s\n",
      "566:\tlearn: 0.0714855\ttotal: 1m 17s\tremaining: 59.5s\n",
      "567:\tlearn: 0.0714508\ttotal: 1m 18s\tremaining: 59.3s\n",
      "568:\tlearn: 0.0713873\ttotal: 1m 18s\tremaining: 59.2s\n",
      "569:\tlearn: 0.0713123\ttotal: 1m 18s\tremaining: 59.1s\n",
      "570:\tlearn: 0.0712662\ttotal: 1m 18s\tremaining: 58.9s\n",
      "571:\tlearn: 0.0711854\ttotal: 1m 18s\tremaining: 58.8s\n",
      "572:\tlearn: 0.0711161\ttotal: 1m 18s\tremaining: 58.6s\n",
      "573:\tlearn: 0.0711392\ttotal: 1m 18s\tremaining: 58.5s\n",
      "574:\tlearn: 0.0711450\ttotal: 1m 18s\tremaining: 58.4s\n",
      "575:\tlearn: 0.0710930\ttotal: 1m 19s\tremaining: 58.2s\n",
      "576:\tlearn: 0.0710180\ttotal: 1m 19s\tremaining: 58.1s\n",
      "577:\tlearn: 0.0709834\ttotal: 1m 19s\tremaining: 57.9s\n",
      "578:\tlearn: 0.0709661\ttotal: 1m 19s\tremaining: 57.8s\n",
      "579:\tlearn: 0.0709488\ttotal: 1m 19s\tremaining: 57.7s\n",
      "580:\tlearn: 0.0709141\ttotal: 1m 19s\tremaining: 57.5s\n",
      "581:\tlearn: 0.0708564\ttotal: 1m 19s\tremaining: 57.4s\n",
      "582:\tlearn: 0.0707814\ttotal: 1m 20s\tremaining: 57.2s\n",
      "583:\tlearn: 0.0706833\ttotal: 1m 20s\tremaining: 57.1s\n",
      "584:\tlearn: 0.0706487\ttotal: 1m 20s\tremaining: 57s\n",
      "585:\tlearn: 0.0706083\ttotal: 1m 20s\tremaining: 56.8s\n",
      "586:\tlearn: 0.0705679\ttotal: 1m 20s\tremaining: 56.7s\n",
      "587:\tlearn: 0.0705506\ttotal: 1m 20s\tremaining: 56.5s\n",
      "588:\tlearn: 0.0705390\ttotal: 1m 20s\tremaining: 56.4s\n",
      "589:\tlearn: 0.0704698\ttotal: 1m 20s\tremaining: 56.3s\n",
      "590:\tlearn: 0.0703947\ttotal: 1m 21s\tremaining: 56.1s\n",
      "591:\tlearn: 0.0703197\ttotal: 1m 21s\tremaining: 56s\n",
      "592:\tlearn: 0.0702216\ttotal: 1m 21s\tremaining: 55.8s\n",
      "593:\tlearn: 0.0702158\ttotal: 1m 21s\tremaining: 55.7s\n",
      "594:\tlearn: 0.0701639\ttotal: 1m 21s\tremaining: 55.6s\n",
      "595:\tlearn: 0.0701235\ttotal: 1m 21s\tremaining: 55.4s\n",
      "596:\tlearn: 0.0701062\ttotal: 1m 21s\tremaining: 55.3s\n",
      "597:\tlearn: 0.0700600\ttotal: 1m 22s\tremaining: 55.1s\n",
      "598:\tlearn: 0.0700485\ttotal: 1m 22s\tremaining: 55s\n",
      "599:\tlearn: 0.0700196\ttotal: 1m 22s\tremaining: 54.9s\n",
      "600:\tlearn: 0.0699561\ttotal: 1m 22s\tremaining: 54.7s\n",
      "601:\tlearn: 0.0698696\ttotal: 1m 22s\tremaining: 54.6s\n",
      "602:\tlearn: 0.0699042\ttotal: 1m 22s\tremaining: 54.5s\n",
      "603:\tlearn: 0.0697888\ttotal: 1m 22s\tremaining: 54.3s\n",
      "604:\tlearn: 0.0697426\ttotal: 1m 22s\tremaining: 54.2s\n",
      "605:\tlearn: 0.0695868\ttotal: 1m 23s\tremaining: 54.1s\n",
      "606:\tlearn: 0.0695579\ttotal: 1m 23s\tremaining: 53.9s\n",
      "607:\tlearn: 0.0695522\ttotal: 1m 23s\tremaining: 53.8s\n",
      "608:\tlearn: 0.0695579\ttotal: 1m 23s\tremaining: 53.7s\n",
      "609:\tlearn: 0.0694945\ttotal: 1m 23s\tremaining: 53.5s\n",
      "610:\tlearn: 0.0695118\ttotal: 1m 23s\tremaining: 53.4s\n",
      "611:\tlearn: 0.0694656\ttotal: 1m 24s\tremaining: 53.3s\n",
      "612:\tlearn: 0.0693964\ttotal: 1m 24s\tremaining: 53.1s\n",
      "613:\tlearn: 0.0693733\ttotal: 1m 24s\tremaining: 53s\n",
      "614:\tlearn: 0.0693386\ttotal: 1m 24s\tremaining: 52.9s\n",
      "615:\tlearn: 0.0693386\ttotal: 1m 24s\tremaining: 52.7s\n",
      "616:\tlearn: 0.0692925\ttotal: 1m 24s\tremaining: 52.6s\n",
      "617:\tlearn: 0.0692752\ttotal: 1m 24s\tremaining: 52.4s\n",
      "618:\tlearn: 0.0692175\ttotal: 1m 24s\tremaining: 52.3s\n",
      "619:\tlearn: 0.0691367\ttotal: 1m 25s\tremaining: 52.1s\n",
      "620:\tlearn: 0.0690328\ttotal: 1m 25s\tremaining: 52s\n",
      "621:\tlearn: 0.0690328\ttotal: 1m 25s\tremaining: 51.9s\n",
      "622:\tlearn: 0.0690386\ttotal: 1m 25s\tremaining: 51.7s\n",
      "623:\tlearn: 0.0689866\ttotal: 1m 25s\tremaining: 51.6s\n",
      "624:\tlearn: 0.0689347\ttotal: 1m 25s\tremaining: 51.5s\n",
      "625:\tlearn: 0.0689058\ttotal: 1m 25s\tremaining: 51.3s\n",
      "626:\tlearn: 0.0688366\ttotal: 1m 26s\tremaining: 51.2s\n",
      "627:\tlearn: 0.0687846\ttotal: 1m 26s\tremaining: 51s\n",
      "628:\tlearn: 0.0687096\ttotal: 1m 26s\tremaining: 50.9s\n",
      "629:\tlearn: 0.0686230\ttotal: 1m 26s\tremaining: 50.8s\n",
      "630:\tlearn: 0.0685884\ttotal: 1m 26s\tremaining: 50.6s\n",
      "631:\tlearn: 0.0684903\ttotal: 1m 26s\tremaining: 50.5s\n",
      "632:\tlearn: 0.0684961\ttotal: 1m 26s\tremaining: 50.3s\n",
      "633:\tlearn: 0.0684845\ttotal: 1m 26s\tremaining: 50.2s\n",
      "634:\tlearn: 0.0684672\ttotal: 1m 27s\tremaining: 50.1s\n",
      "635:\tlearn: 0.0684037\ttotal: 1m 27s\tremaining: 49.9s\n",
      "636:\tlearn: 0.0683691\ttotal: 1m 27s\tremaining: 49.8s\n",
      "637:\tlearn: 0.0682999\ttotal: 1m 27s\tremaining: 49.6s\n",
      "638:\tlearn: 0.0682422\ttotal: 1m 27s\tremaining: 49.5s\n",
      "639:\tlearn: 0.0681556\ttotal: 1m 27s\tremaining: 49.4s\n",
      "640:\tlearn: 0.0681844\ttotal: 1m 27s\tremaining: 49.2s\n",
      "641:\tlearn: 0.0681614\ttotal: 1m 28s\tremaining: 49.1s\n",
      "642:\tlearn: 0.0680979\ttotal: 1m 28s\tremaining: 49s\n",
      "643:\tlearn: 0.0680633\ttotal: 1m 28s\tremaining: 48.8s\n",
      "644:\tlearn: 0.0680633\ttotal: 1m 28s\tremaining: 48.7s\n",
      "645:\tlearn: 0.0679940\ttotal: 1m 28s\tremaining: 48.5s\n",
      "646:\tlearn: 0.0679940\ttotal: 1m 28s\tremaining: 48.4s\n",
      "647:\tlearn: 0.0679305\ttotal: 1m 28s\tremaining: 48.3s\n",
      "648:\tlearn: 0.0679074\ttotal: 1m 29s\tremaining: 48.1s\n",
      "649:\tlearn: 0.0678786\ttotal: 1m 29s\tremaining: 48s\n",
      "650:\tlearn: 0.0678613\ttotal: 1m 29s\tremaining: 47.9s\n",
      "651:\tlearn: 0.0678151\ttotal: 1m 29s\tremaining: 47.7s\n",
      "652:\tlearn: 0.0677574\ttotal: 1m 29s\tremaining: 47.6s\n",
      "653:\tlearn: 0.0676593\ttotal: 1m 29s\tremaining: 47.5s\n",
      "654:\tlearn: 0.0675900\ttotal: 1m 29s\tremaining: 47.3s\n",
      "655:\tlearn: 0.0675958\ttotal: 1m 29s\tremaining: 47.2s\n",
      "656:\tlearn: 0.0675843\ttotal: 1m 30s\tremaining: 47.1s\n",
      "657:\tlearn: 0.0675208\ttotal: 1m 30s\tremaining: 46.9s\n",
      "658:\tlearn: 0.0675439\ttotal: 1m 30s\tremaining: 46.8s\n",
      "659:\tlearn: 0.0675208\ttotal: 1m 30s\tremaining: 46.6s\n",
      "660:\tlearn: 0.0674746\ttotal: 1m 30s\tremaining: 46.5s\n",
      "661:\tlearn: 0.0674400\ttotal: 1m 30s\tremaining: 46.4s\n",
      "662:\tlearn: 0.0673707\ttotal: 1m 31s\tremaining: 46.3s\n",
      "663:\tlearn: 0.0673476\ttotal: 1m 31s\tremaining: 46.2s\n",
      "664:\tlearn: 0.0672957\ttotal: 1m 31s\tremaining: 46s\n",
      "665:\tlearn: 0.0672842\ttotal: 1m 31s\tremaining: 45.9s\n",
      "666:\tlearn: 0.0672495\ttotal: 1m 31s\tremaining: 45.8s\n",
      "667:\tlearn: 0.0671630\ttotal: 1m 31s\tremaining: 45.7s\n",
      "668:\tlearn: 0.0670880\ttotal: 1m 32s\tremaining: 45.5s\n",
      "669:\tlearn: 0.0670360\ttotal: 1m 32s\tremaining: 45.4s\n",
      "670:\tlearn: 0.0669898\ttotal: 1m 32s\tremaining: 45.2s\n",
      "671:\tlearn: 0.0669610\ttotal: 1m 32s\tremaining: 45.1s\n",
      "672:\tlearn: 0.0668744\ttotal: 1m 32s\tremaining: 45s\n",
      "673:\tlearn: 0.0668052\ttotal: 1m 32s\tremaining: 44.8s\n",
      "674:\tlearn: 0.0667186\ttotal: 1m 32s\tremaining: 44.7s\n",
      "675:\tlearn: 0.0667532\ttotal: 1m 32s\tremaining: 44.6s\n",
      "676:\tlearn: 0.0666955\ttotal: 1m 33s\tremaining: 44.4s\n",
      "677:\tlearn: 0.0666782\ttotal: 1m 33s\tremaining: 44.3s\n",
      "678:\tlearn: 0.0666494\ttotal: 1m 33s\tremaining: 44.2s\n",
      "679:\tlearn: 0.0666494\ttotal: 1m 33s\tremaining: 44s\n",
      "680:\tlearn: 0.0665859\ttotal: 1m 33s\tremaining: 43.9s\n",
      "681:\tlearn: 0.0664878\ttotal: 1m 33s\tremaining: 43.7s\n",
      "682:\tlearn: 0.0664127\ttotal: 1m 33s\tremaining: 43.6s\n",
      "683:\tlearn: 0.0664474\ttotal: 1m 34s\tremaining: 43.5s\n",
      "684:\tlearn: 0.0663897\ttotal: 1m 34s\tremaining: 43.3s\n",
      "685:\tlearn: 0.0663608\ttotal: 1m 34s\tremaining: 43.2s\n",
      "686:\tlearn: 0.0663319\ttotal: 1m 34s\tremaining: 43s\n",
      "687:\tlearn: 0.0662454\ttotal: 1m 34s\tremaining: 42.9s\n",
      "688:\tlearn: 0.0662223\ttotal: 1m 34s\tremaining: 42.8s\n",
      "689:\tlearn: 0.0661761\ttotal: 1m 34s\tremaining: 42.6s\n",
      "690:\tlearn: 0.0661069\ttotal: 1m 35s\tremaining: 42.5s\n",
      "691:\tlearn: 0.0660434\ttotal: 1m 35s\tremaining: 42.3s\n",
      "692:\tlearn: 0.0659915\ttotal: 1m 35s\tremaining: 42.2s\n",
      "693:\tlearn: 0.0659511\ttotal: 1m 35s\tremaining: 42.1s\n",
      "694:\tlearn: 0.0659107\ttotal: 1m 35s\tremaining: 41.9s\n",
      "695:\tlearn: 0.0658876\ttotal: 1m 35s\tremaining: 41.8s\n",
      "696:\tlearn: 0.0658356\ttotal: 1m 35s\tremaining: 41.7s\n",
      "697:\tlearn: 0.0657606\ttotal: 1m 35s\tremaining: 41.5s\n",
      "698:\tlearn: 0.0657202\ttotal: 1m 36s\tremaining: 41.4s\n",
      "699:\tlearn: 0.0657029\ttotal: 1m 36s\tremaining: 41.2s\n",
      "700:\tlearn: 0.0656741\ttotal: 1m 36s\tremaining: 41.1s\n",
      "701:\tlearn: 0.0656106\ttotal: 1m 36s\tremaining: 41s\n",
      "702:\tlearn: 0.0655529\ttotal: 1m 36s\tremaining: 40.8s\n",
      "703:\tlearn: 0.0655182\ttotal: 1m 36s\tremaining: 40.7s\n",
      "704:\tlearn: 0.0654663\ttotal: 1m 36s\tremaining: 40.5s\n",
      "705:\tlearn: 0.0654144\ttotal: 1m 37s\tremaining: 40.4s\n",
      "706:\tlearn: 0.0653797\ttotal: 1m 37s\tremaining: 40.3s\n",
      "707:\tlearn: 0.0653740\ttotal: 1m 37s\tremaining: 40.1s\n",
      "708:\tlearn: 0.0653566\ttotal: 1m 37s\tremaining: 40s\n",
      "709:\tlearn: 0.0652932\ttotal: 1m 37s\tremaining: 39.8s\n",
      "710:\tlearn: 0.0652528\ttotal: 1m 37s\tremaining: 39.7s\n",
      "711:\tlearn: 0.0652585\ttotal: 1m 37s\tremaining: 39.6s\n",
      "712:\tlearn: 0.0651777\ttotal: 1m 37s\tremaining: 39.4s\n",
      "713:\tlearn: 0.0651431\ttotal: 1m 38s\tremaining: 39.3s\n",
      "714:\tlearn: 0.0651027\ttotal: 1m 38s\tremaining: 39.2s\n",
      "715:\tlearn: 0.0650739\ttotal: 1m 38s\tremaining: 39s\n",
      "716:\tlearn: 0.0650450\ttotal: 1m 38s\tremaining: 38.9s\n",
      "717:\tlearn: 0.0649815\ttotal: 1m 38s\tremaining: 38.7s\n",
      "718:\tlearn: 0.0649873\ttotal: 1m 38s\tremaining: 38.6s\n",
      "719:\tlearn: 0.0649584\ttotal: 1m 38s\tremaining: 38.5s\n",
      "720:\tlearn: 0.0649123\ttotal: 1m 39s\tremaining: 38.3s\n",
      "721:\tlearn: 0.0648603\ttotal: 1m 39s\tremaining: 38.2s\n",
      "722:\tlearn: 0.0648026\ttotal: 1m 39s\tremaining: 38s\n",
      "723:\tlearn: 0.0648084\ttotal: 1m 39s\tremaining: 37.9s\n",
      "724:\tlearn: 0.0647507\ttotal: 1m 39s\tremaining: 37.8s\n",
      "725:\tlearn: 0.0646872\ttotal: 1m 39s\tremaining: 37.6s\n",
      "726:\tlearn: 0.0646699\ttotal: 1m 39s\tremaining: 37.5s\n",
      "727:\tlearn: 0.0646468\ttotal: 1m 39s\tremaining: 37.4s\n",
      "728:\tlearn: 0.0646410\ttotal: 1m 40s\tremaining: 37.2s\n",
      "729:\tlearn: 0.0645949\ttotal: 1m 40s\tremaining: 37.1s\n",
      "730:\tlearn: 0.0645429\ttotal: 1m 40s\tremaining: 36.9s\n",
      "731:\tlearn: 0.0645545\ttotal: 1m 40s\tremaining: 36.8s\n",
      "732:\tlearn: 0.0644968\ttotal: 1m 40s\tremaining: 36.7s\n",
      "733:\tlearn: 0.0644391\ttotal: 1m 40s\tremaining: 36.5s\n",
      "734:\tlearn: 0.0644217\ttotal: 1m 40s\tremaining: 36.4s\n",
      "735:\tlearn: 0.0644044\ttotal: 1m 41s\tremaining: 36.2s\n",
      "736:\tlearn: 0.0643871\ttotal: 1m 41s\tremaining: 36.1s\n",
      "737:\tlearn: 0.0643525\ttotal: 1m 41s\tremaining: 36s\n",
      "738:\tlearn: 0.0642428\ttotal: 1m 41s\tremaining: 35.8s\n",
      "739:\tlearn: 0.0642313\ttotal: 1m 41s\tremaining: 35.7s\n",
      "740:\tlearn: 0.0641967\ttotal: 1m 41s\tremaining: 35.5s\n",
      "741:\tlearn: 0.0642255\ttotal: 1m 41s\tremaining: 35.4s\n",
      "742:\tlearn: 0.0641332\ttotal: 1m 41s\tremaining: 35.3s\n",
      "743:\tlearn: 0.0640755\ttotal: 1m 42s\tremaining: 35.1s\n",
      "744:\tlearn: 0.0639774\ttotal: 1m 42s\tremaining: 35s\n",
      "745:\tlearn: 0.0639370\ttotal: 1m 42s\tremaining: 34.9s\n",
      "746:\tlearn: 0.0638158\ttotal: 1m 42s\tremaining: 34.7s\n",
      "747:\tlearn: 0.0637465\ttotal: 1m 42s\tremaining: 34.6s\n",
      "748:\tlearn: 0.0637061\ttotal: 1m 42s\tremaining: 34.4s\n",
      "749:\tlearn: 0.0636023\ttotal: 1m 42s\tremaining: 34.3s\n",
      "750:\tlearn: 0.0635330\ttotal: 1m 43s\tremaining: 34.2s\n",
      "751:\tlearn: 0.0635272\ttotal: 1m 43s\tremaining: 34s\n",
      "752:\tlearn: 0.0634984\ttotal: 1m 43s\tremaining: 33.9s\n",
      "753:\tlearn: 0.0634176\ttotal: 1m 43s\tremaining: 33.7s\n",
      "754:\tlearn: 0.0633772\ttotal: 1m 43s\tremaining: 33.6s\n",
      "755:\tlearn: 0.0633599\ttotal: 1m 43s\tremaining: 33.5s\n",
      "756:\tlearn: 0.0633079\ttotal: 1m 43s\tremaining: 33.3s\n",
      "757:\tlearn: 0.0632733\ttotal: 1m 43s\tremaining: 33.2s\n",
      "758:\tlearn: 0.0632560\ttotal: 1m 44s\tremaining: 33.1s\n",
      "759:\tlearn: 0.0632271\ttotal: 1m 44s\tremaining: 32.9s\n",
      "760:\tlearn: 0.0632329\ttotal: 1m 44s\tremaining: 32.8s\n",
      "761:\tlearn: 0.0631637\ttotal: 1m 44s\tremaining: 32.6s\n",
      "762:\tlearn: 0.0631694\ttotal: 1m 44s\tremaining: 32.5s\n",
      "763:\tlearn: 0.0630771\ttotal: 1m 44s\tremaining: 32.4s\n",
      "764:\tlearn: 0.0630309\ttotal: 1m 44s\tremaining: 32.2s\n",
      "765:\tlearn: 0.0630367\ttotal: 1m 45s\tremaining: 32.1s\n",
      "766:\tlearn: 0.0629559\ttotal: 1m 45s\tremaining: 32s\n",
      "767:\tlearn: 0.0629155\ttotal: 1m 45s\tremaining: 31.8s\n",
      "768:\tlearn: 0.0628636\ttotal: 1m 45s\tremaining: 31.7s\n",
      "769:\tlearn: 0.0628232\ttotal: 1m 45s\tremaining: 31.6s\n",
      "770:\tlearn: 0.0627712\ttotal: 1m 45s\tremaining: 31.4s\n",
      "771:\tlearn: 0.0627539\ttotal: 1m 45s\tremaining: 31.3s\n",
      "772:\tlearn: 0.0626674\ttotal: 1m 46s\tremaining: 31.1s\n",
      "773:\tlearn: 0.0626558\ttotal: 1m 46s\tremaining: 31s\n",
      "774:\tlearn: 0.0626616\ttotal: 1m 46s\tremaining: 30.9s\n",
      "775:\tlearn: 0.0626270\ttotal: 1m 46s\tremaining: 30.7s\n",
      "776:\tlearn: 0.0626096\ttotal: 1m 46s\tremaining: 30.6s\n",
      "777:\tlearn: 0.0626270\ttotal: 1m 46s\tremaining: 30.4s\n",
      "778:\tlearn: 0.0626327\ttotal: 1m 46s\tremaining: 30.3s\n",
      "779:\tlearn: 0.0625808\ttotal: 1m 46s\tremaining: 30.2s\n",
      "780:\tlearn: 0.0625462\ttotal: 1m 47s\tremaining: 30s\n",
      "781:\tlearn: 0.0625173\ttotal: 1m 47s\tremaining: 29.9s\n",
      "782:\tlearn: 0.0625115\ttotal: 1m 47s\tremaining: 29.8s\n",
      "783:\tlearn: 0.0624769\ttotal: 1m 47s\tremaining: 29.6s\n",
      "784:\tlearn: 0.0624769\ttotal: 1m 47s\tremaining: 29.5s\n",
      "785:\tlearn: 0.0624365\ttotal: 1m 47s\tremaining: 29.3s\n",
      "786:\tlearn: 0.0623961\ttotal: 1m 47s\tremaining: 29.2s\n",
      "787:\tlearn: 0.0623211\ttotal: 1m 48s\tremaining: 29.1s\n",
      "788:\tlearn: 0.0623557\ttotal: 1m 48s\tremaining: 28.9s\n",
      "789:\tlearn: 0.0623038\ttotal: 1m 48s\tremaining: 28.8s\n",
      "790:\tlearn: 0.0621826\ttotal: 1m 48s\tremaining: 28.6s\n",
      "791:\tlearn: 0.0621941\ttotal: 1m 48s\tremaining: 28.5s\n",
      "792:\tlearn: 0.0621191\ttotal: 1m 48s\tremaining: 28.4s\n",
      "793:\tlearn: 0.0621018\ttotal: 1m 48s\tremaining: 28.2s\n",
      "794:\tlearn: 0.0620845\ttotal: 1m 48s\tremaining: 28.1s\n",
      "795:\tlearn: 0.0620614\ttotal: 1m 49s\tremaining: 28s\n",
      "796:\tlearn: 0.0619979\ttotal: 1m 49s\tremaining: 27.8s\n",
      "797:\tlearn: 0.0619806\ttotal: 1m 49s\tremaining: 27.7s\n",
      "798:\tlearn: 0.0619748\ttotal: 1m 49s\tremaining: 27.5s\n",
      "799:\tlearn: 0.0619979\ttotal: 1m 49s\tremaining: 27.4s\n",
      "800:\tlearn: 0.0619691\ttotal: 1m 49s\tremaining: 27.3s\n",
      "801:\tlearn: 0.0619344\ttotal: 1m 49s\tremaining: 27.1s\n",
      "802:\tlearn: 0.0619287\ttotal: 1m 50s\tremaining: 27s\n",
      "803:\tlearn: 0.0619402\ttotal: 1m 50s\tremaining: 26.9s\n",
      "804:\tlearn: 0.0618998\ttotal: 1m 50s\tremaining: 26.7s\n",
      "805:\tlearn: 0.0618940\ttotal: 1m 50s\tremaining: 26.6s\n",
      "806:\tlearn: 0.0618190\ttotal: 1m 50s\tremaining: 26.4s\n",
      "807:\tlearn: 0.0617613\ttotal: 1m 50s\tremaining: 26.3s\n",
      "808:\tlearn: 0.0617267\ttotal: 1m 50s\tremaining: 26.2s\n",
      "809:\tlearn: 0.0617209\ttotal: 1m 50s\tremaining: 26s\n",
      "810:\tlearn: 0.0617036\ttotal: 1m 51s\tremaining: 25.9s\n",
      "811:\tlearn: 0.0616747\ttotal: 1m 51s\tremaining: 25.7s\n",
      "812:\tlearn: 0.0616113\ttotal: 1m 51s\tremaining: 25.6s\n",
      "813:\tlearn: 0.0615997\ttotal: 1m 51s\tremaining: 25.5s\n",
      "814:\tlearn: 0.0615824\ttotal: 1m 51s\tremaining: 25.3s\n",
      "815:\tlearn: 0.0615593\ttotal: 1m 51s\tremaining: 25.2s\n",
      "816:\tlearn: 0.0615074\ttotal: 1m 51s\tremaining: 25.1s\n",
      "817:\tlearn: 0.0614785\ttotal: 1m 52s\tremaining: 24.9s\n",
      "818:\tlearn: 0.0614554\ttotal: 1m 52s\tremaining: 24.8s\n",
      "819:\tlearn: 0.0614497\ttotal: 1m 52s\tremaining: 24.6s\n",
      "820:\tlearn: 0.0614208\ttotal: 1m 52s\tremaining: 24.5s\n",
      "821:\tlearn: 0.0613920\ttotal: 1m 52s\tremaining: 24.4s\n",
      "822:\tlearn: 0.0613573\ttotal: 1m 52s\tremaining: 24.2s\n",
      "823:\tlearn: 0.0613343\ttotal: 1m 52s\tremaining: 24.1s\n",
      "824:\tlearn: 0.0612073\ttotal: 1m 52s\tremaining: 24s\n",
      "825:\tlearn: 0.0612073\ttotal: 1m 53s\tremaining: 23.8s\n",
      "826:\tlearn: 0.0611554\ttotal: 1m 53s\tremaining: 23.7s\n",
      "827:\tlearn: 0.0611207\ttotal: 1m 53s\tremaining: 23.5s\n",
      "828:\tlearn: 0.0610919\ttotal: 1m 53s\tremaining: 23.4s\n",
      "829:\tlearn: 0.0610457\ttotal: 1m 53s\tremaining: 23.3s\n",
      "830:\tlearn: 0.0610226\ttotal: 1m 53s\tremaining: 23.1s\n",
      "831:\tlearn: 0.0610515\ttotal: 1m 53s\tremaining: 23s\n",
      "832:\tlearn: 0.0609476\ttotal: 1m 54s\tremaining: 22.9s\n",
      "833:\tlearn: 0.0608841\ttotal: 1m 54s\tremaining: 22.7s\n",
      "834:\tlearn: 0.0608610\ttotal: 1m 54s\tremaining: 22.6s\n",
      "835:\tlearn: 0.0608264\ttotal: 1m 54s\tremaining: 22.5s\n",
      "836:\tlearn: 0.0608553\ttotal: 1m 54s\tremaining: 22.3s\n",
      "837:\tlearn: 0.0607860\ttotal: 1m 54s\tremaining: 22.2s\n",
      "838:\tlearn: 0.0607110\ttotal: 1m 55s\tremaining: 22.1s\n",
      "839:\tlearn: 0.0607052\ttotal: 1m 55s\tremaining: 21.9s\n",
      "840:\tlearn: 0.0606994\ttotal: 1m 55s\tremaining: 21.8s\n",
      "841:\tlearn: 0.0607052\ttotal: 1m 55s\tremaining: 21.7s\n",
      "842:\tlearn: 0.0606417\ttotal: 1m 55s\tremaining: 21.5s\n",
      "843:\tlearn: 0.0605956\ttotal: 1m 55s\tremaining: 21.4s\n",
      "844:\tlearn: 0.0605667\ttotal: 1m 55s\tremaining: 21.3s\n",
      "845:\tlearn: 0.0604628\ttotal: 1m 56s\tremaining: 21.1s\n",
      "846:\tlearn: 0.0604340\ttotal: 1m 56s\tremaining: 21s\n",
      "847:\tlearn: 0.0603705\ttotal: 1m 56s\tremaining: 20.9s\n",
      "848:\tlearn: 0.0603128\ttotal: 1m 56s\tremaining: 20.7s\n",
      "849:\tlearn: 0.0602666\ttotal: 1m 56s\tremaining: 20.6s\n",
      "850:\tlearn: 0.0602608\ttotal: 1m 56s\tremaining: 20.5s\n",
      "851:\tlearn: 0.0602320\ttotal: 1m 57s\tremaining: 20.3s\n",
      "852:\tlearn: 0.0602205\ttotal: 1m 57s\tremaining: 20.2s\n",
      "853:\tlearn: 0.0602031\ttotal: 1m 57s\tremaining: 20.1s\n",
      "854:\tlearn: 0.0601570\ttotal: 1m 57s\tremaining: 19.9s\n",
      "855:\tlearn: 0.0600877\ttotal: 1m 57s\tremaining: 19.8s\n",
      "856:\tlearn: 0.0600935\ttotal: 1m 57s\tremaining: 19.7s\n",
      "857:\tlearn: 0.0600877\ttotal: 1m 58s\tremaining: 19.6s\n",
      "858:\tlearn: 0.0600242\ttotal: 1m 58s\tremaining: 19.4s\n",
      "859:\tlearn: 0.0599838\ttotal: 1m 58s\tremaining: 19.3s\n",
      "860:\tlearn: 0.0599377\ttotal: 1m 58s\tremaining: 19.2s\n",
      "861:\tlearn: 0.0599204\ttotal: 1m 58s\tremaining: 19s\n",
      "862:\tlearn: 0.0598223\ttotal: 1m 59s\tremaining: 18.9s\n",
      "863:\tlearn: 0.0597934\ttotal: 1m 59s\tremaining: 18.8s\n",
      "864:\tlearn: 0.0597761\ttotal: 1m 59s\tremaining: 18.7s\n",
      "865:\tlearn: 0.0597703\ttotal: 1m 59s\tremaining: 18.5s\n",
      "866:\tlearn: 0.0597299\ttotal: 1m 59s\tremaining: 18.4s\n",
      "867:\tlearn: 0.0596953\ttotal: 1m 59s\tremaining: 18.2s\n",
      "868:\tlearn: 0.0596780\ttotal: 2m\tremaining: 18.1s\n",
      "869:\tlearn: 0.0596607\ttotal: 2m\tremaining: 18s\n",
      "870:\tlearn: 0.0596318\ttotal: 2m\tremaining: 17.8s\n",
      "871:\tlearn: 0.0595568\ttotal: 2m\tremaining: 17.7s\n",
      "872:\tlearn: 0.0595395\ttotal: 2m\tremaining: 17.5s\n",
      "873:\tlearn: 0.0595279\ttotal: 2m\tremaining: 17.4s\n",
      "874:\tlearn: 0.0595048\ttotal: 2m\tremaining: 17.3s\n",
      "875:\tlearn: 0.0594125\ttotal: 2m\tremaining: 17.1s\n",
      "876:\tlearn: 0.0593259\ttotal: 2m 1s\tremaining: 17s\n",
      "877:\tlearn: 0.0593375\ttotal: 2m 1s\tremaining: 16.8s\n",
      "878:\tlearn: 0.0593029\ttotal: 2m 1s\tremaining: 16.7s\n",
      "879:\tlearn: 0.0592509\ttotal: 2m 1s\tremaining: 16.6s\n",
      "880:\tlearn: 0.0592394\ttotal: 2m 1s\tremaining: 16.4s\n",
      "881:\tlearn: 0.0592221\ttotal: 2m 1s\tremaining: 16.3s\n",
      "882:\tlearn: 0.0592163\ttotal: 2m 1s\tremaining: 16.2s\n",
      "883:\tlearn: 0.0591470\ttotal: 2m 2s\tremaining: 16s\n",
      "884:\tlearn: 0.0591009\ttotal: 2m 2s\tremaining: 15.9s\n",
      "885:\tlearn: 0.0591124\ttotal: 2m 2s\tremaining: 15.7s\n",
      "886:\tlearn: 0.0590778\ttotal: 2m 2s\tremaining: 15.6s\n",
      "887:\tlearn: 0.0589797\ttotal: 2m 2s\tremaining: 15.5s\n",
      "888:\tlearn: 0.0589393\ttotal: 2m 2s\tremaining: 15.3s\n",
      "889:\tlearn: 0.0588758\ttotal: 2m 2s\tremaining: 15.2s\n",
      "890:\tlearn: 0.0587892\ttotal: 2m 2s\tremaining: 15s\n",
      "891:\tlearn: 0.0587662\ttotal: 2m 3s\tremaining: 14.9s\n",
      "892:\tlearn: 0.0587258\ttotal: 2m 3s\tremaining: 14.8s\n",
      "893:\tlearn: 0.0586911\ttotal: 2m 3s\tremaining: 14.6s\n",
      "894:\tlearn: 0.0586046\ttotal: 2m 3s\tremaining: 14.5s\n",
      "895:\tlearn: 0.0586046\ttotal: 2m 3s\tremaining: 14.3s\n",
      "896:\tlearn: 0.0585815\ttotal: 2m 3s\tremaining: 14.2s\n",
      "897:\tlearn: 0.0585757\ttotal: 2m 3s\tremaining: 14.1s\n",
      "898:\tlearn: 0.0585353\ttotal: 2m 4s\tremaining: 13.9s\n",
      "899:\tlearn: 0.0585007\ttotal: 2m 4s\tremaining: 13.8s\n",
      "900:\tlearn: 0.0584372\ttotal: 2m 4s\tremaining: 13.7s\n",
      "901:\tlearn: 0.0584026\ttotal: 2m 4s\tremaining: 13.5s\n",
      "902:\tlearn: 0.0583449\ttotal: 2m 4s\tremaining: 13.4s\n",
      "903:\tlearn: 0.0583449\ttotal: 2m 4s\tremaining: 13.2s\n",
      "904:\tlearn: 0.0582929\ttotal: 2m 4s\tremaining: 13.1s\n",
      "905:\tlearn: 0.0582814\ttotal: 2m 4s\tremaining: 13s\n",
      "906:\tlearn: 0.0582756\ttotal: 2m 5s\tremaining: 12.8s\n",
      "907:\tlearn: 0.0582237\ttotal: 2m 5s\tremaining: 12.7s\n",
      "908:\tlearn: 0.0582179\ttotal: 2m 5s\tremaining: 12.5s\n",
      "909:\tlearn: 0.0581891\ttotal: 2m 5s\tremaining: 12.4s\n",
      "910:\tlearn: 0.0581256\ttotal: 2m 5s\tremaining: 12.3s\n",
      "911:\tlearn: 0.0580621\ttotal: 2m 5s\tremaining: 12.1s\n",
      "912:\tlearn: 0.0580044\ttotal: 2m 5s\tremaining: 12s\n",
      "913:\tlearn: 0.0579640\ttotal: 2m 6s\tremaining: 11.9s\n",
      "914:\tlearn: 0.0579409\ttotal: 2m 6s\tremaining: 11.7s\n",
      "915:\tlearn: 0.0579294\ttotal: 2m 6s\tremaining: 11.6s\n",
      "916:\tlearn: 0.0579005\ttotal: 2m 6s\tremaining: 11.4s\n",
      "917:\tlearn: 0.0578024\ttotal: 2m 6s\tremaining: 11.3s\n",
      "918:\tlearn: 0.0577389\ttotal: 2m 6s\tremaining: 11.2s\n",
      "919:\tlearn: 0.0576062\ttotal: 2m 6s\tremaining: 11s\n",
      "920:\tlearn: 0.0575831\ttotal: 2m 6s\tremaining: 10.9s\n",
      "921:\tlearn: 0.0574792\ttotal: 2m 7s\tremaining: 10.8s\n",
      "922:\tlearn: 0.0574677\ttotal: 2m 7s\tremaining: 10.6s\n",
      "923:\tlearn: 0.0574446\ttotal: 2m 7s\tremaining: 10.5s\n",
      "924:\tlearn: 0.0574042\ttotal: 2m 7s\tremaining: 10.3s\n",
      "925:\tlearn: 0.0573753\ttotal: 2m 7s\tremaining: 10.2s\n",
      "926:\tlearn: 0.0573176\ttotal: 2m 7s\tremaining: 10.1s\n",
      "927:\tlearn: 0.0573465\ttotal: 2m 7s\tremaining: 9.92s\n",
      "928:\tlearn: 0.0573003\ttotal: 2m 8s\tremaining: 9.78s\n",
      "929:\tlearn: 0.0573234\ttotal: 2m 8s\tremaining: 9.65s\n",
      "930:\tlearn: 0.0572946\ttotal: 2m 8s\tremaining: 9.51s\n",
      "931:\tlearn: 0.0572311\ttotal: 2m 8s\tremaining: 9.37s\n",
      "932:\tlearn: 0.0571907\ttotal: 2m 8s\tremaining: 9.23s\n",
      "933:\tlearn: 0.0571272\ttotal: 2m 8s\tremaining: 9.09s\n",
      "934:\tlearn: 0.0571099\ttotal: 2m 8s\tremaining: 8.96s\n",
      "935:\tlearn: 0.0571330\ttotal: 2m 8s\tremaining: 8.82s\n",
      "936:\tlearn: 0.0571560\ttotal: 2m 9s\tremaining: 8.68s\n",
      "937:\tlearn: 0.0570983\ttotal: 2m 9s\tremaining: 8.54s\n",
      "938:\tlearn: 0.0570060\ttotal: 2m 9s\tremaining: 8.4s\n",
      "939:\tlearn: 0.0568790\ttotal: 2m 9s\tremaining: 8.27s\n",
      "940:\tlearn: 0.0568906\ttotal: 2m 9s\tremaining: 8.14s\n",
      "941:\tlearn: 0.0568098\ttotal: 2m 9s\tremaining: 8s\n",
      "942:\tlearn: 0.0567521\ttotal: 2m 10s\tremaining: 7.87s\n",
      "943:\tlearn: 0.0567001\ttotal: 2m 10s\tremaining: 7.73s\n",
      "944:\tlearn: 0.0566597\ttotal: 2m 10s\tremaining: 7.59s\n",
      "945:\tlearn: 0.0566309\ttotal: 2m 10s\tremaining: 7.45s\n",
      "946:\tlearn: 0.0566078\ttotal: 2m 10s\tremaining: 7.31s\n",
      "947:\tlearn: 0.0565847\ttotal: 2m 10s\tremaining: 7.18s\n",
      "948:\tlearn: 0.0565732\ttotal: 2m 10s\tremaining: 7.04s\n",
      "949:\tlearn: 0.0565732\ttotal: 2m 11s\tremaining: 6.9s\n",
      "950:\tlearn: 0.0564751\ttotal: 2m 11s\tremaining: 6.76s\n",
      "951:\tlearn: 0.0564462\ttotal: 2m 11s\tremaining: 6.63s\n",
      "952:\tlearn: 0.0564520\ttotal: 2m 11s\tremaining: 6.49s\n",
      "953:\tlearn: 0.0563654\ttotal: 2m 11s\tremaining: 6.35s\n",
      "954:\tlearn: 0.0563366\ttotal: 2m 11s\tremaining: 6.21s\n",
      "955:\tlearn: 0.0563423\ttotal: 2m 12s\tremaining: 6.08s\n",
      "956:\tlearn: 0.0563193\ttotal: 2m 12s\tremaining: 5.94s\n",
      "957:\tlearn: 0.0563135\ttotal: 2m 12s\tremaining: 5.8s\n",
      "958:\tlearn: 0.0562327\ttotal: 2m 12s\tremaining: 5.66s\n",
      "959:\tlearn: 0.0561461\ttotal: 2m 12s\tremaining: 5.52s\n",
      "960:\tlearn: 0.0561115\ttotal: 2m 12s\tremaining: 5.38s\n",
      "961:\tlearn: 0.0560307\ttotal: 2m 12s\tremaining: 5.25s\n",
      "962:\tlearn: 0.0560538\ttotal: 2m 12s\tremaining: 5.11s\n",
      "963:\tlearn: 0.0560307\ttotal: 2m 13s\tremaining: 4.97s\n",
      "964:\tlearn: 0.0559903\ttotal: 2m 13s\tremaining: 4.83s\n",
      "965:\tlearn: 0.0559268\ttotal: 2m 13s\tremaining: 4.7s\n",
      "966:\tlearn: 0.0559268\ttotal: 2m 13s\tremaining: 4.56s\n",
      "967:\tlearn: 0.0558749\ttotal: 2m 13s\tremaining: 4.42s\n",
      "968:\tlearn: 0.0558172\ttotal: 2m 13s\tremaining: 4.28s\n",
      "969:\tlearn: 0.0558056\ttotal: 2m 14s\tremaining: 4.15s\n",
      "970:\tlearn: 0.0557479\ttotal: 2m 14s\tremaining: 4.01s\n",
      "971:\tlearn: 0.0556902\ttotal: 2m 14s\tremaining: 3.87s\n",
      "972:\tlearn: 0.0556556\ttotal: 2m 14s\tremaining: 3.73s\n",
      "973:\tlearn: 0.0555863\ttotal: 2m 14s\tremaining: 3.59s\n",
      "974:\tlearn: 0.0555748\ttotal: 2m 14s\tremaining: 3.45s\n",
      "975:\tlearn: 0.0555921\ttotal: 2m 14s\tremaining: 3.32s\n",
      "976:\tlearn: 0.0556036\ttotal: 2m 15s\tremaining: 3.18s\n",
      "977:\tlearn: 0.0555806\ttotal: 2m 15s\tremaining: 3.04s\n",
      "978:\tlearn: 0.0554825\ttotal: 2m 15s\tremaining: 2.9s\n",
      "979:\tlearn: 0.0554017\ttotal: 2m 15s\tremaining: 2.76s\n",
      "980:\tlearn: 0.0553728\ttotal: 2m 15s\tremaining: 2.63s\n",
      "981:\tlearn: 0.0553497\ttotal: 2m 15s\tremaining: 2.49s\n",
      "982:\tlearn: 0.0552632\ttotal: 2m 15s\tremaining: 2.35s\n",
      "983:\tlearn: 0.0552343\ttotal: 2m 15s\tremaining: 2.21s\n",
      "984:\tlearn: 0.0552632\ttotal: 2m 16s\tremaining: 2.07s\n",
      "985:\tlearn: 0.0552112\ttotal: 2m 16s\tremaining: 1.93s\n",
      "986:\tlearn: 0.0551477\ttotal: 2m 16s\tremaining: 1.79s\n",
      "987:\tlearn: 0.0550958\ttotal: 2m 16s\tremaining: 1.66s\n",
      "988:\tlearn: 0.0550785\ttotal: 2m 16s\tremaining: 1.52s\n",
      "989:\tlearn: 0.0550323\ttotal: 2m 16s\tremaining: 1.38s\n",
      "990:\tlearn: 0.0549977\ttotal: 2m 16s\tremaining: 1.24s\n",
      "991:\tlearn: 0.0549342\ttotal: 2m 17s\tremaining: 1.1s\n",
      "992:\tlearn: 0.0549342\ttotal: 2m 17s\tremaining: 967ms\n",
      "993:\tlearn: 0.0549169\ttotal: 2m 17s\tremaining: 829ms\n",
      "994:\tlearn: 0.0548996\ttotal: 2m 17s\tremaining: 690ms\n",
      "995:\tlearn: 0.0548361\ttotal: 2m 17s\tremaining: 552ms\n",
      "996:\tlearn: 0.0548015\ttotal: 2m 17s\tremaining: 414ms\n",
      "997:\tlearn: 0.0547553\ttotal: 2m 17s\tremaining: 276ms\n",
      "998:\tlearn: 0.0546745\ttotal: 2m 17s\tremaining: 138ms\n",
      "999:\tlearn: 0.0546687\ttotal: 2m 18s\tremaining: 0us\n",
      "Learning rate set to 0.026476\n",
      "0:\tlearn: 0.1111842\ttotal: 132ms\tremaining: 2m 11s\n",
      "1:\tlearn: 0.1113631\ttotal: 261ms\tremaining: 2m 10s\n",
      "2:\tlearn: 0.1115940\ttotal: 391ms\tremaining: 2m 9s\n",
      "3:\tlearn: 0.1116343\ttotal: 491ms\tremaining: 2m 2s\n",
      "4:\tlearn: 0.1116401\ttotal: 621ms\tremaining: 2m 3s\n",
      "5:\tlearn: 0.1116459\ttotal: 757ms\tremaining: 2m 5s\n",
      "6:\tlearn: 0.1116459\ttotal: 884ms\tremaining: 2m 5s\n",
      "7:\tlearn: 0.1116459\ttotal: 1.01s\tremaining: 2m 4s\n",
      "8:\tlearn: 0.1116459\ttotal: 1.14s\tremaining: 2m 5s\n",
      "9:\tlearn: 0.1116459\ttotal: 1.27s\tremaining: 2m 6s\n",
      "10:\tlearn: 0.1116459\ttotal: 1.41s\tremaining: 2m 6s\n",
      "11:\tlearn: 0.1116459\ttotal: 1.54s\tremaining: 2m 6s\n",
      "12:\tlearn: 0.1116459\ttotal: 1.68s\tremaining: 2m 7s\n",
      "13:\tlearn: 0.1116517\ttotal: 1.81s\tremaining: 2m 7s\n",
      "14:\tlearn: 0.1116517\ttotal: 1.94s\tremaining: 2m 7s\n",
      "15:\tlearn: 0.1116459\ttotal: 2.07s\tremaining: 2m 7s\n",
      "16:\tlearn: 0.1116459\ttotal: 2.19s\tremaining: 2m 6s\n",
      "17:\tlearn: 0.1116459\ttotal: 2.32s\tremaining: 2m 6s\n",
      "18:\tlearn: 0.1116401\ttotal: 2.46s\tremaining: 2m 7s\n",
      "19:\tlearn: 0.1116401\ttotal: 2.59s\tremaining: 2m 6s\n",
      "20:\tlearn: 0.1116517\ttotal: 2.72s\tremaining: 2m 6s\n",
      "21:\tlearn: 0.1116286\ttotal: 2.85s\tremaining: 2m 6s\n",
      "22:\tlearn: 0.1116286\ttotal: 2.97s\tremaining: 2m 6s\n",
      "23:\tlearn: 0.1116286\ttotal: 3.1s\tremaining: 2m 6s\n",
      "24:\tlearn: 0.1116286\ttotal: 3.24s\tremaining: 2m 6s\n",
      "25:\tlearn: 0.1116286\ttotal: 3.37s\tremaining: 2m 6s\n",
      "26:\tlearn: 0.1115882\ttotal: 3.51s\tremaining: 2m 6s\n",
      "27:\tlearn: 0.1115536\ttotal: 3.63s\tremaining: 2m 6s\n",
      "28:\tlearn: 0.1115593\ttotal: 3.76s\tremaining: 2m 5s\n",
      "29:\tlearn: 0.1115420\ttotal: 3.89s\tremaining: 2m 5s\n",
      "30:\tlearn: 0.1115016\ttotal: 4.03s\tremaining: 2m 5s\n",
      "31:\tlearn: 0.1114612\ttotal: 4.16s\tremaining: 2m 5s\n",
      "32:\tlearn: 0.1114612\ttotal: 4.29s\tremaining: 2m 5s\n",
      "33:\tlearn: 0.1114670\ttotal: 4.42s\tremaining: 2m 5s\n",
      "34:\tlearn: 0.1114497\ttotal: 4.55s\tremaining: 2m 5s\n",
      "35:\tlearn: 0.1113977\ttotal: 4.68s\tremaining: 2m 5s\n",
      "36:\tlearn: 0.1113920\ttotal: 4.82s\tremaining: 2m 5s\n",
      "37:\tlearn: 0.1113516\ttotal: 4.95s\tremaining: 2m 5s\n",
      "38:\tlearn: 0.1113054\ttotal: 5.08s\tremaining: 2m 5s\n",
      "39:\tlearn: 0.1112765\ttotal: 5.21s\tremaining: 2m 5s\n",
      "40:\tlearn: 0.1112419\ttotal: 5.35s\tremaining: 2m 5s\n",
      "41:\tlearn: 0.1112131\ttotal: 5.49s\tremaining: 2m 5s\n",
      "42:\tlearn: 0.1111611\ttotal: 5.62s\tremaining: 2m 4s\n",
      "43:\tlearn: 0.1110630\ttotal: 5.75s\tremaining: 2m 4s\n",
      "44:\tlearn: 0.1110169\ttotal: 5.88s\tremaining: 2m 4s\n",
      "45:\tlearn: 0.1110111\ttotal: 6.01s\tremaining: 2m 4s\n",
      "46:\tlearn: 0.1109187\ttotal: 6.15s\tremaining: 2m 4s\n",
      "47:\tlearn: 0.1108553\ttotal: 6.28s\tremaining: 2m 4s\n",
      "48:\tlearn: 0.1107456\ttotal: 6.42s\tremaining: 2m 4s\n",
      "49:\tlearn: 0.1107052\ttotal: 6.55s\tremaining: 2m 4s\n",
      "50:\tlearn: 0.1106302\ttotal: 6.69s\tremaining: 2m 4s\n",
      "51:\tlearn: 0.1105494\ttotal: 6.82s\tremaining: 2m 4s\n",
      "52:\tlearn: 0.1105609\ttotal: 6.96s\tremaining: 2m 4s\n",
      "53:\tlearn: 0.1103936\ttotal: 7.09s\tremaining: 2m 4s\n",
      "54:\tlearn: 0.1103416\ttotal: 7.21s\tremaining: 2m 3s\n",
      "55:\tlearn: 0.1102782\ttotal: 7.35s\tremaining: 2m 3s\n",
      "56:\tlearn: 0.1103012\ttotal: 7.49s\tremaining: 2m 3s\n",
      "57:\tlearn: 0.1102031\ttotal: 7.62s\tremaining: 2m 3s\n",
      "58:\tlearn: 0.1100993\ttotal: 7.77s\tremaining: 2m 3s\n",
      "59:\tlearn: 0.1100069\ttotal: 7.91s\tremaining: 2m 3s\n",
      "60:\tlearn: 0.1099492\ttotal: 8.05s\tremaining: 2m 3s\n",
      "61:\tlearn: 0.1097703\ttotal: 8.18s\tremaining: 2m 3s\n",
      "62:\tlearn: 0.1096318\ttotal: 8.31s\tremaining: 2m 3s\n",
      "63:\tlearn: 0.1095222\ttotal: 8.45s\tremaining: 2m 3s\n",
      "64:\tlearn: 0.1094183\ttotal: 8.58s\tremaining: 2m 3s\n",
      "65:\tlearn: 0.1093259\ttotal: 8.71s\tremaining: 2m 3s\n",
      "66:\tlearn: 0.1093259\ttotal: 8.84s\tremaining: 2m 3s\n",
      "67:\tlearn: 0.1093433\ttotal: 8.98s\tremaining: 2m 3s\n",
      "68:\tlearn: 0.1091990\ttotal: 9.11s\tremaining: 2m 2s\n",
      "69:\tlearn: 0.1091874\ttotal: 9.23s\tremaining: 2m 2s\n",
      "70:\tlearn: 0.1090720\ttotal: 9.37s\tremaining: 2m 2s\n",
      "71:\tlearn: 0.1088643\ttotal: 9.51s\tremaining: 2m 2s\n",
      "72:\tlearn: 0.1087719\ttotal: 9.64s\tremaining: 2m 2s\n",
      "73:\tlearn: 0.1087027\ttotal: 9.78s\tremaining: 2m 2s\n",
      "74:\tlearn: 0.1086854\ttotal: 9.91s\tremaining: 2m 2s\n",
      "75:\tlearn: 0.1084661\ttotal: 10s\tremaining: 2m 2s\n",
      "76:\tlearn: 0.1084661\ttotal: 10.2s\tremaining: 2m 1s\n",
      "77:\tlearn: 0.1082583\ttotal: 10.3s\tremaining: 2m 1s\n",
      "78:\tlearn: 0.1081487\ttotal: 10.5s\tremaining: 2m 1s\n",
      "79:\tlearn: 0.1080332\ttotal: 10.6s\tremaining: 2m 1s\n",
      "80:\tlearn: 0.1078947\ttotal: 10.7s\tremaining: 2m 1s\n",
      "81:\tlearn: 0.1077735\ttotal: 10.9s\tremaining: 2m 1s\n",
      "82:\tlearn: 0.1077043\ttotal: 11s\tremaining: 2m 1s\n",
      "83:\tlearn: 0.1076697\ttotal: 11.2s\tremaining: 2m 1s\n",
      "84:\tlearn: 0.1075889\ttotal: 11.3s\tremaining: 2m 1s\n",
      "85:\tlearn: 0.1075023\ttotal: 11.4s\tremaining: 2m 1s\n",
      "86:\tlearn: 0.1074100\ttotal: 11.6s\tremaining: 2m 1s\n",
      "87:\tlearn: 0.1073003\ttotal: 11.7s\tremaining: 2m 1s\n",
      "88:\tlearn: 0.1072311\ttotal: 11.8s\tremaining: 2m 1s\n",
      "89:\tlearn: 0.1070926\ttotal: 12s\tremaining: 2m\n",
      "90:\tlearn: 0.1070637\ttotal: 12.1s\tremaining: 2m\n",
      "91:\tlearn: 0.1068386\ttotal: 12.2s\tremaining: 2m\n",
      "92:\tlearn: 0.1067232\ttotal: 12.4s\tremaining: 2m\n",
      "93:\tlearn: 0.1064751\ttotal: 12.5s\tremaining: 2m\n",
      "94:\tlearn: 0.1064462\ttotal: 12.6s\tremaining: 2m\n",
      "95:\tlearn: 0.1062846\ttotal: 12.8s\tremaining: 2m\n",
      "96:\tlearn: 0.1061115\ttotal: 12.9s\tremaining: 2m\n",
      "97:\tlearn: 0.1058807\ttotal: 13s\tremaining: 2m\n",
      "98:\tlearn: 0.1057018\ttotal: 13.2s\tremaining: 1m 59s\n",
      "99:\tlearn: 0.1055113\ttotal: 13.3s\tremaining: 1m 59s\n",
      "100:\tlearn: 0.1053440\ttotal: 13.4s\tremaining: 1m 59s\n",
      "101:\tlearn: 0.1052689\ttotal: 13.6s\tremaining: 1m 59s\n",
      "102:\tlearn: 0.1051131\ttotal: 13.7s\tremaining: 1m 59s\n",
      "103:\tlearn: 0.1050554\ttotal: 13.8s\tremaining: 1m 59s\n",
      "104:\tlearn: 0.1049861\ttotal: 14s\tremaining: 1m 59s\n",
      "105:\tlearn: 0.1048823\ttotal: 14.1s\tremaining: 1m 58s\n",
      "106:\tlearn: 0.1047495\ttotal: 14.2s\tremaining: 1m 58s\n",
      "107:\tlearn: 0.1046457\ttotal: 14.4s\tremaining: 1m 58s\n",
      "108:\tlearn: 0.1045129\ttotal: 14.5s\tremaining: 1m 58s\n",
      "109:\tlearn: 0.1044321\ttotal: 14.6s\tremaining: 1m 58s\n",
      "110:\tlearn: 0.1043802\ttotal: 14.8s\tremaining: 1m 58s\n",
      "111:\tlearn: 0.1042705\ttotal: 14.9s\tremaining: 1m 58s\n",
      "112:\tlearn: 0.1041436\ttotal: 15s\tremaining: 1m 58s\n",
      "113:\tlearn: 0.1040455\ttotal: 15.2s\tremaining: 1m 57s\n",
      "114:\tlearn: 0.1039301\ttotal: 15.3s\tremaining: 1m 57s\n",
      "115:\tlearn: 0.1036934\ttotal: 15.5s\tremaining: 1m 58s\n",
      "116:\tlearn: 0.1035088\ttotal: 15.6s\tremaining: 1m 57s\n",
      "117:\tlearn: 0.1034511\ttotal: 15.8s\tremaining: 1m 57s\n",
      "118:\tlearn: 0.1033068\ttotal: 15.9s\tremaining: 1m 57s\n",
      "119:\tlearn: 0.1032664\ttotal: 16s\tremaining: 1m 57s\n",
      "120:\tlearn: 0.1031798\ttotal: 16.2s\tremaining: 1m 57s\n",
      "121:\tlearn: 0.1029144\ttotal: 16.3s\tremaining: 1m 57s\n",
      "122:\tlearn: 0.1027701\ttotal: 16.5s\tremaining: 1m 57s\n",
      "123:\tlearn: 0.1027008\ttotal: 16.6s\tremaining: 1m 57s\n",
      "124:\tlearn: 0.1026373\ttotal: 16.7s\tremaining: 1m 57s\n",
      "125:\tlearn: 0.1025046\ttotal: 16.8s\tremaining: 1m 56s\n",
      "126:\tlearn: 0.1023315\ttotal: 17s\tremaining: 1m 56s\n",
      "127:\tlearn: 0.1022565\ttotal: 17.1s\tremaining: 1m 56s\n",
      "128:\tlearn: 0.1021699\ttotal: 17.2s\tremaining: 1m 56s\n",
      "129:\tlearn: 0.1019448\ttotal: 17.4s\tremaining: 1m 56s\n",
      "130:\tlearn: 0.1018756\ttotal: 17.5s\tremaining: 1m 56s\n",
      "131:\tlearn: 0.1017602\ttotal: 17.6s\tremaining: 1m 56s\n",
      "132:\tlearn: 0.1016563\ttotal: 17.8s\tremaining: 1m 55s\n",
      "133:\tlearn: 0.1015582\ttotal: 17.9s\tremaining: 1m 55s\n",
      "134:\tlearn: 0.1013793\ttotal: 18s\tremaining: 1m 55s\n",
      "135:\tlearn: 0.1013389\ttotal: 18.2s\tremaining: 1m 55s\n",
      "136:\tlearn: 0.1012061\ttotal: 18.3s\tremaining: 1m 55s\n",
      "137:\tlearn: 0.1011773\ttotal: 18.4s\tremaining: 1m 55s\n",
      "138:\tlearn: 0.1010215\ttotal: 18.6s\tremaining: 1m 55s\n",
      "139:\tlearn: 0.1009003\ttotal: 18.7s\tremaining: 1m 54s\n",
      "140:\tlearn: 0.1007733\ttotal: 18.8s\tremaining: 1m 54s\n",
      "141:\tlearn: 0.1005713\ttotal: 19s\tremaining: 1m 54s\n",
      "142:\tlearn: 0.1005021\ttotal: 19.1s\tremaining: 1m 54s\n",
      "143:\tlearn: 0.1003578\ttotal: 19.3s\tremaining: 1m 54s\n",
      "144:\tlearn: 0.1002135\ttotal: 19.4s\tremaining: 1m 54s\n",
      "145:\tlearn: 0.1000173\ttotal: 19.5s\tremaining: 1m 54s\n",
      "146:\tlearn: 0.0999481\ttotal: 19.7s\tremaining: 1m 54s\n",
      "147:\tlearn: 0.0998096\ttotal: 19.8s\tremaining: 1m 53s\n",
      "148:\tlearn: 0.0996364\ttotal: 19.9s\tremaining: 1m 53s\n",
      "149:\tlearn: 0.0995441\ttotal: 20.1s\tremaining: 1m 53s\n",
      "150:\tlearn: 0.0994402\ttotal: 20.2s\tremaining: 1m 53s\n",
      "151:\tlearn: 0.0993594\ttotal: 20.3s\tremaining: 1m 53s\n",
      "152:\tlearn: 0.0992959\ttotal: 20.5s\tremaining: 1m 53s\n",
      "153:\tlearn: 0.0991863\ttotal: 20.6s\tremaining: 1m 53s\n",
      "154:\tlearn: 0.0991113\ttotal: 20.7s\tremaining: 1m 53s\n",
      "155:\tlearn: 0.0990132\ttotal: 20.9s\tremaining: 1m 52s\n",
      "156:\tlearn: 0.0989208\ttotal: 21s\tremaining: 1m 52s\n",
      "157:\tlearn: 0.0987939\ttotal: 21.1s\tremaining: 1m 52s\n",
      "158:\tlearn: 0.0986438\ttotal: 21.3s\tremaining: 1m 52s\n",
      "159:\tlearn: 0.0986380\ttotal: 21.4s\tremaining: 1m 52s\n",
      "160:\tlearn: 0.0984822\ttotal: 21.5s\tremaining: 1m 52s\n",
      "161:\tlearn: 0.0983899\ttotal: 21.7s\tremaining: 1m 52s\n",
      "162:\tlearn: 0.0982514\ttotal: 21.8s\tremaining: 1m 51s\n",
      "163:\tlearn: 0.0981706\ttotal: 21.9s\tremaining: 1m 51s\n",
      "164:\tlearn: 0.0980609\ttotal: 22.1s\tremaining: 1m 51s\n",
      "165:\tlearn: 0.0979686\ttotal: 22.2s\tremaining: 1m 51s\n",
      "166:\tlearn: 0.0979398\ttotal: 22.3s\tremaining: 1m 51s\n",
      "167:\tlearn: 0.0977724\ttotal: 22.5s\tremaining: 1m 51s\n",
      "168:\tlearn: 0.0977089\ttotal: 22.6s\tremaining: 1m 51s\n",
      "169:\tlearn: 0.0975473\ttotal: 22.8s\tremaining: 1m 51s\n",
      "170:\tlearn: 0.0974781\ttotal: 22.9s\tremaining: 1m 50s\n",
      "171:\tlearn: 0.0973569\ttotal: 23s\tremaining: 1m 50s\n",
      "172:\tlearn: 0.0972703\ttotal: 23.2s\tremaining: 1m 50s\n",
      "173:\tlearn: 0.0971376\ttotal: 23.3s\tremaining: 1m 50s\n",
      "174:\tlearn: 0.0970106\ttotal: 23.4s\tremaining: 1m 50s\n",
      "175:\tlearn: 0.0969125\ttotal: 23.6s\tremaining: 1m 50s\n",
      "176:\tlearn: 0.0968375\ttotal: 23.7s\tremaining: 1m 50s\n",
      "177:\tlearn: 0.0968202\ttotal: 23.8s\tremaining: 1m 50s\n",
      "178:\tlearn: 0.0967509\ttotal: 24s\tremaining: 1m 49s\n",
      "179:\tlearn: 0.0966874\ttotal: 24.1s\tremaining: 1m 49s\n",
      "180:\tlearn: 0.0966355\ttotal: 24.2s\tremaining: 1m 49s\n",
      "181:\tlearn: 0.0965720\ttotal: 24.4s\tremaining: 1m 49s\n",
      "182:\tlearn: 0.0965259\ttotal: 24.5s\tremaining: 1m 49s\n",
      "183:\tlearn: 0.0964220\ttotal: 24.6s\tremaining: 1m 49s\n",
      "184:\tlearn: 0.0963296\ttotal: 24.8s\tremaining: 1m 49s\n",
      "185:\tlearn: 0.0962315\ttotal: 24.9s\tremaining: 1m 48s\n",
      "186:\tlearn: 0.0961911\ttotal: 25s\tremaining: 1m 48s\n",
      "187:\tlearn: 0.0960930\ttotal: 25.2s\tremaining: 1m 48s\n",
      "188:\tlearn: 0.0959892\ttotal: 25.3s\tremaining: 1m 48s\n",
      "189:\tlearn: 0.0959430\ttotal: 25.4s\tremaining: 1m 48s\n",
      "190:\tlearn: 0.0959661\ttotal: 25.6s\tremaining: 1m 48s\n",
      "191:\tlearn: 0.0958795\ttotal: 25.7s\tremaining: 1m 48s\n",
      "192:\tlearn: 0.0958391\ttotal: 25.9s\tremaining: 1m 48s\n",
      "193:\tlearn: 0.0957929\ttotal: 26s\tremaining: 1m 48s\n",
      "194:\tlearn: 0.0956660\ttotal: 26.2s\tremaining: 1m 48s\n",
      "195:\tlearn: 0.0955448\ttotal: 26.3s\tremaining: 1m 47s\n",
      "196:\tlearn: 0.0954813\ttotal: 26.5s\tremaining: 1m 47s\n",
      "197:\tlearn: 0.0953890\ttotal: 26.6s\tremaining: 1m 47s\n",
      "198:\tlearn: 0.0952274\ttotal: 26.7s\tremaining: 1m 47s\n",
      "199:\tlearn: 0.0951697\ttotal: 26.9s\tremaining: 1m 47s\n",
      "200:\tlearn: 0.0951408\ttotal: 27s\tremaining: 1m 47s\n",
      "201:\tlearn: 0.0950658\ttotal: 27.1s\tremaining: 1m 47s\n",
      "202:\tlearn: 0.0950716\ttotal: 27.3s\tremaining: 1m 46s\n",
      "203:\tlearn: 0.0950369\ttotal: 27.4s\tremaining: 1m 46s\n",
      "204:\tlearn: 0.0948753\ttotal: 27.5s\tremaining: 1m 46s\n",
      "205:\tlearn: 0.0947830\ttotal: 27.7s\tremaining: 1m 46s\n",
      "206:\tlearn: 0.0947253\ttotal: 27.8s\tremaining: 1m 46s\n",
      "207:\tlearn: 0.0945983\ttotal: 27.9s\tremaining: 1m 46s\n",
      "208:\tlearn: 0.0944829\ttotal: 28.1s\tremaining: 1m 46s\n",
      "209:\tlearn: 0.0944656\ttotal: 28.2s\tremaining: 1m 46s\n",
      "210:\tlearn: 0.0943964\ttotal: 28.3s\tremaining: 1m 45s\n",
      "211:\tlearn: 0.0943098\ttotal: 28.5s\tremaining: 1m 45s\n",
      "212:\tlearn: 0.0942348\ttotal: 28.6s\tremaining: 1m 45s\n",
      "213:\tlearn: 0.0941597\ttotal: 28.7s\tremaining: 1m 45s\n",
      "214:\tlearn: 0.0940905\ttotal: 28.9s\tremaining: 1m 45s\n",
      "215:\tlearn: 0.0939520\ttotal: 29s\tremaining: 1m 45s\n",
      "216:\tlearn: 0.0939116\ttotal: 29.1s\tremaining: 1m 45s\n",
      "217:\tlearn: 0.0938250\ttotal: 29.2s\tremaining: 1m 44s\n",
      "218:\tlearn: 0.0936865\ttotal: 29.4s\tremaining: 1m 44s\n",
      "219:\tlearn: 0.0936000\ttotal: 29.5s\tremaining: 1m 44s\n",
      "220:\tlearn: 0.0934961\ttotal: 29.7s\tremaining: 1m 44s\n",
      "221:\tlearn: 0.0934384\ttotal: 29.8s\tremaining: 1m 44s\n",
      "222:\tlearn: 0.0933922\ttotal: 29.9s\tremaining: 1m 44s\n",
      "223:\tlearn: 0.0933172\ttotal: 30s\tremaining: 1m 44s\n",
      "224:\tlearn: 0.0932306\ttotal: 30.2s\tremaining: 1m 43s\n",
      "225:\tlearn: 0.0932710\ttotal: 30.3s\tremaining: 1m 43s\n",
      "226:\tlearn: 0.0931440\ttotal: 30.5s\tremaining: 1m 43s\n",
      "227:\tlearn: 0.0930748\ttotal: 30.6s\tremaining: 1m 43s\n",
      "228:\tlearn: 0.0929017\ttotal: 30.7s\tremaining: 1m 43s\n",
      "229:\tlearn: 0.0928555\ttotal: 30.8s\tremaining: 1m 43s\n",
      "230:\tlearn: 0.0927862\ttotal: 31s\tremaining: 1m 43s\n",
      "231:\tlearn: 0.0927458\ttotal: 31.1s\tremaining: 1m 42s\n",
      "232:\tlearn: 0.0926881\ttotal: 31.2s\tremaining: 1m 42s\n",
      "233:\tlearn: 0.0926189\ttotal: 31.4s\tremaining: 1m 42s\n",
      "234:\tlearn: 0.0925323\ttotal: 31.5s\tremaining: 1m 42s\n",
      "235:\tlearn: 0.0924977\ttotal: 31.7s\tremaining: 1m 42s\n",
      "236:\tlearn: 0.0924688\ttotal: 31.8s\tremaining: 1m 42s\n",
      "237:\tlearn: 0.0923592\ttotal: 31.9s\tremaining: 1m 42s\n",
      "238:\tlearn: 0.0923015\ttotal: 32s\tremaining: 1m 42s\n",
      "239:\tlearn: 0.0922322\ttotal: 32.2s\tremaining: 1m 41s\n",
      "240:\tlearn: 0.0921341\ttotal: 32.3s\tremaining: 1m 41s\n",
      "241:\tlearn: 0.0920533\ttotal: 32.4s\tremaining: 1m 41s\n",
      "242:\tlearn: 0.0919321\ttotal: 32.6s\tremaining: 1m 41s\n",
      "243:\tlearn: 0.0918860\ttotal: 32.7s\tremaining: 1m 41s\n",
      "244:\tlearn: 0.0917590\ttotal: 32.8s\tremaining: 1m 41s\n",
      "245:\tlearn: 0.0916782\ttotal: 33s\tremaining: 1m 41s\n",
      "246:\tlearn: 0.0916667\ttotal: 33.1s\tremaining: 1m 40s\n",
      "247:\tlearn: 0.0916724\ttotal: 33.3s\tremaining: 1m 40s\n",
      "248:\tlearn: 0.0914762\ttotal: 33.4s\tremaining: 1m 40s\n",
      "249:\tlearn: 0.0913954\ttotal: 33.5s\tremaining: 1m 40s\n",
      "250:\tlearn: 0.0913550\ttotal: 33.7s\tremaining: 1m 40s\n",
      "251:\tlearn: 0.0913839\ttotal: 33.8s\tremaining: 1m 40s\n",
      "252:\tlearn: 0.0912627\ttotal: 33.9s\tremaining: 1m 40s\n",
      "253:\tlearn: 0.0911473\ttotal: 34.1s\tremaining: 1m 40s\n",
      "254:\tlearn: 0.0910780\ttotal: 34.2s\tremaining: 1m 39s\n",
      "255:\tlearn: 0.0910319\ttotal: 34.3s\tremaining: 1m 39s\n",
      "256:\tlearn: 0.0909972\ttotal: 34.5s\tremaining: 1m 39s\n",
      "257:\tlearn: 0.0909568\ttotal: 34.6s\tremaining: 1m 39s\n",
      "258:\tlearn: 0.0909280\ttotal: 34.7s\tremaining: 1m 39s\n",
      "259:\tlearn: 0.0908991\ttotal: 34.9s\tremaining: 1m 39s\n",
      "260:\tlearn: 0.0908010\ttotal: 35s\tremaining: 1m 39s\n",
      "261:\tlearn: 0.0907606\ttotal: 35.1s\tremaining: 1m 38s\n",
      "262:\tlearn: 0.0907145\ttotal: 35.3s\tremaining: 1m 38s\n",
      "263:\tlearn: 0.0905125\ttotal: 35.4s\tremaining: 1m 38s\n",
      "264:\tlearn: 0.0904374\ttotal: 35.5s\tremaining: 1m 38s\n",
      "265:\tlearn: 0.0903913\ttotal: 35.7s\tremaining: 1m 38s\n",
      "266:\tlearn: 0.0903336\ttotal: 35.8s\tremaining: 1m 38s\n",
      "267:\tlearn: 0.0902355\ttotal: 35.9s\tremaining: 1m 38s\n",
      "268:\tlearn: 0.0901200\ttotal: 36.1s\tremaining: 1m 38s\n",
      "269:\tlearn: 0.0900219\ttotal: 36.2s\tremaining: 1m 37s\n",
      "270:\tlearn: 0.0899065\ttotal: 36.4s\tremaining: 1m 37s\n",
      "271:\tlearn: 0.0897565\ttotal: 36.5s\tremaining: 1m 37s\n",
      "272:\tlearn: 0.0896872\ttotal: 36.6s\tremaining: 1m 37s\n",
      "273:\tlearn: 0.0897045\ttotal: 36.8s\tremaining: 1m 37s\n",
      "274:\tlearn: 0.0896468\ttotal: 36.9s\tremaining: 1m 37s\n",
      "275:\tlearn: 0.0895199\ttotal: 37s\tremaining: 1m 37s\n",
      "276:\tlearn: 0.0894910\ttotal: 37.2s\tremaining: 1m 36s\n",
      "277:\tlearn: 0.0893467\ttotal: 37.3s\tremaining: 1m 36s\n",
      "278:\tlearn: 0.0893352\ttotal: 37.4s\tremaining: 1m 36s\n",
      "279:\tlearn: 0.0892255\ttotal: 37.6s\tremaining: 1m 36s\n",
      "280:\tlearn: 0.0891563\ttotal: 37.7s\tremaining: 1m 36s\n",
      "281:\tlearn: 0.0890351\ttotal: 37.8s\tremaining: 1m 36s\n",
      "282:\tlearn: 0.0890235\ttotal: 38s\tremaining: 1m 36s\n",
      "283:\tlearn: 0.0889774\ttotal: 38.1s\tremaining: 1m 36s\n",
      "284:\tlearn: 0.0888331\ttotal: 38.2s\tremaining: 1m 35s\n",
      "285:\tlearn: 0.0888158\ttotal: 38.4s\tremaining: 1m 35s\n",
      "286:\tlearn: 0.0887696\ttotal: 38.5s\tremaining: 1m 35s\n",
      "287:\tlearn: 0.0886946\ttotal: 38.6s\tremaining: 1m 35s\n",
      "288:\tlearn: 0.0886773\ttotal: 38.8s\tremaining: 1m 35s\n",
      "289:\tlearn: 0.0886542\ttotal: 38.9s\tremaining: 1m 35s\n",
      "290:\tlearn: 0.0885907\ttotal: 39s\tremaining: 1m 35s\n",
      "291:\tlearn: 0.0885042\ttotal: 39.2s\tremaining: 1m 34s\n",
      "292:\tlearn: 0.0884984\ttotal: 39.3s\tremaining: 1m 34s\n",
      "293:\tlearn: 0.0884234\ttotal: 39.4s\tremaining: 1m 34s\n",
      "294:\tlearn: 0.0883887\ttotal: 39.6s\tremaining: 1m 34s\n",
      "295:\tlearn: 0.0883253\ttotal: 39.7s\tremaining: 1m 34s\n",
      "296:\tlearn: 0.0882906\ttotal: 39.8s\tremaining: 1m 34s\n",
      "297:\tlearn: 0.0882214\ttotal: 40s\tremaining: 1m 34s\n",
      "298:\tlearn: 0.0882098\ttotal: 40.1s\tremaining: 1m 34s\n",
      "299:\tlearn: 0.0881348\ttotal: 40.2s\tremaining: 1m 33s\n",
      "300:\tlearn: 0.0880425\ttotal: 40.4s\tremaining: 1m 33s\n",
      "301:\tlearn: 0.0879790\ttotal: 40.5s\tremaining: 1m 33s\n",
      "302:\tlearn: 0.0879617\ttotal: 40.7s\tremaining: 1m 33s\n",
      "303:\tlearn: 0.0879328\ttotal: 40.8s\tremaining: 1m 33s\n",
      "304:\tlearn: 0.0877712\ttotal: 41s\tremaining: 1m 33s\n",
      "305:\tlearn: 0.0877482\ttotal: 41.1s\tremaining: 1m 33s\n",
      "306:\tlearn: 0.0876847\ttotal: 41.2s\tremaining: 1m 33s\n",
      "307:\tlearn: 0.0875923\ttotal: 41.4s\tremaining: 1m 32s\n",
      "308:\tlearn: 0.0874885\ttotal: 41.5s\tremaining: 1m 32s\n",
      "309:\tlearn: 0.0874307\ttotal: 41.6s\tremaining: 1m 32s\n",
      "310:\tlearn: 0.0874307\ttotal: 41.8s\tremaining: 1m 32s\n",
      "311:\tlearn: 0.0873730\ttotal: 41.9s\tremaining: 1m 32s\n",
      "312:\tlearn: 0.0873096\ttotal: 42s\tremaining: 1m 32s\n",
      "313:\tlearn: 0.0872807\ttotal: 42.2s\tremaining: 1m 32s\n",
      "314:\tlearn: 0.0872288\ttotal: 42.3s\tremaining: 1m 31s\n",
      "315:\tlearn: 0.0871422\ttotal: 42.4s\tremaining: 1m 31s\n",
      "316:\tlearn: 0.0870845\ttotal: 42.6s\tremaining: 1m 31s\n",
      "317:\tlearn: 0.0870268\ttotal: 42.7s\tremaining: 1m 31s\n",
      "318:\tlearn: 0.0869402\ttotal: 42.9s\tremaining: 1m 31s\n",
      "319:\tlearn: 0.0869575\ttotal: 43s\tremaining: 1m 31s\n",
      "320:\tlearn: 0.0868940\ttotal: 43.2s\tremaining: 1m 31s\n",
      "321:\tlearn: 0.0869344\ttotal: 43.3s\tremaining: 1m 31s\n",
      "322:\tlearn: 0.0868133\ttotal: 43.4s\tremaining: 1m 31s\n",
      "323:\tlearn: 0.0867151\ttotal: 43.6s\tremaining: 1m 30s\n",
      "324:\tlearn: 0.0866978\ttotal: 43.7s\tremaining: 1m 30s\n",
      "325:\tlearn: 0.0865940\ttotal: 43.9s\tremaining: 1m 30s\n",
      "326:\tlearn: 0.0864728\ttotal: 44s\tremaining: 1m 30s\n",
      "327:\tlearn: 0.0863573\ttotal: 44.1s\tremaining: 1m 30s\n",
      "328:\tlearn: 0.0863804\ttotal: 44.3s\tremaining: 1m 30s\n",
      "329:\tlearn: 0.0863169\ttotal: 44.4s\tremaining: 1m 30s\n",
      "330:\tlearn: 0.0863747\ttotal: 44.5s\tremaining: 1m 29s\n",
      "331:\tlearn: 0.0862823\ttotal: 44.7s\tremaining: 1m 29s\n",
      "332:\tlearn: 0.0861611\ttotal: 44.8s\tremaining: 1m 29s\n",
      "333:\tlearn: 0.0860919\ttotal: 44.9s\tremaining: 1m 29s\n",
      "334:\tlearn: 0.0860515\ttotal: 45.1s\tremaining: 1m 29s\n",
      "335:\tlearn: 0.0859765\ttotal: 45.2s\tremaining: 1m 29s\n",
      "336:\tlearn: 0.0859361\ttotal: 45.4s\tremaining: 1m 29s\n",
      "337:\tlearn: 0.0859072\ttotal: 45.5s\tremaining: 1m 29s\n",
      "338:\tlearn: 0.0858783\ttotal: 45.6s\tremaining: 1m 28s\n",
      "339:\tlearn: 0.0858610\ttotal: 45.8s\tremaining: 1m 28s\n",
      "340:\tlearn: 0.0858322\ttotal: 45.9s\tremaining: 1m 28s\n",
      "341:\tlearn: 0.0857687\ttotal: 46s\tremaining: 1m 28s\n",
      "342:\tlearn: 0.0856764\ttotal: 46.2s\tremaining: 1m 28s\n",
      "343:\tlearn: 0.0856071\ttotal: 46.3s\tremaining: 1m 28s\n",
      "344:\tlearn: 0.0855263\ttotal: 46.4s\tremaining: 1m 28s\n",
      "345:\tlearn: 0.0855090\ttotal: 46.6s\tremaining: 1m 28s\n",
      "346:\tlearn: 0.0854167\ttotal: 46.7s\tremaining: 1m 27s\n",
      "347:\tlearn: 0.0854340\ttotal: 46.8s\tremaining: 1m 27s\n",
      "348:\tlearn: 0.0853128\ttotal: 47s\tremaining: 1m 27s\n",
      "349:\tlearn: 0.0851916\ttotal: 47.1s\tremaining: 1m 27s\n",
      "350:\tlearn: 0.0851916\ttotal: 47.2s\tremaining: 1m 27s\n",
      "351:\tlearn: 0.0850993\ttotal: 47.4s\tremaining: 1m 27s\n",
      "352:\tlearn: 0.0851281\ttotal: 47.5s\tremaining: 1m 27s\n",
      "353:\tlearn: 0.0850589\ttotal: 47.6s\tremaining: 1m 26s\n",
      "354:\tlearn: 0.0849665\ttotal: 47.8s\tremaining: 1m 26s\n",
      "355:\tlearn: 0.0849434\ttotal: 47.9s\tremaining: 1m 26s\n",
      "356:\tlearn: 0.0848223\ttotal: 48s\tremaining: 1m 26s\n",
      "357:\tlearn: 0.0848338\ttotal: 48.2s\tremaining: 1m 26s\n",
      "358:\tlearn: 0.0847761\ttotal: 48.3s\tremaining: 1m 26s\n",
      "359:\tlearn: 0.0846953\ttotal: 48.4s\tremaining: 1m 26s\n",
      "360:\tlearn: 0.0846895\ttotal: 48.6s\tremaining: 1m 25s\n",
      "361:\tlearn: 0.0846549\ttotal: 48.7s\tremaining: 1m 25s\n",
      "362:\tlearn: 0.0845856\ttotal: 48.8s\tremaining: 1m 25s\n",
      "363:\tlearn: 0.0845106\ttotal: 49s\tremaining: 1m 25s\n",
      "364:\tlearn: 0.0845048\ttotal: 49.1s\tremaining: 1m 25s\n",
      "365:\tlearn: 0.0844587\ttotal: 49.2s\tremaining: 1m 25s\n",
      "366:\tlearn: 0.0843779\ttotal: 49.4s\tremaining: 1m 25s\n",
      "367:\tlearn: 0.0843259\ttotal: 49.5s\tremaining: 1m 25s\n",
      "368:\tlearn: 0.0842509\ttotal: 49.6s\tremaining: 1m 24s\n",
      "369:\tlearn: 0.0841355\ttotal: 49.8s\tremaining: 1m 24s\n",
      "370:\tlearn: 0.0840316\ttotal: 49.9s\tremaining: 1m 24s\n",
      "371:\tlearn: 0.0840143\ttotal: 50s\tremaining: 1m 24s\n",
      "372:\tlearn: 0.0839335\ttotal: 50.2s\tremaining: 1m 24s\n",
      "373:\tlearn: 0.0839855\ttotal: 50.3s\tremaining: 1m 24s\n",
      "374:\tlearn: 0.0838816\ttotal: 50.4s\tremaining: 1m 24s\n",
      "375:\tlearn: 0.0837488\ttotal: 50.6s\tremaining: 1m 23s\n",
      "376:\tlearn: 0.0837027\ttotal: 50.7s\tremaining: 1m 23s\n",
      "377:\tlearn: 0.0836623\ttotal: 50.9s\tremaining: 1m 23s\n",
      "378:\tlearn: 0.0835065\ttotal: 51s\tremaining: 1m 23s\n",
      "379:\tlearn: 0.0834718\ttotal: 51.1s\tremaining: 1m 23s\n",
      "380:\tlearn: 0.0834488\ttotal: 51.3s\tremaining: 1m 23s\n",
      "381:\tlearn: 0.0834430\ttotal: 51.4s\tremaining: 1m 23s\n",
      "382:\tlearn: 0.0834257\ttotal: 51.5s\tremaining: 1m 23s\n",
      "383:\tlearn: 0.0833968\ttotal: 51.7s\tremaining: 1m 22s\n",
      "384:\tlearn: 0.0833564\ttotal: 51.8s\tremaining: 1m 22s\n",
      "385:\tlearn: 0.0832525\ttotal: 51.9s\tremaining: 1m 22s\n",
      "386:\tlearn: 0.0831429\ttotal: 52.1s\tremaining: 1m 22s\n",
      "387:\tlearn: 0.0830390\ttotal: 52.2s\tremaining: 1m 22s\n",
      "388:\tlearn: 0.0829928\ttotal: 52.4s\tremaining: 1m 22s\n",
      "389:\tlearn: 0.0829871\ttotal: 52.5s\tremaining: 1m 22s\n",
      "390:\tlearn: 0.0829582\ttotal: 52.7s\tremaining: 1m 22s\n",
      "391:\tlearn: 0.0828255\ttotal: 52.8s\tremaining: 1m 21s\n",
      "392:\tlearn: 0.0827331\ttotal: 53s\tremaining: 1m 21s\n",
      "393:\tlearn: 0.0827505\ttotal: 53.1s\tremaining: 1m 21s\n",
      "394:\tlearn: 0.0825946\ttotal: 53.3s\tremaining: 1m 21s\n",
      "395:\tlearn: 0.0825023\ttotal: 53.5s\tremaining: 1m 21s\n",
      "396:\tlearn: 0.0824677\ttotal: 53.6s\tremaining: 1m 21s\n",
      "397:\tlearn: 0.0824215\ttotal: 53.8s\tremaining: 1m 21s\n",
      "398:\tlearn: 0.0823349\ttotal: 53.9s\tremaining: 1m 21s\n",
      "399:\tlearn: 0.0823696\ttotal: 54.1s\tremaining: 1m 21s\n",
      "400:\tlearn: 0.0823061\ttotal: 54.2s\tremaining: 1m 21s\n",
      "401:\tlearn: 0.0822311\ttotal: 54.4s\tremaining: 1m 20s\n",
      "402:\tlearn: 0.0822195\ttotal: 54.5s\tremaining: 1m 20s\n",
      "403:\tlearn: 0.0821734\ttotal: 54.7s\tremaining: 1m 20s\n",
      "404:\tlearn: 0.0821330\ttotal: 54.8s\tremaining: 1m 20s\n",
      "405:\tlearn: 0.0819887\ttotal: 55s\tremaining: 1m 20s\n",
      "406:\tlearn: 0.0819079\ttotal: 55.1s\tremaining: 1m 20s\n",
      "407:\tlearn: 0.0819310\ttotal: 55.3s\tremaining: 1m 20s\n",
      "408:\tlearn: 0.0818848\ttotal: 55.4s\tremaining: 1m 20s\n",
      "409:\tlearn: 0.0818271\ttotal: 55.6s\tremaining: 1m 20s\n",
      "410:\tlearn: 0.0817809\ttotal: 55.8s\tremaining: 1m 19s\n",
      "411:\tlearn: 0.0817521\ttotal: 56s\tremaining: 1m 19s\n",
      "412:\tlearn: 0.0817117\ttotal: 56.2s\tremaining: 1m 19s\n",
      "413:\tlearn: 0.0816713\ttotal: 56.4s\tremaining: 1m 19s\n",
      "414:\tlearn: 0.0816020\ttotal: 56.6s\tremaining: 1m 19s\n",
      "415:\tlearn: 0.0816020\ttotal: 56.8s\tremaining: 1m 19s\n",
      "416:\tlearn: 0.0814808\ttotal: 57s\tremaining: 1m 19s\n",
      "417:\tlearn: 0.0813885\ttotal: 57.2s\tremaining: 1m 19s\n",
      "418:\tlearn: 0.0813712\ttotal: 57.4s\tremaining: 1m 19s\n",
      "419:\tlearn: 0.0813654\ttotal: 57.5s\tremaining: 1m 19s\n",
      "420:\tlearn: 0.0813827\ttotal: 57.7s\tremaining: 1m 19s\n",
      "421:\tlearn: 0.0812500\ttotal: 57.9s\tremaining: 1m 19s\n",
      "422:\tlearn: 0.0811923\ttotal: 58s\tremaining: 1m 19s\n",
      "423:\tlearn: 0.0811634\ttotal: 58.2s\tremaining: 1m 19s\n",
      "424:\tlearn: 0.0811057\ttotal: 58.3s\tremaining: 1m 18s\n",
      "425:\tlearn: 0.0810307\ttotal: 58.5s\tremaining: 1m 18s\n",
      "426:\tlearn: 0.0809672\ttotal: 58.6s\tremaining: 1m 18s\n",
      "427:\tlearn: 0.0809211\ttotal: 58.7s\tremaining: 1m 18s\n",
      "428:\tlearn: 0.0809672\ttotal: 58.9s\tremaining: 1m 18s\n",
      "429:\tlearn: 0.0808518\ttotal: 59s\tremaining: 1m 18s\n",
      "430:\tlearn: 0.0807941\ttotal: 59.1s\tremaining: 1m 18s\n",
      "431:\tlearn: 0.0807248\ttotal: 59.3s\tremaining: 1m 17s\n",
      "432:\tlearn: 0.0806671\ttotal: 59.4s\tremaining: 1m 17s\n",
      "433:\tlearn: 0.0806844\ttotal: 59.5s\tremaining: 1m 17s\n",
      "434:\tlearn: 0.0806036\ttotal: 59.7s\tremaining: 1m 17s\n",
      "435:\tlearn: 0.0805344\ttotal: 59.8s\tremaining: 1m 17s\n",
      "436:\tlearn: 0.0804767\ttotal: 59.9s\tremaining: 1m 17s\n",
      "437:\tlearn: 0.0804132\ttotal: 1m\tremaining: 1m 17s\n",
      "438:\tlearn: 0.0803324\ttotal: 1m\tremaining: 1m 16s\n",
      "439:\tlearn: 0.0803324\ttotal: 1m\tremaining: 1m 16s\n",
      "440:\tlearn: 0.0802689\ttotal: 1m\tremaining: 1m 16s\n",
      "441:\tlearn: 0.0802343\ttotal: 1m\tremaining: 1m 16s\n",
      "442:\tlearn: 0.0802112\ttotal: 1m\tremaining: 1m 16s\n",
      "443:\tlearn: 0.0801073\ttotal: 1m\tremaining: 1m 16s\n",
      "444:\tlearn: 0.0800843\ttotal: 1m\tremaining: 1m 16s\n",
      "445:\tlearn: 0.0799977\ttotal: 1m 1s\tremaining: 1m 15s\n",
      "446:\tlearn: 0.0799169\ttotal: 1m 1s\tremaining: 1m 15s\n",
      "447:\tlearn: 0.0799227\ttotal: 1m 1s\tremaining: 1m 15s\n",
      "448:\tlearn: 0.0799169\ttotal: 1m 1s\tremaining: 1m 15s\n",
      "449:\tlearn: 0.0797553\ttotal: 1m 1s\tremaining: 1m 15s\n",
      "450:\tlearn: 0.0797380\ttotal: 1m 1s\tremaining: 1m 15s\n",
      "451:\tlearn: 0.0796110\ttotal: 1m 1s\tremaining: 1m 15s\n",
      "452:\tlearn: 0.0795764\ttotal: 1m 2s\tremaining: 1m 14s\n",
      "453:\tlearn: 0.0795360\ttotal: 1m 2s\tremaining: 1m 14s\n",
      "454:\tlearn: 0.0794668\ttotal: 1m 2s\tremaining: 1m 14s\n",
      "455:\tlearn: 0.0794090\ttotal: 1m 2s\tremaining: 1m 14s\n",
      "456:\tlearn: 0.0793513\ttotal: 1m 2s\tremaining: 1m 14s\n",
      "457:\tlearn: 0.0792763\ttotal: 1m 2s\tremaining: 1m 14s\n",
      "458:\tlearn: 0.0792705\ttotal: 1m 2s\tremaining: 1m 14s\n",
      "459:\tlearn: 0.0792071\ttotal: 1m 2s\tremaining: 1m 13s\n",
      "460:\tlearn: 0.0791955\ttotal: 1m 3s\tremaining: 1m 13s\n",
      "461:\tlearn: 0.0791032\ttotal: 1m 3s\tremaining: 1m 13s\n",
      "462:\tlearn: 0.0790628\ttotal: 1m 3s\tremaining: 1m 13s\n",
      "463:\tlearn: 0.0789358\ttotal: 1m 3s\tremaining: 1m 13s\n",
      "464:\tlearn: 0.0788377\ttotal: 1m 3s\tremaining: 1m 13s\n",
      "465:\tlearn: 0.0787742\ttotal: 1m 3s\tremaining: 1m 13s\n",
      "466:\tlearn: 0.0787223\ttotal: 1m 3s\tremaining: 1m 12s\n",
      "467:\tlearn: 0.0786473\ttotal: 1m 4s\tremaining: 1m 12s\n",
      "468:\tlearn: 0.0786011\ttotal: 1m 4s\tremaining: 1m 12s\n",
      "469:\tlearn: 0.0785088\ttotal: 1m 4s\tremaining: 1m 12s\n",
      "470:\tlearn: 0.0784857\ttotal: 1m 4s\tremaining: 1m 12s\n",
      "471:\tlearn: 0.0783934\ttotal: 1m 4s\tremaining: 1m 12s\n",
      "472:\tlearn: 0.0783645\ttotal: 1m 4s\tremaining: 1m 12s\n",
      "473:\tlearn: 0.0782837\ttotal: 1m 4s\tremaining: 1m 11s\n",
      "474:\tlearn: 0.0781798\ttotal: 1m 5s\tremaining: 1m 11s\n",
      "475:\tlearn: 0.0781394\ttotal: 1m 5s\tremaining: 1m 11s\n",
      "476:\tlearn: 0.0780875\ttotal: 1m 5s\tremaining: 1m 11s\n",
      "477:\tlearn: 0.0779952\ttotal: 1m 5s\tremaining: 1m 11s\n",
      "478:\tlearn: 0.0779432\ttotal: 1m 5s\tremaining: 1m 11s\n",
      "479:\tlearn: 0.0779144\ttotal: 1m 5s\tremaining: 1m 11s\n",
      "480:\tlearn: 0.0778855\ttotal: 1m 5s\tremaining: 1m 11s\n",
      "481:\tlearn: 0.0778163\ttotal: 1m 5s\tremaining: 1m 10s\n",
      "482:\tlearn: 0.0777585\ttotal: 1m 6s\tremaining: 1m 10s\n",
      "483:\tlearn: 0.0776835\ttotal: 1m 6s\tremaining: 1m 10s\n",
      "484:\tlearn: 0.0776431\ttotal: 1m 6s\tremaining: 1m 10s\n",
      "485:\tlearn: 0.0775623\ttotal: 1m 6s\tremaining: 1m 10s\n",
      "486:\tlearn: 0.0774527\ttotal: 1m 6s\tremaining: 1m 10s\n",
      "487:\tlearn: 0.0773892\ttotal: 1m 6s\tremaining: 1m 10s\n",
      "488:\tlearn: 0.0773661\ttotal: 1m 6s\tremaining: 1m 9s\n",
      "489:\tlearn: 0.0773084\ttotal: 1m 7s\tremaining: 1m 9s\n",
      "490:\tlearn: 0.0772911\ttotal: 1m 7s\tremaining: 1m 9s\n",
      "491:\tlearn: 0.0772738\ttotal: 1m 7s\tremaining: 1m 9s\n",
      "492:\tlearn: 0.0772622\ttotal: 1m 7s\tremaining: 1m 9s\n",
      "493:\tlearn: 0.0771988\ttotal: 1m 7s\tremaining: 1m 9s\n",
      "494:\tlearn: 0.0771180\ttotal: 1m 7s\tremaining: 1m 9s\n",
      "495:\tlearn: 0.0771122\ttotal: 1m 7s\tremaining: 1m 8s\n",
      "496:\tlearn: 0.0770487\ttotal: 1m 7s\tremaining: 1m 8s\n",
      "497:\tlearn: 0.0769795\ttotal: 1m 8s\tremaining: 1m 8s\n",
      "498:\tlearn: 0.0769391\ttotal: 1m 8s\tremaining: 1m 8s\n",
      "499:\tlearn: 0.0767832\ttotal: 1m 8s\tremaining: 1m 8s\n",
      "500:\tlearn: 0.0767890\ttotal: 1m 8s\tremaining: 1m 8s\n",
      "501:\tlearn: 0.0767428\ttotal: 1m 8s\tremaining: 1m 8s\n",
      "502:\tlearn: 0.0766505\ttotal: 1m 8s\tremaining: 1m 7s\n",
      "503:\tlearn: 0.0766563\ttotal: 1m 8s\tremaining: 1m 7s\n",
      "504:\tlearn: 0.0766043\ttotal: 1m 9s\tremaining: 1m 7s\n",
      "505:\tlearn: 0.0766159\ttotal: 1m 9s\tremaining: 1m 7s\n",
      "506:\tlearn: 0.0765409\ttotal: 1m 9s\tremaining: 1m 7s\n",
      "507:\tlearn: 0.0765351\ttotal: 1m 9s\tremaining: 1m 7s\n",
      "508:\tlearn: 0.0764601\ttotal: 1m 9s\tremaining: 1m 7s\n",
      "509:\tlearn: 0.0764254\ttotal: 1m 9s\tremaining: 1m 6s\n",
      "510:\tlearn: 0.0762581\ttotal: 1m 9s\tremaining: 1m 6s\n",
      "511:\tlearn: 0.0762350\ttotal: 1m 9s\tremaining: 1m 6s\n",
      "512:\tlearn: 0.0762177\ttotal: 1m 10s\tremaining: 1m 6s\n",
      "513:\tlearn: 0.0761773\ttotal: 1m 10s\tremaining: 1m 6s\n",
      "514:\tlearn: 0.0761427\ttotal: 1m 10s\tremaining: 1m 6s\n",
      "515:\tlearn: 0.0760157\ttotal: 1m 10s\tremaining: 1m 6s\n",
      "516:\tlearn: 0.0759638\ttotal: 1m 10s\tremaining: 1m 6s\n",
      "517:\tlearn: 0.0759003\ttotal: 1m 10s\tremaining: 1m 5s\n",
      "518:\tlearn: 0.0758599\ttotal: 1m 10s\tremaining: 1m 5s\n",
      "519:\tlearn: 0.0758253\ttotal: 1m 11s\tremaining: 1m 5s\n",
      "520:\tlearn: 0.0757329\ttotal: 1m 11s\tremaining: 1m 5s\n",
      "521:\tlearn: 0.0757214\ttotal: 1m 11s\tremaining: 1m 5s\n",
      "522:\tlearn: 0.0756983\ttotal: 1m 11s\tremaining: 1m 5s\n",
      "523:\tlearn: 0.0756694\ttotal: 1m 11s\tremaining: 1m 5s\n",
      "524:\tlearn: 0.0756117\ttotal: 1m 11s\tremaining: 1m 4s\n",
      "525:\tlearn: 0.0754790\ttotal: 1m 11s\tremaining: 1m 4s\n",
      "526:\tlearn: 0.0754097\ttotal: 1m 12s\tremaining: 1m 4s\n",
      "527:\tlearn: 0.0753578\ttotal: 1m 12s\tremaining: 1m 4s\n",
      "528:\tlearn: 0.0753463\ttotal: 1m 12s\tremaining: 1m 4s\n",
      "529:\tlearn: 0.0752539\ttotal: 1m 12s\tremaining: 1m 4s\n",
      "530:\tlearn: 0.0751558\ttotal: 1m 12s\tremaining: 1m 4s\n",
      "531:\tlearn: 0.0751212\ttotal: 1m 12s\tremaining: 1m 3s\n",
      "532:\tlearn: 0.0751385\ttotal: 1m 12s\tremaining: 1m 3s\n",
      "533:\tlearn: 0.0751154\ttotal: 1m 12s\tremaining: 1m 3s\n",
      "534:\tlearn: 0.0749769\ttotal: 1m 13s\tremaining: 1m 3s\n",
      "535:\tlearn: 0.0749365\ttotal: 1m 13s\tremaining: 1m 3s\n",
      "536:\tlearn: 0.0749423\ttotal: 1m 13s\tremaining: 1m 3s\n",
      "537:\tlearn: 0.0748096\ttotal: 1m 13s\tremaining: 1m 3s\n",
      "538:\tlearn: 0.0748153\ttotal: 1m 13s\tremaining: 1m 2s\n",
      "539:\tlearn: 0.0747980\ttotal: 1m 13s\tremaining: 1m 2s\n",
      "540:\tlearn: 0.0747749\ttotal: 1m 13s\tremaining: 1m 2s\n",
      "541:\tlearn: 0.0746422\ttotal: 1m 14s\tremaining: 1m 2s\n",
      "542:\tlearn: 0.0746249\ttotal: 1m 14s\tremaining: 1m 2s\n",
      "543:\tlearn: 0.0746018\ttotal: 1m 14s\tremaining: 1m 2s\n",
      "544:\tlearn: 0.0745037\ttotal: 1m 14s\tremaining: 1m 2s\n",
      "545:\tlearn: 0.0744402\ttotal: 1m 14s\tremaining: 1m 2s\n",
      "546:\tlearn: 0.0744748\ttotal: 1m 14s\tremaining: 1m 1s\n",
      "547:\tlearn: 0.0744402\ttotal: 1m 14s\tremaining: 1m 1s\n",
      "548:\tlearn: 0.0744287\ttotal: 1m 14s\tremaining: 1m 1s\n",
      "549:\tlearn: 0.0743363\ttotal: 1m 15s\tremaining: 1m 1s\n",
      "550:\tlearn: 0.0742094\ttotal: 1m 15s\tremaining: 1m 1s\n",
      "551:\tlearn: 0.0741921\ttotal: 1m 15s\tremaining: 1m 1s\n",
      "552:\tlearn: 0.0741055\ttotal: 1m 15s\tremaining: 1m 1s\n",
      "553:\tlearn: 0.0740305\ttotal: 1m 15s\tremaining: 1m\n",
      "554:\tlearn: 0.0739381\ttotal: 1m 15s\tremaining: 1m\n",
      "555:\tlearn: 0.0739093\ttotal: 1m 15s\tremaining: 1m\n",
      "556:\tlearn: 0.0738343\ttotal: 1m 16s\tremaining: 1m\n",
      "557:\tlearn: 0.0737823\ttotal: 1m 16s\tremaining: 1m\n",
      "558:\tlearn: 0.0737765\ttotal: 1m 16s\tremaining: 1m\n",
      "559:\tlearn: 0.0737246\ttotal: 1m 16s\tremaining: 1m\n",
      "560:\tlearn: 0.0737131\ttotal: 1m 16s\tremaining: 60s\n",
      "561:\tlearn: 0.0736611\ttotal: 1m 16s\tremaining: 59.9s\n",
      "562:\tlearn: 0.0735515\ttotal: 1m 16s\tremaining: 59.7s\n",
      "563:\tlearn: 0.0734822\ttotal: 1m 17s\tremaining: 59.6s\n",
      "564:\tlearn: 0.0734649\ttotal: 1m 17s\tremaining: 59.4s\n",
      "565:\tlearn: 0.0734418\ttotal: 1m 17s\tremaining: 59.3s\n",
      "566:\tlearn: 0.0734014\ttotal: 1m 17s\tremaining: 59.1s\n",
      "567:\tlearn: 0.0733495\ttotal: 1m 17s\tremaining: 59s\n",
      "568:\tlearn: 0.0732572\ttotal: 1m 17s\tremaining: 58.9s\n",
      "569:\tlearn: 0.0732052\ttotal: 1m 17s\tremaining: 58.7s\n",
      "570:\tlearn: 0.0731994\ttotal: 1m 17s\tremaining: 58.6s\n",
      "571:\tlearn: 0.0731648\ttotal: 1m 18s\tremaining: 58.4s\n",
      "572:\tlearn: 0.0731129\ttotal: 1m 18s\tremaining: 58.3s\n",
      "573:\tlearn: 0.0730148\ttotal: 1m 18s\tremaining: 58.2s\n",
      "574:\tlearn: 0.0730032\ttotal: 1m 18s\tremaining: 58s\n",
      "575:\tlearn: 0.0730032\ttotal: 1m 18s\tremaining: 57.9s\n",
      "576:\tlearn: 0.0729801\ttotal: 1m 18s\tremaining: 57.8s\n",
      "577:\tlearn: 0.0729628\ttotal: 1m 18s\tremaining: 57.6s\n",
      "578:\tlearn: 0.0728705\ttotal: 1m 19s\tremaining: 57.5s\n",
      "579:\tlearn: 0.0727608\ttotal: 1m 19s\tremaining: 57.3s\n",
      "580:\tlearn: 0.0727089\ttotal: 1m 19s\tremaining: 57.2s\n",
      "581:\tlearn: 0.0726512\ttotal: 1m 19s\tremaining: 57.1s\n",
      "582:\tlearn: 0.0726166\ttotal: 1m 19s\tremaining: 56.9s\n",
      "583:\tlearn: 0.0724665\ttotal: 1m 19s\tremaining: 56.8s\n",
      "584:\tlearn: 0.0723627\ttotal: 1m 19s\tremaining: 56.6s\n",
      "585:\tlearn: 0.0722992\ttotal: 1m 19s\tremaining: 56.5s\n",
      "586:\tlearn: 0.0722184\ttotal: 1m 20s\tremaining: 56.4s\n",
      "587:\tlearn: 0.0722126\ttotal: 1m 20s\tremaining: 56.2s\n",
      "588:\tlearn: 0.0722184\ttotal: 1m 20s\tremaining: 56.1s\n",
      "589:\tlearn: 0.0721260\ttotal: 1m 20s\tremaining: 55.9s\n",
      "590:\tlearn: 0.0721260\ttotal: 1m 20s\tremaining: 55.8s\n",
      "591:\tlearn: 0.0720222\ttotal: 1m 20s\tremaining: 55.7s\n",
      "592:\tlearn: 0.0720048\ttotal: 1m 20s\tremaining: 55.5s\n",
      "593:\tlearn: 0.0720222\ttotal: 1m 21s\tremaining: 55.4s\n",
      "594:\tlearn: 0.0720106\ttotal: 1m 21s\tremaining: 55.2s\n",
      "595:\tlearn: 0.0719414\ttotal: 1m 21s\tremaining: 55.1s\n",
      "596:\tlearn: 0.0718490\ttotal: 1m 21s\tremaining: 55s\n",
      "597:\tlearn: 0.0718086\ttotal: 1m 21s\tremaining: 54.8s\n",
      "598:\tlearn: 0.0717740\ttotal: 1m 21s\tremaining: 54.7s\n",
      "599:\tlearn: 0.0716701\ttotal: 1m 21s\tremaining: 54.6s\n",
      "600:\tlearn: 0.0716528\ttotal: 1m 21s\tremaining: 54.4s\n",
      "601:\tlearn: 0.0715836\ttotal: 1m 22s\tremaining: 54.3s\n",
      "602:\tlearn: 0.0715316\ttotal: 1m 22s\tremaining: 54.1s\n",
      "603:\tlearn: 0.0715085\ttotal: 1m 22s\tremaining: 54s\n",
      "604:\tlearn: 0.0713989\ttotal: 1m 22s\tremaining: 53.9s\n",
      "605:\tlearn: 0.0714739\ttotal: 1m 22s\tremaining: 53.7s\n",
      "606:\tlearn: 0.0714220\ttotal: 1m 22s\tremaining: 53.6s\n",
      "607:\tlearn: 0.0713239\ttotal: 1m 22s\tremaining: 53.4s\n",
      "608:\tlearn: 0.0712892\ttotal: 1m 23s\tremaining: 53.3s\n",
      "609:\tlearn: 0.0712027\ttotal: 1m 23s\tremaining: 53.2s\n",
      "610:\tlearn: 0.0712027\ttotal: 1m 23s\tremaining: 53s\n",
      "611:\tlearn: 0.0711796\ttotal: 1m 23s\tremaining: 52.9s\n",
      "612:\tlearn: 0.0711450\ttotal: 1m 23s\tremaining: 52.8s\n",
      "613:\tlearn: 0.0711046\ttotal: 1m 23s\tremaining: 52.6s\n",
      "614:\tlearn: 0.0710238\ttotal: 1m 23s\tremaining: 52.5s\n",
      "615:\tlearn: 0.0710642\ttotal: 1m 23s\tremaining: 52.4s\n",
      "616:\tlearn: 0.0710007\ttotal: 1m 24s\tremaining: 52.2s\n",
      "617:\tlearn: 0.0709314\ttotal: 1m 24s\tremaining: 52.1s\n",
      "618:\tlearn: 0.0708853\ttotal: 1m 24s\tremaining: 51.9s\n",
      "619:\tlearn: 0.0708391\ttotal: 1m 24s\tremaining: 51.8s\n",
      "620:\tlearn: 0.0707756\ttotal: 1m 24s\tremaining: 51.7s\n",
      "621:\tlearn: 0.0707814\ttotal: 1m 24s\tremaining: 51.5s\n",
      "622:\tlearn: 0.0707006\ttotal: 1m 24s\tremaining: 51.4s\n",
      "623:\tlearn: 0.0706256\ttotal: 1m 25s\tremaining: 51.2s\n",
      "624:\tlearn: 0.0705967\ttotal: 1m 25s\tremaining: 51.1s\n",
      "625:\tlearn: 0.0705794\ttotal: 1m 25s\tremaining: 51s\n",
      "626:\tlearn: 0.0705563\ttotal: 1m 25s\tremaining: 50.8s\n",
      "627:\tlearn: 0.0704755\ttotal: 1m 25s\tremaining: 50.7s\n",
      "628:\tlearn: 0.0703774\ttotal: 1m 25s\tremaining: 50.6s\n",
      "629:\tlearn: 0.0703486\ttotal: 1m 25s\tremaining: 50.4s\n",
      "630:\tlearn: 0.0702562\ttotal: 1m 26s\tremaining: 50.3s\n",
      "631:\tlearn: 0.0702793\ttotal: 1m 26s\tremaining: 50.2s\n",
      "632:\tlearn: 0.0702158\ttotal: 1m 26s\tremaining: 50s\n",
      "633:\tlearn: 0.0701639\ttotal: 1m 26s\tremaining: 49.9s\n",
      "634:\tlearn: 0.0701466\ttotal: 1m 26s\tremaining: 49.8s\n",
      "635:\tlearn: 0.0700542\ttotal: 1m 26s\tremaining: 49.6s\n",
      "636:\tlearn: 0.0700139\ttotal: 1m 26s\tremaining: 49.5s\n",
      "637:\tlearn: 0.0699273\ttotal: 1m 26s\tremaining: 49.3s\n",
      "638:\tlearn: 0.0699388\ttotal: 1m 27s\tremaining: 49.2s\n",
      "639:\tlearn: 0.0699273\ttotal: 1m 27s\tremaining: 49.1s\n",
      "640:\tlearn: 0.0698465\ttotal: 1m 27s\tremaining: 48.9s\n",
      "641:\tlearn: 0.0698003\ttotal: 1m 27s\tremaining: 48.8s\n",
      "642:\tlearn: 0.0696907\ttotal: 1m 27s\tremaining: 48.7s\n",
      "643:\tlearn: 0.0695983\ttotal: 1m 27s\tremaining: 48.5s\n",
      "644:\tlearn: 0.0695579\ttotal: 1m 27s\tremaining: 48.4s\n",
      "645:\tlearn: 0.0695579\ttotal: 1m 28s\tremaining: 48.2s\n",
      "646:\tlearn: 0.0694598\ttotal: 1m 28s\tremaining: 48.1s\n",
      "647:\tlearn: 0.0694425\ttotal: 1m 28s\tremaining: 48s\n",
      "648:\tlearn: 0.0694194\ttotal: 1m 28s\tremaining: 47.8s\n",
      "649:\tlearn: 0.0693790\ttotal: 1m 28s\tremaining: 47.7s\n",
      "650:\tlearn: 0.0693617\ttotal: 1m 28s\tremaining: 47.6s\n",
      "651:\tlearn: 0.0692636\ttotal: 1m 28s\tremaining: 47.4s\n",
      "652:\tlearn: 0.0692117\ttotal: 1m 28s\tremaining: 47.3s\n",
      "653:\tlearn: 0.0691424\ttotal: 1m 29s\tremaining: 47.1s\n",
      "654:\tlearn: 0.0691136\ttotal: 1m 29s\tremaining: 47s\n",
      "655:\tlearn: 0.0690443\ttotal: 1m 29s\tremaining: 46.9s\n",
      "656:\tlearn: 0.0690328\ttotal: 1m 29s\tremaining: 46.7s\n",
      "657:\tlearn: 0.0689578\ttotal: 1m 29s\tremaining: 46.6s\n",
      "658:\tlearn: 0.0688481\ttotal: 1m 29s\tremaining: 46.5s\n",
      "659:\tlearn: 0.0687731\ttotal: 1m 29s\tremaining: 46.3s\n",
      "660:\tlearn: 0.0687442\ttotal: 1m 30s\tremaining: 46.2s\n",
      "661:\tlearn: 0.0687211\ttotal: 1m 30s\tremaining: 46s\n",
      "662:\tlearn: 0.0686519\ttotal: 1m 30s\tremaining: 45.9s\n",
      "663:\tlearn: 0.0686346\ttotal: 1m 30s\tremaining: 45.8s\n",
      "664:\tlearn: 0.0686230\ttotal: 1m 30s\tremaining: 45.6s\n",
      "665:\tlearn: 0.0686230\ttotal: 1m 30s\tremaining: 45.5s\n",
      "666:\tlearn: 0.0685134\ttotal: 1m 30s\tremaining: 45.4s\n",
      "667:\tlearn: 0.0684961\ttotal: 1m 30s\tremaining: 45.2s\n",
      "668:\tlearn: 0.0684672\ttotal: 1m 31s\tremaining: 45.1s\n",
      "669:\tlearn: 0.0684211\ttotal: 1m 31s\tremaining: 44.9s\n",
      "670:\tlearn: 0.0684037\ttotal: 1m 31s\tremaining: 44.8s\n",
      "671:\tlearn: 0.0683576\ttotal: 1m 31s\tremaining: 44.7s\n",
      "672:\tlearn: 0.0682768\ttotal: 1m 31s\tremaining: 44.5s\n",
      "673:\tlearn: 0.0682075\ttotal: 1m 31s\tremaining: 44.4s\n",
      "674:\tlearn: 0.0682133\ttotal: 1m 31s\tremaining: 44.2s\n",
      "675:\tlearn: 0.0681902\ttotal: 1m 32s\tremaining: 44.1s\n",
      "676:\tlearn: 0.0681556\ttotal: 1m 32s\tremaining: 44s\n",
      "677:\tlearn: 0.0680863\ttotal: 1m 32s\tremaining: 43.8s\n",
      "678:\tlearn: 0.0680633\ttotal: 1m 32s\tremaining: 43.7s\n",
      "679:\tlearn: 0.0679825\ttotal: 1m 32s\tremaining: 43.6s\n",
      "680:\tlearn: 0.0679132\ttotal: 1m 32s\tremaining: 43.4s\n",
      "681:\tlearn: 0.0678497\ttotal: 1m 32s\tremaining: 43.3s\n",
      "682:\tlearn: 0.0678093\ttotal: 1m 32s\tremaining: 43.2s\n",
      "683:\tlearn: 0.0677978\ttotal: 1m 33s\tremaining: 43s\n",
      "684:\tlearn: 0.0677632\ttotal: 1m 33s\tremaining: 42.9s\n",
      "685:\tlearn: 0.0677632\ttotal: 1m 33s\tremaining: 42.8s\n",
      "686:\tlearn: 0.0678036\ttotal: 1m 33s\tremaining: 42.6s\n",
      "687:\tlearn: 0.0678036\ttotal: 1m 33s\tremaining: 42.5s\n",
      "688:\tlearn: 0.0677632\ttotal: 1m 33s\tremaining: 42.3s\n",
      "689:\tlearn: 0.0676073\ttotal: 1m 33s\tremaining: 42.2s\n",
      "690:\tlearn: 0.0675785\ttotal: 1m 34s\tremaining: 42.1s\n",
      "691:\tlearn: 0.0675323\ttotal: 1m 34s\tremaining: 41.9s\n",
      "692:\tlearn: 0.0674515\ttotal: 1m 34s\tremaining: 41.8s\n",
      "693:\tlearn: 0.0674284\ttotal: 1m 34s\tremaining: 41.6s\n",
      "694:\tlearn: 0.0674054\ttotal: 1m 34s\tremaining: 41.5s\n",
      "695:\tlearn: 0.0674169\ttotal: 1m 34s\tremaining: 41.4s\n",
      "696:\tlearn: 0.0673592\ttotal: 1m 34s\tremaining: 41.2s\n",
      "697:\tlearn: 0.0672899\ttotal: 1m 34s\tremaining: 41.1s\n",
      "698:\tlearn: 0.0673130\ttotal: 1m 35s\tremaining: 41s\n",
      "699:\tlearn: 0.0672611\ttotal: 1m 35s\tremaining: 40.8s\n",
      "700:\tlearn: 0.0671745\ttotal: 1m 35s\tremaining: 40.7s\n",
      "701:\tlearn: 0.0671745\ttotal: 1m 35s\tremaining: 40.5s\n",
      "702:\tlearn: 0.0670995\ttotal: 1m 35s\tremaining: 40.4s\n",
      "703:\tlearn: 0.0670995\ttotal: 1m 35s\tremaining: 40.3s\n",
      "704:\tlearn: 0.0670129\ttotal: 1m 35s\tremaining: 40.1s\n",
      "705:\tlearn: 0.0669264\ttotal: 1m 36s\tremaining: 40s\n",
      "706:\tlearn: 0.0667936\ttotal: 1m 36s\tremaining: 39.9s\n",
      "707:\tlearn: 0.0667475\ttotal: 1m 36s\tremaining: 39.7s\n",
      "708:\tlearn: 0.0666032\ttotal: 1m 36s\tremaining: 39.6s\n",
      "709:\tlearn: 0.0665339\ttotal: 1m 36s\tremaining: 39.5s\n",
      "710:\tlearn: 0.0665339\ttotal: 1m 36s\tremaining: 39.3s\n",
      "711:\tlearn: 0.0664358\ttotal: 1m 36s\tremaining: 39.2s\n",
      "712:\tlearn: 0.0664243\ttotal: 1m 36s\tremaining: 39s\n",
      "713:\tlearn: 0.0663089\ttotal: 1m 37s\tremaining: 38.9s\n",
      "714:\tlearn: 0.0662685\ttotal: 1m 37s\tremaining: 38.8s\n",
      "715:\tlearn: 0.0662050\ttotal: 1m 37s\tremaining: 38.6s\n",
      "716:\tlearn: 0.0661934\ttotal: 1m 37s\tremaining: 38.5s\n",
      "717:\tlearn: 0.0661934\ttotal: 1m 37s\tremaining: 38.4s\n",
      "718:\tlearn: 0.0661530\ttotal: 1m 37s\tremaining: 38.2s\n",
      "719:\tlearn: 0.0661242\ttotal: 1m 37s\tremaining: 38.1s\n",
      "720:\tlearn: 0.0660607\ttotal: 1m 38s\tremaining: 38s\n",
      "721:\tlearn: 0.0660723\ttotal: 1m 38s\tremaining: 37.8s\n",
      "722:\tlearn: 0.0660030\ttotal: 1m 38s\tremaining: 37.7s\n",
      "723:\tlearn: 0.0659857\ttotal: 1m 38s\tremaining: 37.5s\n",
      "724:\tlearn: 0.0659222\ttotal: 1m 38s\tremaining: 37.4s\n",
      "725:\tlearn: 0.0658530\ttotal: 1m 38s\tremaining: 37.3s\n",
      "726:\tlearn: 0.0658472\ttotal: 1m 38s\tremaining: 37.1s\n",
      "727:\tlearn: 0.0658414\ttotal: 1m 39s\tremaining: 37s\n",
      "728:\tlearn: 0.0658068\ttotal: 1m 39s\tremaining: 36.9s\n",
      "729:\tlearn: 0.0657779\ttotal: 1m 39s\tremaining: 36.7s\n",
      "730:\tlearn: 0.0657318\ttotal: 1m 39s\tremaining: 36.6s\n",
      "731:\tlearn: 0.0656221\ttotal: 1m 39s\tremaining: 36.5s\n",
      "732:\tlearn: 0.0655875\ttotal: 1m 39s\tremaining: 36.3s\n",
      "733:\tlearn: 0.0655644\ttotal: 1m 39s\tremaining: 36.2s\n",
      "734:\tlearn: 0.0655529\ttotal: 1m 39s\tremaining: 36s\n",
      "735:\tlearn: 0.0655009\ttotal: 1m 40s\tremaining: 35.9s\n",
      "736:\tlearn: 0.0654374\ttotal: 1m 40s\tremaining: 35.8s\n",
      "737:\tlearn: 0.0653278\ttotal: 1m 40s\tremaining: 35.6s\n",
      "738:\tlearn: 0.0653163\ttotal: 1m 40s\tremaining: 35.5s\n",
      "739:\tlearn: 0.0652759\ttotal: 1m 40s\tremaining: 35.4s\n",
      "740:\tlearn: 0.0652701\ttotal: 1m 40s\tremaining: 35.2s\n",
      "741:\tlearn: 0.0651893\ttotal: 1m 40s\tremaining: 35.1s\n",
      "742:\tlearn: 0.0651951\ttotal: 1m 41s\tremaining: 35s\n",
      "743:\tlearn: 0.0651316\ttotal: 1m 41s\tremaining: 34.8s\n",
      "744:\tlearn: 0.0651316\ttotal: 1m 41s\tremaining: 34.7s\n",
      "745:\tlearn: 0.0650450\ttotal: 1m 41s\tremaining: 34.5s\n",
      "746:\tlearn: 0.0649988\ttotal: 1m 41s\tremaining: 34.4s\n",
      "747:\tlearn: 0.0649354\ttotal: 1m 41s\tremaining: 34.3s\n",
      "748:\tlearn: 0.0648430\ttotal: 1m 41s\tremaining: 34.1s\n",
      "749:\tlearn: 0.0648199\ttotal: 1m 42s\tremaining: 34s\n",
      "750:\tlearn: 0.0647969\ttotal: 1m 42s\tremaining: 33.9s\n",
      "751:\tlearn: 0.0647969\ttotal: 1m 42s\tremaining: 33.7s\n",
      "752:\tlearn: 0.0647507\ttotal: 1m 42s\tremaining: 33.6s\n",
      "753:\tlearn: 0.0646641\ttotal: 1m 42s\tremaining: 33.5s\n",
      "754:\tlearn: 0.0646006\ttotal: 1m 42s\tremaining: 33.3s\n",
      "755:\tlearn: 0.0645487\ttotal: 1m 42s\tremaining: 33.2s\n",
      "756:\tlearn: 0.0644679\ttotal: 1m 42s\tremaining: 33s\n",
      "757:\tlearn: 0.0644044\ttotal: 1m 43s\tremaining: 32.9s\n",
      "758:\tlearn: 0.0643871\ttotal: 1m 43s\tremaining: 32.8s\n",
      "759:\tlearn: 0.0643179\ttotal: 1m 43s\tremaining: 32.6s\n",
      "760:\tlearn: 0.0642832\ttotal: 1m 43s\tremaining: 32.5s\n",
      "761:\tlearn: 0.0642313\ttotal: 1m 43s\tremaining: 32.4s\n",
      "762:\tlearn: 0.0642313\ttotal: 1m 43s\tremaining: 32.2s\n",
      "763:\tlearn: 0.0642313\ttotal: 1m 43s\tremaining: 32.1s\n",
      "764:\tlearn: 0.0641794\ttotal: 1m 44s\tremaining: 32s\n",
      "765:\tlearn: 0.0641678\ttotal: 1m 44s\tremaining: 31.8s\n",
      "766:\tlearn: 0.0641332\ttotal: 1m 44s\tremaining: 31.7s\n",
      "767:\tlearn: 0.0640639\ttotal: 1m 44s\tremaining: 31.5s\n",
      "768:\tlearn: 0.0639889\ttotal: 1m 44s\tremaining: 31.4s\n",
      "769:\tlearn: 0.0639254\ttotal: 1m 44s\tremaining: 31.3s\n",
      "770:\tlearn: 0.0639370\ttotal: 1m 44s\tremaining: 31.1s\n",
      "771:\tlearn: 0.0638850\ttotal: 1m 44s\tremaining: 31s\n",
      "772:\tlearn: 0.0638620\ttotal: 1m 45s\tremaining: 30.9s\n",
      "773:\tlearn: 0.0638158\ttotal: 1m 45s\tremaining: 30.7s\n",
      "774:\tlearn: 0.0637061\ttotal: 1m 45s\tremaining: 30.6s\n",
      "775:\tlearn: 0.0636253\ttotal: 1m 45s\tremaining: 30.4s\n",
      "776:\tlearn: 0.0635907\ttotal: 1m 45s\tremaining: 30.3s\n",
      "777:\tlearn: 0.0636023\ttotal: 1m 45s\tremaining: 30.2s\n",
      "778:\tlearn: 0.0635503\ttotal: 1m 45s\tremaining: 30s\n",
      "779:\tlearn: 0.0635099\ttotal: 1m 46s\tremaining: 29.9s\n",
      "780:\tlearn: 0.0634753\ttotal: 1m 46s\tremaining: 29.8s\n",
      "781:\tlearn: 0.0634407\ttotal: 1m 46s\tremaining: 29.6s\n",
      "782:\tlearn: 0.0633772\ttotal: 1m 46s\tremaining: 29.5s\n",
      "783:\tlearn: 0.0633714\ttotal: 1m 46s\tremaining: 29.4s\n",
      "784:\tlearn: 0.0633426\ttotal: 1m 46s\tremaining: 29.2s\n",
      "785:\tlearn: 0.0633079\ttotal: 1m 46s\tremaining: 29.1s\n",
      "786:\tlearn: 0.0632618\ttotal: 1m 46s\tremaining: 28.9s\n",
      "787:\tlearn: 0.0632214\ttotal: 1m 47s\tremaining: 28.8s\n",
      "788:\tlearn: 0.0631810\ttotal: 1m 47s\tremaining: 28.7s\n",
      "789:\tlearn: 0.0631694\ttotal: 1m 47s\tremaining: 28.5s\n",
      "790:\tlearn: 0.0631348\ttotal: 1m 47s\tremaining: 28.4s\n",
      "791:\tlearn: 0.0631117\ttotal: 1m 47s\tremaining: 28.3s\n",
      "792:\tlearn: 0.0630540\ttotal: 1m 47s\tremaining: 28.1s\n",
      "793:\tlearn: 0.0629097\ttotal: 1m 47s\tremaining: 28s\n",
      "794:\tlearn: 0.0628693\ttotal: 1m 48s\tremaining: 27.9s\n",
      "795:\tlearn: 0.0629040\ttotal: 1m 48s\tremaining: 27.7s\n",
      "796:\tlearn: 0.0629155\ttotal: 1m 48s\tremaining: 27.6s\n",
      "797:\tlearn: 0.0628405\ttotal: 1m 48s\tremaining: 27.4s\n",
      "798:\tlearn: 0.0627770\ttotal: 1m 48s\tremaining: 27.3s\n",
      "799:\tlearn: 0.0627424\ttotal: 1m 48s\tremaining: 27.2s\n",
      "800:\tlearn: 0.0626962\ttotal: 1m 48s\tremaining: 27s\n",
      "801:\tlearn: 0.0626904\ttotal: 1m 48s\tremaining: 26.9s\n",
      "802:\tlearn: 0.0626904\ttotal: 1m 49s\tremaining: 26.8s\n",
      "803:\tlearn: 0.0625808\ttotal: 1m 49s\tremaining: 26.6s\n",
      "804:\tlearn: 0.0625693\ttotal: 1m 49s\tremaining: 26.5s\n",
      "805:\tlearn: 0.0625231\ttotal: 1m 49s\tremaining: 26.4s\n",
      "806:\tlearn: 0.0625231\ttotal: 1m 49s\tremaining: 26.2s\n",
      "807:\tlearn: 0.0625000\ttotal: 1m 49s\tremaining: 26.1s\n",
      "808:\tlearn: 0.0624365\ttotal: 1m 49s\tremaining: 25.9s\n",
      "809:\tlearn: 0.0624077\ttotal: 1m 50s\tremaining: 25.8s\n",
      "810:\tlearn: 0.0622980\ttotal: 1m 50s\tremaining: 25.7s\n",
      "811:\tlearn: 0.0622288\ttotal: 1m 50s\tremaining: 25.5s\n",
      "812:\tlearn: 0.0621999\ttotal: 1m 50s\tremaining: 25.4s\n",
      "813:\tlearn: 0.0621941\ttotal: 1m 50s\tremaining: 25.3s\n",
      "814:\tlearn: 0.0621768\ttotal: 1m 50s\tremaining: 25.1s\n",
      "815:\tlearn: 0.0620960\ttotal: 1m 50s\tremaining: 25s\n",
      "816:\tlearn: 0.0620787\ttotal: 1m 50s\tremaining: 24.9s\n",
      "817:\tlearn: 0.0620268\ttotal: 1m 51s\tremaining: 24.7s\n",
      "818:\tlearn: 0.0619056\ttotal: 1m 51s\tremaining: 24.6s\n",
      "819:\tlearn: 0.0619402\ttotal: 1m 51s\tremaining: 24.4s\n",
      "820:\tlearn: 0.0618767\ttotal: 1m 51s\tremaining: 24.3s\n",
      "821:\tlearn: 0.0617959\ttotal: 1m 51s\tremaining: 24.2s\n",
      "822:\tlearn: 0.0617844\ttotal: 1m 51s\tremaining: 24s\n",
      "823:\tlearn: 0.0617671\ttotal: 1m 51s\tremaining: 23.9s\n",
      "824:\tlearn: 0.0616921\ttotal: 1m 52s\tremaining: 23.8s\n",
      "825:\tlearn: 0.0616113\ttotal: 1m 52s\tremaining: 23.6s\n",
      "826:\tlearn: 0.0615882\ttotal: 1m 52s\tremaining: 23.5s\n",
      "827:\tlearn: 0.0615593\ttotal: 1m 52s\tremaining: 23.4s\n",
      "828:\tlearn: 0.0615882\ttotal: 1m 52s\tremaining: 23.2s\n",
      "829:\tlearn: 0.0615997\ttotal: 1m 52s\tremaining: 23.1s\n",
      "830:\tlearn: 0.0615305\ttotal: 1m 52s\tremaining: 22.9s\n",
      "831:\tlearn: 0.0614728\ttotal: 1m 52s\tremaining: 22.8s\n",
      "832:\tlearn: 0.0614728\ttotal: 1m 53s\tremaining: 22.7s\n",
      "833:\tlearn: 0.0613862\ttotal: 1m 53s\tremaining: 22.5s\n",
      "834:\tlearn: 0.0613516\ttotal: 1m 53s\tremaining: 22.4s\n",
      "835:\tlearn: 0.0612881\ttotal: 1m 53s\tremaining: 22.3s\n",
      "836:\tlearn: 0.0612535\ttotal: 1m 53s\tremaining: 22.1s\n",
      "837:\tlearn: 0.0611554\ttotal: 1m 53s\tremaining: 22s\n",
      "838:\tlearn: 0.0611611\ttotal: 1m 53s\tremaining: 21.9s\n",
      "839:\tlearn: 0.0611438\ttotal: 1m 54s\tremaining: 21.7s\n",
      "840:\tlearn: 0.0610688\ttotal: 1m 54s\tremaining: 21.6s\n",
      "841:\tlearn: 0.0610572\ttotal: 1m 54s\tremaining: 21.4s\n",
      "842:\tlearn: 0.0610169\ttotal: 1m 54s\tremaining: 21.3s\n",
      "843:\tlearn: 0.0610053\ttotal: 1m 54s\tremaining: 21.2s\n",
      "844:\tlearn: 0.0609880\ttotal: 1m 54s\tremaining: 21s\n",
      "845:\tlearn: 0.0608899\ttotal: 1m 54s\tremaining: 20.9s\n",
      "846:\tlearn: 0.0608610\ttotal: 1m 54s\tremaining: 20.8s\n",
      "847:\tlearn: 0.0608264\ttotal: 1m 55s\tremaining: 20.6s\n",
      "848:\tlearn: 0.0608264\ttotal: 1m 55s\tremaining: 20.5s\n",
      "849:\tlearn: 0.0607514\ttotal: 1m 55s\tremaining: 20.4s\n",
      "850:\tlearn: 0.0607456\ttotal: 1m 55s\tremaining: 20.2s\n",
      "851:\tlearn: 0.0607283\ttotal: 1m 55s\tremaining: 20.1s\n",
      "852:\tlearn: 0.0607283\ttotal: 1m 55s\tremaining: 20s\n",
      "853:\tlearn: 0.0606475\ttotal: 1m 55s\tremaining: 19.8s\n",
      "854:\tlearn: 0.0606937\ttotal: 1m 56s\tremaining: 19.7s\n",
      "855:\tlearn: 0.0606821\ttotal: 1m 56s\tremaining: 19.6s\n",
      "856:\tlearn: 0.0606129\ttotal: 1m 56s\tremaining: 19.4s\n",
      "857:\tlearn: 0.0605321\ttotal: 1m 56s\tremaining: 19.3s\n",
      "858:\tlearn: 0.0605205\ttotal: 1m 56s\tremaining: 19.1s\n",
      "859:\tlearn: 0.0604801\ttotal: 1m 56s\tremaining: 19s\n",
      "860:\tlearn: 0.0604744\ttotal: 1m 56s\tremaining: 18.9s\n",
      "861:\tlearn: 0.0604340\ttotal: 1m 57s\tremaining: 18.7s\n",
      "862:\tlearn: 0.0603590\ttotal: 1m 57s\tremaining: 18.6s\n",
      "863:\tlearn: 0.0603301\ttotal: 1m 57s\tremaining: 18.5s\n",
      "864:\tlearn: 0.0603012\ttotal: 1m 57s\tremaining: 18.3s\n",
      "865:\tlearn: 0.0602493\ttotal: 1m 57s\tremaining: 18.2s\n",
      "866:\tlearn: 0.0602378\ttotal: 1m 57s\tremaining: 18.1s\n",
      "867:\tlearn: 0.0601858\ttotal: 1m 57s\tremaining: 17.9s\n",
      "868:\tlearn: 0.0601339\ttotal: 1m 57s\tremaining: 17.8s\n",
      "869:\tlearn: 0.0601223\ttotal: 1m 58s\tremaining: 17.6s\n",
      "870:\tlearn: 0.0600589\ttotal: 1m 58s\tremaining: 17.5s\n",
      "871:\tlearn: 0.0599781\ttotal: 1m 58s\tremaining: 17.4s\n",
      "872:\tlearn: 0.0600185\ttotal: 1m 58s\tremaining: 17.2s\n",
      "873:\tlearn: 0.0599550\ttotal: 1m 58s\tremaining: 17.1s\n",
      "874:\tlearn: 0.0599261\ttotal: 1m 58s\tremaining: 17s\n",
      "875:\tlearn: 0.0599204\ttotal: 1m 58s\tremaining: 16.8s\n",
      "876:\tlearn: 0.0599377\ttotal: 1m 59s\tremaining: 16.7s\n",
      "877:\tlearn: 0.0599319\ttotal: 1m 59s\tremaining: 16.6s\n",
      "878:\tlearn: 0.0599030\ttotal: 1m 59s\tremaining: 16.4s\n",
      "879:\tlearn: 0.0598915\ttotal: 1m 59s\tremaining: 16.3s\n",
      "880:\tlearn: 0.0598453\ttotal: 1m 59s\tremaining: 16.1s\n",
      "881:\tlearn: 0.0598280\ttotal: 1m 59s\tremaining: 16s\n",
      "882:\tlearn: 0.0597819\ttotal: 1m 59s\tremaining: 15.9s\n",
      "883:\tlearn: 0.0597126\ttotal: 1m 59s\tremaining: 15.7s\n",
      "884:\tlearn: 0.0596895\ttotal: 2m\tremaining: 15.6s\n",
      "885:\tlearn: 0.0596837\ttotal: 2m\tremaining: 15.5s\n",
      "886:\tlearn: 0.0596491\ttotal: 2m\tremaining: 15.3s\n",
      "887:\tlearn: 0.0595626\ttotal: 2m\tremaining: 15.2s\n",
      "888:\tlearn: 0.0595568\ttotal: 2m\tremaining: 15.1s\n",
      "889:\tlearn: 0.0595626\ttotal: 2m\tremaining: 14.9s\n",
      "890:\tlearn: 0.0594818\ttotal: 2m\tremaining: 14.8s\n",
      "891:\tlearn: 0.0593952\ttotal: 2m 1s\tremaining: 14.7s\n",
      "892:\tlearn: 0.0593837\ttotal: 2m 1s\tremaining: 14.5s\n",
      "893:\tlearn: 0.0593086\ttotal: 2m 1s\tremaining: 14.4s\n",
      "894:\tlearn: 0.0592971\ttotal: 2m 1s\tremaining: 14.3s\n",
      "895:\tlearn: 0.0592798\ttotal: 2m 1s\tremaining: 14.1s\n",
      "896:\tlearn: 0.0592221\ttotal: 2m 1s\tremaining: 14s\n",
      "897:\tlearn: 0.0592048\ttotal: 2m 1s\tremaining: 13.8s\n",
      "898:\tlearn: 0.0591240\ttotal: 2m 2s\tremaining: 13.7s\n",
      "899:\tlearn: 0.0591413\ttotal: 2m 2s\tremaining: 13.6s\n",
      "900:\tlearn: 0.0590951\ttotal: 2m 2s\tremaining: 13.4s\n",
      "901:\tlearn: 0.0589566\ttotal: 2m 2s\tremaining: 13.3s\n",
      "902:\tlearn: 0.0589393\ttotal: 2m 2s\tremaining: 13.2s\n",
      "903:\tlearn: 0.0588758\ttotal: 2m 2s\tremaining: 13s\n",
      "904:\tlearn: 0.0588470\ttotal: 2m 2s\tremaining: 12.9s\n",
      "905:\tlearn: 0.0587719\ttotal: 2m 3s\tremaining: 12.8s\n",
      "906:\tlearn: 0.0587546\ttotal: 2m 3s\tremaining: 12.6s\n",
      "907:\tlearn: 0.0587084\ttotal: 2m 3s\tremaining: 12.5s\n",
      "908:\tlearn: 0.0586796\ttotal: 2m 3s\tremaining: 12.4s\n",
      "909:\tlearn: 0.0586046\ttotal: 2m 3s\tremaining: 12.2s\n",
      "910:\tlearn: 0.0586161\ttotal: 2m 3s\tremaining: 12.1s\n",
      "911:\tlearn: 0.0585757\ttotal: 2m 3s\tremaining: 11.9s\n",
      "912:\tlearn: 0.0585526\ttotal: 2m 3s\tremaining: 11.8s\n",
      "913:\tlearn: 0.0585295\ttotal: 2m 4s\tremaining: 11.7s\n",
      "914:\tlearn: 0.0584603\ttotal: 2m 4s\tremaining: 11.5s\n",
      "915:\tlearn: 0.0584141\ttotal: 2m 4s\tremaining: 11.4s\n",
      "916:\tlearn: 0.0583853\ttotal: 2m 4s\tremaining: 11.3s\n",
      "917:\tlearn: 0.0583045\ttotal: 2m 4s\tremaining: 11.1s\n",
      "918:\tlearn: 0.0583102\ttotal: 2m 4s\tremaining: 11s\n",
      "919:\tlearn: 0.0582699\ttotal: 2m 4s\tremaining: 10.9s\n",
      "920:\tlearn: 0.0582583\ttotal: 2m 4s\tremaining: 10.7s\n",
      "921:\tlearn: 0.0581891\ttotal: 2m 5s\tremaining: 10.6s\n",
      "922:\tlearn: 0.0581833\ttotal: 2m 5s\tremaining: 10.4s\n",
      "923:\tlearn: 0.0581371\ttotal: 2m 5s\tremaining: 10.3s\n",
      "924:\tlearn: 0.0581256\ttotal: 2m 5s\tremaining: 10.2s\n",
      "925:\tlearn: 0.0580621\ttotal: 2m 5s\tremaining: 10s\n",
      "926:\tlearn: 0.0580563\ttotal: 2m 5s\tremaining: 9.91s\n",
      "927:\tlearn: 0.0579351\ttotal: 2m 5s\tremaining: 9.77s\n",
      "928:\tlearn: 0.0579063\ttotal: 2m 6s\tremaining: 9.63s\n",
      "929:\tlearn: 0.0578659\ttotal: 2m 6s\tremaining: 9.5s\n",
      "930:\tlearn: 0.0578139\ttotal: 2m 6s\tremaining: 9.36s\n",
      "931:\tlearn: 0.0577966\ttotal: 2m 6s\tremaining: 9.23s\n",
      "932:\tlearn: 0.0577274\ttotal: 2m 6s\tremaining: 9.09s\n",
      "933:\tlearn: 0.0577389\ttotal: 2m 6s\tremaining: 8.96s\n",
      "934:\tlearn: 0.0576812\ttotal: 2m 6s\tremaining: 8.82s\n",
      "935:\tlearn: 0.0577043\ttotal: 2m 7s\tremaining: 8.69s\n",
      "936:\tlearn: 0.0576524\ttotal: 2m 7s\tremaining: 8.55s\n",
      "937:\tlearn: 0.0576293\ttotal: 2m 7s\tremaining: 8.42s\n",
      "938:\tlearn: 0.0576120\ttotal: 2m 7s\tremaining: 8.28s\n",
      "939:\tlearn: 0.0575658\ttotal: 2m 7s\tremaining: 8.15s\n",
      "940:\tlearn: 0.0575600\ttotal: 2m 7s\tremaining: 8.02s\n",
      "941:\tlearn: 0.0574735\ttotal: 2m 8s\tremaining: 7.88s\n",
      "942:\tlearn: 0.0574792\ttotal: 2m 8s\tremaining: 7.75s\n",
      "943:\tlearn: 0.0574331\ttotal: 2m 8s\tremaining: 7.61s\n",
      "944:\tlearn: 0.0573869\ttotal: 2m 8s\tremaining: 7.48s\n",
      "945:\tlearn: 0.0573407\ttotal: 2m 8s\tremaining: 7.34s\n",
      "946:\tlearn: 0.0573003\ttotal: 2m 8s\tremaining: 7.21s\n",
      "947:\tlearn: 0.0572542\ttotal: 2m 8s\tremaining: 7.07s\n",
      "948:\tlearn: 0.0572657\ttotal: 2m 9s\tremaining: 6.93s\n",
      "949:\tlearn: 0.0572599\ttotal: 2m 9s\tremaining: 6.8s\n",
      "950:\tlearn: 0.0572599\ttotal: 2m 9s\tremaining: 6.67s\n",
      "951:\tlearn: 0.0572368\ttotal: 2m 9s\tremaining: 6.53s\n",
      "952:\tlearn: 0.0571618\ttotal: 2m 9s\tremaining: 6.39s\n",
      "953:\tlearn: 0.0571099\ttotal: 2m 9s\tremaining: 6.26s\n",
      "954:\tlearn: 0.0570753\ttotal: 2m 9s\tremaining: 6.12s\n",
      "955:\tlearn: 0.0570406\ttotal: 2m 10s\tremaining: 5.99s\n",
      "956:\tlearn: 0.0570406\ttotal: 2m 10s\tremaining: 5.85s\n",
      "957:\tlearn: 0.0569829\ttotal: 2m 10s\tremaining: 5.72s\n",
      "958:\tlearn: 0.0569598\ttotal: 2m 10s\tremaining: 5.58s\n",
      "959:\tlearn: 0.0569425\ttotal: 2m 10s\tremaining: 5.45s\n",
      "960:\tlearn: 0.0568964\ttotal: 2m 10s\tremaining: 5.31s\n",
      "961:\tlearn: 0.0568329\ttotal: 2m 11s\tremaining: 5.18s\n",
      "962:\tlearn: 0.0567521\ttotal: 2m 11s\tremaining: 5.04s\n",
      "963:\tlearn: 0.0567694\ttotal: 2m 11s\tremaining: 4.91s\n",
      "964:\tlearn: 0.0567521\ttotal: 2m 11s\tremaining: 4.77s\n",
      "965:\tlearn: 0.0567290\ttotal: 2m 11s\tremaining: 4.64s\n",
      "966:\tlearn: 0.0566944\ttotal: 2m 12s\tremaining: 4.5s\n",
      "967:\tlearn: 0.0566540\ttotal: 2m 12s\tremaining: 4.37s\n",
      "968:\tlearn: 0.0566367\ttotal: 2m 12s\tremaining: 4.24s\n",
      "969:\tlearn: 0.0566136\ttotal: 2m 12s\tremaining: 4.1s\n",
      "970:\tlearn: 0.0565789\ttotal: 2m 12s\tremaining: 3.96s\n",
      "971:\tlearn: 0.0565212\ttotal: 2m 12s\tremaining: 3.83s\n",
      "972:\tlearn: 0.0565386\ttotal: 2m 13s\tremaining: 3.69s\n",
      "973:\tlearn: 0.0564866\ttotal: 2m 13s\tremaining: 3.56s\n",
      "974:\tlearn: 0.0564289\ttotal: 2m 13s\tremaining: 3.42s\n",
      "975:\tlearn: 0.0563770\ttotal: 2m 13s\tremaining: 3.28s\n",
      "976:\tlearn: 0.0563308\ttotal: 2m 13s\tremaining: 3.15s\n",
      "977:\tlearn: 0.0562789\ttotal: 2m 13s\tremaining: 3.01s\n",
      "978:\tlearn: 0.0562615\ttotal: 2m 13s\tremaining: 2.87s\n",
      "979:\tlearn: 0.0562673\ttotal: 2m 14s\tremaining: 2.74s\n",
      "980:\tlearn: 0.0561519\ttotal: 2m 14s\tremaining: 2.6s\n",
      "981:\tlearn: 0.0560769\ttotal: 2m 14s\tremaining: 2.46s\n",
      "982:\tlearn: 0.0560538\ttotal: 2m 14s\tremaining: 2.33s\n",
      "983:\tlearn: 0.0560192\ttotal: 2m 14s\tremaining: 2.19s\n",
      "984:\tlearn: 0.0559672\ttotal: 2m 14s\tremaining: 2.05s\n",
      "985:\tlearn: 0.0559441\ttotal: 2m 14s\tremaining: 1.92s\n",
      "986:\tlearn: 0.0559268\ttotal: 2m 15s\tremaining: 1.78s\n",
      "987:\tlearn: 0.0558691\ttotal: 2m 15s\tremaining: 1.64s\n",
      "988:\tlearn: 0.0558460\ttotal: 2m 15s\tremaining: 1.5s\n",
      "989:\tlearn: 0.0557825\ttotal: 2m 15s\tremaining: 1.37s\n",
      "990:\tlearn: 0.0557652\ttotal: 2m 15s\tremaining: 1.23s\n",
      "991:\tlearn: 0.0557537\ttotal: 2m 15s\tremaining: 1.09s\n",
      "992:\tlearn: 0.0557075\ttotal: 2m 15s\tremaining: 958ms\n",
      "993:\tlearn: 0.0556671\ttotal: 2m 15s\tremaining: 821ms\n",
      "994:\tlearn: 0.0556094\ttotal: 2m 16s\tremaining: 684ms\n",
      "995:\tlearn: 0.0555748\ttotal: 2m 16s\tremaining: 547ms\n",
      "996:\tlearn: 0.0555575\ttotal: 2m 16s\tremaining: 410ms\n",
      "997:\tlearn: 0.0554940\ttotal: 2m 16s\tremaining: 274ms\n",
      "998:\tlearn: 0.0554767\ttotal: 2m 16s\tremaining: 137ms\n",
      "999:\tlearn: 0.0554709\ttotal: 2m 16s\tremaining: 0us\n",
      "Learning rate set to 0.026476\n",
      "0:\tlearn: 0.1097068\ttotal: 132ms\tremaining: 2m 11s\n",
      "1:\tlearn: 0.1108091\ttotal: 262ms\tremaining: 2m 10s\n",
      "2:\tlearn: 0.1108957\ttotal: 392ms\tremaining: 2m 10s\n",
      "3:\tlearn: 0.1109014\ttotal: 523ms\tremaining: 2m 10s\n",
      "4:\tlearn: 0.1110342\ttotal: 649ms\tremaining: 2m 9s\n",
      "5:\tlearn: 0.1110515\ttotal: 785ms\tremaining: 2m 9s\n",
      "6:\tlearn: 0.1108783\ttotal: 908ms\tremaining: 2m 8s\n",
      "7:\tlearn: 0.1108610\ttotal: 1.04s\tremaining: 2m 8s\n",
      "8:\tlearn: 0.1110861\ttotal: 1.17s\tremaining: 2m 9s\n",
      "9:\tlearn: 0.1110861\ttotal: 1.3s\tremaining: 2m 8s\n",
      "10:\tlearn: 0.1110515\ttotal: 1.44s\tremaining: 2m 9s\n",
      "11:\tlearn: 0.1110457\ttotal: 1.56s\tremaining: 2m 8s\n",
      "12:\tlearn: 0.1110284\ttotal: 1.69s\tremaining: 2m 8s\n",
      "13:\tlearn: 0.1109707\ttotal: 1.82s\tremaining: 2m 8s\n",
      "14:\tlearn: 0.1109822\ttotal: 1.95s\tremaining: 2m 8s\n",
      "15:\tlearn: 0.1108206\ttotal: 2.09s\tremaining: 2m 8s\n",
      "16:\tlearn: 0.1108841\ttotal: 2.22s\tremaining: 2m 8s\n",
      "17:\tlearn: 0.1108899\ttotal: 2.35s\tremaining: 2m 8s\n",
      "18:\tlearn: 0.1108841\ttotal: 2.48s\tremaining: 2m 8s\n",
      "19:\tlearn: 0.1108149\ttotal: 2.62s\tremaining: 2m 8s\n",
      "20:\tlearn: 0.1107860\ttotal: 2.75s\tremaining: 2m 8s\n",
      "21:\tlearn: 0.1107572\ttotal: 2.88s\tremaining: 2m 7s\n",
      "22:\tlearn: 0.1106648\ttotal: 3.01s\tremaining: 2m 7s\n",
      "23:\tlearn: 0.1105956\ttotal: 3.14s\tremaining: 2m 7s\n",
      "24:\tlearn: 0.1104859\ttotal: 3.27s\tremaining: 2m 7s\n",
      "25:\tlearn: 0.1104571\ttotal: 3.4s\tremaining: 2m 7s\n",
      "26:\tlearn: 0.1102608\ttotal: 3.53s\tremaining: 2m 7s\n",
      "27:\tlearn: 0.1101397\ttotal: 3.66s\tremaining: 2m 7s\n",
      "28:\tlearn: 0.1100819\ttotal: 3.79s\tremaining: 2m 6s\n",
      "29:\tlearn: 0.1099954\ttotal: 3.92s\tremaining: 2m 6s\n",
      "30:\tlearn: 0.1098857\ttotal: 4.05s\tremaining: 2m 6s\n",
      "31:\tlearn: 0.1095972\ttotal: 4.18s\tremaining: 2m 6s\n",
      "32:\tlearn: 0.1095106\ttotal: 4.31s\tremaining: 2m 6s\n",
      "33:\tlearn: 0.1094645\ttotal: 4.46s\tremaining: 2m 6s\n",
      "34:\tlearn: 0.1093779\ttotal: 4.59s\tremaining: 2m 6s\n",
      "35:\tlearn: 0.1093144\ttotal: 4.72s\tremaining: 2m 6s\n",
      "36:\tlearn: 0.1091586\ttotal: 4.85s\tremaining: 2m 6s\n",
      "37:\tlearn: 0.1091644\ttotal: 4.98s\tremaining: 2m 6s\n",
      "38:\tlearn: 0.1089855\ttotal: 5.11s\tremaining: 2m 5s\n",
      "39:\tlearn: 0.1089277\ttotal: 5.24s\tremaining: 2m 5s\n",
      "40:\tlearn: 0.1088585\ttotal: 5.37s\tremaining: 2m 5s\n",
      "41:\tlearn: 0.1087315\ttotal: 5.51s\tremaining: 2m 5s\n",
      "42:\tlearn: 0.1087950\ttotal: 5.64s\tremaining: 2m 5s\n",
      "43:\tlearn: 0.1086103\ttotal: 5.77s\tremaining: 2m 5s\n",
      "44:\tlearn: 0.1085007\ttotal: 5.9s\tremaining: 2m 5s\n",
      "45:\tlearn: 0.1085065\ttotal: 6.05s\tremaining: 2m 5s\n",
      "46:\tlearn: 0.1083160\ttotal: 6.18s\tremaining: 2m 5s\n",
      "47:\tlearn: 0.1081833\ttotal: 6.31s\tremaining: 2m 5s\n",
      "48:\tlearn: 0.1080794\ttotal: 6.44s\tremaining: 2m 5s\n",
      "49:\tlearn: 0.1079236\ttotal: 6.58s\tremaining: 2m 4s\n",
      "50:\tlearn: 0.1078543\ttotal: 6.71s\tremaining: 2m 4s\n",
      "51:\tlearn: 0.1076350\ttotal: 6.84s\tremaining: 2m 4s\n",
      "52:\tlearn: 0.1075139\ttotal: 6.97s\tremaining: 2m 4s\n",
      "53:\tlearn: 0.1072426\ttotal: 7.11s\tremaining: 2m 4s\n",
      "54:\tlearn: 0.1070522\ttotal: 7.24s\tremaining: 2m 4s\n",
      "55:\tlearn: 0.1069541\ttotal: 7.38s\tremaining: 2m 4s\n",
      "56:\tlearn: 0.1067001\ttotal: 7.51s\tremaining: 2m 4s\n",
      "57:\tlearn: 0.1066771\ttotal: 7.64s\tremaining: 2m 4s\n",
      "58:\tlearn: 0.1066193\ttotal: 7.78s\tremaining: 2m 4s\n",
      "59:\tlearn: 0.1064231\ttotal: 7.91s\tremaining: 2m 3s\n",
      "60:\tlearn: 0.1062154\ttotal: 8.04s\tremaining: 2m 3s\n",
      "61:\tlearn: 0.1061404\ttotal: 8.17s\tremaining: 2m 3s\n",
      "62:\tlearn: 0.1059672\ttotal: 8.3s\tremaining: 2m 3s\n",
      "63:\tlearn: 0.1057191\ttotal: 8.45s\tremaining: 2m 3s\n",
      "64:\tlearn: 0.1055229\ttotal: 8.6s\tremaining: 2m 3s\n",
      "65:\tlearn: 0.1054074\ttotal: 8.74s\tremaining: 2m 3s\n",
      "66:\tlearn: 0.1052516\ttotal: 8.89s\tremaining: 2m 3s\n",
      "67:\tlearn: 0.1051189\ttotal: 9.03s\tremaining: 2m 3s\n",
      "68:\tlearn: 0.1050150\ttotal: 9.18s\tremaining: 2m 3s\n",
      "69:\tlearn: 0.1049400\ttotal: 9.31s\tremaining: 2m 3s\n",
      "70:\tlearn: 0.1048419\ttotal: 9.45s\tremaining: 2m 3s\n",
      "71:\tlearn: 0.1046283\ttotal: 9.59s\tremaining: 2m 3s\n",
      "72:\tlearn: 0.1045937\ttotal: 9.72s\tremaining: 2m 3s\n",
      "73:\tlearn: 0.1045014\ttotal: 9.86s\tremaining: 2m 3s\n",
      "74:\tlearn: 0.1041551\ttotal: 9.99s\tremaining: 2m 3s\n",
      "75:\tlearn: 0.1040801\ttotal: 10.1s\tremaining: 2m 3s\n",
      "76:\tlearn: 0.1039185\ttotal: 10.3s\tremaining: 2m 2s\n",
      "77:\tlearn: 0.1036415\ttotal: 10.4s\tremaining: 2m 2s\n",
      "78:\tlearn: 0.1035319\ttotal: 10.5s\tremaining: 2m 2s\n",
      "79:\tlearn: 0.1033356\ttotal: 10.7s\tremaining: 2m 2s\n",
      "80:\tlearn: 0.1032029\ttotal: 10.8s\tremaining: 2m 2s\n",
      "81:\tlearn: 0.1029374\ttotal: 10.9s\tremaining: 2m 2s\n",
      "82:\tlearn: 0.1028913\ttotal: 11.1s\tremaining: 2m 2s\n",
      "83:\tlearn: 0.1027816\ttotal: 11.2s\tremaining: 2m 2s\n",
      "84:\tlearn: 0.1026547\ttotal: 11.3s\tremaining: 2m 1s\n",
      "85:\tlearn: 0.1026085\ttotal: 11.5s\tremaining: 2m 1s\n",
      "86:\tlearn: 0.1023603\ttotal: 11.6s\tremaining: 2m 1s\n",
      "87:\tlearn: 0.1021814\ttotal: 11.7s\tremaining: 2m 1s\n",
      "88:\tlearn: 0.1019910\ttotal: 11.9s\tremaining: 2m 1s\n",
      "89:\tlearn: 0.1019910\ttotal: 12s\tremaining: 2m 1s\n",
      "90:\tlearn: 0.1019506\ttotal: 12.1s\tremaining: 2m 1s\n",
      "91:\tlearn: 0.1018063\ttotal: 12.3s\tremaining: 2m 1s\n",
      "92:\tlearn: 0.1017140\ttotal: 12.4s\tremaining: 2m\n",
      "93:\tlearn: 0.1015813\ttotal: 12.5s\tremaining: 2m\n",
      "94:\tlearn: 0.1014716\ttotal: 12.7s\tremaining: 2m\n",
      "95:\tlearn: 0.1012927\ttotal: 12.8s\tremaining: 2m\n",
      "96:\tlearn: 0.1012408\ttotal: 12.9s\tremaining: 2m\n",
      "97:\tlearn: 0.1011600\ttotal: 13.1s\tremaining: 2m\n",
      "98:\tlearn: 0.1008887\ttotal: 13.2s\tremaining: 2m\n",
      "99:\tlearn: 0.1007733\ttotal: 13.3s\tremaining: 1m 59s\n",
      "100:\tlearn: 0.1007098\ttotal: 13.5s\tremaining: 1m 59s\n",
      "101:\tlearn: 0.1005944\ttotal: 13.6s\tremaining: 1m 59s\n",
      "102:\tlearn: 0.1004213\ttotal: 13.7s\tremaining: 1m 59s\n",
      "103:\tlearn: 0.1003751\ttotal: 13.8s\tremaining: 1m 59s\n",
      "104:\tlearn: 0.1003463\ttotal: 14s\tremaining: 1m 59s\n",
      "105:\tlearn: 0.1000981\ttotal: 14.1s\tremaining: 1m 59s\n",
      "106:\tlearn: 0.0999654\ttotal: 14.2s\tremaining: 1m 58s\n",
      "107:\tlearn: 0.0998326\ttotal: 14.4s\tremaining: 1m 58s\n",
      "108:\tlearn: 0.0996653\ttotal: 14.5s\tremaining: 1m 58s\n",
      "109:\tlearn: 0.0995614\ttotal: 14.6s\tremaining: 1m 58s\n",
      "110:\tlearn: 0.0994460\ttotal: 14.8s\tremaining: 1m 58s\n",
      "111:\tlearn: 0.0992844\ttotal: 14.9s\tremaining: 1m 58s\n",
      "112:\tlearn: 0.0992209\ttotal: 15s\tremaining: 1m 58s\n",
      "113:\tlearn: 0.0990940\ttotal: 15.2s\tremaining: 1m 57s\n",
      "114:\tlearn: 0.0989670\ttotal: 15.3s\tremaining: 1m 57s\n",
      "115:\tlearn: 0.0988804\ttotal: 15.4s\tremaining: 1m 57s\n",
      "116:\tlearn: 0.0987304\ttotal: 15.6s\tremaining: 1m 57s\n",
      "117:\tlearn: 0.0985284\ttotal: 15.7s\tremaining: 1m 57s\n",
      "118:\tlearn: 0.0984822\ttotal: 15.8s\tremaining: 1m 57s\n",
      "119:\tlearn: 0.0982918\ttotal: 16s\tremaining: 1m 57s\n",
      "120:\tlearn: 0.0981475\ttotal: 16.1s\tremaining: 1m 57s\n",
      "121:\tlearn: 0.0981129\ttotal: 16.2s\tremaining: 1m 56s\n",
      "122:\tlearn: 0.0979398\ttotal: 16.4s\tremaining: 1m 56s\n",
      "123:\tlearn: 0.0978070\ttotal: 16.5s\tremaining: 1m 56s\n",
      "124:\tlearn: 0.0976512\ttotal: 16.6s\tremaining: 1m 56s\n",
      "125:\tlearn: 0.0975646\ttotal: 16.8s\tremaining: 1m 56s\n",
      "126:\tlearn: 0.0974434\ttotal: 16.9s\tremaining: 1m 56s\n",
      "127:\tlearn: 0.0972819\ttotal: 17.1s\tremaining: 1m 56s\n",
      "128:\tlearn: 0.0970568\ttotal: 17.2s\tremaining: 1m 56s\n",
      "129:\tlearn: 0.0970279\ttotal: 17.3s\tremaining: 1m 55s\n",
      "130:\tlearn: 0.0969760\ttotal: 17.5s\tremaining: 1m 55s\n",
      "131:\tlearn: 0.0968779\ttotal: 17.6s\tremaining: 1m 55s\n",
      "132:\tlearn: 0.0967740\ttotal: 17.7s\tremaining: 1m 55s\n",
      "133:\tlearn: 0.0966470\ttotal: 17.9s\tremaining: 1m 55s\n",
      "134:\tlearn: 0.0965316\ttotal: 18s\tremaining: 1m 55s\n",
      "135:\tlearn: 0.0964624\ttotal: 18.1s\tremaining: 1m 55s\n",
      "136:\tlearn: 0.0962604\ttotal: 18.2s\tremaining: 1m 54s\n",
      "137:\tlearn: 0.0960873\ttotal: 18.4s\tremaining: 1m 54s\n",
      "138:\tlearn: 0.0960180\ttotal: 18.5s\tremaining: 1m 54s\n",
      "139:\tlearn: 0.0959834\ttotal: 18.6s\tremaining: 1m 54s\n",
      "140:\tlearn: 0.0959314\ttotal: 18.8s\tremaining: 1m 54s\n",
      "141:\tlearn: 0.0958102\ttotal: 18.9s\tremaining: 1m 54s\n",
      "142:\tlearn: 0.0956775\ttotal: 19s\tremaining: 1m 54s\n",
      "143:\tlearn: 0.0955275\ttotal: 19.2s\tremaining: 1m 54s\n",
      "144:\tlearn: 0.0952966\ttotal: 19.4s\tremaining: 1m 54s\n",
      "145:\tlearn: 0.0952735\ttotal: 19.5s\tremaining: 1m 54s\n",
      "146:\tlearn: 0.0950889\ttotal: 19.6s\tremaining: 1m 53s\n",
      "147:\tlearn: 0.0951062\ttotal: 19.8s\tremaining: 1m 53s\n",
      "148:\tlearn: 0.0950081\ttotal: 19.9s\tremaining: 1m 53s\n",
      "149:\tlearn: 0.0948407\ttotal: 20s\tremaining: 1m 53s\n",
      "150:\tlearn: 0.0948465\ttotal: 20.2s\tremaining: 1m 53s\n",
      "151:\tlearn: 0.0947542\ttotal: 20.3s\tremaining: 1m 53s\n",
      "152:\tlearn: 0.0947080\ttotal: 20.4s\tremaining: 1m 53s\n",
      "153:\tlearn: 0.0946214\ttotal: 20.6s\tremaining: 1m 53s\n",
      "154:\tlearn: 0.0943560\ttotal: 20.7s\tremaining: 1m 53s\n",
      "155:\tlearn: 0.0942636\ttotal: 20.9s\tremaining: 1m 52s\n",
      "156:\tlearn: 0.0940847\ttotal: 21s\tremaining: 1m 52s\n",
      "157:\tlearn: 0.0939404\ttotal: 21.1s\tremaining: 1m 52s\n",
      "158:\tlearn: 0.0938770\ttotal: 21.3s\tremaining: 1m 52s\n",
      "159:\tlearn: 0.0936923\ttotal: 21.4s\tremaining: 1m 52s\n",
      "160:\tlearn: 0.0936000\ttotal: 21.5s\tremaining: 1m 52s\n",
      "161:\tlearn: 0.0935538\ttotal: 21.7s\tremaining: 1m 52s\n",
      "162:\tlearn: 0.0934441\ttotal: 21.8s\tremaining: 1m 51s\n",
      "163:\tlearn: 0.0933229\ttotal: 21.9s\tremaining: 1m 51s\n",
      "164:\tlearn: 0.0932422\ttotal: 22.1s\tremaining: 1m 51s\n",
      "165:\tlearn: 0.0931152\ttotal: 22.2s\tremaining: 1m 51s\n",
      "166:\tlearn: 0.0929709\ttotal: 22.3s\tremaining: 1m 51s\n",
      "167:\tlearn: 0.0929074\ttotal: 22.5s\tremaining: 1m 51s\n",
      "168:\tlearn: 0.0928209\ttotal: 22.6s\tremaining: 1m 51s\n",
      "169:\tlearn: 0.0926939\ttotal: 22.7s\tremaining: 1m 50s\n",
      "170:\tlearn: 0.0926766\ttotal: 22.9s\tremaining: 1m 50s\n",
      "171:\tlearn: 0.0926362\ttotal: 23s\tremaining: 1m 50s\n",
      "172:\tlearn: 0.0925612\ttotal: 23.1s\tremaining: 1m 50s\n",
      "173:\tlearn: 0.0924111\ttotal: 23.3s\tremaining: 1m 50s\n",
      "174:\tlearn: 0.0922380\ttotal: 23.4s\tremaining: 1m 50s\n",
      "175:\tlearn: 0.0922034\ttotal: 23.6s\tremaining: 1m 50s\n",
      "176:\tlearn: 0.0921572\ttotal: 23.7s\tremaining: 1m 50s\n",
      "177:\tlearn: 0.0920245\ttotal: 23.9s\tremaining: 1m 50s\n",
      "178:\tlearn: 0.0919206\ttotal: 24s\tremaining: 1m 50s\n",
      "179:\tlearn: 0.0917994\ttotal: 24.1s\tremaining: 1m 49s\n",
      "180:\tlearn: 0.0916955\ttotal: 24.3s\tremaining: 1m 49s\n",
      "181:\tlearn: 0.0916436\ttotal: 24.4s\tremaining: 1m 49s\n",
      "182:\tlearn: 0.0915570\ttotal: 24.5s\tremaining: 1m 49s\n",
      "183:\tlearn: 0.0916147\ttotal: 24.7s\tremaining: 1m 49s\n",
      "184:\tlearn: 0.0915166\ttotal: 24.8s\tremaining: 1m 49s\n",
      "185:\tlearn: 0.0915166\ttotal: 24.9s\tremaining: 1m 49s\n",
      "186:\tlearn: 0.0913839\ttotal: 25.1s\tremaining: 1m 49s\n",
      "187:\tlearn: 0.0912858\ttotal: 25.2s\tremaining: 1m 48s\n",
      "188:\tlearn: 0.0912281\ttotal: 25.3s\tremaining: 1m 48s\n",
      "189:\tlearn: 0.0912512\ttotal: 25.5s\tremaining: 1m 48s\n",
      "190:\tlearn: 0.0912165\ttotal: 25.6s\tremaining: 1m 48s\n",
      "191:\tlearn: 0.0911761\ttotal: 25.7s\tremaining: 1m 48s\n",
      "192:\tlearn: 0.0911415\ttotal: 25.9s\tremaining: 1m 48s\n",
      "193:\tlearn: 0.0910780\ttotal: 26s\tremaining: 1m 47s\n",
      "194:\tlearn: 0.0910896\ttotal: 26.1s\tremaining: 1m 47s\n",
      "195:\tlearn: 0.0910434\ttotal: 26.3s\tremaining: 1m 47s\n",
      "196:\tlearn: 0.0909453\ttotal: 26.4s\tremaining: 1m 47s\n",
      "197:\tlearn: 0.0909222\ttotal: 26.5s\tremaining: 1m 47s\n",
      "198:\tlearn: 0.0909222\ttotal: 26.7s\tremaining: 1m 47s\n",
      "199:\tlearn: 0.0907491\ttotal: 26.8s\tremaining: 1m 47s\n",
      "200:\tlearn: 0.0906683\ttotal: 26.9s\tremaining: 1m 47s\n",
      "201:\tlearn: 0.0905644\ttotal: 27.1s\tremaining: 1m 46s\n",
      "202:\tlearn: 0.0904201\ttotal: 27.2s\tremaining: 1m 46s\n",
      "203:\tlearn: 0.0903393\ttotal: 27.4s\tremaining: 1m 46s\n",
      "204:\tlearn: 0.0902701\ttotal: 27.5s\tremaining: 1m 46s\n",
      "205:\tlearn: 0.0902355\ttotal: 27.6s\tremaining: 1m 46s\n",
      "206:\tlearn: 0.0900970\ttotal: 27.8s\tremaining: 1m 46s\n",
      "207:\tlearn: 0.0900335\ttotal: 27.9s\tremaining: 1m 46s\n",
      "208:\tlearn: 0.0900046\ttotal: 28s\tremaining: 1m 46s\n",
      "209:\tlearn: 0.0899411\ttotal: 28.2s\tremaining: 1m 45s\n",
      "210:\tlearn: 0.0898719\ttotal: 28.3s\tremaining: 1m 45s\n",
      "211:\tlearn: 0.0898488\ttotal: 28.4s\tremaining: 1m 45s\n",
      "212:\tlearn: 0.0897911\ttotal: 28.6s\tremaining: 1m 45s\n",
      "213:\tlearn: 0.0897392\ttotal: 28.7s\tremaining: 1m 45s\n",
      "214:\tlearn: 0.0896295\ttotal: 28.8s\tremaining: 1m 45s\n",
      "215:\tlearn: 0.0896122\ttotal: 29s\tremaining: 1m 45s\n",
      "216:\tlearn: 0.0895314\ttotal: 29.1s\tremaining: 1m 45s\n",
      "217:\tlearn: 0.0894910\ttotal: 29.2s\tremaining: 1m 44s\n",
      "218:\tlearn: 0.0893987\ttotal: 29.4s\tremaining: 1m 44s\n",
      "219:\tlearn: 0.0892198\ttotal: 29.5s\tremaining: 1m 44s\n",
      "220:\tlearn: 0.0891274\ttotal: 29.6s\tremaining: 1m 44s\n",
      "221:\tlearn: 0.0889947\ttotal: 29.8s\tremaining: 1m 44s\n",
      "222:\tlearn: 0.0890178\ttotal: 29.9s\tremaining: 1m 44s\n",
      "223:\tlearn: 0.0889831\ttotal: 30.1s\tremaining: 1m 44s\n",
      "224:\tlearn: 0.0889139\ttotal: 30.2s\tremaining: 1m 43s\n",
      "225:\tlearn: 0.0888504\ttotal: 30.3s\tremaining: 1m 43s\n",
      "226:\tlearn: 0.0886542\ttotal: 30.5s\tremaining: 1m 43s\n",
      "227:\tlearn: 0.0886657\ttotal: 30.6s\tremaining: 1m 43s\n",
      "228:\tlearn: 0.0886023\ttotal: 30.7s\tremaining: 1m 43s\n",
      "229:\tlearn: 0.0885272\ttotal: 30.9s\tremaining: 1m 43s\n",
      "230:\tlearn: 0.0884580\ttotal: 31s\tremaining: 1m 43s\n",
      "231:\tlearn: 0.0885042\ttotal: 31.1s\tremaining: 1m 43s\n",
      "232:\tlearn: 0.0885215\ttotal: 31.2s\tremaining: 1m 42s\n",
      "233:\tlearn: 0.0884407\ttotal: 31.4s\tremaining: 1m 42s\n",
      "234:\tlearn: 0.0883195\ttotal: 31.5s\tremaining: 1m 42s\n",
      "235:\tlearn: 0.0882560\ttotal: 31.7s\tremaining: 1m 42s\n",
      "236:\tlearn: 0.0881983\ttotal: 31.8s\tremaining: 1m 42s\n",
      "237:\tlearn: 0.0881637\ttotal: 31.9s\tremaining: 1m 42s\n",
      "238:\tlearn: 0.0880367\ttotal: 32.1s\tremaining: 1m 42s\n",
      "239:\tlearn: 0.0879732\ttotal: 32.2s\tremaining: 1m 41s\n",
      "240:\tlearn: 0.0878578\ttotal: 32.3s\tremaining: 1m 41s\n",
      "241:\tlearn: 0.0878405\ttotal: 32.5s\tremaining: 1m 41s\n",
      "242:\tlearn: 0.0878405\ttotal: 32.6s\tremaining: 1m 41s\n",
      "243:\tlearn: 0.0877655\ttotal: 32.7s\tremaining: 1m 41s\n",
      "244:\tlearn: 0.0876674\ttotal: 32.9s\tremaining: 1m 41s\n",
      "245:\tlearn: 0.0876154\ttotal: 33s\tremaining: 1m 41s\n",
      "246:\tlearn: 0.0875404\ttotal: 33.1s\tremaining: 1m 41s\n",
      "247:\tlearn: 0.0874596\ttotal: 33.3s\tremaining: 1m 40s\n",
      "248:\tlearn: 0.0874134\ttotal: 33.4s\tremaining: 1m 40s\n",
      "249:\tlearn: 0.0874307\ttotal: 33.5s\tremaining: 1m 40s\n",
      "250:\tlearn: 0.0873615\ttotal: 33.7s\tremaining: 1m 40s\n",
      "251:\tlearn: 0.0872980\ttotal: 33.8s\tremaining: 1m 40s\n",
      "252:\tlearn: 0.0871768\ttotal: 33.9s\tremaining: 1m 40s\n",
      "253:\tlearn: 0.0872114\ttotal: 34.1s\tremaining: 1m 40s\n",
      "254:\tlearn: 0.0872057\ttotal: 34.2s\tremaining: 1m 39s\n",
      "255:\tlearn: 0.0870960\ttotal: 34.3s\tremaining: 1m 39s\n",
      "256:\tlearn: 0.0870672\ttotal: 34.5s\tremaining: 1m 39s\n",
      "257:\tlearn: 0.0870152\ttotal: 34.6s\tremaining: 1m 39s\n",
      "258:\tlearn: 0.0869344\ttotal: 34.7s\tremaining: 1m 39s\n",
      "259:\tlearn: 0.0868133\ttotal: 34.9s\tremaining: 1m 39s\n",
      "260:\tlearn: 0.0867959\ttotal: 35s\tremaining: 1m 39s\n",
      "261:\tlearn: 0.0867729\ttotal: 35.1s\tremaining: 1m 38s\n",
      "262:\tlearn: 0.0867729\ttotal: 35.3s\tremaining: 1m 38s\n",
      "263:\tlearn: 0.0867209\ttotal: 35.4s\tremaining: 1m 38s\n",
      "264:\tlearn: 0.0866286\ttotal: 35.5s\tremaining: 1m 38s\n",
      "265:\tlearn: 0.0865478\ttotal: 35.7s\tremaining: 1m 38s\n",
      "266:\tlearn: 0.0865074\ttotal: 35.8s\tremaining: 1m 38s\n",
      "267:\tlearn: 0.0864151\ttotal: 35.9s\tremaining: 1m 38s\n",
      "268:\tlearn: 0.0863458\ttotal: 36.1s\tremaining: 1m 38s\n",
      "269:\tlearn: 0.0863343\ttotal: 36.2s\tremaining: 1m 37s\n",
      "270:\tlearn: 0.0862881\ttotal: 36.3s\tremaining: 1m 37s\n",
      "271:\tlearn: 0.0862015\ttotal: 36.5s\tremaining: 1m 37s\n",
      "272:\tlearn: 0.0861150\ttotal: 36.6s\tremaining: 1m 37s\n",
      "273:\tlearn: 0.0859476\ttotal: 36.8s\tremaining: 1m 37s\n",
      "274:\tlearn: 0.0859303\ttotal: 36.9s\tremaining: 1m 37s\n",
      "275:\tlearn: 0.0858149\ttotal: 37s\tremaining: 1m 37s\n",
      "276:\tlearn: 0.0856821\ttotal: 37.1s\tremaining: 1m 36s\n",
      "277:\tlearn: 0.0856821\ttotal: 37.3s\tremaining: 1m 36s\n",
      "278:\tlearn: 0.0856187\ttotal: 37.4s\tremaining: 1m 36s\n",
      "279:\tlearn: 0.0855725\ttotal: 37.6s\tremaining: 1m 36s\n",
      "280:\tlearn: 0.0854801\ttotal: 37.7s\tremaining: 1m 36s\n",
      "281:\tlearn: 0.0854513\ttotal: 37.8s\tremaining: 1m 36s\n",
      "282:\tlearn: 0.0853128\ttotal: 38s\tremaining: 1m 36s\n",
      "283:\tlearn: 0.0851281\ttotal: 38.1s\tremaining: 1m 36s\n",
      "284:\tlearn: 0.0851050\ttotal: 38.2s\tremaining: 1m 35s\n",
      "285:\tlearn: 0.0851339\ttotal: 38.3s\tremaining: 1m 35s\n",
      "286:\tlearn: 0.0850819\ttotal: 38.5s\tremaining: 1m 35s\n",
      "287:\tlearn: 0.0850358\ttotal: 38.6s\tremaining: 1m 35s\n",
      "288:\tlearn: 0.0849896\ttotal: 38.8s\tremaining: 1m 35s\n",
      "289:\tlearn: 0.0849319\ttotal: 39s\tremaining: 1m 35s\n",
      "290:\tlearn: 0.0849434\ttotal: 39.1s\tremaining: 1m 35s\n",
      "291:\tlearn: 0.0848396\ttotal: 39.3s\tremaining: 1m 35s\n",
      "292:\tlearn: 0.0847819\ttotal: 39.4s\tremaining: 1m 35s\n",
      "293:\tlearn: 0.0847357\ttotal: 39.5s\tremaining: 1m 34s\n",
      "294:\tlearn: 0.0847299\ttotal: 39.7s\tremaining: 1m 34s\n",
      "295:\tlearn: 0.0847241\ttotal: 39.8s\tremaining: 1m 34s\n",
      "296:\tlearn: 0.0846953\ttotal: 39.9s\tremaining: 1m 34s\n",
      "297:\tlearn: 0.0846607\ttotal: 40.1s\tremaining: 1m 34s\n",
      "298:\tlearn: 0.0845799\ttotal: 40.2s\tremaining: 1m 34s\n",
      "299:\tlearn: 0.0845972\ttotal: 40.3s\tremaining: 1m 34s\n",
      "300:\tlearn: 0.0844645\ttotal: 40.4s\tremaining: 1m 33s\n",
      "301:\tlearn: 0.0843952\ttotal: 40.6s\tremaining: 1m 33s\n",
      "302:\tlearn: 0.0843086\ttotal: 40.7s\tremaining: 1m 33s\n",
      "303:\tlearn: 0.0842740\ttotal: 40.8s\tremaining: 1m 33s\n",
      "304:\tlearn: 0.0841644\ttotal: 41s\tremaining: 1m 33s\n",
      "305:\tlearn: 0.0841701\ttotal: 41.1s\tremaining: 1m 33s\n",
      "306:\tlearn: 0.0841470\ttotal: 41.2s\tremaining: 1m 33s\n",
      "307:\tlearn: 0.0841182\ttotal: 41.4s\tremaining: 1m 32s\n",
      "308:\tlearn: 0.0839566\ttotal: 41.5s\tremaining: 1m 32s\n",
      "309:\tlearn: 0.0838354\ttotal: 41.6s\tremaining: 1m 32s\n",
      "310:\tlearn: 0.0838527\ttotal: 41.8s\tremaining: 1m 32s\n",
      "311:\tlearn: 0.0838066\ttotal: 41.9s\tremaining: 1m 32s\n",
      "312:\tlearn: 0.0837488\ttotal: 42.1s\tremaining: 1m 32s\n",
      "313:\tlearn: 0.0836854\ttotal: 42.2s\tremaining: 1m 32s\n",
      "314:\tlearn: 0.0836219\ttotal: 42.3s\tremaining: 1m 32s\n",
      "315:\tlearn: 0.0835584\ttotal: 42.5s\tremaining: 1m 31s\n",
      "316:\tlearn: 0.0834718\ttotal: 42.6s\tremaining: 1m 31s\n",
      "317:\tlearn: 0.0834257\ttotal: 42.7s\tremaining: 1m 31s\n",
      "318:\tlearn: 0.0833853\ttotal: 42.9s\tremaining: 1m 31s\n",
      "319:\tlearn: 0.0832468\ttotal: 43s\tremaining: 1m 31s\n",
      "320:\tlearn: 0.0831544\ttotal: 43.1s\tremaining: 1m 31s\n",
      "321:\tlearn: 0.0831025\ttotal: 43.2s\tremaining: 1m 31s\n",
      "322:\tlearn: 0.0830390\ttotal: 43.4s\tremaining: 1m 30s\n",
      "323:\tlearn: 0.0830159\ttotal: 43.5s\tremaining: 1m 30s\n",
      "324:\tlearn: 0.0829813\ttotal: 43.6s\tremaining: 1m 30s\n",
      "325:\tlearn: 0.0829236\ttotal: 43.8s\tremaining: 1m 30s\n",
      "326:\tlearn: 0.0827966\ttotal: 43.9s\tremaining: 1m 30s\n",
      "327:\tlearn: 0.0827620\ttotal: 44.1s\tremaining: 1m 30s\n",
      "328:\tlearn: 0.0826870\ttotal: 44.2s\tremaining: 1m 30s\n",
      "329:\tlearn: 0.0826177\ttotal: 44.3s\tremaining: 1m 29s\n",
      "330:\tlearn: 0.0825716\ttotal: 44.5s\tremaining: 1m 29s\n",
      "331:\tlearn: 0.0824965\ttotal: 44.6s\tremaining: 1m 29s\n",
      "332:\tlearn: 0.0824850\ttotal: 44.7s\tremaining: 1m 29s\n",
      "333:\tlearn: 0.0824100\ttotal: 44.9s\tremaining: 1m 29s\n",
      "334:\tlearn: 0.0824100\ttotal: 45s\tremaining: 1m 29s\n",
      "335:\tlearn: 0.0823465\ttotal: 45.1s\tremaining: 1m 29s\n",
      "336:\tlearn: 0.0822946\ttotal: 45.3s\tremaining: 1m 29s\n",
      "337:\tlearn: 0.0821849\ttotal: 45.4s\tremaining: 1m 28s\n",
      "338:\tlearn: 0.0821272\ttotal: 45.5s\tremaining: 1m 28s\n",
      "339:\tlearn: 0.0821330\ttotal: 45.7s\tremaining: 1m 28s\n",
      "340:\tlearn: 0.0820868\ttotal: 45.8s\tremaining: 1m 28s\n",
      "341:\tlearn: 0.0820810\ttotal: 45.9s\tremaining: 1m 28s\n",
      "342:\tlearn: 0.0819714\ttotal: 46.1s\tremaining: 1m 28s\n",
      "343:\tlearn: 0.0819310\ttotal: 46.2s\tremaining: 1m 28s\n",
      "344:\tlearn: 0.0818502\ttotal: 46.3s\tremaining: 1m 27s\n",
      "345:\tlearn: 0.0817694\ttotal: 46.5s\tremaining: 1m 27s\n",
      "346:\tlearn: 0.0816655\ttotal: 46.6s\tremaining: 1m 27s\n",
      "347:\tlearn: 0.0816482\ttotal: 46.7s\tremaining: 1m 27s\n",
      "348:\tlearn: 0.0816078\ttotal: 46.9s\tremaining: 1m 27s\n",
      "349:\tlearn: 0.0815501\ttotal: 47s\tremaining: 1m 27s\n",
      "350:\tlearn: 0.0815155\ttotal: 47.1s\tremaining: 1m 27s\n",
      "351:\tlearn: 0.0814231\ttotal: 47.2s\tremaining: 1m 26s\n",
      "352:\tlearn: 0.0814347\ttotal: 47.4s\tremaining: 1m 26s\n",
      "353:\tlearn: 0.0814174\ttotal: 47.5s\tremaining: 1m 26s\n",
      "354:\tlearn: 0.0813539\ttotal: 47.6s\tremaining: 1m 26s\n",
      "355:\tlearn: 0.0812211\ttotal: 47.8s\tremaining: 1m 26s\n",
      "356:\tlearn: 0.0811807\ttotal: 47.9s\tremaining: 1m 26s\n",
      "357:\tlearn: 0.0811577\ttotal: 48s\tremaining: 1m 26s\n",
      "358:\tlearn: 0.0810422\ttotal: 48.2s\tremaining: 1m 26s\n",
      "359:\tlearn: 0.0810134\ttotal: 48.3s\tremaining: 1m 25s\n",
      "360:\tlearn: 0.0809614\ttotal: 48.4s\tremaining: 1m 25s\n",
      "361:\tlearn: 0.0809614\ttotal: 48.6s\tremaining: 1m 25s\n",
      "362:\tlearn: 0.0809268\ttotal: 48.7s\tremaining: 1m 25s\n",
      "363:\tlearn: 0.0808980\ttotal: 48.8s\tremaining: 1m 25s\n",
      "364:\tlearn: 0.0808403\ttotal: 49s\tremaining: 1m 25s\n",
      "365:\tlearn: 0.0807768\ttotal: 49.1s\tremaining: 1m 25s\n",
      "366:\tlearn: 0.0806440\ttotal: 49.3s\tremaining: 1m 24s\n",
      "367:\tlearn: 0.0806094\ttotal: 49.4s\tremaining: 1m 24s\n",
      "368:\tlearn: 0.0805517\ttotal: 49.5s\tremaining: 1m 24s\n",
      "369:\tlearn: 0.0804651\ttotal: 49.7s\tremaining: 1m 24s\n",
      "370:\tlearn: 0.0804363\ttotal: 49.8s\tremaining: 1m 24s\n",
      "371:\tlearn: 0.0804363\ttotal: 49.9s\tremaining: 1m 24s\n",
      "372:\tlearn: 0.0803093\ttotal: 50.1s\tremaining: 1m 24s\n",
      "373:\tlearn: 0.0802805\ttotal: 50.2s\tremaining: 1m 24s\n",
      "374:\tlearn: 0.0801824\ttotal: 50.4s\tremaining: 1m 23s\n",
      "375:\tlearn: 0.0801073\ttotal: 50.5s\tremaining: 1m 23s\n",
      "376:\tlearn: 0.0800496\ttotal: 50.6s\tremaining: 1m 23s\n",
      "377:\tlearn: 0.0799515\ttotal: 50.8s\tremaining: 1m 23s\n",
      "378:\tlearn: 0.0798880\ttotal: 50.9s\tremaining: 1m 23s\n",
      "379:\tlearn: 0.0798130\ttotal: 51s\tremaining: 1m 23s\n",
      "380:\tlearn: 0.0797034\ttotal: 51.2s\tremaining: 1m 23s\n",
      "381:\tlearn: 0.0795995\ttotal: 51.3s\tremaining: 1m 23s\n",
      "382:\tlearn: 0.0795764\ttotal: 51.4s\tremaining: 1m 22s\n",
      "383:\tlearn: 0.0795302\ttotal: 51.6s\tremaining: 1m 22s\n",
      "384:\tlearn: 0.0794494\ttotal: 51.7s\tremaining: 1m 22s\n",
      "385:\tlearn: 0.0793802\ttotal: 51.8s\tremaining: 1m 22s\n",
      "386:\tlearn: 0.0793860\ttotal: 52s\tremaining: 1m 22s\n",
      "387:\tlearn: 0.0794264\ttotal: 52.1s\tremaining: 1m 22s\n",
      "388:\tlearn: 0.0793340\ttotal: 52.2s\tremaining: 1m 22s\n",
      "389:\tlearn: 0.0792590\ttotal: 52.4s\tremaining: 1m 21s\n",
      "390:\tlearn: 0.0791840\ttotal: 52.5s\tremaining: 1m 21s\n",
      "391:\tlearn: 0.0791609\ttotal: 52.6s\tremaining: 1m 21s\n",
      "392:\tlearn: 0.0791724\ttotal: 52.8s\tremaining: 1m 21s\n",
      "393:\tlearn: 0.0790628\ttotal: 52.9s\tremaining: 1m 21s\n",
      "394:\tlearn: 0.0790397\ttotal: 53s\tremaining: 1m 21s\n",
      "395:\tlearn: 0.0789705\ttotal: 53.2s\tremaining: 1m 21s\n",
      "396:\tlearn: 0.0789070\ttotal: 53.3s\tremaining: 1m 20s\n",
      "397:\tlearn: 0.0788839\ttotal: 53.4s\tremaining: 1m 20s\n",
      "398:\tlearn: 0.0788781\ttotal: 53.6s\tremaining: 1m 20s\n",
      "399:\tlearn: 0.0788550\ttotal: 53.7s\tremaining: 1m 20s\n",
      "400:\tlearn: 0.0787858\ttotal: 53.9s\tremaining: 1m 20s\n",
      "401:\tlearn: 0.0786819\ttotal: 54s\tremaining: 1m 20s\n",
      "402:\tlearn: 0.0785665\ttotal: 54.2s\tremaining: 1m 20s\n",
      "403:\tlearn: 0.0784857\ttotal: 54.3s\tremaining: 1m 20s\n",
      "404:\tlearn: 0.0783472\ttotal: 54.4s\tremaining: 1m 19s\n",
      "405:\tlearn: 0.0782029\ttotal: 54.6s\tremaining: 1m 19s\n",
      "406:\tlearn: 0.0781914\ttotal: 54.7s\tremaining: 1m 19s\n",
      "407:\tlearn: 0.0780875\ttotal: 54.8s\tremaining: 1m 19s\n",
      "408:\tlearn: 0.0780529\ttotal: 55s\tremaining: 1m 19s\n",
      "409:\tlearn: 0.0780009\ttotal: 55.1s\tremaining: 1m 19s\n",
      "410:\tlearn: 0.0778797\ttotal: 55.3s\tremaining: 1m 19s\n",
      "411:\tlearn: 0.0778509\ttotal: 55.4s\tremaining: 1m 19s\n",
      "412:\tlearn: 0.0777989\ttotal: 55.5s\tremaining: 1m 18s\n",
      "413:\tlearn: 0.0777701\ttotal: 55.7s\tremaining: 1m 18s\n",
      "414:\tlearn: 0.0776951\ttotal: 55.8s\tremaining: 1m 18s\n",
      "415:\tlearn: 0.0776258\ttotal: 55.9s\tremaining: 1m 18s\n",
      "416:\tlearn: 0.0775739\ttotal: 56.1s\tremaining: 1m 18s\n",
      "417:\tlearn: 0.0774469\ttotal: 56.2s\tremaining: 1m 18s\n",
      "418:\tlearn: 0.0774123\ttotal: 56.3s\tremaining: 1m 18s\n",
      "419:\tlearn: 0.0773892\ttotal: 56.5s\tremaining: 1m 18s\n",
      "420:\tlearn: 0.0773373\ttotal: 56.6s\tremaining: 1m 17s\n",
      "421:\tlearn: 0.0772969\ttotal: 56.7s\tremaining: 1m 17s\n",
      "422:\tlearn: 0.0772334\ttotal: 56.9s\tremaining: 1m 17s\n",
      "423:\tlearn: 0.0771064\ttotal: 57s\tremaining: 1m 17s\n",
      "424:\tlearn: 0.0770314\ttotal: 57.1s\tremaining: 1m 17s\n",
      "425:\tlearn: 0.0769506\ttotal: 57.3s\tremaining: 1m 17s\n",
      "426:\tlearn: 0.0768813\ttotal: 57.4s\tremaining: 1m 17s\n",
      "427:\tlearn: 0.0768698\ttotal: 57.5s\tremaining: 1m 16s\n",
      "428:\tlearn: 0.0768063\ttotal: 57.7s\tremaining: 1m 16s\n",
      "429:\tlearn: 0.0767890\ttotal: 57.8s\tremaining: 1m 16s\n",
      "430:\tlearn: 0.0767544\ttotal: 57.9s\tremaining: 1m 16s\n",
      "431:\tlearn: 0.0767255\ttotal: 58.1s\tremaining: 1m 16s\n",
      "432:\tlearn: 0.0766851\ttotal: 58.2s\tremaining: 1m 16s\n",
      "433:\tlearn: 0.0766563\ttotal: 58.3s\tremaining: 1m 16s\n",
      "434:\tlearn: 0.0765697\ttotal: 58.5s\tremaining: 1m 15s\n",
      "435:\tlearn: 0.0764947\ttotal: 58.6s\tremaining: 1m 15s\n",
      "436:\tlearn: 0.0763850\ttotal: 58.7s\tremaining: 1m 15s\n",
      "437:\tlearn: 0.0763331\ttotal: 58.9s\tremaining: 1m 15s\n",
      "438:\tlearn: 0.0762523\ttotal: 59s\tremaining: 1m 15s\n",
      "439:\tlearn: 0.0762465\ttotal: 59.1s\tremaining: 1m 15s\n",
      "440:\tlearn: 0.0761657\ttotal: 59.3s\tremaining: 1m 15s\n",
      "441:\tlearn: 0.0761542\ttotal: 59.4s\tremaining: 1m 15s\n",
      "442:\tlearn: 0.0761600\ttotal: 59.6s\tremaining: 1m 14s\n",
      "443:\tlearn: 0.0760792\ttotal: 59.7s\tremaining: 1m 14s\n",
      "444:\tlearn: 0.0759984\ttotal: 59.8s\tremaining: 1m 14s\n",
      "445:\tlearn: 0.0759926\ttotal: 60s\tremaining: 1m 14s\n",
      "446:\tlearn: 0.0759291\ttotal: 1m\tremaining: 1m 14s\n",
      "447:\tlearn: 0.0759003\ttotal: 1m\tremaining: 1m 14s\n",
      "448:\tlearn: 0.0759003\ttotal: 1m\tremaining: 1m 14s\n",
      "449:\tlearn: 0.0758426\ttotal: 1m\tremaining: 1m 14s\n",
      "450:\tlearn: 0.0757964\ttotal: 1m\tremaining: 1m 13s\n",
      "451:\tlearn: 0.0757502\ttotal: 1m\tremaining: 1m 13s\n",
      "452:\tlearn: 0.0756521\ttotal: 1m\tremaining: 1m 13s\n",
      "453:\tlearn: 0.0756348\ttotal: 1m 1s\tremaining: 1m 13s\n",
      "454:\tlearn: 0.0755309\ttotal: 1m 1s\tremaining: 1m 13s\n",
      "455:\tlearn: 0.0754732\ttotal: 1m 1s\tremaining: 1m 13s\n",
      "456:\tlearn: 0.0754328\ttotal: 1m 1s\tremaining: 1m 13s\n",
      "457:\tlearn: 0.0753001\ttotal: 1m 1s\tremaining: 1m 12s\n",
      "458:\tlearn: 0.0752539\ttotal: 1m 1s\tremaining: 1m 12s\n",
      "459:\tlearn: 0.0751327\ttotal: 1m 1s\tremaining: 1m 12s\n",
      "460:\tlearn: 0.0750923\ttotal: 1m 2s\tremaining: 1m 12s\n",
      "461:\tlearn: 0.0750693\ttotal: 1m 2s\tremaining: 1m 12s\n",
      "462:\tlearn: 0.0750058\ttotal: 1m 2s\tremaining: 1m 12s\n",
      "463:\tlearn: 0.0749827\ttotal: 1m 2s\tremaining: 1m 12s\n",
      "464:\tlearn: 0.0749711\ttotal: 1m 2s\tremaining: 1m 11s\n",
      "465:\tlearn: 0.0748788\ttotal: 1m 2s\tremaining: 1m 11s\n",
      "466:\tlearn: 0.0748615\ttotal: 1m 2s\tremaining: 1m 11s\n",
      "467:\tlearn: 0.0748384\ttotal: 1m 2s\tremaining: 1m 11s\n",
      "468:\tlearn: 0.0748153\ttotal: 1m 3s\tremaining: 1m 11s\n",
      "469:\tlearn: 0.0747403\ttotal: 1m 3s\tremaining: 1m 11s\n",
      "470:\tlearn: 0.0747114\ttotal: 1m 3s\tremaining: 1m 11s\n",
      "471:\tlearn: 0.0746480\ttotal: 1m 3s\tremaining: 1m 11s\n",
      "472:\tlearn: 0.0746307\ttotal: 1m 3s\tremaining: 1m 10s\n",
      "473:\tlearn: 0.0744979\ttotal: 1m 3s\tremaining: 1m 10s\n",
      "474:\tlearn: 0.0744402\ttotal: 1m 3s\tremaining: 1m 10s\n",
      "475:\tlearn: 0.0744171\ttotal: 1m 4s\tremaining: 1m 10s\n",
      "476:\tlearn: 0.0744691\ttotal: 1m 4s\tremaining: 1m 10s\n",
      "477:\tlearn: 0.0744114\ttotal: 1m 4s\tremaining: 1m 10s\n",
      "478:\tlearn: 0.0743248\ttotal: 1m 4s\tremaining: 1m 10s\n",
      "479:\tlearn: 0.0743306\ttotal: 1m 4s\tremaining: 1m 9s\n",
      "480:\tlearn: 0.0742613\ttotal: 1m 4s\tremaining: 1m 9s\n",
      "481:\tlearn: 0.0742209\ttotal: 1m 4s\tremaining: 1m 9s\n",
      "482:\tlearn: 0.0741286\ttotal: 1m 4s\tremaining: 1m 9s\n",
      "483:\tlearn: 0.0740709\ttotal: 1m 5s\tremaining: 1m 9s\n",
      "484:\tlearn: 0.0740016\ttotal: 1m 5s\tremaining: 1m 9s\n",
      "485:\tlearn: 0.0738977\ttotal: 1m 5s\tremaining: 1m 9s\n",
      "486:\tlearn: 0.0738169\ttotal: 1m 5s\tremaining: 1m 9s\n",
      "487:\tlearn: 0.0737188\ttotal: 1m 5s\tremaining: 1m 8s\n",
      "488:\tlearn: 0.0736669\ttotal: 1m 5s\tremaining: 1m 8s\n",
      "489:\tlearn: 0.0736438\ttotal: 1m 5s\tremaining: 1m 8s\n",
      "490:\tlearn: 0.0735688\ttotal: 1m 6s\tremaining: 1m 8s\n",
      "491:\tlearn: 0.0735169\ttotal: 1m 6s\tremaining: 1m 8s\n",
      "492:\tlearn: 0.0734361\ttotal: 1m 6s\tremaining: 1m 8s\n",
      "493:\tlearn: 0.0734187\ttotal: 1m 6s\tremaining: 1m 8s\n",
      "494:\tlearn: 0.0733322\ttotal: 1m 6s\tremaining: 1m 8s\n",
      "495:\tlearn: 0.0733264\ttotal: 1m 6s\tremaining: 1m 7s\n",
      "496:\tlearn: 0.0732860\ttotal: 1m 6s\tremaining: 1m 7s\n",
      "497:\tlearn: 0.0732860\ttotal: 1m 7s\tremaining: 1m 7s\n",
      "498:\tlearn: 0.0732514\ttotal: 1m 7s\tremaining: 1m 7s\n",
      "499:\tlearn: 0.0731590\ttotal: 1m 7s\tremaining: 1m 7s\n",
      "500:\tlearn: 0.0730205\ttotal: 1m 7s\tremaining: 1m 7s\n",
      "501:\tlearn: 0.0730148\ttotal: 1m 7s\tremaining: 1m 7s\n",
      "502:\tlearn: 0.0728878\ttotal: 1m 7s\tremaining: 1m 7s\n",
      "503:\tlearn: 0.0728590\ttotal: 1m 8s\tremaining: 1m 6s\n",
      "504:\tlearn: 0.0727666\ttotal: 1m 8s\tremaining: 1m 6s\n",
      "505:\tlearn: 0.0726974\ttotal: 1m 8s\tremaining: 1m 6s\n",
      "506:\tlearn: 0.0725993\ttotal: 1m 8s\tremaining: 1m 6s\n",
      "507:\tlearn: 0.0725242\ttotal: 1m 8s\tremaining: 1m 6s\n",
      "508:\tlearn: 0.0725185\ttotal: 1m 8s\tremaining: 1m 6s\n",
      "509:\tlearn: 0.0724030\ttotal: 1m 9s\tremaining: 1m 6s\n",
      "510:\tlearn: 0.0722761\ttotal: 1m 9s\tremaining: 1m 6s\n",
      "511:\tlearn: 0.0722588\ttotal: 1m 9s\tremaining: 1m 6s\n",
      "512:\tlearn: 0.0722126\ttotal: 1m 9s\tremaining: 1m 5s\n",
      "513:\tlearn: 0.0721376\ttotal: 1m 9s\tremaining: 1m 5s\n",
      "514:\tlearn: 0.0721549\ttotal: 1m 9s\tremaining: 1m 5s\n",
      "515:\tlearn: 0.0720395\ttotal: 1m 10s\tremaining: 1m 5s\n",
      "516:\tlearn: 0.0720395\ttotal: 1m 10s\tremaining: 1m 5s\n",
      "517:\tlearn: 0.0720106\ttotal: 1m 10s\tremaining: 1m 5s\n",
      "518:\tlearn: 0.0719183\ttotal: 1m 10s\tremaining: 1m 5s\n",
      "519:\tlearn: 0.0718433\ttotal: 1m 10s\tremaining: 1m 5s\n",
      "520:\tlearn: 0.0717798\ttotal: 1m 11s\tremaining: 1m 5s\n",
      "521:\tlearn: 0.0717625\ttotal: 1m 11s\tremaining: 1m 5s\n",
      "522:\tlearn: 0.0716586\ttotal: 1m 11s\tremaining: 1m 5s\n",
      "523:\tlearn: 0.0716528\ttotal: 1m 11s\tremaining: 1m 4s\n",
      "524:\tlearn: 0.0716066\ttotal: 1m 11s\tremaining: 1m 4s\n",
      "525:\tlearn: 0.0715836\ttotal: 1m 11s\tremaining: 1m 4s\n",
      "526:\tlearn: 0.0715489\ttotal: 1m 11s\tremaining: 1m 4s\n",
      "527:\tlearn: 0.0714739\ttotal: 1m 12s\tremaining: 1m 4s\n",
      "528:\tlearn: 0.0714220\ttotal: 1m 12s\tremaining: 1m 4s\n",
      "529:\tlearn: 0.0713527\ttotal: 1m 12s\tremaining: 1m 4s\n",
      "530:\tlearn: 0.0713181\ttotal: 1m 12s\tremaining: 1m 4s\n",
      "531:\tlearn: 0.0713008\ttotal: 1m 12s\tremaining: 1m 3s\n",
      "532:\tlearn: 0.0713296\ttotal: 1m 12s\tremaining: 1m 3s\n",
      "533:\tlearn: 0.0712950\ttotal: 1m 12s\tremaining: 1m 3s\n",
      "534:\tlearn: 0.0712431\ttotal: 1m 13s\tremaining: 1m 3s\n",
      "535:\tlearn: 0.0712662\ttotal: 1m 13s\tremaining: 1m 3s\n",
      "536:\tlearn: 0.0711969\ttotal: 1m 13s\tremaining: 1m 3s\n",
      "537:\tlearn: 0.0711738\ttotal: 1m 13s\tremaining: 1m 3s\n",
      "538:\tlearn: 0.0711161\ttotal: 1m 13s\tremaining: 1m 2s\n",
      "539:\tlearn: 0.0709834\ttotal: 1m 13s\tremaining: 1m 2s\n",
      "540:\tlearn: 0.0709661\ttotal: 1m 13s\tremaining: 1m 2s\n",
      "541:\tlearn: 0.0708102\ttotal: 1m 14s\tremaining: 1m 2s\n",
      "542:\tlearn: 0.0707987\ttotal: 1m 14s\tremaining: 1m 2s\n",
      "543:\tlearn: 0.0707756\ttotal: 1m 14s\tremaining: 1m 2s\n",
      "544:\tlearn: 0.0707468\ttotal: 1m 14s\tremaining: 1m 2s\n",
      "545:\tlearn: 0.0706948\ttotal: 1m 14s\tremaining: 1m 1s\n",
      "546:\tlearn: 0.0706833\ttotal: 1m 14s\tremaining: 1m 1s\n",
      "547:\tlearn: 0.0705736\ttotal: 1m 14s\tremaining: 1m 1s\n",
      "548:\tlearn: 0.0704813\ttotal: 1m 14s\tremaining: 1m 1s\n",
      "549:\tlearn: 0.0704524\ttotal: 1m 15s\tremaining: 1m 1s\n",
      "550:\tlearn: 0.0703947\ttotal: 1m 15s\tremaining: 1m 1s\n",
      "551:\tlearn: 0.0702793\ttotal: 1m 15s\tremaining: 1m 1s\n",
      "552:\tlearn: 0.0702505\ttotal: 1m 15s\tremaining: 1m 1s\n",
      "553:\tlearn: 0.0701812\ttotal: 1m 15s\tremaining: 1m\n",
      "554:\tlearn: 0.0701466\ttotal: 1m 15s\tremaining: 1m\n",
      "555:\tlearn: 0.0701754\ttotal: 1m 15s\tremaining: 1m\n",
      "556:\tlearn: 0.0701235\ttotal: 1m 16s\tremaining: 1m\n",
      "557:\tlearn: 0.0700600\ttotal: 1m 16s\tremaining: 1m\n",
      "558:\tlearn: 0.0699850\ttotal: 1m 16s\tremaining: 1m\n",
      "559:\tlearn: 0.0699100\ttotal: 1m 16s\tremaining: 1m\n",
      "560:\tlearn: 0.0698984\ttotal: 1m 16s\tremaining: 59.9s\n",
      "561:\tlearn: 0.0698407\ttotal: 1m 16s\tremaining: 59.8s\n",
      "562:\tlearn: 0.0698349\ttotal: 1m 16s\tremaining: 59.6s\n",
      "563:\tlearn: 0.0697426\ttotal: 1m 16s\tremaining: 59.5s\n",
      "564:\tlearn: 0.0697080\ttotal: 1m 17s\tremaining: 59.3s\n",
      "565:\tlearn: 0.0696560\ttotal: 1m 17s\tremaining: 59.2s\n",
      "566:\tlearn: 0.0696214\ttotal: 1m 17s\tremaining: 59.1s\n",
      "567:\tlearn: 0.0695233\ttotal: 1m 17s\tremaining: 58.9s\n",
      "568:\tlearn: 0.0694079\ttotal: 1m 17s\tremaining: 58.8s\n",
      "569:\tlearn: 0.0694137\ttotal: 1m 17s\tremaining: 58.6s\n",
      "570:\tlearn: 0.0693790\ttotal: 1m 17s\tremaining: 58.5s\n",
      "571:\tlearn: 0.0693560\ttotal: 1m 18s\tremaining: 58.4s\n",
      "572:\tlearn: 0.0692867\ttotal: 1m 18s\tremaining: 58.2s\n",
      "573:\tlearn: 0.0692117\ttotal: 1m 18s\tremaining: 58.1s\n",
      "574:\tlearn: 0.0691367\ttotal: 1m 18s\tremaining: 58s\n",
      "575:\tlearn: 0.0690732\ttotal: 1m 18s\tremaining: 57.8s\n",
      "576:\tlearn: 0.0691020\ttotal: 1m 18s\tremaining: 57.7s\n",
      "577:\tlearn: 0.0690963\ttotal: 1m 18s\tremaining: 57.5s\n",
      "578:\tlearn: 0.0691251\ttotal: 1m 18s\tremaining: 57.4s\n",
      "579:\tlearn: 0.0690559\ttotal: 1m 19s\tremaining: 57.3s\n",
      "580:\tlearn: 0.0689289\ttotal: 1m 19s\tremaining: 57.1s\n",
      "581:\tlearn: 0.0689058\ttotal: 1m 19s\tremaining: 57s\n",
      "582:\tlearn: 0.0688308\ttotal: 1m 19s\tremaining: 56.9s\n",
      "583:\tlearn: 0.0688193\ttotal: 1m 19s\tremaining: 56.7s\n",
      "584:\tlearn: 0.0687327\ttotal: 1m 19s\tremaining: 56.6s\n",
      "585:\tlearn: 0.0686634\ttotal: 1m 19s\tremaining: 56.4s\n",
      "586:\tlearn: 0.0686115\ttotal: 1m 20s\tremaining: 56.3s\n",
      "587:\tlearn: 0.0686115\ttotal: 1m 20s\tremaining: 56.2s\n",
      "588:\tlearn: 0.0686057\ttotal: 1m 20s\tremaining: 56s\n",
      "589:\tlearn: 0.0685596\ttotal: 1m 20s\tremaining: 55.9s\n",
      "590:\tlearn: 0.0685076\ttotal: 1m 20s\tremaining: 55.8s\n",
      "591:\tlearn: 0.0684268\ttotal: 1m 20s\tremaining: 55.6s\n",
      "592:\tlearn: 0.0684037\ttotal: 1m 20s\tremaining: 55.5s\n",
      "593:\tlearn: 0.0684384\ttotal: 1m 20s\tremaining: 55.4s\n",
      "594:\tlearn: 0.0683691\ttotal: 1m 21s\tremaining: 55.2s\n",
      "595:\tlearn: 0.0683172\ttotal: 1m 21s\tremaining: 55.1s\n",
      "596:\tlearn: 0.0682710\ttotal: 1m 21s\tremaining: 54.9s\n",
      "597:\tlearn: 0.0682191\ttotal: 1m 21s\tremaining: 54.8s\n",
      "598:\tlearn: 0.0681671\ttotal: 1m 21s\tremaining: 54.7s\n",
      "599:\tlearn: 0.0681094\ttotal: 1m 21s\tremaining: 54.5s\n",
      "600:\tlearn: 0.0680633\ttotal: 1m 21s\tremaining: 54.4s\n",
      "601:\tlearn: 0.0679882\ttotal: 1m 22s\tremaining: 54.2s\n",
      "602:\tlearn: 0.0679478\ttotal: 1m 22s\tremaining: 54.1s\n",
      "603:\tlearn: 0.0679998\ttotal: 1m 22s\tremaining: 54s\n",
      "604:\tlearn: 0.0679247\ttotal: 1m 22s\tremaining: 53.8s\n",
      "605:\tlearn: 0.0677920\ttotal: 1m 22s\tremaining: 53.7s\n",
      "606:\tlearn: 0.0677862\ttotal: 1m 22s\tremaining: 53.5s\n",
      "607:\tlearn: 0.0676708\ttotal: 1m 22s\tremaining: 53.4s\n",
      "608:\tlearn: 0.0675785\ttotal: 1m 22s\tremaining: 53.3s\n",
      "609:\tlearn: 0.0675496\ttotal: 1m 23s\tremaining: 53.1s\n",
      "610:\tlearn: 0.0675323\ttotal: 1m 23s\tremaining: 53s\n",
      "611:\tlearn: 0.0674977\ttotal: 1m 23s\tremaining: 52.9s\n",
      "612:\tlearn: 0.0674631\ttotal: 1m 23s\tremaining: 52.7s\n",
      "613:\tlearn: 0.0674227\ttotal: 1m 23s\tremaining: 52.6s\n",
      "614:\tlearn: 0.0673938\ttotal: 1m 23s\tremaining: 52.5s\n",
      "615:\tlearn: 0.0673419\ttotal: 1m 23s\tremaining: 52.3s\n",
      "616:\tlearn: 0.0672611\ttotal: 1m 24s\tremaining: 52.2s\n",
      "617:\tlearn: 0.0671861\ttotal: 1m 24s\tremaining: 52.1s\n",
      "618:\tlearn: 0.0672207\ttotal: 1m 24s\tremaining: 51.9s\n",
      "619:\tlearn: 0.0671630\ttotal: 1m 24s\tremaining: 51.8s\n",
      "620:\tlearn: 0.0670706\ttotal: 1m 24s\tremaining: 51.7s\n",
      "621:\tlearn: 0.0670591\ttotal: 1m 24s\tremaining: 51.5s\n",
      "622:\tlearn: 0.0670014\ttotal: 1m 24s\tremaining: 51.4s\n",
      "623:\tlearn: 0.0669321\ttotal: 1m 25s\tremaining: 51.2s\n",
      "624:\tlearn: 0.0668975\ttotal: 1m 25s\tremaining: 51.1s\n",
      "625:\tlearn: 0.0668975\ttotal: 1m 25s\tremaining: 51s\n",
      "626:\tlearn: 0.0668456\ttotal: 1m 25s\tremaining: 50.8s\n",
      "627:\tlearn: 0.0667705\ttotal: 1m 25s\tremaining: 50.7s\n",
      "628:\tlearn: 0.0667936\ttotal: 1m 25s\tremaining: 50.5s\n",
      "629:\tlearn: 0.0667475\ttotal: 1m 25s\tremaining: 50.4s\n",
      "630:\tlearn: 0.0666667\ttotal: 1m 25s\tremaining: 50.3s\n",
      "631:\tlearn: 0.0666609\ttotal: 1m 26s\tremaining: 50.1s\n",
      "632:\tlearn: 0.0666436\ttotal: 1m 26s\tremaining: 50s\n",
      "633:\tlearn: 0.0666378\ttotal: 1m 26s\tremaining: 49.9s\n",
      "634:\tlearn: 0.0665859\ttotal: 1m 26s\tremaining: 49.7s\n",
      "635:\tlearn: 0.0665339\ttotal: 1m 26s\tremaining: 49.6s\n",
      "636:\tlearn: 0.0664935\ttotal: 1m 26s\tremaining: 49.4s\n",
      "637:\tlearn: 0.0664301\ttotal: 1m 26s\tremaining: 49.3s\n",
      "638:\tlearn: 0.0664185\ttotal: 1m 27s\tremaining: 49.2s\n",
      "639:\tlearn: 0.0663493\ttotal: 1m 27s\tremaining: 49s\n",
      "640:\tlearn: 0.0662569\ttotal: 1m 27s\tremaining: 48.9s\n",
      "641:\tlearn: 0.0662165\ttotal: 1m 27s\tremaining: 48.8s\n",
      "642:\tlearn: 0.0661357\ttotal: 1m 27s\tremaining: 48.6s\n",
      "643:\tlearn: 0.0660838\ttotal: 1m 27s\tremaining: 48.5s\n",
      "644:\tlearn: 0.0660376\ttotal: 1m 27s\tremaining: 48.3s\n",
      "645:\tlearn: 0.0660030\ttotal: 1m 27s\tremaining: 48.2s\n",
      "646:\tlearn: 0.0659107\ttotal: 1m 28s\tremaining: 48.1s\n",
      "647:\tlearn: 0.0658703\ttotal: 1m 28s\tremaining: 47.9s\n",
      "648:\tlearn: 0.0658876\ttotal: 1m 28s\tremaining: 47.8s\n",
      "649:\tlearn: 0.0657895\ttotal: 1m 28s\tremaining: 47.7s\n",
      "650:\tlearn: 0.0657260\ttotal: 1m 28s\tremaining: 47.5s\n",
      "651:\tlearn: 0.0656971\ttotal: 1m 28s\tremaining: 47.4s\n",
      "652:\tlearn: 0.0656163\ttotal: 1m 28s\tremaining: 47.2s\n",
      "653:\tlearn: 0.0655933\ttotal: 1m 29s\tremaining: 47.1s\n",
      "654:\tlearn: 0.0655413\ttotal: 1m 29s\tremaining: 47s\n",
      "655:\tlearn: 0.0655413\ttotal: 1m 29s\tremaining: 46.8s\n",
      "656:\tlearn: 0.0654952\ttotal: 1m 29s\tremaining: 46.7s\n",
      "657:\tlearn: 0.0654317\ttotal: 1m 29s\tremaining: 46.6s\n",
      "658:\tlearn: 0.0654086\ttotal: 1m 29s\tremaining: 46.4s\n",
      "659:\tlearn: 0.0653393\ttotal: 1m 29s\tremaining: 46.3s\n",
      "660:\tlearn: 0.0653105\ttotal: 1m 29s\tremaining: 46.1s\n",
      "661:\tlearn: 0.0652066\ttotal: 1m 30s\tremaining: 46s\n",
      "662:\tlearn: 0.0651431\ttotal: 1m 30s\tremaining: 45.9s\n",
      "663:\tlearn: 0.0650912\ttotal: 1m 30s\tremaining: 45.7s\n",
      "664:\tlearn: 0.0650046\ttotal: 1m 30s\tremaining: 45.6s\n",
      "665:\tlearn: 0.0649469\ttotal: 1m 30s\tremaining: 45.5s\n",
      "666:\tlearn: 0.0649411\ttotal: 1m 30s\tremaining: 45.3s\n",
      "667:\tlearn: 0.0648777\ttotal: 1m 30s\tremaining: 45.2s\n",
      "668:\tlearn: 0.0647853\ttotal: 1m 31s\tremaining: 45s\n",
      "669:\tlearn: 0.0646814\ttotal: 1m 31s\tremaining: 44.9s\n",
      "670:\tlearn: 0.0646353\ttotal: 1m 31s\tremaining: 44.8s\n",
      "671:\tlearn: 0.0646237\ttotal: 1m 31s\tremaining: 44.6s\n",
      "672:\tlearn: 0.0645429\ttotal: 1m 31s\tremaining: 44.5s\n",
      "673:\tlearn: 0.0644795\ttotal: 1m 31s\tremaining: 44.4s\n",
      "674:\tlearn: 0.0645487\ttotal: 1m 31s\tremaining: 44.2s\n",
      "675:\tlearn: 0.0645141\ttotal: 1m 31s\tremaining: 44.1s\n",
      "676:\tlearn: 0.0644621\ttotal: 1m 32s\tremaining: 43.9s\n",
      "677:\tlearn: 0.0644333\ttotal: 1m 32s\tremaining: 43.8s\n",
      "678:\tlearn: 0.0644102\ttotal: 1m 32s\tremaining: 43.7s\n",
      "679:\tlearn: 0.0643006\ttotal: 1m 32s\tremaining: 43.5s\n",
      "680:\tlearn: 0.0641967\ttotal: 1m 32s\tremaining: 43.4s\n",
      "681:\tlearn: 0.0641678\ttotal: 1m 32s\tremaining: 43.3s\n",
      "682:\tlearn: 0.0641217\ttotal: 1m 32s\tremaining: 43.1s\n",
      "683:\tlearn: 0.0640697\ttotal: 1m 33s\tremaining: 43s\n",
      "684:\tlearn: 0.0640870\ttotal: 1m 33s\tremaining: 42.9s\n",
      "685:\tlearn: 0.0640005\ttotal: 1m 33s\tremaining: 42.7s\n",
      "686:\tlearn: 0.0639312\ttotal: 1m 33s\tremaining: 42.6s\n",
      "687:\tlearn: 0.0639197\ttotal: 1m 33s\tremaining: 42.4s\n",
      "688:\tlearn: 0.0639024\ttotal: 1m 33s\tremaining: 42.3s\n",
      "689:\tlearn: 0.0639139\ttotal: 1m 33s\tremaining: 42.2s\n",
      "690:\tlearn: 0.0638620\ttotal: 1m 33s\tremaining: 42s\n",
      "691:\tlearn: 0.0637927\ttotal: 1m 34s\tremaining: 41.9s\n",
      "692:\tlearn: 0.0637235\ttotal: 1m 34s\tremaining: 41.8s\n",
      "693:\tlearn: 0.0636369\ttotal: 1m 34s\tremaining: 41.6s\n",
      "694:\tlearn: 0.0636023\ttotal: 1m 34s\tremaining: 41.5s\n",
      "695:\tlearn: 0.0635561\ttotal: 1m 34s\tremaining: 41.3s\n",
      "696:\tlearn: 0.0635330\ttotal: 1m 34s\tremaining: 41.2s\n",
      "697:\tlearn: 0.0634695\ttotal: 1m 34s\tremaining: 41.1s\n",
      "698:\tlearn: 0.0634291\ttotal: 1m 35s\tremaining: 40.9s\n",
      "699:\tlearn: 0.0634060\ttotal: 1m 35s\tremaining: 40.8s\n",
      "700:\tlearn: 0.0633945\ttotal: 1m 35s\tremaining: 40.7s\n",
      "701:\tlearn: 0.0633483\ttotal: 1m 35s\tremaining: 40.5s\n",
      "702:\tlearn: 0.0633541\ttotal: 1m 35s\tremaining: 40.4s\n",
      "703:\tlearn: 0.0632906\ttotal: 1m 35s\tremaining: 40.2s\n",
      "704:\tlearn: 0.0632618\ttotal: 1m 35s\tremaining: 40.1s\n",
      "705:\tlearn: 0.0632387\ttotal: 1m 35s\tremaining: 40s\n",
      "706:\tlearn: 0.0632156\ttotal: 1m 36s\tremaining: 39.8s\n",
      "707:\tlearn: 0.0631290\ttotal: 1m 36s\tremaining: 39.7s\n",
      "708:\tlearn: 0.0630482\ttotal: 1m 36s\tremaining: 39.6s\n",
      "709:\tlearn: 0.0630771\ttotal: 1m 36s\tremaining: 39.4s\n",
      "710:\tlearn: 0.0630425\ttotal: 1m 36s\tremaining: 39.3s\n",
      "711:\tlearn: 0.0630309\ttotal: 1m 36s\tremaining: 39.2s\n",
      "712:\tlearn: 0.0629732\ttotal: 1m 36s\tremaining: 39s\n",
      "713:\tlearn: 0.0629501\ttotal: 1m 37s\tremaining: 38.9s\n",
      "714:\tlearn: 0.0629444\ttotal: 1m 37s\tremaining: 38.7s\n",
      "715:\tlearn: 0.0628520\ttotal: 1m 37s\tremaining: 38.6s\n",
      "716:\tlearn: 0.0627886\ttotal: 1m 37s\tremaining: 38.5s\n",
      "717:\tlearn: 0.0627943\ttotal: 1m 37s\tremaining: 38.3s\n",
      "718:\tlearn: 0.0627193\ttotal: 1m 37s\tremaining: 38.2s\n",
      "719:\tlearn: 0.0626443\ttotal: 1m 37s\tremaining: 38.1s\n",
      "720:\tlearn: 0.0626270\ttotal: 1m 37s\tremaining: 37.9s\n",
      "721:\tlearn: 0.0625519\ttotal: 1m 38s\tremaining: 37.8s\n",
      "722:\tlearn: 0.0624711\ttotal: 1m 38s\tremaining: 37.6s\n",
      "723:\tlearn: 0.0625000\ttotal: 1m 38s\tremaining: 37.5s\n",
      "724:\tlearn: 0.0624019\ttotal: 1m 38s\tremaining: 37.4s\n",
      "725:\tlearn: 0.0623500\ttotal: 1m 38s\tremaining: 37.2s\n",
      "726:\tlearn: 0.0623326\ttotal: 1m 38s\tremaining: 37.1s\n",
      "727:\tlearn: 0.0623038\ttotal: 1m 38s\tremaining: 37s\n",
      "728:\tlearn: 0.0622461\ttotal: 1m 39s\tremaining: 36.9s\n",
      "729:\tlearn: 0.0622230\ttotal: 1m 39s\tremaining: 36.7s\n",
      "730:\tlearn: 0.0621249\ttotal: 1m 39s\tremaining: 36.6s\n",
      "731:\tlearn: 0.0621768\ttotal: 1m 39s\tremaining: 36.4s\n",
      "732:\tlearn: 0.0621076\ttotal: 1m 39s\tremaining: 36.3s\n",
      "733:\tlearn: 0.0621191\ttotal: 1m 39s\tremaining: 36.2s\n",
      "734:\tlearn: 0.0621018\ttotal: 1m 39s\tremaining: 36s\n",
      "735:\tlearn: 0.0620268\ttotal: 1m 40s\tremaining: 35.9s\n",
      "736:\tlearn: 0.0619460\ttotal: 1m 40s\tremaining: 35.8s\n",
      "737:\tlearn: 0.0619056\ttotal: 1m 40s\tremaining: 35.6s\n",
      "738:\tlearn: 0.0618940\ttotal: 1m 40s\tremaining: 35.5s\n",
      "739:\tlearn: 0.0618306\ttotal: 1m 40s\tremaining: 35.4s\n",
      "740:\tlearn: 0.0618017\ttotal: 1m 40s\tremaining: 35.2s\n",
      "741:\tlearn: 0.0618075\ttotal: 1m 40s\tremaining: 35.1s\n",
      "742:\tlearn: 0.0617151\ttotal: 1m 41s\tremaining: 34.9s\n",
      "743:\tlearn: 0.0617151\ttotal: 1m 41s\tremaining: 34.8s\n",
      "744:\tlearn: 0.0616517\ttotal: 1m 41s\tremaining: 34.7s\n",
      "745:\tlearn: 0.0616459\ttotal: 1m 41s\tremaining: 34.5s\n",
      "746:\tlearn: 0.0616170\ttotal: 1m 41s\tremaining: 34.4s\n",
      "747:\tlearn: 0.0615651\ttotal: 1m 41s\tremaining: 34.3s\n",
      "748:\tlearn: 0.0615132\ttotal: 1m 41s\tremaining: 34.1s\n",
      "749:\tlearn: 0.0614208\ttotal: 1m 41s\tremaining: 34s\n",
      "750:\tlearn: 0.0613920\ttotal: 1m 42s\tremaining: 33.8s\n",
      "751:\tlearn: 0.0614035\ttotal: 1m 42s\tremaining: 33.7s\n",
      "752:\tlearn: 0.0613343\ttotal: 1m 42s\tremaining: 33.6s\n",
      "753:\tlearn: 0.0612996\ttotal: 1m 42s\tremaining: 33.4s\n",
      "754:\tlearn: 0.0611958\ttotal: 1m 42s\tremaining: 33.3s\n",
      "755:\tlearn: 0.0612015\ttotal: 1m 42s\tremaining: 33.2s\n",
      "756:\tlearn: 0.0610111\ttotal: 1m 42s\tremaining: 33s\n",
      "757:\tlearn: 0.0610572\ttotal: 1m 43s\tremaining: 32.9s\n",
      "758:\tlearn: 0.0609938\ttotal: 1m 43s\tremaining: 32.7s\n",
      "759:\tlearn: 0.0609822\ttotal: 1m 43s\tremaining: 32.6s\n",
      "760:\tlearn: 0.0609361\ttotal: 1m 43s\tremaining: 32.5s\n",
      "761:\tlearn: 0.0608899\ttotal: 1m 43s\tremaining: 32.3s\n",
      "762:\tlearn: 0.0608322\ttotal: 1m 43s\tremaining: 32.2s\n",
      "763:\tlearn: 0.0608206\ttotal: 1m 43s\tremaining: 32.1s\n",
      "764:\tlearn: 0.0607918\ttotal: 1m 43s\tremaining: 31.9s\n",
      "765:\tlearn: 0.0607629\ttotal: 1m 44s\tremaining: 31.8s\n",
      "766:\tlearn: 0.0606821\ttotal: 1m 44s\tremaining: 31.7s\n",
      "767:\tlearn: 0.0606706\ttotal: 1m 44s\tremaining: 31.5s\n",
      "768:\tlearn: 0.0606187\ttotal: 1m 44s\tremaining: 31.4s\n",
      "769:\tlearn: 0.0605956\ttotal: 1m 44s\tremaining: 31.2s\n",
      "770:\tlearn: 0.0605436\ttotal: 1m 44s\tremaining: 31.1s\n",
      "771:\tlearn: 0.0604686\ttotal: 1m 44s\tremaining: 31s\n",
      "772:\tlearn: 0.0604282\ttotal: 1m 44s\tremaining: 30.8s\n",
      "773:\tlearn: 0.0604051\ttotal: 1m 45s\tremaining: 30.7s\n",
      "774:\tlearn: 0.0603416\ttotal: 1m 45s\tremaining: 30.6s\n",
      "775:\tlearn: 0.0603474\ttotal: 1m 45s\tremaining: 30.4s\n",
      "776:\tlearn: 0.0603474\ttotal: 1m 45s\tremaining: 30.3s\n",
      "777:\tlearn: 0.0603012\ttotal: 1m 45s\tremaining: 30.2s\n",
      "778:\tlearn: 0.0602320\ttotal: 1m 45s\tremaining: 30s\n",
      "779:\tlearn: 0.0601454\ttotal: 1m 45s\tremaining: 29.9s\n",
      "780:\tlearn: 0.0601454\ttotal: 1m 46s\tremaining: 29.7s\n",
      "781:\tlearn: 0.0600935\ttotal: 1m 46s\tremaining: 29.6s\n",
      "782:\tlearn: 0.0600819\ttotal: 1m 46s\tremaining: 29.5s\n",
      "783:\tlearn: 0.0600589\ttotal: 1m 46s\tremaining: 29.3s\n",
      "784:\tlearn: 0.0600242\ttotal: 1m 46s\tremaining: 29.2s\n",
      "785:\tlearn: 0.0599492\ttotal: 1m 46s\tremaining: 29.1s\n",
      "786:\tlearn: 0.0598915\ttotal: 1m 46s\tremaining: 28.9s\n",
      "787:\tlearn: 0.0598569\ttotal: 1m 47s\tremaining: 28.8s\n",
      "788:\tlearn: 0.0598338\ttotal: 1m 47s\tremaining: 28.6s\n",
      "789:\tlearn: 0.0597357\ttotal: 1m 47s\tremaining: 28.5s\n",
      "790:\tlearn: 0.0596434\ttotal: 1m 47s\tremaining: 28.4s\n",
      "791:\tlearn: 0.0596260\ttotal: 1m 47s\tremaining: 28.2s\n",
      "792:\tlearn: 0.0595856\ttotal: 1m 47s\tremaining: 28.1s\n",
      "793:\tlearn: 0.0594760\ttotal: 1m 47s\tremaining: 28s\n",
      "794:\tlearn: 0.0594587\ttotal: 1m 47s\tremaining: 27.8s\n",
      "795:\tlearn: 0.0593663\ttotal: 1m 48s\tremaining: 27.7s\n",
      "796:\tlearn: 0.0593029\ttotal: 1m 48s\tremaining: 27.6s\n",
      "797:\tlearn: 0.0593202\ttotal: 1m 48s\tremaining: 27.4s\n",
      "798:\tlearn: 0.0592798\ttotal: 1m 48s\tremaining: 27.3s\n",
      "799:\tlearn: 0.0591874\ttotal: 1m 48s\tremaining: 27.1s\n",
      "800:\tlearn: 0.0590951\ttotal: 1m 48s\tremaining: 27s\n",
      "801:\tlearn: 0.0590778\ttotal: 1m 48s\tremaining: 26.9s\n",
      "802:\tlearn: 0.0590605\ttotal: 1m 48s\tremaining: 26.7s\n",
      "803:\tlearn: 0.0590547\ttotal: 1m 49s\tremaining: 26.6s\n",
      "804:\tlearn: 0.0589912\ttotal: 1m 49s\tremaining: 26.5s\n",
      "805:\tlearn: 0.0589624\ttotal: 1m 49s\tremaining: 26.3s\n",
      "806:\tlearn: 0.0589451\ttotal: 1m 49s\tremaining: 26.2s\n",
      "807:\tlearn: 0.0588758\ttotal: 1m 49s\tremaining: 26.1s\n",
      "808:\tlearn: 0.0588470\ttotal: 1m 49s\tremaining: 25.9s\n",
      "809:\tlearn: 0.0588412\ttotal: 1m 49s\tremaining: 25.8s\n",
      "810:\tlearn: 0.0587662\ttotal: 1m 50s\tremaining: 25.6s\n",
      "811:\tlearn: 0.0587431\ttotal: 1m 50s\tremaining: 25.5s\n",
      "812:\tlearn: 0.0586969\ttotal: 1m 50s\tremaining: 25.4s\n",
      "813:\tlearn: 0.0586681\ttotal: 1m 50s\tremaining: 25.2s\n",
      "814:\tlearn: 0.0586507\ttotal: 1m 50s\tremaining: 25.1s\n",
      "815:\tlearn: 0.0586450\ttotal: 1m 50s\tremaining: 25s\n",
      "816:\tlearn: 0.0586507\ttotal: 1m 50s\tremaining: 24.8s\n",
      "817:\tlearn: 0.0586103\ttotal: 1m 51s\tremaining: 24.7s\n",
      "818:\tlearn: 0.0585873\ttotal: 1m 51s\tremaining: 24.6s\n",
      "819:\tlearn: 0.0585469\ttotal: 1m 51s\tremaining: 24.4s\n",
      "820:\tlearn: 0.0585007\ttotal: 1m 51s\tremaining: 24.3s\n",
      "821:\tlearn: 0.0584603\ttotal: 1m 51s\tremaining: 24.2s\n",
      "822:\tlearn: 0.0584314\ttotal: 1m 51s\tremaining: 24s\n",
      "823:\tlearn: 0.0583910\ttotal: 1m 51s\tremaining: 23.9s\n",
      "824:\tlearn: 0.0583564\ttotal: 1m 51s\tremaining: 23.7s\n",
      "825:\tlearn: 0.0583102\ttotal: 1m 52s\tremaining: 23.6s\n",
      "826:\tlearn: 0.0583276\ttotal: 1m 52s\tremaining: 23.5s\n",
      "827:\tlearn: 0.0582929\ttotal: 1m 52s\tremaining: 23.3s\n",
      "828:\tlearn: 0.0582872\ttotal: 1m 52s\tremaining: 23.2s\n",
      "829:\tlearn: 0.0581948\ttotal: 1m 52s\tremaining: 23.1s\n",
      "830:\tlearn: 0.0581429\ttotal: 1m 52s\tremaining: 22.9s\n",
      "831:\tlearn: 0.0581140\ttotal: 1m 52s\tremaining: 22.8s\n",
      "832:\tlearn: 0.0580736\ttotal: 1m 53s\tremaining: 22.7s\n",
      "833:\tlearn: 0.0579986\ttotal: 1m 53s\tremaining: 22.5s\n",
      "834:\tlearn: 0.0579928\ttotal: 1m 53s\tremaining: 22.4s\n",
      "835:\tlearn: 0.0579351\ttotal: 1m 53s\tremaining: 22.2s\n",
      "836:\tlearn: 0.0578890\ttotal: 1m 53s\tremaining: 22.1s\n",
      "837:\tlearn: 0.0579005\ttotal: 1m 53s\tremaining: 22s\n",
      "838:\tlearn: 0.0578717\ttotal: 1m 53s\tremaining: 21.8s\n",
      "839:\tlearn: 0.0578370\ttotal: 1m 53s\tremaining: 21.7s\n",
      "840:\tlearn: 0.0577966\ttotal: 1m 54s\tremaining: 21.6s\n",
      "841:\tlearn: 0.0577735\ttotal: 1m 54s\tremaining: 21.4s\n",
      "842:\tlearn: 0.0577274\ttotal: 1m 54s\tremaining: 21.3s\n",
      "843:\tlearn: 0.0576985\ttotal: 1m 54s\tremaining: 21.2s\n",
      "844:\tlearn: 0.0576928\ttotal: 1m 54s\tremaining: 21s\n",
      "845:\tlearn: 0.0576754\ttotal: 1m 54s\tremaining: 20.9s\n",
      "846:\tlearn: 0.0576350\ttotal: 1m 54s\tremaining: 20.8s\n",
      "847:\tlearn: 0.0576466\ttotal: 1m 55s\tremaining: 20.6s\n",
      "848:\tlearn: 0.0575658\ttotal: 1m 55s\tremaining: 20.5s\n",
      "849:\tlearn: 0.0575485\ttotal: 1m 55s\tremaining: 20.4s\n",
      "850:\tlearn: 0.0575254\ttotal: 1m 55s\tremaining: 20.2s\n",
      "851:\tlearn: 0.0574965\ttotal: 1m 55s\tremaining: 20.1s\n",
      "852:\tlearn: 0.0574850\ttotal: 1m 55s\tremaining: 20s\n",
      "853:\tlearn: 0.0574388\ttotal: 1m 55s\tremaining: 19.8s\n",
      "854:\tlearn: 0.0573580\ttotal: 1m 56s\tremaining: 19.7s\n",
      "855:\tlearn: 0.0573349\ttotal: 1m 56s\tremaining: 19.6s\n",
      "856:\tlearn: 0.0572484\ttotal: 1m 56s\tremaining: 19.4s\n",
      "857:\tlearn: 0.0572542\ttotal: 1m 56s\tremaining: 19.3s\n",
      "858:\tlearn: 0.0572195\ttotal: 1m 56s\tremaining: 19.1s\n",
      "859:\tlearn: 0.0571503\ttotal: 1m 56s\tremaining: 19s\n",
      "860:\tlearn: 0.0571503\ttotal: 1m 56s\tremaining: 18.9s\n",
      "861:\tlearn: 0.0570637\ttotal: 1m 57s\tremaining: 18.7s\n",
      "862:\tlearn: 0.0570002\ttotal: 1m 57s\tremaining: 18.6s\n",
      "863:\tlearn: 0.0569483\ttotal: 1m 57s\tremaining: 18.5s\n",
      "864:\tlearn: 0.0569367\ttotal: 1m 57s\tremaining: 18.3s\n",
      "865:\tlearn: 0.0569425\ttotal: 1m 57s\tremaining: 18.2s\n",
      "866:\tlearn: 0.0569425\ttotal: 1m 57s\tremaining: 18.1s\n",
      "867:\tlearn: 0.0568906\ttotal: 1m 57s\tremaining: 17.9s\n",
      "868:\tlearn: 0.0568560\ttotal: 1m 57s\tremaining: 17.8s\n",
      "869:\tlearn: 0.0567809\ttotal: 1m 58s\tremaining: 17.6s\n",
      "870:\tlearn: 0.0567348\ttotal: 1m 58s\tremaining: 17.5s\n",
      "871:\tlearn: 0.0567117\ttotal: 1m 58s\tremaining: 17.4s\n",
      "872:\tlearn: 0.0566771\ttotal: 1m 58s\tremaining: 17.2s\n",
      "873:\tlearn: 0.0566251\ttotal: 1m 58s\tremaining: 17.1s\n",
      "874:\tlearn: 0.0565212\ttotal: 1m 58s\tremaining: 17s\n",
      "875:\tlearn: 0.0565212\ttotal: 1m 58s\tremaining: 16.8s\n",
      "876:\tlearn: 0.0564347\ttotal: 1m 59s\tremaining: 16.7s\n",
      "877:\tlearn: 0.0564116\ttotal: 1m 59s\tremaining: 16.6s\n",
      "878:\tlearn: 0.0563943\ttotal: 1m 59s\tremaining: 16.4s\n",
      "879:\tlearn: 0.0563481\ttotal: 1m 59s\tremaining: 16.3s\n",
      "880:\tlearn: 0.0563539\ttotal: 1m 59s\tremaining: 16.2s\n",
      "881:\tlearn: 0.0563308\ttotal: 1m 59s\tremaining: 16s\n",
      "882:\tlearn: 0.0563596\ttotal: 1m 59s\tremaining: 15.9s\n",
      "883:\tlearn: 0.0563019\ttotal: 2m\tremaining: 15.7s\n",
      "884:\tlearn: 0.0563193\ttotal: 2m\tremaining: 15.6s\n",
      "885:\tlearn: 0.0562789\ttotal: 2m\tremaining: 15.5s\n",
      "886:\tlearn: 0.0562673\ttotal: 2m\tremaining: 15.3s\n",
      "887:\tlearn: 0.0561807\ttotal: 2m\tremaining: 15.2s\n",
      "888:\tlearn: 0.0561865\ttotal: 2m\tremaining: 15.1s\n",
      "889:\tlearn: 0.0562154\ttotal: 2m\tremaining: 14.9s\n",
      "890:\tlearn: 0.0561230\ttotal: 2m 1s\tremaining: 14.8s\n",
      "891:\tlearn: 0.0560769\ttotal: 2m 1s\tremaining: 14.7s\n",
      "892:\tlearn: 0.0560249\ttotal: 2m 1s\tremaining: 14.5s\n",
      "893:\tlearn: 0.0559672\ttotal: 2m 1s\tremaining: 14.4s\n",
      "894:\tlearn: 0.0559037\ttotal: 2m 1s\tremaining: 14.3s\n",
      "895:\tlearn: 0.0558691\ttotal: 2m 1s\tremaining: 14.1s\n",
      "896:\tlearn: 0.0558056\ttotal: 2m 1s\tremaining: 14s\n",
      "897:\tlearn: 0.0557941\ttotal: 2m 2s\tremaining: 13.9s\n",
      "898:\tlearn: 0.0557825\ttotal: 2m 2s\tremaining: 13.7s\n",
      "899:\tlearn: 0.0557710\ttotal: 2m 2s\tremaining: 13.6s\n",
      "900:\tlearn: 0.0557306\ttotal: 2m 2s\tremaining: 13.5s\n",
      "901:\tlearn: 0.0556671\ttotal: 2m 2s\tremaining: 13.3s\n",
      "902:\tlearn: 0.0556729\ttotal: 2m 2s\tremaining: 13.2s\n",
      "903:\tlearn: 0.0556498\ttotal: 2m 2s\tremaining: 13.1s\n",
      "904:\tlearn: 0.0556210\ttotal: 2m 3s\tremaining: 12.9s\n",
      "905:\tlearn: 0.0555229\ttotal: 2m 3s\tremaining: 12.8s\n",
      "906:\tlearn: 0.0555459\ttotal: 2m 3s\tremaining: 12.6s\n",
      "907:\tlearn: 0.0554709\ttotal: 2m 3s\tremaining: 12.5s\n",
      "908:\tlearn: 0.0553901\ttotal: 2m 3s\tremaining: 12.4s\n",
      "909:\tlearn: 0.0553613\ttotal: 2m 3s\tremaining: 12.2s\n",
      "910:\tlearn: 0.0553209\ttotal: 2m 3s\tremaining: 12.1s\n",
      "911:\tlearn: 0.0552805\ttotal: 2m 4s\tremaining: 12s\n",
      "912:\tlearn: 0.0552054\ttotal: 2m 4s\tremaining: 11.8s\n",
      "913:\tlearn: 0.0552054\ttotal: 2m 4s\tremaining: 11.7s\n",
      "914:\tlearn: 0.0551881\ttotal: 2m 4s\tremaining: 11.6s\n",
      "915:\tlearn: 0.0551766\ttotal: 2m 4s\tremaining: 11.4s\n",
      "916:\tlearn: 0.0551189\ttotal: 2m 4s\tremaining: 11.3s\n",
      "917:\tlearn: 0.0550843\ttotal: 2m 4s\tremaining: 11.2s\n",
      "918:\tlearn: 0.0549861\ttotal: 2m 4s\tremaining: 11s\n",
      "919:\tlearn: 0.0549919\ttotal: 2m 5s\tremaining: 10.9s\n",
      "920:\tlearn: 0.0549458\ttotal: 2m 5s\tremaining: 10.7s\n",
      "921:\tlearn: 0.0549111\ttotal: 2m 5s\tremaining: 10.6s\n",
      "922:\tlearn: 0.0548938\ttotal: 2m 5s\tremaining: 10.5s\n",
      "923:\tlearn: 0.0548246\ttotal: 2m 5s\tremaining: 10.3s\n",
      "924:\tlearn: 0.0547553\ttotal: 2m 5s\tremaining: 10.2s\n",
      "925:\tlearn: 0.0547265\ttotal: 2m 5s\tremaining: 10.1s\n",
      "926:\tlearn: 0.0546803\ttotal: 2m 6s\tremaining: 9.93s\n",
      "927:\tlearn: 0.0546168\ttotal: 2m 6s\tremaining: 9.79s\n",
      "928:\tlearn: 0.0545706\ttotal: 2m 6s\tremaining: 9.65s\n",
      "929:\tlearn: 0.0545880\ttotal: 2m 6s\tremaining: 9.52s\n",
      "930:\tlearn: 0.0545764\ttotal: 2m 6s\tremaining: 9.38s\n",
      "931:\tlearn: 0.0545129\ttotal: 2m 6s\tremaining: 9.24s\n",
      "932:\tlearn: 0.0544552\ttotal: 2m 6s\tremaining: 9.11s\n",
      "933:\tlearn: 0.0543975\ttotal: 2m 6s\tremaining: 8.97s\n",
      "934:\tlearn: 0.0543744\ttotal: 2m 7s\tremaining: 8.84s\n",
      "935:\tlearn: 0.0543802\ttotal: 2m 7s\tremaining: 8.7s\n",
      "936:\tlearn: 0.0543917\ttotal: 2m 7s\tremaining: 8.56s\n",
      "937:\tlearn: 0.0543571\ttotal: 2m 7s\tremaining: 8.43s\n",
      "938:\tlearn: 0.0543283\ttotal: 2m 7s\tremaining: 8.29s\n",
      "939:\tlearn: 0.0542821\ttotal: 2m 7s\tremaining: 8.16s\n",
      "940:\tlearn: 0.0541955\ttotal: 2m 7s\tremaining: 8.02s\n",
      "941:\tlearn: 0.0542301\ttotal: 2m 8s\tremaining: 7.88s\n",
      "942:\tlearn: 0.0541955\ttotal: 2m 8s\tremaining: 7.75s\n",
      "943:\tlearn: 0.0541609\ttotal: 2m 8s\tremaining: 7.61s\n",
      "944:\tlearn: 0.0541436\ttotal: 2m 8s\tremaining: 7.47s\n",
      "945:\tlearn: 0.0540743\ttotal: 2m 8s\tremaining: 7.34s\n",
      "946:\tlearn: 0.0540339\ttotal: 2m 8s\tremaining: 7.21s\n",
      "947:\tlearn: 0.0540108\ttotal: 2m 8s\tremaining: 7.07s\n",
      "948:\tlearn: 0.0539820\ttotal: 2m 9s\tremaining: 6.93s\n",
      "949:\tlearn: 0.0539358\ttotal: 2m 9s\tremaining: 6.8s\n",
      "950:\tlearn: 0.0538839\ttotal: 2m 9s\tremaining: 6.66s\n",
      "951:\tlearn: 0.0539070\ttotal: 2m 9s\tremaining: 6.53s\n",
      "952:\tlearn: 0.0538839\ttotal: 2m 9s\tremaining: 6.39s\n",
      "953:\tlearn: 0.0538319\ttotal: 2m 9s\tremaining: 6.25s\n",
      "954:\tlearn: 0.0537858\ttotal: 2m 9s\tremaining: 6.12s\n",
      "955:\tlearn: 0.0537512\ttotal: 2m 10s\tremaining: 5.98s\n",
      "956:\tlearn: 0.0537338\ttotal: 2m 10s\tremaining: 5.85s\n",
      "957:\tlearn: 0.0537454\ttotal: 2m 10s\tremaining: 5.71s\n",
      "958:\tlearn: 0.0537108\ttotal: 2m 10s\tremaining: 5.58s\n",
      "959:\tlearn: 0.0536877\ttotal: 2m 10s\tremaining: 5.44s\n",
      "960:\tlearn: 0.0536473\ttotal: 2m 10s\tremaining: 5.3s\n",
      "961:\tlearn: 0.0536011\ttotal: 2m 10s\tremaining: 5.17s\n",
      "962:\tlearn: 0.0535665\ttotal: 2m 10s\tremaining: 5.03s\n",
      "963:\tlearn: 0.0535896\ttotal: 2m 11s\tremaining: 4.9s\n",
      "964:\tlearn: 0.0535896\ttotal: 2m 11s\tremaining: 4.76s\n",
      "965:\tlearn: 0.0535434\ttotal: 2m 11s\tremaining: 4.63s\n",
      "966:\tlearn: 0.0535088\ttotal: 2m 11s\tremaining: 4.49s\n",
      "967:\tlearn: 0.0534568\ttotal: 2m 11s\tremaining: 4.35s\n",
      "968:\tlearn: 0.0534049\ttotal: 2m 11s\tremaining: 4.22s\n",
      "969:\tlearn: 0.0533645\ttotal: 2m 11s\tremaining: 4.08s\n",
      "970:\tlearn: 0.0533760\ttotal: 2m 12s\tremaining: 3.94s\n",
      "971:\tlearn: 0.0533530\ttotal: 2m 12s\tremaining: 3.81s\n",
      "972:\tlearn: 0.0533241\ttotal: 2m 12s\tremaining: 3.67s\n",
      "973:\tlearn: 0.0532952\ttotal: 2m 12s\tremaining: 3.54s\n",
      "974:\tlearn: 0.0532895\ttotal: 2m 12s\tremaining: 3.4s\n",
      "975:\tlearn: 0.0532722\ttotal: 2m 12s\tremaining: 3.26s\n",
      "976:\tlearn: 0.0532548\ttotal: 2m 12s\tremaining: 3.13s\n",
      "977:\tlearn: 0.0532375\ttotal: 2m 13s\tremaining: 2.99s\n",
      "978:\tlearn: 0.0532375\ttotal: 2m 13s\tremaining: 2.86s\n",
      "979:\tlearn: 0.0532087\ttotal: 2m 13s\tremaining: 2.72s\n",
      "980:\tlearn: 0.0531798\ttotal: 2m 13s\tremaining: 2.58s\n",
      "981:\tlearn: 0.0531567\ttotal: 2m 13s\tremaining: 2.45s\n",
      "982:\tlearn: 0.0531279\ttotal: 2m 13s\tremaining: 2.31s\n",
      "983:\tlearn: 0.0531221\ttotal: 2m 13s\tremaining: 2.17s\n",
      "984:\tlearn: 0.0530817\ttotal: 2m 13s\tremaining: 2.04s\n",
      "985:\tlearn: 0.0530182\ttotal: 2m 14s\tremaining: 1.9s\n",
      "986:\tlearn: 0.0530240\ttotal: 2m 14s\tremaining: 1.77s\n",
      "987:\tlearn: 0.0530067\ttotal: 2m 14s\tremaining: 1.63s\n",
      "988:\tlearn: 0.0528970\ttotal: 2m 14s\tremaining: 1.5s\n",
      "989:\tlearn: 0.0528855\ttotal: 2m 14s\tremaining: 1.36s\n",
      "990:\tlearn: 0.0528624\ttotal: 2m 14s\tremaining: 1.22s\n",
      "991:\tlearn: 0.0528278\ttotal: 2m 15s\tremaining: 1.09s\n",
      "992:\tlearn: 0.0528451\ttotal: 2m 15s\tremaining: 953ms\n",
      "993:\tlearn: 0.0528509\ttotal: 2m 15s\tremaining: 817ms\n",
      "994:\tlearn: 0.0528509\ttotal: 2m 15s\tremaining: 681ms\n",
      "995:\tlearn: 0.0527470\ttotal: 2m 15s\tremaining: 545ms\n",
      "996:\tlearn: 0.0527239\ttotal: 2m 15s\tremaining: 409ms\n",
      "997:\tlearn: 0.0526893\ttotal: 2m 15s\tremaining: 272ms\n",
      "998:\tlearn: 0.0526951\ttotal: 2m 16s\tremaining: 136ms\n",
      "999:\tlearn: 0.0526489\ttotal: 2m 16s\tremaining: 0us\n",
      "Learning rate set to 0.026476\n",
      "0:\tlearn: 0.1094933\ttotal: 159ms\tremaining: 2m 38s\n",
      "1:\tlearn: 0.1100877\ttotal: 305ms\tremaining: 2m 32s\n",
      "2:\tlearn: 0.1108091\ttotal: 452ms\tremaining: 2m 30s\n",
      "3:\tlearn: 0.1109014\ttotal: 555ms\tremaining: 2m 18s\n",
      "4:\tlearn: 0.1109765\ttotal: 711ms\tremaining: 2m 21s\n",
      "5:\tlearn: 0.1111034\ttotal: 853ms\tremaining: 2m 21s\n",
      "6:\tlearn: 0.1110399\ttotal: 984ms\tremaining: 2m 19s\n",
      "7:\tlearn: 0.1111438\ttotal: 1.12s\tremaining: 2m 18s\n",
      "8:\tlearn: 0.1111265\ttotal: 1.25s\tremaining: 2m 17s\n",
      "9:\tlearn: 0.1111092\ttotal: 1.38s\tremaining: 2m 16s\n",
      "10:\tlearn: 0.1110572\ttotal: 1.51s\tremaining: 2m 15s\n",
      "11:\tlearn: 0.1109187\ttotal: 1.64s\tremaining: 2m 14s\n",
      "12:\tlearn: 0.1109130\ttotal: 1.77s\tremaining: 2m 14s\n",
      "13:\tlearn: 0.1107052\ttotal: 1.9s\tremaining: 2m 13s\n",
      "14:\tlearn: 0.1107052\ttotal: 2.02s\tremaining: 2m 12s\n",
      "15:\tlearn: 0.1106475\ttotal: 2.15s\tremaining: 2m 12s\n",
      "16:\tlearn: 0.1107341\ttotal: 2.28s\tremaining: 2m 12s\n",
      "17:\tlearn: 0.1108264\ttotal: 2.41s\tremaining: 2m 11s\n",
      "18:\tlearn: 0.1107572\ttotal: 2.54s\tremaining: 2m 11s\n",
      "19:\tlearn: 0.1107398\ttotal: 2.67s\tremaining: 2m 11s\n",
      "20:\tlearn: 0.1107052\ttotal: 2.8s\tremaining: 2m 10s\n",
      "21:\tlearn: 0.1106187\ttotal: 2.96s\tremaining: 2m 11s\n",
      "22:\tlearn: 0.1105956\ttotal: 3.09s\tremaining: 2m 11s\n",
      "23:\tlearn: 0.1105725\ttotal: 3.15s\tremaining: 2m 8s\n",
      "24:\tlearn: 0.1104975\ttotal: 3.28s\tremaining: 2m 8s\n",
      "25:\tlearn: 0.1103820\ttotal: 3.41s\tremaining: 2m 7s\n",
      "26:\tlearn: 0.1103705\ttotal: 3.55s\tremaining: 2m 7s\n",
      "27:\tlearn: 0.1103301\ttotal: 3.67s\tremaining: 2m 7s\n",
      "28:\tlearn: 0.1103128\ttotal: 3.81s\tremaining: 2m 7s\n",
      "29:\tlearn: 0.1103359\ttotal: 3.94s\tremaining: 2m 7s\n",
      "30:\tlearn: 0.1103359\ttotal: 4.08s\tremaining: 2m 7s\n",
      "31:\tlearn: 0.1103243\ttotal: 4.21s\tremaining: 2m 7s\n",
      "32:\tlearn: 0.1102493\ttotal: 4.31s\tremaining: 2m 6s\n",
      "33:\tlearn: 0.1102378\ttotal: 4.44s\tremaining: 2m 6s\n",
      "34:\tlearn: 0.1102205\ttotal: 4.58s\tremaining: 2m 6s\n",
      "35:\tlearn: 0.1101743\ttotal: 4.71s\tremaining: 2m 6s\n",
      "36:\tlearn: 0.1099838\ttotal: 4.84s\tremaining: 2m 5s\n",
      "37:\tlearn: 0.1097645\ttotal: 4.97s\tremaining: 2m 5s\n",
      "38:\tlearn: 0.1097530\ttotal: 5.1s\tremaining: 2m 5s\n",
      "39:\tlearn: 0.1097299\ttotal: 5.23s\tremaining: 2m 5s\n",
      "40:\tlearn: 0.1095106\ttotal: 5.37s\tremaining: 2m 5s\n",
      "41:\tlearn: 0.1093202\ttotal: 5.5s\tremaining: 2m 5s\n",
      "42:\tlearn: 0.1093259\ttotal: 5.66s\tremaining: 2m 5s\n",
      "43:\tlearn: 0.1091355\ttotal: 5.84s\tremaining: 2m 6s\n",
      "44:\tlearn: 0.1090259\ttotal: 6s\tremaining: 2m 7s\n",
      "45:\tlearn: 0.1089162\ttotal: 6.14s\tremaining: 2m 7s\n",
      "46:\tlearn: 0.1087662\ttotal: 6.29s\tremaining: 2m 7s\n",
      "47:\tlearn: 0.1086969\ttotal: 6.43s\tremaining: 2m 7s\n",
      "48:\tlearn: 0.1085988\ttotal: 6.58s\tremaining: 2m 7s\n",
      "49:\tlearn: 0.1084892\ttotal: 6.73s\tremaining: 2m 7s\n",
      "50:\tlearn: 0.1084488\ttotal: 6.89s\tremaining: 2m 8s\n",
      "51:\tlearn: 0.1082468\ttotal: 7.06s\tremaining: 2m 8s\n",
      "52:\tlearn: 0.1081602\ttotal: 7.23s\tremaining: 2m 9s\n",
      "53:\tlearn: 0.1080910\ttotal: 7.41s\tremaining: 2m 9s\n",
      "54:\tlearn: 0.1079698\ttotal: 7.59s\tremaining: 2m 10s\n",
      "55:\tlearn: 0.1077966\ttotal: 7.75s\tremaining: 2m 10s\n",
      "56:\tlearn: 0.1077966\ttotal: 7.92s\tremaining: 2m 11s\n",
      "57:\tlearn: 0.1076350\ttotal: 8.07s\tremaining: 2m 11s\n",
      "58:\tlearn: 0.1075946\ttotal: 8.23s\tremaining: 2m 11s\n",
      "59:\tlearn: 0.1075946\ttotal: 8.39s\tremaining: 2m 11s\n",
      "60:\tlearn: 0.1074677\ttotal: 8.55s\tremaining: 2m 11s\n",
      "61:\tlearn: 0.1072715\ttotal: 8.71s\tremaining: 2m 11s\n",
      "62:\tlearn: 0.1071676\ttotal: 8.88s\tremaining: 2m 12s\n",
      "63:\tlearn: 0.1069945\ttotal: 9.04s\tremaining: 2m 12s\n",
      "64:\tlearn: 0.1068271\ttotal: 9.2s\tremaining: 2m 12s\n",
      "65:\tlearn: 0.1067694\ttotal: 9.37s\tremaining: 2m 12s\n",
      "66:\tlearn: 0.1066424\ttotal: 9.52s\tremaining: 2m 12s\n",
      "67:\tlearn: 0.1065559\ttotal: 9.69s\tremaining: 2m 12s\n",
      "68:\tlearn: 0.1063943\ttotal: 9.85s\tremaining: 2m 12s\n",
      "69:\tlearn: 0.1062962\ttotal: 10s\tremaining: 2m 12s\n",
      "70:\tlearn: 0.1061173\ttotal: 10.1s\tremaining: 2m 12s\n",
      "71:\tlearn: 0.1059499\ttotal: 10.3s\tremaining: 2m 13s\n",
      "72:\tlearn: 0.1058633\ttotal: 10.6s\tremaining: 2m 14s\n",
      "73:\tlearn: 0.1058518\ttotal: 10.8s\tremaining: 2m 14s\n",
      "74:\tlearn: 0.1057018\ttotal: 11s\tremaining: 2m 15s\n",
      "75:\tlearn: 0.1055402\ttotal: 11.1s\tremaining: 2m 15s\n",
      "76:\tlearn: 0.1054190\ttotal: 11.3s\tremaining: 2m 15s\n",
      "77:\tlearn: 0.1053497\ttotal: 11.5s\tremaining: 2m 16s\n",
      "78:\tlearn: 0.1050727\ttotal: 11.7s\tremaining: 2m 16s\n",
      "79:\tlearn: 0.1049054\ttotal: 11.9s\tremaining: 2m 16s\n",
      "80:\tlearn: 0.1046918\ttotal: 12s\tremaining: 2m 16s\n",
      "81:\tlearn: 0.1044725\ttotal: 12.2s\tremaining: 2m 16s\n",
      "82:\tlearn: 0.1042244\ttotal: 12.3s\tremaining: 2m 16s\n",
      "83:\tlearn: 0.1041205\ttotal: 12.5s\tremaining: 2m 15s\n",
      "84:\tlearn: 0.1039935\ttotal: 12.6s\tremaining: 2m 15s\n",
      "85:\tlearn: 0.1037338\ttotal: 12.7s\tremaining: 2m 15s\n",
      "86:\tlearn: 0.1036704\ttotal: 12.9s\tremaining: 2m 15s\n",
      "87:\tlearn: 0.1034337\ttotal: 13s\tremaining: 2m 14s\n",
      "88:\tlearn: 0.1032779\ttotal: 13.1s\tremaining: 2m 14s\n",
      "89:\tlearn: 0.1031914\ttotal: 13.3s\tremaining: 2m 14s\n",
      "90:\tlearn: 0.1030817\ttotal: 13.4s\tremaining: 2m 13s\n",
      "91:\tlearn: 0.1030298\ttotal: 13.5s\tremaining: 2m 13s\n",
      "92:\tlearn: 0.1028566\ttotal: 13.7s\tremaining: 2m 13s\n",
      "93:\tlearn: 0.1027989\ttotal: 13.8s\tremaining: 2m 13s\n",
      "94:\tlearn: 0.1026373\ttotal: 13.9s\tremaining: 2m 12s\n",
      "95:\tlearn: 0.1025104\ttotal: 14.1s\tremaining: 2m 12s\n",
      "96:\tlearn: 0.1022911\ttotal: 14.2s\tremaining: 2m 12s\n",
      "97:\tlearn: 0.1022103\ttotal: 14.3s\tremaining: 2m 12s\n",
      "98:\tlearn: 0.1021872\ttotal: 14.5s\tremaining: 2m 11s\n",
      "99:\tlearn: 0.1020256\ttotal: 14.6s\tremaining: 2m 11s\n",
      "100:\tlearn: 0.1018121\ttotal: 14.7s\tremaining: 2m 11s\n",
      "101:\tlearn: 0.1017544\ttotal: 14.9s\tremaining: 2m 10s\n",
      "102:\tlearn: 0.1015813\ttotal: 15s\tremaining: 2m 10s\n",
      "103:\tlearn: 0.1013850\ttotal: 15.1s\tremaining: 2m 10s\n",
      "104:\tlearn: 0.1013100\ttotal: 15.3s\tremaining: 2m 10s\n",
      "105:\tlearn: 0.1013966\ttotal: 15.4s\tremaining: 2m 10s\n",
      "106:\tlearn: 0.1011542\ttotal: 15.5s\tremaining: 2m 9s\n",
      "107:\tlearn: 0.1010446\ttotal: 15.7s\tremaining: 2m 9s\n",
      "108:\tlearn: 0.1009522\ttotal: 15.8s\tremaining: 2m 9s\n",
      "109:\tlearn: 0.1008022\ttotal: 15.9s\tremaining: 2m 9s\n",
      "110:\tlearn: 0.1006406\ttotal: 16.1s\tremaining: 2m 8s\n",
      "111:\tlearn: 0.1005713\ttotal: 16.2s\tremaining: 2m 8s\n",
      "112:\tlearn: 0.1004501\ttotal: 16.4s\tremaining: 2m 8s\n",
      "113:\tlearn: 0.1002655\ttotal: 16.5s\tremaining: 2m 8s\n",
      "114:\tlearn: 0.1001847\ttotal: 16.6s\tremaining: 2m 7s\n",
      "115:\tlearn: 0.1000346\ttotal: 16.8s\tremaining: 2m 7s\n",
      "116:\tlearn: 0.0999481\ttotal: 16.9s\tremaining: 2m 7s\n",
      "117:\tlearn: 0.0997749\ttotal: 17s\tremaining: 2m 7s\n",
      "118:\tlearn: 0.0995903\ttotal: 17.2s\tremaining: 2m 7s\n",
      "119:\tlearn: 0.0995325\ttotal: 17.3s\tremaining: 2m 6s\n",
      "120:\tlearn: 0.0994518\ttotal: 17.4s\tremaining: 2m 6s\n",
      "121:\tlearn: 0.0992729\ttotal: 17.6s\tremaining: 2m 6s\n",
      "122:\tlearn: 0.0991921\ttotal: 17.7s\tremaining: 2m 6s\n",
      "123:\tlearn: 0.0990940\ttotal: 17.8s\tremaining: 2m 5s\n",
      "124:\tlearn: 0.0990247\ttotal: 18s\tremaining: 2m 5s\n",
      "125:\tlearn: 0.0989439\ttotal: 18.1s\tremaining: 2m 5s\n",
      "126:\tlearn: 0.0986784\ttotal: 18.2s\tremaining: 2m 5s\n",
      "127:\tlearn: 0.0985976\ttotal: 18.4s\tremaining: 2m 5s\n",
      "128:\tlearn: 0.0984707\ttotal: 18.5s\tremaining: 2m 4s\n",
      "129:\tlearn: 0.0983841\ttotal: 18.6s\tremaining: 2m 4s\n",
      "130:\tlearn: 0.0982976\ttotal: 18.8s\tremaining: 2m 4s\n",
      "131:\tlearn: 0.0983033\ttotal: 18.9s\tremaining: 2m 4s\n",
      "132:\tlearn: 0.0981302\ttotal: 19s\tremaining: 2m 4s\n",
      "133:\tlearn: 0.0980205\ttotal: 19.2s\tremaining: 2m 3s\n",
      "134:\tlearn: 0.0979975\ttotal: 19.3s\tremaining: 2m 3s\n",
      "135:\tlearn: 0.0979455\ttotal: 19.4s\tremaining: 2m 3s\n",
      "136:\tlearn: 0.0978590\ttotal: 19.6s\tremaining: 2m 3s\n",
      "137:\tlearn: 0.0977724\ttotal: 19.7s\tremaining: 2m 3s\n",
      "138:\tlearn: 0.0977205\ttotal: 19.8s\tremaining: 2m 2s\n",
      "139:\tlearn: 0.0975993\ttotal: 20s\tremaining: 2m 2s\n",
      "140:\tlearn: 0.0974723\ttotal: 20.1s\tremaining: 2m 2s\n",
      "141:\tlearn: 0.0974723\ttotal: 20.2s\tremaining: 2m 2s\n",
      "142:\tlearn: 0.0972645\ttotal: 20.4s\tremaining: 2m 2s\n",
      "143:\tlearn: 0.0971203\ttotal: 20.5s\tremaining: 2m 1s\n",
      "144:\tlearn: 0.0970222\ttotal: 20.6s\tremaining: 2m 1s\n",
      "145:\tlearn: 0.0969067\ttotal: 20.8s\tremaining: 2m 1s\n",
      "146:\tlearn: 0.0968144\ttotal: 20.9s\tremaining: 2m 1s\n",
      "147:\tlearn: 0.0966701\ttotal: 21s\tremaining: 2m 1s\n",
      "148:\tlearn: 0.0965489\ttotal: 21.2s\tremaining: 2m\n",
      "149:\tlearn: 0.0964681\ttotal: 21.3s\tremaining: 2m\n",
      "150:\tlearn: 0.0963643\ttotal: 21.5s\tremaining: 2m\n",
      "151:\tlearn: 0.0963239\ttotal: 21.6s\tremaining: 2m\n",
      "152:\tlearn: 0.0962719\ttotal: 21.7s\tremaining: 2m\n",
      "153:\tlearn: 0.0962488\ttotal: 21.9s\tremaining: 2m\n",
      "154:\tlearn: 0.0961623\ttotal: 22s\tremaining: 1m 59s\n",
      "155:\tlearn: 0.0960873\ttotal: 22.2s\tremaining: 1m 59s\n",
      "156:\tlearn: 0.0960238\ttotal: 22.3s\tremaining: 1m 59s\n",
      "157:\tlearn: 0.0959430\ttotal: 22.4s\tremaining: 1m 59s\n",
      "158:\tlearn: 0.0958218\ttotal: 22.6s\tremaining: 1m 59s\n",
      "159:\tlearn: 0.0957699\ttotal: 22.7s\tremaining: 1m 59s\n",
      "160:\tlearn: 0.0956544\ttotal: 22.8s\tremaining: 1m 59s\n",
      "161:\tlearn: 0.0955967\ttotal: 23s\tremaining: 1m 58s\n",
      "162:\tlearn: 0.0955448\ttotal: 23.1s\tremaining: 1m 58s\n",
      "163:\tlearn: 0.0954524\ttotal: 23.2s\tremaining: 1m 58s\n",
      "164:\tlearn: 0.0952966\ttotal: 23.4s\tremaining: 1m 58s\n",
      "165:\tlearn: 0.0951812\ttotal: 23.5s\tremaining: 1m 58s\n",
      "166:\tlearn: 0.0950658\ttotal: 23.6s\tremaining: 1m 57s\n",
      "167:\tlearn: 0.0949273\ttotal: 23.8s\tremaining: 1m 57s\n",
      "168:\tlearn: 0.0948349\ttotal: 24s\tremaining: 1m 57s\n",
      "169:\tlearn: 0.0947311\ttotal: 24.2s\tremaining: 1m 58s\n",
      "170:\tlearn: 0.0946849\ttotal: 24.5s\tremaining: 1m 58s\n",
      "171:\tlearn: 0.0946445\ttotal: 24.7s\tremaining: 1m 59s\n",
      "172:\tlearn: 0.0945868\ttotal: 24.9s\tremaining: 1m 59s\n",
      "173:\tlearn: 0.0945060\ttotal: 25.1s\tremaining: 1m 59s\n",
      "174:\tlearn: 0.0944310\ttotal: 25.3s\tremaining: 1m 59s\n",
      "175:\tlearn: 0.0943386\ttotal: 25.4s\tremaining: 1m 59s\n",
      "176:\tlearn: 0.0942982\ttotal: 25.6s\tremaining: 1m 58s\n",
      "177:\tlearn: 0.0942809\ttotal: 25.7s\tremaining: 1m 58s\n",
      "178:\tlearn: 0.0941828\ttotal: 25.9s\tremaining: 1m 58s\n",
      "179:\tlearn: 0.0941482\ttotal: 26s\tremaining: 1m 58s\n",
      "180:\tlearn: 0.0940270\ttotal: 26.2s\tremaining: 1m 58s\n",
      "181:\tlearn: 0.0938943\ttotal: 26.3s\tremaining: 1m 58s\n",
      "182:\tlearn: 0.0938077\ttotal: 26.4s\tremaining: 1m 58s\n",
      "183:\tlearn: 0.0937962\ttotal: 26.6s\tremaining: 1m 57s\n",
      "184:\tlearn: 0.0937154\ttotal: 26.7s\tremaining: 1m 57s\n",
      "185:\tlearn: 0.0936461\ttotal: 26.8s\tremaining: 1m 57s\n",
      "186:\tlearn: 0.0936865\ttotal: 27s\tremaining: 1m 57s\n",
      "187:\tlearn: 0.0936577\ttotal: 27.1s\tremaining: 1m 57s\n",
      "188:\tlearn: 0.0935365\ttotal: 27.2s\tremaining: 1m 56s\n",
      "189:\tlearn: 0.0935076\ttotal: 27.4s\tremaining: 1m 56s\n",
      "190:\tlearn: 0.0933691\ttotal: 27.5s\tremaining: 1m 56s\n",
      "191:\tlearn: 0.0932422\ttotal: 27.6s\tremaining: 1m 56s\n",
      "192:\tlearn: 0.0931729\ttotal: 27.8s\tremaining: 1m 56s\n",
      "193:\tlearn: 0.0931210\ttotal: 27.9s\tremaining: 1m 55s\n",
      "194:\tlearn: 0.0930748\ttotal: 28s\tremaining: 1m 55s\n",
      "195:\tlearn: 0.0930229\ttotal: 28.2s\tremaining: 1m 55s\n",
      "196:\tlearn: 0.0929651\ttotal: 28.3s\tremaining: 1m 55s\n",
      "197:\tlearn: 0.0929074\ttotal: 28.4s\tremaining: 1m 55s\n",
      "198:\tlearn: 0.0928266\ttotal: 28.6s\tremaining: 1m 55s\n",
      "199:\tlearn: 0.0927689\ttotal: 28.7s\tremaining: 1m 54s\n",
      "200:\tlearn: 0.0926881\ttotal: 28.8s\tremaining: 1m 54s\n",
      "201:\tlearn: 0.0925843\ttotal: 29s\tremaining: 1m 54s\n",
      "202:\tlearn: 0.0925612\ttotal: 29.1s\tremaining: 1m 54s\n",
      "203:\tlearn: 0.0923938\ttotal: 29.2s\tremaining: 1m 54s\n",
      "204:\tlearn: 0.0923707\ttotal: 29.4s\tremaining: 1m 53s\n",
      "205:\tlearn: 0.0923361\ttotal: 29.5s\tremaining: 1m 53s\n",
      "206:\tlearn: 0.0923303\ttotal: 29.6s\tremaining: 1m 53s\n",
      "207:\tlearn: 0.0921976\ttotal: 29.8s\tremaining: 1m 53s\n",
      "208:\tlearn: 0.0921803\ttotal: 29.9s\tremaining: 1m 53s\n",
      "209:\tlearn: 0.0921572\ttotal: 30s\tremaining: 1m 53s\n",
      "210:\tlearn: 0.0920476\ttotal: 30.2s\tremaining: 1m 52s\n",
      "211:\tlearn: 0.0920302\ttotal: 30.3s\tremaining: 1m 52s\n",
      "212:\tlearn: 0.0919552\ttotal: 30.5s\tremaining: 1m 52s\n",
      "213:\tlearn: 0.0919206\ttotal: 30.6s\tremaining: 1m 52s\n",
      "214:\tlearn: 0.0917936\ttotal: 30.7s\tremaining: 1m 52s\n",
      "215:\tlearn: 0.0916667\ttotal: 30.9s\tremaining: 1m 52s\n",
      "216:\tlearn: 0.0916032\ttotal: 31s\tremaining: 1m 51s\n",
      "217:\tlearn: 0.0916147\ttotal: 31.1s\tremaining: 1m 51s\n",
      "218:\tlearn: 0.0915974\ttotal: 31.3s\tremaining: 1m 51s\n",
      "219:\tlearn: 0.0915339\ttotal: 31.4s\tremaining: 1m 51s\n",
      "220:\tlearn: 0.0914878\ttotal: 31.5s\tremaining: 1m 51s\n",
      "221:\tlearn: 0.0914705\ttotal: 31.7s\tremaining: 1m 50s\n",
      "222:\tlearn: 0.0913781\ttotal: 31.8s\tremaining: 1m 50s\n",
      "223:\tlearn: 0.0913089\ttotal: 31.9s\tremaining: 1m 50s\n",
      "224:\tlearn: 0.0912512\ttotal: 32.1s\tremaining: 1m 50s\n",
      "225:\tlearn: 0.0910665\ttotal: 32.2s\tremaining: 1m 50s\n",
      "226:\tlearn: 0.0910145\ttotal: 32.3s\tremaining: 1m 50s\n",
      "227:\tlearn: 0.0910088\ttotal: 32.5s\tremaining: 1m 49s\n",
      "228:\tlearn: 0.0908934\ttotal: 32.6s\tremaining: 1m 49s\n",
      "229:\tlearn: 0.0908587\ttotal: 32.7s\tremaining: 1m 49s\n",
      "230:\tlearn: 0.0907491\ttotal: 32.9s\tremaining: 1m 49s\n",
      "231:\tlearn: 0.0906452\ttotal: 33s\tremaining: 1m 49s\n",
      "232:\tlearn: 0.0905529\ttotal: 33.1s\tremaining: 1m 49s\n",
      "233:\tlearn: 0.0905009\ttotal: 33.3s\tremaining: 1m 48s\n",
      "234:\tlearn: 0.0904548\ttotal: 33.4s\tremaining: 1m 48s\n",
      "235:\tlearn: 0.0903278\ttotal: 33.5s\tremaining: 1m 48s\n",
      "236:\tlearn: 0.0902874\ttotal: 33.7s\tremaining: 1m 48s\n",
      "237:\tlearn: 0.0902181\ttotal: 33.8s\tremaining: 1m 48s\n",
      "238:\tlearn: 0.0901604\ttotal: 33.9s\tremaining: 1m 48s\n",
      "239:\tlearn: 0.0901431\ttotal: 34.1s\tremaining: 1m 47s\n",
      "240:\tlearn: 0.0901258\ttotal: 34.2s\tremaining: 1m 47s\n",
      "241:\tlearn: 0.0899700\ttotal: 34.4s\tremaining: 1m 47s\n",
      "242:\tlearn: 0.0899931\ttotal: 34.5s\tremaining: 1m 47s\n",
      "243:\tlearn: 0.0899469\ttotal: 34.6s\tremaining: 1m 47s\n",
      "244:\tlearn: 0.0899469\ttotal: 34.8s\tremaining: 1m 47s\n",
      "245:\tlearn: 0.0898777\ttotal: 34.9s\tremaining: 1m 47s\n",
      "246:\tlearn: 0.0898546\ttotal: 35s\tremaining: 1m 46s\n",
      "247:\tlearn: 0.0898199\ttotal: 35.2s\tremaining: 1m 46s\n",
      "248:\tlearn: 0.0897795\ttotal: 35.3s\tremaining: 1m 46s\n",
      "249:\tlearn: 0.0896584\ttotal: 35.4s\tremaining: 1m 46s\n",
      "250:\tlearn: 0.0894852\ttotal: 35.6s\tremaining: 1m 46s\n",
      "251:\tlearn: 0.0894506\ttotal: 35.7s\tremaining: 1m 46s\n",
      "252:\tlearn: 0.0893929\ttotal: 35.9s\tremaining: 1m 45s\n",
      "253:\tlearn: 0.0893525\ttotal: 36s\tremaining: 1m 45s\n",
      "254:\tlearn: 0.0893006\ttotal: 36.1s\tremaining: 1m 45s\n",
      "255:\tlearn: 0.0892486\ttotal: 36.2s\tremaining: 1m 45s\n",
      "256:\tlearn: 0.0891447\ttotal: 36.4s\tremaining: 1m 45s\n",
      "257:\tlearn: 0.0891678\ttotal: 36.5s\tremaining: 1m 44s\n",
      "258:\tlearn: 0.0890697\ttotal: 36.6s\tremaining: 1m 44s\n",
      "259:\tlearn: 0.0890813\ttotal: 36.8s\tremaining: 1m 44s\n",
      "260:\tlearn: 0.0890466\ttotal: 36.9s\tremaining: 1m 44s\n",
      "261:\tlearn: 0.0890062\ttotal: 37.1s\tremaining: 1m 44s\n",
      "262:\tlearn: 0.0889139\ttotal: 37.2s\tremaining: 1m 44s\n",
      "263:\tlearn: 0.0887639\ttotal: 37.4s\tremaining: 1m 44s\n",
      "264:\tlearn: 0.0886484\ttotal: 37.5s\tremaining: 1m 44s\n",
      "265:\tlearn: 0.0886427\ttotal: 37.6s\tremaining: 1m 43s\n",
      "266:\tlearn: 0.0885734\ttotal: 37.8s\tremaining: 1m 43s\n",
      "267:\tlearn: 0.0885734\ttotal: 37.9s\tremaining: 1m 43s\n",
      "268:\tlearn: 0.0885446\ttotal: 38s\tremaining: 1m 43s\n",
      "269:\tlearn: 0.0884580\ttotal: 38.2s\tremaining: 1m 43s\n",
      "270:\tlearn: 0.0884118\ttotal: 38.3s\tremaining: 1m 43s\n",
      "271:\tlearn: 0.0883253\ttotal: 38.4s\tremaining: 1m 42s\n",
      "272:\tlearn: 0.0882849\ttotal: 38.6s\tremaining: 1m 42s\n",
      "273:\tlearn: 0.0882271\ttotal: 38.7s\tremaining: 1m 42s\n",
      "274:\tlearn: 0.0881694\ttotal: 38.8s\tremaining: 1m 42s\n",
      "275:\tlearn: 0.0881060\ttotal: 39s\tremaining: 1m 42s\n",
      "276:\tlearn: 0.0880771\ttotal: 39.1s\tremaining: 1m 42s\n",
      "277:\tlearn: 0.0880309\ttotal: 39.3s\tremaining: 1m 41s\n",
      "278:\tlearn: 0.0879444\ttotal: 39.4s\tremaining: 1m 41s\n",
      "279:\tlearn: 0.0878578\ttotal: 39.5s\tremaining: 1m 41s\n",
      "280:\tlearn: 0.0878578\ttotal: 39.7s\tremaining: 1m 41s\n",
      "281:\tlearn: 0.0878520\ttotal: 39.8s\tremaining: 1m 41s\n",
      "282:\tlearn: 0.0878059\ttotal: 39.9s\tremaining: 1m 41s\n",
      "283:\tlearn: 0.0877597\ttotal: 40.1s\tremaining: 1m 41s\n",
      "284:\tlearn: 0.0876904\ttotal: 40.2s\tremaining: 1m 40s\n",
      "285:\tlearn: 0.0876270\ttotal: 40.3s\tremaining: 1m 40s\n",
      "286:\tlearn: 0.0875808\ttotal: 40.5s\tremaining: 1m 40s\n",
      "287:\tlearn: 0.0875289\ttotal: 40.6s\tremaining: 1m 40s\n",
      "288:\tlearn: 0.0874423\ttotal: 40.8s\tremaining: 1m 40s\n",
      "289:\tlearn: 0.0874019\ttotal: 40.9s\tremaining: 1m 40s\n",
      "290:\tlearn: 0.0873730\ttotal: 41s\tremaining: 1m 39s\n",
      "291:\tlearn: 0.0873961\ttotal: 41.2s\tremaining: 1m 39s\n",
      "292:\tlearn: 0.0872518\ttotal: 41.3s\tremaining: 1m 39s\n",
      "293:\tlearn: 0.0871941\ttotal: 41.4s\tremaining: 1m 39s\n",
      "294:\tlearn: 0.0871422\ttotal: 41.6s\tremaining: 1m 39s\n",
      "295:\tlearn: 0.0870614\ttotal: 41.7s\tremaining: 1m 39s\n",
      "296:\tlearn: 0.0869460\ttotal: 41.8s\tremaining: 1m 39s\n",
      "297:\tlearn: 0.0868767\ttotal: 42s\tremaining: 1m 38s\n",
      "298:\tlearn: 0.0868017\ttotal: 42.1s\tremaining: 1m 38s\n",
      "299:\tlearn: 0.0867382\ttotal: 42.2s\tremaining: 1m 38s\n",
      "300:\tlearn: 0.0866863\ttotal: 42.4s\tremaining: 1m 38s\n",
      "301:\tlearn: 0.0866574\ttotal: 42.5s\tremaining: 1m 38s\n",
      "302:\tlearn: 0.0866228\ttotal: 42.6s\tremaining: 1m 38s\n",
      "303:\tlearn: 0.0865420\ttotal: 42.8s\tremaining: 1m 37s\n",
      "304:\tlearn: 0.0864670\ttotal: 42.9s\tremaining: 1m 37s\n",
      "305:\tlearn: 0.0863977\ttotal: 43s\tremaining: 1m 37s\n",
      "306:\tlearn: 0.0863689\ttotal: 43.2s\tremaining: 1m 37s\n",
      "307:\tlearn: 0.0863516\ttotal: 43.3s\tremaining: 1m 37s\n",
      "308:\tlearn: 0.0863343\ttotal: 43.4s\tremaining: 1m 37s\n",
      "309:\tlearn: 0.0862477\ttotal: 43.6s\tremaining: 1m 36s\n",
      "310:\tlearn: 0.0862304\ttotal: 43.7s\tremaining: 1m 36s\n",
      "311:\tlearn: 0.0861496\ttotal: 43.8s\tremaining: 1m 36s\n",
      "312:\tlearn: 0.0860803\ttotal: 44s\tremaining: 1m 36s\n",
      "313:\tlearn: 0.0860342\ttotal: 44.1s\tremaining: 1m 36s\n",
      "314:\tlearn: 0.0859765\ttotal: 44.3s\tremaining: 1m 36s\n",
      "315:\tlearn: 0.0859591\ttotal: 44.4s\tremaining: 1m 36s\n",
      "316:\tlearn: 0.0859707\ttotal: 44.5s\tremaining: 1m 35s\n",
      "317:\tlearn: 0.0859245\ttotal: 44.7s\tremaining: 1m 35s\n",
      "318:\tlearn: 0.0858380\ttotal: 44.8s\tremaining: 1m 35s\n",
      "319:\tlearn: 0.0857745\ttotal: 45s\tremaining: 1m 35s\n",
      "320:\tlearn: 0.0857341\ttotal: 45.1s\tremaining: 1m 35s\n",
      "321:\tlearn: 0.0856417\ttotal: 45.2s\tremaining: 1m 35s\n",
      "322:\tlearn: 0.0856129\ttotal: 45.4s\tremaining: 1m 35s\n",
      "323:\tlearn: 0.0855552\ttotal: 45.5s\tremaining: 1m 34s\n",
      "324:\tlearn: 0.0855263\ttotal: 45.6s\tremaining: 1m 34s\n",
      "325:\tlearn: 0.0855148\ttotal: 45.8s\tremaining: 1m 34s\n",
      "326:\tlearn: 0.0853878\ttotal: 45.9s\tremaining: 1m 34s\n",
      "327:\tlearn: 0.0853186\ttotal: 46s\tremaining: 1m 34s\n",
      "328:\tlearn: 0.0853532\ttotal: 46.2s\tremaining: 1m 34s\n",
      "329:\tlearn: 0.0852955\ttotal: 46.3s\tremaining: 1m 34s\n",
      "330:\tlearn: 0.0852782\ttotal: 46.4s\tremaining: 1m 33s\n",
      "331:\tlearn: 0.0851570\ttotal: 46.6s\tremaining: 1m 33s\n",
      "332:\tlearn: 0.0851166\ttotal: 46.7s\tremaining: 1m 33s\n",
      "333:\tlearn: 0.0851108\ttotal: 46.9s\tremaining: 1m 33s\n",
      "334:\tlearn: 0.0851339\ttotal: 47s\tremaining: 1m 33s\n",
      "335:\tlearn: 0.0851108\ttotal: 47.1s\tremaining: 1m 33s\n",
      "336:\tlearn: 0.0851339\ttotal: 47.3s\tremaining: 1m 32s\n",
      "337:\tlearn: 0.0850993\ttotal: 47.4s\tremaining: 1m 32s\n",
      "338:\tlearn: 0.0850069\ttotal: 47.5s\tremaining: 1m 32s\n",
      "339:\tlearn: 0.0849261\ttotal: 47.6s\tremaining: 1m 32s\n",
      "340:\tlearn: 0.0848857\ttotal: 47.8s\tremaining: 1m 32s\n",
      "341:\tlearn: 0.0848511\ttotal: 47.9s\tremaining: 1m 32s\n",
      "342:\tlearn: 0.0848338\ttotal: 48.1s\tremaining: 1m 32s\n",
      "343:\tlearn: 0.0847530\ttotal: 48.2s\tremaining: 1m 31s\n",
      "344:\tlearn: 0.0847645\ttotal: 48.3s\tremaining: 1m 31s\n",
      "345:\tlearn: 0.0846837\ttotal: 48.4s\tremaining: 1m 31s\n",
      "346:\tlearn: 0.0845683\ttotal: 48.6s\tremaining: 1m 31s\n",
      "347:\tlearn: 0.0845395\ttotal: 48.7s\tremaining: 1m 31s\n",
      "348:\tlearn: 0.0844702\ttotal: 48.8s\tremaining: 1m 31s\n",
      "349:\tlearn: 0.0844067\ttotal: 49s\tremaining: 1m 30s\n",
      "350:\tlearn: 0.0843433\ttotal: 49.1s\tremaining: 1m 30s\n",
      "351:\tlearn: 0.0842798\ttotal: 49.2s\tremaining: 1m 30s\n",
      "352:\tlearn: 0.0841817\ttotal: 49.4s\tremaining: 1m 30s\n",
      "353:\tlearn: 0.0841874\ttotal: 49.5s\tremaining: 1m 30s\n",
      "354:\tlearn: 0.0841470\ttotal: 49.6s\tremaining: 1m 30s\n",
      "355:\tlearn: 0.0840489\ttotal: 49.8s\tremaining: 1m 30s\n",
      "356:\tlearn: 0.0839277\ttotal: 49.9s\tremaining: 1m 29s\n",
      "357:\tlearn: 0.0838527\ttotal: 50s\tremaining: 1m 29s\n",
      "358:\tlearn: 0.0837604\ttotal: 50.2s\tremaining: 1m 29s\n",
      "359:\tlearn: 0.0837719\ttotal: 50.3s\tremaining: 1m 29s\n",
      "360:\tlearn: 0.0837892\ttotal: 50.5s\tremaining: 1m 29s\n",
      "361:\tlearn: 0.0837373\ttotal: 50.6s\tremaining: 1m 29s\n",
      "362:\tlearn: 0.0836969\ttotal: 50.7s\tremaining: 1m 29s\n",
      "363:\tlearn: 0.0836277\ttotal: 50.9s\tremaining: 1m 28s\n",
      "364:\tlearn: 0.0835815\ttotal: 51s\tremaining: 1m 28s\n",
      "365:\tlearn: 0.0836161\ttotal: 51.2s\tremaining: 1m 28s\n",
      "366:\tlearn: 0.0834718\ttotal: 51.3s\tremaining: 1m 28s\n",
      "367:\tlearn: 0.0834257\ttotal: 51.4s\tremaining: 1m 28s\n",
      "368:\tlearn: 0.0833910\ttotal: 51.6s\tremaining: 1m 28s\n",
      "369:\tlearn: 0.0833160\ttotal: 51.7s\tremaining: 1m 28s\n",
      "370:\tlearn: 0.0832872\ttotal: 51.8s\tremaining: 1m 27s\n",
      "371:\tlearn: 0.0832237\ttotal: 52s\tremaining: 1m 27s\n",
      "372:\tlearn: 0.0831256\ttotal: 52.1s\tremaining: 1m 27s\n",
      "373:\tlearn: 0.0830794\ttotal: 52.3s\tremaining: 1m 27s\n",
      "374:\tlearn: 0.0829755\ttotal: 52.4s\tremaining: 1m 27s\n",
      "375:\tlearn: 0.0829582\ttotal: 52.5s\tremaining: 1m 27s\n",
      "376:\tlearn: 0.0829524\ttotal: 52.7s\tremaining: 1m 27s\n",
      "377:\tlearn: 0.0828659\ttotal: 52.8s\tremaining: 1m 26s\n",
      "378:\tlearn: 0.0827909\ttotal: 52.9s\tremaining: 1m 26s\n",
      "379:\tlearn: 0.0827851\ttotal: 53.1s\tremaining: 1m 26s\n",
      "380:\tlearn: 0.0826581\ttotal: 53.2s\tremaining: 1m 26s\n",
      "381:\tlearn: 0.0826350\ttotal: 53.4s\tremaining: 1m 26s\n",
      "382:\tlearn: 0.0825716\ttotal: 53.5s\tremaining: 1m 26s\n",
      "383:\tlearn: 0.0825658\ttotal: 53.6s\tremaining: 1m 26s\n",
      "384:\tlearn: 0.0824792\ttotal: 53.8s\tremaining: 1m 25s\n",
      "385:\tlearn: 0.0824042\ttotal: 53.9s\tremaining: 1m 25s\n",
      "386:\tlearn: 0.0824792\ttotal: 54.1s\tremaining: 1m 25s\n",
      "387:\tlearn: 0.0824042\ttotal: 54.2s\tremaining: 1m 25s\n",
      "388:\tlearn: 0.0822888\ttotal: 54.3s\tremaining: 1m 25s\n",
      "389:\tlearn: 0.0821907\ttotal: 54.5s\tremaining: 1m 25s\n",
      "390:\tlearn: 0.0821099\ttotal: 54.6s\tremaining: 1m 25s\n",
      "391:\tlearn: 0.0820868\ttotal: 54.7s\tremaining: 1m 24s\n",
      "392:\tlearn: 0.0820233\ttotal: 54.9s\tremaining: 1m 24s\n",
      "393:\tlearn: 0.0820002\ttotal: 55s\tremaining: 1m 24s\n",
      "394:\tlearn: 0.0819829\ttotal: 55.1s\tremaining: 1m 24s\n",
      "395:\tlearn: 0.0818444\ttotal: 55.3s\tremaining: 1m 24s\n",
      "396:\tlearn: 0.0817694\ttotal: 55.4s\tremaining: 1m 24s\n",
      "397:\tlearn: 0.0817117\ttotal: 55.5s\tremaining: 1m 24s\n",
      "398:\tlearn: 0.0816367\ttotal: 55.7s\tremaining: 1m 23s\n",
      "399:\tlearn: 0.0816367\ttotal: 55.8s\tremaining: 1m 23s\n",
      "400:\tlearn: 0.0815732\ttotal: 55.9s\tremaining: 1m 23s\n",
      "401:\tlearn: 0.0815616\ttotal: 56.1s\tremaining: 1m 23s\n",
      "402:\tlearn: 0.0815270\ttotal: 56.2s\tremaining: 1m 23s\n",
      "403:\tlearn: 0.0814289\ttotal: 56.3s\tremaining: 1m 23s\n",
      "404:\tlearn: 0.0813943\ttotal: 56.5s\tremaining: 1m 22s\n",
      "405:\tlearn: 0.0812962\ttotal: 56.6s\tremaining: 1m 22s\n",
      "406:\tlearn: 0.0813366\ttotal: 56.7s\tremaining: 1m 22s\n",
      "407:\tlearn: 0.0812096\ttotal: 56.9s\tremaining: 1m 22s\n",
      "408:\tlearn: 0.0811404\ttotal: 57s\tremaining: 1m 22s\n",
      "409:\tlearn: 0.0810942\ttotal: 57.2s\tremaining: 1m 22s\n",
      "410:\tlearn: 0.0810596\ttotal: 57.3s\tremaining: 1m 22s\n",
      "411:\tlearn: 0.0809672\ttotal: 57.4s\tremaining: 1m 21s\n",
      "412:\tlearn: 0.0809153\ttotal: 57.6s\tremaining: 1m 21s\n",
      "413:\tlearn: 0.0808749\ttotal: 57.7s\tremaining: 1m 21s\n",
      "414:\tlearn: 0.0807999\ttotal: 57.8s\tremaining: 1m 21s\n",
      "415:\tlearn: 0.0807710\ttotal: 58s\tremaining: 1m 21s\n",
      "416:\tlearn: 0.0807364\ttotal: 58.1s\tremaining: 1m 21s\n",
      "417:\tlearn: 0.0806210\ttotal: 58.2s\tremaining: 1m 21s\n",
      "418:\tlearn: 0.0806267\ttotal: 58.4s\tremaining: 1m 20s\n",
      "419:\tlearn: 0.0805229\ttotal: 58.5s\tremaining: 1m 20s\n",
      "420:\tlearn: 0.0804594\ttotal: 58.6s\tremaining: 1m 20s\n",
      "421:\tlearn: 0.0804363\ttotal: 58.8s\tremaining: 1m 20s\n",
      "422:\tlearn: 0.0803324\ttotal: 58.9s\tremaining: 1m 20s\n",
      "423:\tlearn: 0.0802689\ttotal: 59s\tremaining: 1m 20s\n",
      "424:\tlearn: 0.0802689\ttotal: 59.2s\tremaining: 1m 20s\n",
      "425:\tlearn: 0.0801824\ttotal: 59.3s\tremaining: 1m 19s\n",
      "426:\tlearn: 0.0800612\ttotal: 59.4s\tremaining: 1m 19s\n",
      "427:\tlearn: 0.0799631\ttotal: 59.6s\tremaining: 1m 19s\n",
      "428:\tlearn: 0.0799111\ttotal: 59.7s\tremaining: 1m 19s\n",
      "429:\tlearn: 0.0798592\ttotal: 59.8s\tremaining: 1m 19s\n",
      "430:\tlearn: 0.0797899\ttotal: 60s\tremaining: 1m 19s\n",
      "431:\tlearn: 0.0797380\ttotal: 1m\tremaining: 1m 19s\n",
      "432:\tlearn: 0.0797149\ttotal: 1m\tremaining: 1m 18s\n",
      "433:\tlearn: 0.0796976\ttotal: 1m\tremaining: 1m 18s\n",
      "434:\tlearn: 0.0796053\ttotal: 1m\tremaining: 1m 18s\n",
      "435:\tlearn: 0.0795706\ttotal: 1m\tremaining: 1m 18s\n",
      "436:\tlearn: 0.0794898\ttotal: 1m\tremaining: 1m 18s\n",
      "437:\tlearn: 0.0794090\ttotal: 1m\tremaining: 1m 18s\n",
      "438:\tlearn: 0.0793513\ttotal: 1m 1s\tremaining: 1m 18s\n",
      "439:\tlearn: 0.0793109\ttotal: 1m 1s\tremaining: 1m 17s\n",
      "440:\tlearn: 0.0792936\ttotal: 1m 1s\tremaining: 1m 17s\n",
      "441:\tlearn: 0.0792244\ttotal: 1m 1s\tremaining: 1m 17s\n",
      "442:\tlearn: 0.0791840\ttotal: 1m 1s\tremaining: 1m 17s\n",
      "443:\tlearn: 0.0791494\ttotal: 1m 1s\tremaining: 1m 17s\n",
      "444:\tlearn: 0.0791090\ttotal: 1m 1s\tremaining: 1m 17s\n",
      "445:\tlearn: 0.0790224\ttotal: 1m 2s\tremaining: 1m 17s\n",
      "446:\tlearn: 0.0789993\ttotal: 1m 2s\tremaining: 1m 16s\n",
      "447:\tlearn: 0.0790397\ttotal: 1m 2s\tremaining: 1m 16s\n",
      "448:\tlearn: 0.0789993\ttotal: 1m 2s\tremaining: 1m 16s\n",
      "449:\tlearn: 0.0789531\ttotal: 1m 2s\tremaining: 1m 16s\n",
      "450:\tlearn: 0.0788608\ttotal: 1m 2s\tremaining: 1m 16s\n",
      "451:\tlearn: 0.0788089\ttotal: 1m 2s\tremaining: 1m 16s\n",
      "452:\tlearn: 0.0787396\ttotal: 1m 2s\tremaining: 1m 15s\n",
      "453:\tlearn: 0.0787281\ttotal: 1m 3s\tremaining: 1m 15s\n",
      "454:\tlearn: 0.0786704\ttotal: 1m 3s\tremaining: 1m 15s\n",
      "455:\tlearn: 0.0786127\ttotal: 1m 3s\tremaining: 1m 15s\n",
      "456:\tlearn: 0.0785549\ttotal: 1m 3s\tremaining: 1m 15s\n",
      "457:\tlearn: 0.0785145\ttotal: 1m 3s\tremaining: 1m 15s\n",
      "458:\tlearn: 0.0784107\ttotal: 1m 3s\tremaining: 1m 15s\n",
      "459:\tlearn: 0.0782952\ttotal: 1m 3s\tremaining: 1m 14s\n",
      "460:\tlearn: 0.0782202\ttotal: 1m 4s\tremaining: 1m 14s\n",
      "461:\tlearn: 0.0781856\ttotal: 1m 4s\tremaining: 1m 14s\n",
      "462:\tlearn: 0.0781163\ttotal: 1m 4s\tremaining: 1m 14s\n",
      "463:\tlearn: 0.0779894\ttotal: 1m 4s\tremaining: 1m 14s\n",
      "464:\tlearn: 0.0779201\ttotal: 1m 4s\tremaining: 1m 14s\n",
      "465:\tlearn: 0.0778855\ttotal: 1m 4s\tremaining: 1m 14s\n",
      "466:\tlearn: 0.0779028\ttotal: 1m 4s\tremaining: 1m 13s\n",
      "467:\tlearn: 0.0778451\ttotal: 1m 4s\tremaining: 1m 13s\n",
      "468:\tlearn: 0.0777759\ttotal: 1m 5s\tremaining: 1m 13s\n",
      "469:\tlearn: 0.0777181\ttotal: 1m 5s\tremaining: 1m 13s\n",
      "470:\tlearn: 0.0776835\ttotal: 1m 5s\tremaining: 1m 13s\n",
      "471:\tlearn: 0.0776431\ttotal: 1m 5s\tremaining: 1m 13s\n",
      "472:\tlearn: 0.0775796\ttotal: 1m 5s\tremaining: 1m 13s\n",
      "473:\tlearn: 0.0775450\ttotal: 1m 5s\tremaining: 1m 12s\n",
      "474:\tlearn: 0.0774815\ttotal: 1m 5s\tremaining: 1m 12s\n",
      "475:\tlearn: 0.0774238\ttotal: 1m 6s\tremaining: 1m 12s\n",
      "476:\tlearn: 0.0774123\ttotal: 1m 6s\tremaining: 1m 12s\n",
      "477:\tlearn: 0.0773777\ttotal: 1m 6s\tremaining: 1m 12s\n",
      "478:\tlearn: 0.0773026\ttotal: 1m 6s\tremaining: 1m 12s\n",
      "479:\tlearn: 0.0772680\ttotal: 1m 6s\tremaining: 1m 12s\n",
      "480:\tlearn: 0.0772218\ttotal: 1m 6s\tremaining: 1m 11s\n",
      "481:\tlearn: 0.0771814\ttotal: 1m 6s\tremaining: 1m 11s\n",
      "482:\tlearn: 0.0771699\ttotal: 1m 6s\tremaining: 1m 11s\n",
      "483:\tlearn: 0.0770718\ttotal: 1m 7s\tremaining: 1m 11s\n",
      "484:\tlearn: 0.0770660\ttotal: 1m 7s\tremaining: 1m 11s\n",
      "485:\tlearn: 0.0770314\ttotal: 1m 7s\tremaining: 1m 11s\n",
      "486:\tlearn: 0.0769391\ttotal: 1m 7s\tremaining: 1m 11s\n",
      "487:\tlearn: 0.0769102\ttotal: 1m 7s\tremaining: 1m 11s\n",
      "488:\tlearn: 0.0768756\ttotal: 1m 7s\tremaining: 1m 10s\n",
      "489:\tlearn: 0.0768525\ttotal: 1m 7s\tremaining: 1m 10s\n",
      "490:\tlearn: 0.0768525\ttotal: 1m 8s\tremaining: 1m 10s\n",
      "491:\tlearn: 0.0767890\ttotal: 1m 8s\tremaining: 1m 10s\n",
      "492:\tlearn: 0.0768121\ttotal: 1m 8s\tremaining: 1m 10s\n",
      "493:\tlearn: 0.0767371\ttotal: 1m 8s\tremaining: 1m 10s\n",
      "494:\tlearn: 0.0766909\ttotal: 1m 8s\tremaining: 1m 10s\n",
      "495:\tlearn: 0.0766620\ttotal: 1m 8s\tremaining: 1m 9s\n",
      "496:\tlearn: 0.0765755\ttotal: 1m 8s\tremaining: 1m 9s\n",
      "497:\tlearn: 0.0765005\ttotal: 1m 9s\tremaining: 1m 9s\n",
      "498:\tlearn: 0.0764139\ttotal: 1m 9s\tremaining: 1m 9s\n",
      "499:\tlearn: 0.0763677\ttotal: 1m 9s\tremaining: 1m 9s\n",
      "500:\tlearn: 0.0763273\ttotal: 1m 9s\tremaining: 1m 9s\n",
      "501:\tlearn: 0.0763389\ttotal: 1m 9s\tremaining: 1m 9s\n",
      "502:\tlearn: 0.0762985\ttotal: 1m 9s\tremaining: 1m 8s\n",
      "503:\tlearn: 0.0762465\ttotal: 1m 9s\tremaining: 1m 8s\n",
      "504:\tlearn: 0.0761657\ttotal: 1m 9s\tremaining: 1m 8s\n",
      "505:\tlearn: 0.0760849\ttotal: 1m 10s\tremaining: 1m 8s\n",
      "506:\tlearn: 0.0760042\ttotal: 1m 10s\tremaining: 1m 8s\n",
      "507:\tlearn: 0.0759349\ttotal: 1m 10s\tremaining: 1m 8s\n",
      "508:\tlearn: 0.0758887\ttotal: 1m 10s\tremaining: 1m 8s\n",
      "509:\tlearn: 0.0758253\ttotal: 1m 10s\tremaining: 1m 7s\n",
      "510:\tlearn: 0.0757791\ttotal: 1m 10s\tremaining: 1m 7s\n",
      "511:\tlearn: 0.0757387\ttotal: 1m 10s\tremaining: 1m 7s\n",
      "512:\tlearn: 0.0756579\ttotal: 1m 11s\tremaining: 1m 7s\n",
      "513:\tlearn: 0.0756348\ttotal: 1m 11s\tremaining: 1m 7s\n",
      "514:\tlearn: 0.0755367\ttotal: 1m 11s\tremaining: 1m 7s\n",
      "515:\tlearn: 0.0754559\ttotal: 1m 11s\tremaining: 1m 7s\n",
      "516:\tlearn: 0.0754559\ttotal: 1m 11s\tremaining: 1m 6s\n",
      "517:\tlearn: 0.0753693\ttotal: 1m 11s\tremaining: 1m 6s\n",
      "518:\tlearn: 0.0753059\ttotal: 1m 11s\tremaining: 1m 6s\n",
      "519:\tlearn: 0.0752597\ttotal: 1m 12s\tremaining: 1m 6s\n",
      "520:\tlearn: 0.0752308\ttotal: 1m 12s\tremaining: 1m 6s\n",
      "521:\tlearn: 0.0752308\ttotal: 1m 12s\tremaining: 1m 6s\n",
      "522:\tlearn: 0.0751616\ttotal: 1m 12s\tremaining: 1m 6s\n",
      "523:\tlearn: 0.0750808\ttotal: 1m 12s\tremaining: 1m 5s\n",
      "524:\tlearn: 0.0749942\ttotal: 1m 12s\tremaining: 1m 5s\n",
      "525:\tlearn: 0.0749942\ttotal: 1m 12s\tremaining: 1m 5s\n",
      "526:\tlearn: 0.0748904\ttotal: 1m 12s\tremaining: 1m 5s\n",
      "527:\tlearn: 0.0748615\ttotal: 1m 13s\tremaining: 1m 5s\n",
      "528:\tlearn: 0.0748038\ttotal: 1m 13s\tremaining: 1m 5s\n",
      "529:\tlearn: 0.0747114\ttotal: 1m 13s\tremaining: 1m 5s\n",
      "530:\tlearn: 0.0746826\ttotal: 1m 13s\tremaining: 1m 4s\n",
      "531:\tlearn: 0.0745556\ttotal: 1m 13s\tremaining: 1m 4s\n",
      "532:\tlearn: 0.0744979\ttotal: 1m 13s\tremaining: 1m 4s\n",
      "533:\tlearn: 0.0744460\ttotal: 1m 13s\tremaining: 1m 4s\n",
      "534:\tlearn: 0.0743940\ttotal: 1m 14s\tremaining: 1m 4s\n",
      "535:\tlearn: 0.0743652\ttotal: 1m 14s\tremaining: 1m 4s\n",
      "536:\tlearn: 0.0743190\ttotal: 1m 14s\tremaining: 1m 4s\n",
      "537:\tlearn: 0.0742209\ttotal: 1m 14s\tremaining: 1m 3s\n",
      "538:\tlearn: 0.0741805\ttotal: 1m 14s\tremaining: 1m 3s\n",
      "539:\tlearn: 0.0741517\ttotal: 1m 14s\tremaining: 1m 3s\n",
      "540:\tlearn: 0.0740824\ttotal: 1m 14s\tremaining: 1m 3s\n",
      "541:\tlearn: 0.0740247\ttotal: 1m 15s\tremaining: 1m 3s\n",
      "542:\tlearn: 0.0739901\ttotal: 1m 15s\tremaining: 1m 3s\n",
      "543:\tlearn: 0.0739381\ttotal: 1m 15s\tremaining: 1m 3s\n",
      "544:\tlearn: 0.0739901\ttotal: 1m 15s\tremaining: 1m 3s\n",
      "545:\tlearn: 0.0739208\ttotal: 1m 15s\tremaining: 1m 2s\n",
      "546:\tlearn: 0.0738400\ttotal: 1m 15s\tremaining: 1m 2s\n",
      "547:\tlearn: 0.0737881\ttotal: 1m 15s\tremaining: 1m 2s\n",
      "548:\tlearn: 0.0737477\ttotal: 1m 16s\tremaining: 1m 2s\n",
      "549:\tlearn: 0.0737304\ttotal: 1m 16s\tremaining: 1m 2s\n",
      "550:\tlearn: 0.0736554\ttotal: 1m 16s\tremaining: 1m 2s\n",
      "551:\tlearn: 0.0735457\ttotal: 1m 16s\tremaining: 1m 2s\n",
      "552:\tlearn: 0.0734880\ttotal: 1m 16s\tremaining: 1m 1s\n",
      "553:\tlearn: 0.0734476\ttotal: 1m 16s\tremaining: 1m 1s\n",
      "554:\tlearn: 0.0734303\ttotal: 1m 16s\tremaining: 1m 1s\n",
      "555:\tlearn: 0.0734187\ttotal: 1m 16s\tremaining: 1m 1s\n",
      "556:\tlearn: 0.0733380\ttotal: 1m 17s\tremaining: 1m 1s\n",
      "557:\tlearn: 0.0732802\ttotal: 1m 17s\tremaining: 1m 1s\n",
      "558:\tlearn: 0.0732514\ttotal: 1m 17s\tremaining: 1m 1s\n",
      "559:\tlearn: 0.0731937\ttotal: 1m 17s\tremaining: 1m\n",
      "560:\tlearn: 0.0731648\ttotal: 1m 17s\tremaining: 1m\n",
      "561:\tlearn: 0.0731302\ttotal: 1m 17s\tremaining: 1m\n",
      "562:\tlearn: 0.0731302\ttotal: 1m 17s\tremaining: 1m\n",
      "563:\tlearn: 0.0730321\ttotal: 1m 18s\tremaining: 1m\n",
      "564:\tlearn: 0.0729801\ttotal: 1m 18s\tremaining: 1m\n",
      "565:\tlearn: 0.0729340\ttotal: 1m 18s\tremaining: 1m\n",
      "566:\tlearn: 0.0729167\ttotal: 1m 18s\tremaining: 59.9s\n",
      "567:\tlearn: 0.0728820\ttotal: 1m 18s\tremaining: 59.8s\n",
      "568:\tlearn: 0.0728301\ttotal: 1m 18s\tremaining: 59.6s\n",
      "569:\tlearn: 0.0728012\ttotal: 1m 18s\tremaining: 59.5s\n",
      "570:\tlearn: 0.0727839\ttotal: 1m 19s\tremaining: 59.4s\n",
      "571:\tlearn: 0.0726858\ttotal: 1m 19s\tremaining: 59.2s\n",
      "572:\tlearn: 0.0726108\ttotal: 1m 19s\tremaining: 59.1s\n",
      "573:\tlearn: 0.0725242\ttotal: 1m 19s\tremaining: 58.9s\n",
      "574:\tlearn: 0.0724608\ttotal: 1m 19s\tremaining: 58.8s\n",
      "575:\tlearn: 0.0724781\ttotal: 1m 19s\tremaining: 58.7s\n",
      "576:\tlearn: 0.0724146\ttotal: 1m 19s\tremaining: 58.5s\n",
      "577:\tlearn: 0.0724261\ttotal: 1m 19s\tremaining: 58.4s\n",
      "578:\tlearn: 0.0723453\ttotal: 1m 20s\tremaining: 58.2s\n",
      "579:\tlearn: 0.0723165\ttotal: 1m 20s\tremaining: 58.1s\n",
      "580:\tlearn: 0.0722819\ttotal: 1m 20s\tremaining: 58s\n",
      "581:\tlearn: 0.0721664\ttotal: 1m 20s\tremaining: 57.8s\n",
      "582:\tlearn: 0.0720914\ttotal: 1m 20s\tremaining: 57.7s\n",
      "583:\tlearn: 0.0720972\ttotal: 1m 20s\tremaining: 57.5s\n",
      "584:\tlearn: 0.0720856\ttotal: 1m 20s\tremaining: 57.4s\n",
      "585:\tlearn: 0.0720222\ttotal: 1m 21s\tremaining: 57.2s\n",
      "586:\tlearn: 0.0719529\ttotal: 1m 21s\tremaining: 57.1s\n",
      "587:\tlearn: 0.0719125\ttotal: 1m 21s\tremaining: 57s\n",
      "588:\tlearn: 0.0719298\ttotal: 1m 21s\tremaining: 56.8s\n",
      "589:\tlearn: 0.0718837\ttotal: 1m 21s\tremaining: 56.7s\n",
      "590:\tlearn: 0.0718779\ttotal: 1m 21s\tremaining: 56.5s\n",
      "591:\tlearn: 0.0718433\ttotal: 1m 21s\tremaining: 56.4s\n",
      "592:\tlearn: 0.0717625\ttotal: 1m 22s\tremaining: 56.3s\n",
      "593:\tlearn: 0.0717567\ttotal: 1m 22s\tremaining: 56.2s\n",
      "594:\tlearn: 0.0717105\ttotal: 1m 22s\tremaining: 56.1s\n",
      "595:\tlearn: 0.0717163\ttotal: 1m 22s\tremaining: 55.9s\n",
      "596:\tlearn: 0.0716528\ttotal: 1m 22s\tremaining: 55.8s\n",
      "597:\tlearn: 0.0715605\ttotal: 1m 22s\tremaining: 55.7s\n",
      "598:\tlearn: 0.0715778\ttotal: 1m 23s\tremaining: 55.6s\n",
      "599:\tlearn: 0.0714912\ttotal: 1m 23s\tremaining: 55.5s\n",
      "600:\tlearn: 0.0714335\ttotal: 1m 23s\tremaining: 55.3s\n",
      "601:\tlearn: 0.0713643\ttotal: 1m 23s\tremaining: 55.2s\n",
      "602:\tlearn: 0.0713354\ttotal: 1m 23s\tremaining: 55.1s\n",
      "603:\tlearn: 0.0712604\ttotal: 1m 23s\tremaining: 54.9s\n",
      "604:\tlearn: 0.0712546\ttotal: 1m 23s\tremaining: 54.8s\n",
      "605:\tlearn: 0.0712258\ttotal: 1m 24s\tremaining: 54.7s\n",
      "606:\tlearn: 0.0711969\ttotal: 1m 24s\tremaining: 54.5s\n",
      "607:\tlearn: 0.0711334\ttotal: 1m 24s\tremaining: 54.4s\n",
      "608:\tlearn: 0.0711103\ttotal: 1m 24s\tremaining: 54.3s\n",
      "609:\tlearn: 0.0710815\ttotal: 1m 24s\tremaining: 54.2s\n",
      "610:\tlearn: 0.0710815\ttotal: 1m 24s\tremaining: 54.1s\n",
      "611:\tlearn: 0.0710584\ttotal: 1m 25s\tremaining: 53.9s\n",
      "612:\tlearn: 0.0709776\ttotal: 1m 25s\tremaining: 53.8s\n",
      "613:\tlearn: 0.0710007\ttotal: 1m 25s\tremaining: 53.7s\n",
      "614:\tlearn: 0.0709603\ttotal: 1m 25s\tremaining: 53.6s\n",
      "615:\tlearn: 0.0709372\ttotal: 1m 25s\tremaining: 53.5s\n",
      "616:\tlearn: 0.0709026\ttotal: 1m 25s\tremaining: 53.4s\n",
      "617:\tlearn: 0.0708910\ttotal: 1m 26s\tremaining: 53.3s\n",
      "618:\tlearn: 0.0708449\ttotal: 1m 26s\tremaining: 53.2s\n",
      "619:\tlearn: 0.0708276\ttotal: 1m 26s\tremaining: 53.1s\n",
      "620:\tlearn: 0.0708045\ttotal: 1m 26s\tremaining: 52.9s\n",
      "621:\tlearn: 0.0708045\ttotal: 1m 26s\tremaining: 52.8s\n",
      "622:\tlearn: 0.0707295\ttotal: 1m 27s\tremaining: 52.7s\n",
      "623:\tlearn: 0.0706775\ttotal: 1m 27s\tremaining: 52.6s\n",
      "624:\tlearn: 0.0706256\ttotal: 1m 27s\tremaining: 52.5s\n",
      "625:\tlearn: 0.0705736\ttotal: 1m 27s\tremaining: 52.3s\n",
      "626:\tlearn: 0.0705275\ttotal: 1m 27s\tremaining: 52.2s\n",
      "627:\tlearn: 0.0704698\ttotal: 1m 27s\tremaining: 52.1s\n",
      "628:\tlearn: 0.0703947\ttotal: 1m 28s\tremaining: 51.9s\n",
      "629:\tlearn: 0.0703486\ttotal: 1m 28s\tremaining: 51.8s\n",
      "630:\tlearn: 0.0702562\ttotal: 1m 28s\tremaining: 51.6s\n",
      "631:\tlearn: 0.0702331\ttotal: 1m 28s\tremaining: 51.5s\n",
      "632:\tlearn: 0.0701985\ttotal: 1m 28s\tremaining: 51.4s\n",
      "633:\tlearn: 0.0701524\ttotal: 1m 28s\tremaining: 51.2s\n",
      "634:\tlearn: 0.0701062\ttotal: 1m 28s\tremaining: 51.1s\n",
      "635:\tlearn: 0.0700773\ttotal: 1m 28s\tremaining: 50.9s\n",
      "636:\tlearn: 0.0700600\ttotal: 1m 29s\tremaining: 50.8s\n",
      "637:\tlearn: 0.0699677\ttotal: 1m 29s\tremaining: 50.6s\n",
      "638:\tlearn: 0.0699792\ttotal: 1m 29s\tremaining: 50.5s\n",
      "639:\tlearn: 0.0699215\ttotal: 1m 29s\tremaining: 50.4s\n",
      "640:\tlearn: 0.0698869\ttotal: 1m 29s\tremaining: 50.2s\n",
      "641:\tlearn: 0.0698580\ttotal: 1m 29s\tremaining: 50.1s\n",
      "642:\tlearn: 0.0698580\ttotal: 1m 29s\tremaining: 49.9s\n",
      "643:\tlearn: 0.0698234\ttotal: 1m 30s\tremaining: 49.8s\n",
      "644:\tlearn: 0.0697657\ttotal: 1m 30s\tremaining: 49.6s\n",
      "645:\tlearn: 0.0697772\ttotal: 1m 30s\tremaining: 49.5s\n",
      "646:\tlearn: 0.0696849\ttotal: 1m 30s\tremaining: 49.4s\n",
      "647:\tlearn: 0.0696849\ttotal: 1m 30s\tremaining: 49.2s\n",
      "648:\tlearn: 0.0695753\ttotal: 1m 30s\tremaining: 49.1s\n",
      "649:\tlearn: 0.0695464\ttotal: 1m 30s\tremaining: 49s\n",
      "650:\tlearn: 0.0695349\ttotal: 1m 31s\tremaining: 48.8s\n",
      "651:\tlearn: 0.0694483\ttotal: 1m 31s\tremaining: 48.7s\n",
      "652:\tlearn: 0.0694137\ttotal: 1m 31s\tremaining: 48.6s\n",
      "653:\tlearn: 0.0693098\ttotal: 1m 31s\tremaining: 48.4s\n",
      "654:\tlearn: 0.0693386\ttotal: 1m 31s\tremaining: 48.3s\n",
      "655:\tlearn: 0.0693156\ttotal: 1m 31s\tremaining: 48.1s\n",
      "656:\tlearn: 0.0692752\ttotal: 1m 31s\tremaining: 48s\n",
      "657:\tlearn: 0.0692001\ttotal: 1m 32s\tremaining: 47.9s\n",
      "658:\tlearn: 0.0691193\ttotal: 1m 32s\tremaining: 47.7s\n",
      "659:\tlearn: 0.0690674\ttotal: 1m 32s\tremaining: 47.6s\n",
      "660:\tlearn: 0.0690270\ttotal: 1m 32s\tremaining: 47.4s\n",
      "661:\tlearn: 0.0690212\ttotal: 1m 32s\tremaining: 47.3s\n",
      "662:\tlearn: 0.0689462\ttotal: 1m 32s\tremaining: 47.2s\n",
      "663:\tlearn: 0.0688943\ttotal: 1m 32s\tremaining: 47s\n",
      "664:\tlearn: 0.0688943\ttotal: 1m 33s\tremaining: 46.9s\n",
      "665:\tlearn: 0.0688712\ttotal: 1m 33s\tremaining: 46.8s\n",
      "666:\tlearn: 0.0688943\ttotal: 1m 33s\tremaining: 46.6s\n",
      "667:\tlearn: 0.0688943\ttotal: 1m 33s\tremaining: 46.5s\n",
      "668:\tlearn: 0.0687846\ttotal: 1m 33s\tremaining: 46.3s\n",
      "669:\tlearn: 0.0687327\ttotal: 1m 33s\tremaining: 46.2s\n",
      "670:\tlearn: 0.0686807\ttotal: 1m 33s\tremaining: 46.1s\n",
      "671:\tlearn: 0.0686692\ttotal: 1m 34s\tremaining: 45.9s\n",
      "672:\tlearn: 0.0685884\ttotal: 1m 34s\tremaining: 45.8s\n",
      "673:\tlearn: 0.0685480\ttotal: 1m 34s\tremaining: 45.7s\n",
      "674:\tlearn: 0.0684441\ttotal: 1m 34s\tremaining: 45.5s\n",
      "675:\tlearn: 0.0683922\ttotal: 1m 34s\tremaining: 45.4s\n",
      "676:\tlearn: 0.0683864\ttotal: 1m 34s\tremaining: 45.2s\n",
      "677:\tlearn: 0.0683576\ttotal: 1m 34s\tremaining: 45.1s\n",
      "678:\tlearn: 0.0683980\ttotal: 1m 35s\tremaining: 45s\n",
      "679:\tlearn: 0.0683345\ttotal: 1m 35s\tremaining: 44.8s\n",
      "680:\tlearn: 0.0682479\ttotal: 1m 35s\tremaining: 44.7s\n",
      "681:\tlearn: 0.0682133\ttotal: 1m 35s\tremaining: 44.6s\n",
      "682:\tlearn: 0.0681729\ttotal: 1m 35s\tremaining: 44.4s\n",
      "683:\tlearn: 0.0682018\ttotal: 1m 35s\tremaining: 44.3s\n",
      "684:\tlearn: 0.0681498\ttotal: 1m 35s\tremaining: 44.1s\n",
      "685:\tlearn: 0.0680517\ttotal: 1m 36s\tremaining: 44s\n",
      "686:\tlearn: 0.0680344\ttotal: 1m 36s\tremaining: 43.9s\n",
      "687:\tlearn: 0.0680229\ttotal: 1m 36s\tremaining: 43.7s\n",
      "688:\tlearn: 0.0679594\ttotal: 1m 36s\tremaining: 43.6s\n",
      "689:\tlearn: 0.0678670\ttotal: 1m 36s\tremaining: 43.4s\n",
      "690:\tlearn: 0.0678266\ttotal: 1m 36s\tremaining: 43.3s\n",
      "691:\tlearn: 0.0678151\ttotal: 1m 36s\tremaining: 43.1s\n",
      "692:\tlearn: 0.0677516\ttotal: 1m 37s\tremaining: 43s\n",
      "693:\tlearn: 0.0677170\ttotal: 1m 37s\tremaining: 42.9s\n",
      "694:\tlearn: 0.0676881\ttotal: 1m 37s\tremaining: 42.7s\n",
      "695:\tlearn: 0.0676362\ttotal: 1m 37s\tremaining: 42.6s\n",
      "696:\tlearn: 0.0675785\ttotal: 1m 37s\tremaining: 42.5s\n",
      "697:\tlearn: 0.0675035\ttotal: 1m 37s\tremaining: 42.3s\n",
      "698:\tlearn: 0.0675323\ttotal: 1m 37s\tremaining: 42.2s\n",
      "699:\tlearn: 0.0674919\ttotal: 1m 38s\tremaining: 42s\n",
      "700:\tlearn: 0.0673880\ttotal: 1m 38s\tremaining: 41.9s\n",
      "701:\tlearn: 0.0673476\ttotal: 1m 38s\tremaining: 41.7s\n",
      "702:\tlearn: 0.0673188\ttotal: 1m 38s\tremaining: 41.6s\n",
      "703:\tlearn: 0.0673072\ttotal: 1m 38s\tremaining: 41.5s\n",
      "704:\tlearn: 0.0672553\ttotal: 1m 38s\tremaining: 41.3s\n",
      "705:\tlearn: 0.0672438\ttotal: 1m 38s\tremaining: 41.2s\n",
      "706:\tlearn: 0.0671918\ttotal: 1m 39s\tremaining: 41s\n",
      "707:\tlearn: 0.0671745\ttotal: 1m 39s\tremaining: 40.9s\n",
      "708:\tlearn: 0.0671630\ttotal: 1m 39s\tremaining: 40.7s\n",
      "709:\tlearn: 0.0671341\ttotal: 1m 39s\tremaining: 40.6s\n",
      "710:\tlearn: 0.0670937\ttotal: 1m 39s\tremaining: 40.5s\n",
      "711:\tlearn: 0.0670072\ttotal: 1m 39s\tremaining: 40.3s\n",
      "712:\tlearn: 0.0670014\ttotal: 1m 39s\tremaining: 40.2s\n",
      "713:\tlearn: 0.0669610\ttotal: 1m 39s\tremaining: 40s\n",
      "714:\tlearn: 0.0668860\ttotal: 1m 40s\tremaining: 39.9s\n",
      "715:\tlearn: 0.0668513\ttotal: 1m 40s\tremaining: 39.8s\n",
      "716:\tlearn: 0.0668052\ttotal: 1m 40s\tremaining: 39.6s\n",
      "717:\tlearn: 0.0667071\ttotal: 1m 40s\tremaining: 39.5s\n",
      "718:\tlearn: 0.0666840\ttotal: 1m 40s\tremaining: 39.3s\n",
      "719:\tlearn: 0.0666378\ttotal: 1m 40s\tremaining: 39.2s\n",
      "720:\tlearn: 0.0666436\ttotal: 1m 40s\tremaining: 39.1s\n",
      "721:\tlearn: 0.0665974\ttotal: 1m 41s\tremaining: 38.9s\n",
      "722:\tlearn: 0.0665455\ttotal: 1m 41s\tremaining: 38.8s\n",
      "723:\tlearn: 0.0664878\ttotal: 1m 41s\tremaining: 38.6s\n",
      "724:\tlearn: 0.0664243\ttotal: 1m 41s\tremaining: 38.5s\n",
      "725:\tlearn: 0.0663262\ttotal: 1m 41s\tremaining: 38.3s\n",
      "726:\tlearn: 0.0663319\ttotal: 1m 41s\tremaining: 38.2s\n",
      "727:\tlearn: 0.0662742\ttotal: 1m 41s\tremaining: 38.1s\n",
      "728:\tlearn: 0.0662223\ttotal: 1m 42s\tremaining: 37.9s\n",
      "729:\tlearn: 0.0662569\ttotal: 1m 42s\tremaining: 37.8s\n",
      "730:\tlearn: 0.0661934\ttotal: 1m 42s\tremaining: 37.6s\n",
      "731:\tlearn: 0.0661415\ttotal: 1m 42s\tremaining: 37.5s\n",
      "732:\tlearn: 0.0660838\ttotal: 1m 42s\tremaining: 37.4s\n",
      "733:\tlearn: 0.0661184\ttotal: 1m 42s\tremaining: 37.2s\n",
      "734:\tlearn: 0.0660549\ttotal: 1m 42s\tremaining: 37.1s\n",
      "735:\tlearn: 0.0660203\ttotal: 1m 42s\tremaining: 36.9s\n",
      "736:\tlearn: 0.0660261\ttotal: 1m 43s\tremaining: 36.8s\n",
      "737:\tlearn: 0.0659626\ttotal: 1m 43s\tremaining: 36.6s\n",
      "738:\tlearn: 0.0659280\ttotal: 1m 43s\tremaining: 36.5s\n",
      "739:\tlearn: 0.0658703\ttotal: 1m 43s\tremaining: 36.4s\n",
      "740:\tlearn: 0.0658241\ttotal: 1m 43s\tremaining: 36.2s\n",
      "741:\tlearn: 0.0657722\ttotal: 1m 43s\tremaining: 36.1s\n",
      "742:\tlearn: 0.0657318\ttotal: 1m 43s\tremaining: 35.9s\n",
      "743:\tlearn: 0.0657087\ttotal: 1m 44s\tremaining: 35.8s\n",
      "744:\tlearn: 0.0656279\ttotal: 1m 44s\tremaining: 35.7s\n",
      "745:\tlearn: 0.0655990\ttotal: 1m 44s\tremaining: 35.5s\n",
      "746:\tlearn: 0.0655471\ttotal: 1m 44s\tremaining: 35.4s\n",
      "747:\tlearn: 0.0655355\ttotal: 1m 44s\tremaining: 35.2s\n",
      "748:\tlearn: 0.0655355\ttotal: 1m 44s\tremaining: 35.1s\n",
      "749:\tlearn: 0.0655009\ttotal: 1m 44s\tremaining: 34.9s\n",
      "750:\tlearn: 0.0654374\ttotal: 1m 44s\tremaining: 34.8s\n",
      "751:\tlearn: 0.0653970\ttotal: 1m 45s\tremaining: 34.7s\n",
      "752:\tlearn: 0.0653682\ttotal: 1m 45s\tremaining: 34.5s\n",
      "753:\tlearn: 0.0652759\ttotal: 1m 45s\tremaining: 34.4s\n",
      "754:\tlearn: 0.0652412\ttotal: 1m 45s\tremaining: 34.2s\n",
      "755:\tlearn: 0.0652355\ttotal: 1m 45s\tremaining: 34.1s\n",
      "756:\tlearn: 0.0652412\ttotal: 1m 45s\tremaining: 34s\n",
      "757:\tlearn: 0.0651951\ttotal: 1m 45s\tremaining: 33.8s\n",
      "758:\tlearn: 0.0651489\ttotal: 1m 46s\tremaining: 33.7s\n",
      "759:\tlearn: 0.0650739\ttotal: 1m 46s\tremaining: 33.5s\n",
      "760:\tlearn: 0.0650912\ttotal: 1m 46s\tremaining: 33.4s\n",
      "761:\tlearn: 0.0650219\ttotal: 1m 46s\tremaining: 33.3s\n",
      "762:\tlearn: 0.0649758\ttotal: 1m 46s\tremaining: 33.1s\n",
      "763:\tlearn: 0.0649354\ttotal: 1m 46s\tremaining: 33s\n",
      "764:\tlearn: 0.0648430\ttotal: 1m 46s\tremaining: 32.8s\n",
      "765:\tlearn: 0.0647911\ttotal: 1m 47s\tremaining: 32.7s\n",
      "766:\tlearn: 0.0647334\ttotal: 1m 47s\tremaining: 32.6s\n",
      "767:\tlearn: 0.0646641\ttotal: 1m 47s\tremaining: 32.4s\n",
      "768:\tlearn: 0.0645949\ttotal: 1m 47s\tremaining: 32.3s\n",
      "769:\tlearn: 0.0645833\ttotal: 1m 47s\tremaining: 32.1s\n",
      "770:\tlearn: 0.0645199\ttotal: 1m 47s\tremaining: 32s\n",
      "771:\tlearn: 0.0644448\ttotal: 1m 47s\tremaining: 31.9s\n",
      "772:\tlearn: 0.0644275\ttotal: 1m 47s\tremaining: 31.7s\n",
      "773:\tlearn: 0.0643987\ttotal: 1m 48s\tremaining: 31.6s\n",
      "774:\tlearn: 0.0643813\ttotal: 1m 48s\tremaining: 31.4s\n",
      "775:\tlearn: 0.0643352\ttotal: 1m 48s\tremaining: 31.3s\n",
      "776:\tlearn: 0.0642775\ttotal: 1m 48s\tremaining: 31.1s\n",
      "777:\tlearn: 0.0642024\ttotal: 1m 48s\tremaining: 31s\n",
      "778:\tlearn: 0.0641909\ttotal: 1m 48s\tremaining: 30.9s\n",
      "779:\tlearn: 0.0641967\ttotal: 1m 48s\tremaining: 30.7s\n",
      "780:\tlearn: 0.0641217\ttotal: 1m 49s\tremaining: 30.6s\n",
      "781:\tlearn: 0.0640639\ttotal: 1m 49s\tremaining: 30.4s\n",
      "782:\tlearn: 0.0640755\ttotal: 1m 49s\tremaining: 30.3s\n",
      "783:\tlearn: 0.0639831\ttotal: 1m 49s\tremaining: 30.2s\n",
      "784:\tlearn: 0.0639139\ttotal: 1m 49s\tremaining: 30s\n",
      "785:\tlearn: 0.0638158\ttotal: 1m 49s\tremaining: 29.9s\n",
      "786:\tlearn: 0.0637754\ttotal: 1m 49s\tremaining: 29.7s\n",
      "787:\tlearn: 0.0637408\ttotal: 1m 49s\tremaining: 29.6s\n",
      "788:\tlearn: 0.0637119\ttotal: 1m 50s\tremaining: 29.4s\n",
      "789:\tlearn: 0.0636715\ttotal: 1m 50s\tremaining: 29.3s\n",
      "790:\tlearn: 0.0636311\ttotal: 1m 50s\tremaining: 29.2s\n",
      "791:\tlearn: 0.0635849\ttotal: 1m 50s\tremaining: 29s\n",
      "792:\tlearn: 0.0635734\ttotal: 1m 50s\tremaining: 28.9s\n",
      "793:\tlearn: 0.0635446\ttotal: 1m 50s\tremaining: 28.7s\n",
      "794:\tlearn: 0.0634926\ttotal: 1m 50s\tremaining: 28.6s\n",
      "795:\tlearn: 0.0635042\ttotal: 1m 51s\tremaining: 28.5s\n",
      "796:\tlearn: 0.0634234\ttotal: 1m 51s\tremaining: 28.3s\n",
      "797:\tlearn: 0.0633541\ttotal: 1m 51s\tremaining: 28.2s\n",
      "798:\tlearn: 0.0633253\ttotal: 1m 51s\tremaining: 28s\n",
      "799:\tlearn: 0.0633079\ttotal: 1m 51s\tremaining: 27.9s\n",
      "800:\tlearn: 0.0633022\ttotal: 1m 51s\tremaining: 27.8s\n",
      "801:\tlearn: 0.0632733\ttotal: 1m 51s\tremaining: 27.6s\n",
      "802:\tlearn: 0.0632329\ttotal: 1m 52s\tremaining: 27.5s\n",
      "803:\tlearn: 0.0631637\ttotal: 1m 52s\tremaining: 27.3s\n",
      "804:\tlearn: 0.0631521\ttotal: 1m 52s\tremaining: 27.2s\n",
      "805:\tlearn: 0.0631060\ttotal: 1m 52s\tremaining: 27.1s\n",
      "806:\tlearn: 0.0630829\ttotal: 1m 52s\tremaining: 26.9s\n",
      "807:\tlearn: 0.0630078\ttotal: 1m 52s\tremaining: 26.8s\n",
      "808:\tlearn: 0.0629617\ttotal: 1m 52s\tremaining: 26.6s\n",
      "809:\tlearn: 0.0628982\ttotal: 1m 53s\tremaining: 26.5s\n",
      "810:\tlearn: 0.0628578\ttotal: 1m 53s\tremaining: 26.4s\n",
      "811:\tlearn: 0.0627886\ttotal: 1m 53s\tremaining: 26.2s\n",
      "812:\tlearn: 0.0627712\ttotal: 1m 53s\tremaining: 26.1s\n",
      "813:\tlearn: 0.0627308\ttotal: 1m 53s\tremaining: 25.9s\n",
      "814:\tlearn: 0.0627135\ttotal: 1m 53s\tremaining: 25.8s\n",
      "815:\tlearn: 0.0626500\ttotal: 1m 53s\tremaining: 25.7s\n",
      "816:\tlearn: 0.0626212\ttotal: 1m 53s\tremaining: 25.5s\n",
      "817:\tlearn: 0.0625981\ttotal: 1m 54s\tremaining: 25.4s\n",
      "818:\tlearn: 0.0625289\ttotal: 1m 54s\tremaining: 25.2s\n",
      "819:\tlearn: 0.0625231\ttotal: 1m 54s\tremaining: 25.1s\n",
      "820:\tlearn: 0.0625000\ttotal: 1m 54s\tremaining: 25s\n",
      "821:\tlearn: 0.0624711\ttotal: 1m 54s\tremaining: 24.8s\n",
      "822:\tlearn: 0.0624538\ttotal: 1m 54s\tremaining: 24.7s\n",
      "823:\tlearn: 0.0623904\ttotal: 1m 54s\tremaining: 24.5s\n",
      "824:\tlearn: 0.0623615\ttotal: 1m 55s\tremaining: 24.4s\n",
      "825:\tlearn: 0.0622461\ttotal: 1m 55s\tremaining: 24.3s\n",
      "826:\tlearn: 0.0622288\ttotal: 1m 55s\tremaining: 24.1s\n",
      "827:\tlearn: 0.0621884\ttotal: 1m 55s\tremaining: 24s\n",
      "828:\tlearn: 0.0621364\ttotal: 1m 55s\tremaining: 23.8s\n",
      "829:\tlearn: 0.0620383\ttotal: 1m 55s\tremaining: 23.7s\n",
      "830:\tlearn: 0.0620152\ttotal: 1m 55s\tremaining: 23.6s\n",
      "831:\tlearn: 0.0619633\ttotal: 1m 55s\tremaining: 23.4s\n",
      "832:\tlearn: 0.0619287\ttotal: 1m 56s\tremaining: 23.3s\n",
      "833:\tlearn: 0.0619114\ttotal: 1m 56s\tremaining: 23.1s\n",
      "834:\tlearn: 0.0618998\ttotal: 1m 56s\tremaining: 23s\n",
      "835:\tlearn: 0.0618075\ttotal: 1m 56s\tremaining: 22.9s\n",
      "836:\tlearn: 0.0617844\ttotal: 1m 56s\tremaining: 22.7s\n",
      "837:\tlearn: 0.0617209\ttotal: 1m 56s\tremaining: 22.6s\n",
      "838:\tlearn: 0.0617094\ttotal: 1m 56s\tremaining: 22.4s\n",
      "839:\tlearn: 0.0616805\ttotal: 1m 57s\tremaining: 22.3s\n",
      "840:\tlearn: 0.0617267\ttotal: 1m 57s\tremaining: 22.2s\n",
      "841:\tlearn: 0.0616517\ttotal: 1m 57s\tremaining: 22s\n",
      "842:\tlearn: 0.0616228\ttotal: 1m 57s\tremaining: 21.9s\n",
      "843:\tlearn: 0.0615305\ttotal: 1m 57s\tremaining: 21.7s\n",
      "844:\tlearn: 0.0614843\ttotal: 1m 57s\tremaining: 21.6s\n",
      "845:\tlearn: 0.0613747\ttotal: 1m 57s\tremaining: 21.4s\n",
      "846:\tlearn: 0.0613400\ttotal: 1m 57s\tremaining: 21.3s\n",
      "847:\tlearn: 0.0612996\ttotal: 1m 58s\tremaining: 21.2s\n",
      "848:\tlearn: 0.0612246\ttotal: 1m 58s\tremaining: 21s\n",
      "849:\tlearn: 0.0611554\ttotal: 1m 58s\tremaining: 20.9s\n",
      "850:\tlearn: 0.0611496\ttotal: 1m 58s\tremaining: 20.7s\n",
      "851:\tlearn: 0.0611207\ttotal: 1m 58s\tremaining: 20.6s\n",
      "852:\tlearn: 0.0610861\ttotal: 1m 58s\tremaining: 20.5s\n",
      "853:\tlearn: 0.0610861\ttotal: 1m 58s\tremaining: 20.3s\n",
      "854:\tlearn: 0.0610803\ttotal: 1m 59s\tremaining: 20.2s\n",
      "855:\tlearn: 0.0610226\ttotal: 1m 59s\tremaining: 20s\n",
      "856:\tlearn: 0.0609938\ttotal: 1m 59s\tremaining: 19.9s\n",
      "857:\tlearn: 0.0609418\ttotal: 1m 59s\tremaining: 19.8s\n",
      "858:\tlearn: 0.0608783\ttotal: 1m 59s\tremaining: 19.6s\n",
      "859:\tlearn: 0.0608206\ttotal: 1m 59s\tremaining: 19.5s\n",
      "860:\tlearn: 0.0608149\ttotal: 1m 59s\tremaining: 19.3s\n",
      "861:\tlearn: 0.0607860\ttotal: 1m 59s\tremaining: 19.2s\n",
      "862:\tlearn: 0.0607283\ttotal: 2m\tremaining: 19.1s\n",
      "863:\tlearn: 0.0606764\ttotal: 2m\tremaining: 18.9s\n",
      "864:\tlearn: 0.0606590\ttotal: 2m\tremaining: 18.8s\n",
      "865:\tlearn: 0.0605436\ttotal: 2m\tremaining: 18.6s\n",
      "866:\tlearn: 0.0605840\ttotal: 2m\tremaining: 18.5s\n",
      "867:\tlearn: 0.0605840\ttotal: 2m\tremaining: 18.4s\n",
      "868:\tlearn: 0.0605725\ttotal: 2m\tremaining: 18.2s\n",
      "869:\tlearn: 0.0605032\ttotal: 2m 1s\tremaining: 18.1s\n",
      "870:\tlearn: 0.0604744\ttotal: 2m 1s\tremaining: 17.9s\n",
      "871:\tlearn: 0.0604109\ttotal: 2m 1s\tremaining: 17.8s\n",
      "872:\tlearn: 0.0604167\ttotal: 2m 1s\tremaining: 17.7s\n",
      "873:\tlearn: 0.0603647\ttotal: 2m 1s\tremaining: 17.5s\n",
      "874:\tlearn: 0.0603243\ttotal: 2m 1s\tremaining: 17.4s\n",
      "875:\tlearn: 0.0603243\ttotal: 2m 1s\tremaining: 17.2s\n",
      "876:\tlearn: 0.0603186\ttotal: 2m 1s\tremaining: 17.1s\n",
      "877:\tlearn: 0.0602435\ttotal: 2m 2s\tremaining: 17s\n",
      "878:\tlearn: 0.0601743\ttotal: 2m 2s\tremaining: 16.8s\n",
      "879:\tlearn: 0.0601685\ttotal: 2m 2s\tremaining: 16.7s\n",
      "880:\tlearn: 0.0601454\ttotal: 2m 2s\tremaining: 16.5s\n",
      "881:\tlearn: 0.0600819\ttotal: 2m 2s\tremaining: 16.4s\n",
      "882:\tlearn: 0.0600704\ttotal: 2m 2s\tremaining: 16.3s\n",
      "883:\tlearn: 0.0600300\ttotal: 2m 2s\tremaining: 16.1s\n",
      "884:\tlearn: 0.0600069\ttotal: 2m 3s\tremaining: 16s\n",
      "885:\tlearn: 0.0599723\ttotal: 2m 3s\tremaining: 15.8s\n",
      "886:\tlearn: 0.0599030\ttotal: 2m 3s\tremaining: 15.7s\n",
      "887:\tlearn: 0.0599319\ttotal: 2m 3s\tremaining: 15.6s\n",
      "888:\tlearn: 0.0598742\ttotal: 2m 3s\tremaining: 15.4s\n",
      "889:\tlearn: 0.0598569\ttotal: 2m 3s\tremaining: 15.3s\n",
      "890:\tlearn: 0.0598569\ttotal: 2m 3s\tremaining: 15.2s\n",
      "891:\tlearn: 0.0598396\ttotal: 2m 3s\tremaining: 15s\n",
      "892:\tlearn: 0.0598280\ttotal: 2m 4s\tremaining: 14.9s\n",
      "893:\tlearn: 0.0597934\ttotal: 2m 4s\tremaining: 14.7s\n",
      "894:\tlearn: 0.0597819\ttotal: 2m 4s\tremaining: 14.6s\n",
      "895:\tlearn: 0.0597241\ttotal: 2m 4s\tremaining: 14.5s\n",
      "896:\tlearn: 0.0597011\ttotal: 2m 4s\tremaining: 14.3s\n",
      "897:\tlearn: 0.0596664\ttotal: 2m 4s\tremaining: 14.2s\n",
      "898:\tlearn: 0.0596549\ttotal: 2m 4s\tremaining: 14s\n",
      "899:\tlearn: 0.0596491\ttotal: 2m 5s\tremaining: 13.9s\n",
      "900:\tlearn: 0.0596318\ttotal: 2m 5s\tremaining: 13.8s\n",
      "901:\tlearn: 0.0595626\ttotal: 2m 5s\tremaining: 13.6s\n",
      "902:\tlearn: 0.0595683\ttotal: 2m 5s\tremaining: 13.5s\n",
      "903:\tlearn: 0.0594991\ttotal: 2m 5s\tremaining: 13.3s\n",
      "904:\tlearn: 0.0594356\ttotal: 2m 5s\tremaining: 13.2s\n",
      "905:\tlearn: 0.0594067\ttotal: 2m 5s\tremaining: 13.1s\n",
      "906:\tlearn: 0.0593894\ttotal: 2m 6s\tremaining: 12.9s\n",
      "907:\tlearn: 0.0593779\ttotal: 2m 6s\tremaining: 12.8s\n",
      "908:\tlearn: 0.0594010\ttotal: 2m 6s\tremaining: 12.6s\n",
      "909:\tlearn: 0.0593490\ttotal: 2m 6s\tremaining: 12.5s\n",
      "910:\tlearn: 0.0592740\ttotal: 2m 6s\tremaining: 12.4s\n",
      "911:\tlearn: 0.0592278\ttotal: 2m 6s\tremaining: 12.2s\n",
      "912:\tlearn: 0.0591990\ttotal: 2m 6s\tremaining: 12.1s\n",
      "913:\tlearn: 0.0591470\ttotal: 2m 6s\tremaining: 11.9s\n",
      "914:\tlearn: 0.0591066\ttotal: 2m 7s\tremaining: 11.8s\n",
      "915:\tlearn: 0.0590720\ttotal: 2m 7s\tremaining: 11.7s\n",
      "916:\tlearn: 0.0590547\ttotal: 2m 7s\tremaining: 11.5s\n",
      "917:\tlearn: 0.0589739\ttotal: 2m 7s\tremaining: 11.4s\n",
      "918:\tlearn: 0.0590085\ttotal: 2m 7s\tremaining: 11.3s\n",
      "919:\tlearn: 0.0589451\ttotal: 2m 7s\tremaining: 11.1s\n",
      "920:\tlearn: 0.0589047\ttotal: 2m 7s\tremaining: 11s\n",
      "921:\tlearn: 0.0589047\ttotal: 2m 8s\tremaining: 10.8s\n",
      "922:\tlearn: 0.0588181\ttotal: 2m 8s\tremaining: 10.7s\n",
      "923:\tlearn: 0.0588181\ttotal: 2m 8s\tremaining: 10.6s\n",
      "924:\tlearn: 0.0587546\ttotal: 2m 8s\tremaining: 10.4s\n",
      "925:\tlearn: 0.0587084\ttotal: 2m 8s\tremaining: 10.3s\n",
      "926:\tlearn: 0.0587142\ttotal: 2m 8s\tremaining: 10.1s\n",
      "927:\tlearn: 0.0586854\ttotal: 2m 8s\tremaining: 10s\n",
      "928:\tlearn: 0.0586277\ttotal: 2m 9s\tremaining: 9.86s\n",
      "929:\tlearn: 0.0585295\ttotal: 2m 9s\tremaining: 9.72s\n",
      "930:\tlearn: 0.0584776\ttotal: 2m 9s\tremaining: 9.58s\n",
      "931:\tlearn: 0.0584199\ttotal: 2m 9s\tremaining: 9.44s\n",
      "932:\tlearn: 0.0584141\ttotal: 2m 9s\tremaining: 9.3s\n",
      "933:\tlearn: 0.0584084\ttotal: 2m 9s\tremaining: 9.16s\n",
      "934:\tlearn: 0.0583333\ttotal: 2m 9s\tremaining: 9.02s\n",
      "935:\tlearn: 0.0582929\ttotal: 2m 9s\tremaining: 8.88s\n",
      "936:\tlearn: 0.0582583\ttotal: 2m 10s\tremaining: 8.75s\n",
      "937:\tlearn: 0.0582064\ttotal: 2m 10s\tremaining: 8.61s\n",
      "938:\tlearn: 0.0581948\ttotal: 2m 10s\tremaining: 8.47s\n",
      "939:\tlearn: 0.0582006\ttotal: 2m 10s\tremaining: 8.33s\n",
      "940:\tlearn: 0.0581891\ttotal: 2m 10s\tremaining: 8.19s\n",
      "941:\tlearn: 0.0581487\ttotal: 2m 10s\tremaining: 8.05s\n",
      "942:\tlearn: 0.0581487\ttotal: 2m 10s\tremaining: 7.91s\n",
      "943:\tlearn: 0.0581198\ttotal: 2m 11s\tremaining: 7.77s\n",
      "944:\tlearn: 0.0581256\ttotal: 2m 11s\tremaining: 7.63s\n",
      "945:\tlearn: 0.0580679\ttotal: 2m 11s\tremaining: 7.5s\n",
      "946:\tlearn: 0.0580102\ttotal: 2m 11s\tremaining: 7.36s\n",
      "947:\tlearn: 0.0580159\ttotal: 2m 11s\tremaining: 7.22s\n",
      "948:\tlearn: 0.0579640\ttotal: 2m 11s\tremaining: 7.08s\n",
      "949:\tlearn: 0.0579467\ttotal: 2m 11s\tremaining: 6.94s\n",
      "950:\tlearn: 0.0579236\ttotal: 2m 11s\tremaining: 6.8s\n",
      "951:\tlearn: 0.0579120\ttotal: 2m 12s\tremaining: 6.66s\n",
      "952:\tlearn: 0.0578947\ttotal: 2m 12s\tremaining: 6.52s\n",
      "953:\tlearn: 0.0578486\ttotal: 2m 12s\tremaining: 6.38s\n",
      "954:\tlearn: 0.0577851\ttotal: 2m 12s\tremaining: 6.24s\n",
      "955:\tlearn: 0.0577389\ttotal: 2m 12s\tremaining: 6.1s\n",
      "956:\tlearn: 0.0577101\ttotal: 2m 12s\tremaining: 5.96s\n",
      "957:\tlearn: 0.0577101\ttotal: 2m 12s\tremaining: 5.83s\n",
      "958:\tlearn: 0.0577043\ttotal: 2m 13s\tremaining: 5.69s\n",
      "959:\tlearn: 0.0576639\ttotal: 2m 13s\tremaining: 5.55s\n",
      "960:\tlearn: 0.0576177\ttotal: 2m 13s\tremaining: 5.41s\n",
      "961:\tlearn: 0.0575716\ttotal: 2m 13s\tremaining: 5.27s\n",
      "962:\tlearn: 0.0575139\ttotal: 2m 13s\tremaining: 5.13s\n",
      "963:\tlearn: 0.0574850\ttotal: 2m 13s\tremaining: 4.99s\n",
      "964:\tlearn: 0.0574446\ttotal: 2m 13s\tremaining: 4.85s\n",
      "965:\tlearn: 0.0574388\ttotal: 2m 13s\tremaining: 4.72s\n",
      "966:\tlearn: 0.0574388\ttotal: 2m 14s\tremaining: 4.58s\n",
      "967:\tlearn: 0.0574273\ttotal: 2m 14s\tremaining: 4.44s\n",
      "968:\tlearn: 0.0573580\ttotal: 2m 14s\tremaining: 4.3s\n",
      "969:\tlearn: 0.0573465\ttotal: 2m 14s\tremaining: 4.16s\n",
      "970:\tlearn: 0.0573119\ttotal: 2m 14s\tremaining: 4.02s\n",
      "971:\tlearn: 0.0572715\ttotal: 2m 14s\tremaining: 3.88s\n",
      "972:\tlearn: 0.0572311\ttotal: 2m 14s\tremaining: 3.74s\n",
      "973:\tlearn: 0.0572311\ttotal: 2m 15s\tremaining: 3.6s\n",
      "974:\tlearn: 0.0571964\ttotal: 2m 15s\tremaining: 3.47s\n",
      "975:\tlearn: 0.0571676\ttotal: 2m 15s\tremaining: 3.33s\n",
      "976:\tlearn: 0.0571503\ttotal: 2m 15s\tremaining: 3.19s\n",
      "977:\tlearn: 0.0571099\ttotal: 2m 15s\tremaining: 3.05s\n",
      "978:\tlearn: 0.0570349\ttotal: 2m 15s\tremaining: 2.91s\n",
      "979:\tlearn: 0.0569887\ttotal: 2m 15s\tremaining: 2.77s\n",
      "980:\tlearn: 0.0569945\ttotal: 2m 16s\tremaining: 2.63s\n",
      "981:\tlearn: 0.0569541\ttotal: 2m 16s\tremaining: 2.5s\n",
      "982:\tlearn: 0.0569252\ttotal: 2m 16s\tremaining: 2.36s\n",
      "983:\tlearn: 0.0569194\ttotal: 2m 16s\tremaining: 2.22s\n",
      "984:\tlearn: 0.0568848\ttotal: 2m 16s\tremaining: 2.08s\n",
      "985:\tlearn: 0.0568617\ttotal: 2m 16s\tremaining: 1.94s\n",
      "986:\tlearn: 0.0568098\ttotal: 2m 16s\tremaining: 1.8s\n",
      "987:\tlearn: 0.0567405\ttotal: 2m 16s\tremaining: 1.66s\n",
      "988:\tlearn: 0.0567232\ttotal: 2m 17s\tremaining: 1.52s\n",
      "989:\tlearn: 0.0566944\ttotal: 2m 17s\tremaining: 1.39s\n",
      "990:\tlearn: 0.0566771\ttotal: 2m 17s\tremaining: 1.25s\n",
      "991:\tlearn: 0.0566251\ttotal: 2m 17s\tremaining: 1.11s\n",
      "992:\tlearn: 0.0565501\ttotal: 2m 17s\tremaining: 970ms\n",
      "993:\tlearn: 0.0565212\ttotal: 2m 17s\tremaining: 831ms\n",
      "994:\tlearn: 0.0565212\ttotal: 2m 17s\tremaining: 693ms\n",
      "995:\tlearn: 0.0564866\ttotal: 2m 18s\tremaining: 554ms\n",
      "996:\tlearn: 0.0564174\ttotal: 2m 18s\tremaining: 416ms\n",
      "997:\tlearn: 0.0564289\ttotal: 2m 18s\tremaining: 277ms\n",
      "998:\tlearn: 0.0564174\ttotal: 2m 18s\tremaining: 139ms\n",
      "999:\tlearn: 0.0563539\ttotal: 2m 18s\tremaining: 0us\n",
      "Learning rate set to 0.026476\n",
      "0:\tlearn: 0.1092394\ttotal: 131ms\tremaining: 2m 10s\n",
      "1:\tlearn: 0.1092625\ttotal: 261ms\tremaining: 2m 10s\n",
      "2:\tlearn: 0.1094587\ttotal: 389ms\tremaining: 2m 9s\n",
      "3:\tlearn: 0.1095510\ttotal: 525ms\tremaining: 2m 10s\n",
      "4:\tlearn: 0.1096491\ttotal: 654ms\tremaining: 2m 10s\n",
      "5:\tlearn: 0.1097011\ttotal: 790ms\tremaining: 2m 10s\n",
      "6:\tlearn: 0.1095279\ttotal: 922ms\tremaining: 2m 10s\n",
      "7:\tlearn: 0.1098800\ttotal: 1.05s\tremaining: 2m 10s\n",
      "8:\tlearn: 0.1097241\ttotal: 1.18s\tremaining: 2m 10s\n",
      "9:\tlearn: 0.1096030\ttotal: 1.32s\tremaining: 2m 10s\n",
      "10:\tlearn: 0.1095337\ttotal: 1.45s\tremaining: 2m 10s\n",
      "11:\tlearn: 0.1095741\ttotal: 1.59s\tremaining: 2m 10s\n",
      "12:\tlearn: 0.1094991\ttotal: 1.73s\tremaining: 2m 11s\n",
      "13:\tlearn: 0.1095799\ttotal: 1.86s\tremaining: 2m 11s\n",
      "14:\tlearn: 0.1095683\ttotal: 2s\tremaining: 2m 11s\n",
      "15:\tlearn: 0.1095337\ttotal: 2.13s\tremaining: 2m 11s\n",
      "16:\tlearn: 0.1095683\ttotal: 2.26s\tremaining: 2m 10s\n",
      "17:\tlearn: 0.1094933\ttotal: 2.39s\tremaining: 2m 10s\n",
      "18:\tlearn: 0.1094760\ttotal: 2.52s\tremaining: 2m 10s\n",
      "19:\tlearn: 0.1093433\ttotal: 2.65s\tremaining: 2m 10s\n",
      "20:\tlearn: 0.1093433\ttotal: 2.79s\tremaining: 2m 9s\n",
      "21:\tlearn: 0.1093375\ttotal: 2.92s\tremaining: 2m 9s\n",
      "22:\tlearn: 0.1092509\ttotal: 3.06s\tremaining: 2m 9s\n",
      "23:\tlearn: 0.1092971\ttotal: 3.2s\tremaining: 2m 10s\n",
      "24:\tlearn: 0.1091701\ttotal: 3.34s\tremaining: 2m 10s\n",
      "25:\tlearn: 0.1091124\ttotal: 3.49s\tremaining: 2m 10s\n",
      "26:\tlearn: 0.1089797\ttotal: 3.62s\tremaining: 2m 10s\n",
      "27:\tlearn: 0.1089970\ttotal: 3.77s\tremaining: 2m 10s\n",
      "28:\tlearn: 0.1090143\ttotal: 3.89s\tremaining: 2m 10s\n",
      "29:\tlearn: 0.1089508\ttotal: 4.04s\tremaining: 2m 10s\n",
      "30:\tlearn: 0.1088527\ttotal: 4.17s\tremaining: 2m 10s\n",
      "31:\tlearn: 0.1087142\ttotal: 4.31s\tremaining: 2m 10s\n",
      "32:\tlearn: 0.1086738\ttotal: 4.44s\tremaining: 2m 10s\n",
      "33:\tlearn: 0.1086392\ttotal: 4.57s\tremaining: 2m 9s\n",
      "34:\tlearn: 0.1085122\ttotal: 4.71s\tremaining: 2m 9s\n",
      "35:\tlearn: 0.1084026\ttotal: 4.85s\tremaining: 2m 9s\n",
      "36:\tlearn: 0.1082410\ttotal: 4.98s\tremaining: 2m 9s\n",
      "37:\tlearn: 0.1081660\ttotal: 5.11s\tremaining: 2m 9s\n",
      "38:\tlearn: 0.1080448\ttotal: 5.26s\tremaining: 2m 9s\n",
      "39:\tlearn: 0.1078890\ttotal: 5.4s\tremaining: 2m 9s\n",
      "40:\tlearn: 0.1079120\ttotal: 5.53s\tremaining: 2m 9s\n",
      "41:\tlearn: 0.1077735\ttotal: 5.67s\tremaining: 2m 9s\n",
      "42:\tlearn: 0.1076062\ttotal: 5.79s\tremaining: 2m 8s\n",
      "43:\tlearn: 0.1075023\ttotal: 5.93s\tremaining: 2m 8s\n",
      "44:\tlearn: 0.1074965\ttotal: 6.06s\tremaining: 2m 8s\n",
      "45:\tlearn: 0.1073523\ttotal: 6.2s\tremaining: 2m 8s\n",
      "46:\tlearn: 0.1072138\ttotal: 6.33s\tremaining: 2m 8s\n",
      "47:\tlearn: 0.1071214\ttotal: 6.46s\tremaining: 2m 8s\n",
      "48:\tlearn: 0.1070926\ttotal: 6.6s\tremaining: 2m 8s\n",
      "49:\tlearn: 0.1069425\ttotal: 6.73s\tremaining: 2m 7s\n",
      "50:\tlearn: 0.1068790\ttotal: 6.86s\tremaining: 2m 7s\n",
      "51:\tlearn: 0.1067578\ttotal: 7.01s\tremaining: 2m 7s\n",
      "52:\tlearn: 0.1065616\ttotal: 7.14s\tremaining: 2m 7s\n",
      "53:\tlearn: 0.1065097\ttotal: 7.27s\tremaining: 2m 7s\n",
      "54:\tlearn: 0.1064578\ttotal: 7.41s\tremaining: 2m 7s\n",
      "55:\tlearn: 0.1063019\ttotal: 7.54s\tremaining: 2m 7s\n",
      "56:\tlearn: 0.1061461\ttotal: 7.67s\tremaining: 2m 6s\n",
      "57:\tlearn: 0.1060769\ttotal: 7.81s\tremaining: 2m 6s\n",
      "58:\tlearn: 0.1060307\ttotal: 7.95s\tremaining: 2m 6s\n",
      "59:\tlearn: 0.1060076\ttotal: 8.08s\tremaining: 2m 6s\n",
      "60:\tlearn: 0.1058576\ttotal: 8.21s\tremaining: 2m 6s\n",
      "61:\tlearn: 0.1057652\ttotal: 8.34s\tremaining: 2m 6s\n",
      "62:\tlearn: 0.1056440\ttotal: 8.47s\tremaining: 2m 6s\n",
      "63:\tlearn: 0.1056440\ttotal: 8.61s\tremaining: 2m 5s\n",
      "64:\tlearn: 0.1055748\ttotal: 8.74s\tremaining: 2m 5s\n",
      "65:\tlearn: 0.1055113\ttotal: 8.87s\tremaining: 2m 5s\n",
      "66:\tlearn: 0.1054363\ttotal: 9.01s\tremaining: 2m 5s\n",
      "67:\tlearn: 0.1054190\ttotal: 9.15s\tremaining: 2m 5s\n",
      "68:\tlearn: 0.1053151\ttotal: 9.28s\tremaining: 2m 5s\n",
      "69:\tlearn: 0.1053209\ttotal: 9.41s\tremaining: 2m 5s\n",
      "70:\tlearn: 0.1052054\ttotal: 9.54s\tremaining: 2m 4s\n",
      "71:\tlearn: 0.1052574\ttotal: 9.61s\tremaining: 2m 3s\n",
      "72:\tlearn: 0.1051420\ttotal: 9.75s\tremaining: 2m 3s\n",
      "73:\tlearn: 0.1049977\ttotal: 9.88s\tremaining: 2m 3s\n",
      "74:\tlearn: 0.1048534\ttotal: 10s\tremaining: 2m 3s\n",
      "75:\tlearn: 0.1046514\ttotal: 10.2s\tremaining: 2m 3s\n",
      "76:\tlearn: 0.1046168\ttotal: 10.3s\tremaining: 2m 3s\n",
      "77:\tlearn: 0.1044610\ttotal: 10.4s\tremaining: 2m 3s\n",
      "78:\tlearn: 0.1043744\ttotal: 10.6s\tremaining: 2m 3s\n",
      "79:\tlearn: 0.1042994\ttotal: 10.7s\tremaining: 2m 3s\n",
      "80:\tlearn: 0.1041609\ttotal: 10.9s\tremaining: 2m 3s\n",
      "81:\tlearn: 0.1040801\ttotal: 11s\tremaining: 2m 3s\n",
      "82:\tlearn: 0.1039358\ttotal: 11.2s\tremaining: 2m 3s\n",
      "83:\tlearn: 0.1036761\ttotal: 11.3s\tremaining: 2m 3s\n",
      "84:\tlearn: 0.1035607\ttotal: 11.5s\tremaining: 2m 3s\n",
      "85:\tlearn: 0.1033010\ttotal: 11.6s\tremaining: 2m 3s\n",
      "86:\tlearn: 0.1031971\ttotal: 11.8s\tremaining: 2m 3s\n",
      "87:\tlearn: 0.1031452\ttotal: 11.9s\tremaining: 2m 3s\n",
      "88:\tlearn: 0.1031106\ttotal: 12.1s\tremaining: 2m 3s\n",
      "89:\tlearn: 0.1029663\ttotal: 12.2s\tremaining: 2m 3s\n",
      "90:\tlearn: 0.1028336\ttotal: 12.3s\tremaining: 2m 3s\n",
      "91:\tlearn: 0.1027239\ttotal: 12.5s\tremaining: 2m 2s\n",
      "92:\tlearn: 0.1025912\ttotal: 12.6s\tremaining: 2m 2s\n",
      "93:\tlearn: 0.1024296\ttotal: 12.7s\tremaining: 2m 2s\n",
      "94:\tlearn: 0.1022161\ttotal: 12.9s\tremaining: 2m 2s\n",
      "95:\tlearn: 0.1021237\ttotal: 13s\tremaining: 2m 2s\n",
      "96:\tlearn: 0.1021237\ttotal: 13.1s\tremaining: 2m 2s\n",
      "97:\tlearn: 0.1020602\ttotal: 13.3s\tremaining: 2m 2s\n",
      "98:\tlearn: 0.1018756\ttotal: 13.4s\tremaining: 2m 2s\n",
      "99:\tlearn: 0.1017371\ttotal: 13.6s\tremaining: 2m 2s\n",
      "100:\tlearn: 0.1016332\ttotal: 13.7s\tremaining: 2m 1s\n",
      "101:\tlearn: 0.1015178\ttotal: 13.8s\tremaining: 2m 1s\n",
      "102:\tlearn: 0.1013908\ttotal: 14s\tremaining: 2m 1s\n",
      "103:\tlearn: 0.1012235\ttotal: 14.1s\tremaining: 2m 1s\n",
      "104:\tlearn: 0.1011542\ttotal: 14.2s\tremaining: 2m 1s\n",
      "105:\tlearn: 0.1008310\ttotal: 14.4s\tremaining: 2m 1s\n",
      "106:\tlearn: 0.1007329\ttotal: 14.5s\tremaining: 2m 1s\n",
      "107:\tlearn: 0.1006060\ttotal: 14.6s\tremaining: 2m\n",
      "108:\tlearn: 0.1004444\ttotal: 14.8s\tremaining: 2m\n",
      "109:\tlearn: 0.1004040\ttotal: 14.9s\tremaining: 2m\n",
      "110:\tlearn: 0.1002770\ttotal: 15.1s\tremaining: 2m\n",
      "111:\tlearn: 0.1001674\ttotal: 15.2s\tremaining: 2m\n",
      "112:\tlearn: 0.1001616\ttotal: 15.3s\tremaining: 2m\n",
      "113:\tlearn: 0.1000981\ttotal: 15.5s\tremaining: 2m\n",
      "114:\tlearn: 0.0999654\ttotal: 15.6s\tremaining: 2m\n",
      "115:\tlearn: 0.0998500\ttotal: 15.7s\tremaining: 1m 59s\n",
      "116:\tlearn: 0.0998153\ttotal: 15.9s\tremaining: 1m 59s\n",
      "117:\tlearn: 0.0997692\ttotal: 16s\tremaining: 1m 59s\n",
      "118:\tlearn: 0.0996941\ttotal: 16.1s\tremaining: 1m 59s\n",
      "119:\tlearn: 0.0996422\ttotal: 16.3s\tremaining: 1m 59s\n",
      "120:\tlearn: 0.0994691\ttotal: 16.4s\tremaining: 1m 59s\n",
      "121:\tlearn: 0.0994229\ttotal: 16.5s\tremaining: 1m 59s\n",
      "122:\tlearn: 0.0993998\ttotal: 16.7s\tremaining: 1m 58s\n",
      "123:\tlearn: 0.0993190\ttotal: 16.8s\tremaining: 1m 58s\n",
      "124:\tlearn: 0.0992555\ttotal: 17s\tremaining: 1m 58s\n",
      "125:\tlearn: 0.0992267\ttotal: 17.1s\tremaining: 1m 58s\n",
      "126:\tlearn: 0.0991228\ttotal: 17.2s\tremaining: 1m 58s\n",
      "127:\tlearn: 0.0990247\ttotal: 17.4s\tremaining: 1m 58s\n",
      "128:\tlearn: 0.0988631\ttotal: 17.5s\tremaining: 1m 58s\n",
      "129:\tlearn: 0.0987765\ttotal: 17.6s\tremaining: 1m 57s\n",
      "130:\tlearn: 0.0987131\ttotal: 17.8s\tremaining: 1m 57s\n",
      "131:\tlearn: 0.0986900\ttotal: 17.9s\tremaining: 1m 57s\n",
      "132:\tlearn: 0.0985919\ttotal: 18s\tremaining: 1m 57s\n",
      "133:\tlearn: 0.0984072\ttotal: 18.2s\tremaining: 1m 57s\n",
      "134:\tlearn: 0.0982572\ttotal: 18.3s\tremaining: 1m 57s\n",
      "135:\tlearn: 0.0981590\ttotal: 18.5s\tremaining: 1m 57s\n",
      "136:\tlearn: 0.0980148\ttotal: 18.6s\tremaining: 1m 57s\n",
      "137:\tlearn: 0.0979282\ttotal: 18.8s\tremaining: 1m 57s\n",
      "138:\tlearn: 0.0978705\ttotal: 18.9s\tremaining: 1m 57s\n",
      "139:\tlearn: 0.0976801\ttotal: 19.1s\tremaining: 1m 57s\n",
      "140:\tlearn: 0.0974954\ttotal: 19.3s\tremaining: 1m 57s\n",
      "141:\tlearn: 0.0973453\ttotal: 19.4s\tremaining: 1m 57s\n",
      "142:\tlearn: 0.0971895\ttotal: 19.6s\tremaining: 1m 57s\n",
      "143:\tlearn: 0.0971145\ttotal: 19.7s\tremaining: 1m 57s\n",
      "144:\tlearn: 0.0970048\ttotal: 19.9s\tremaining: 1m 57s\n",
      "145:\tlearn: 0.0969587\ttotal: 20s\tremaining: 1m 57s\n",
      "146:\tlearn: 0.0969183\ttotal: 20.2s\tremaining: 1m 57s\n",
      "147:\tlearn: 0.0967798\ttotal: 20.3s\tremaining: 1m 56s\n",
      "148:\tlearn: 0.0966932\ttotal: 20.5s\tremaining: 1m 56s\n",
      "149:\tlearn: 0.0966470\ttotal: 20.6s\tremaining: 1m 56s\n",
      "150:\tlearn: 0.0965720\ttotal: 20.8s\tremaining: 1m 56s\n",
      "151:\tlearn: 0.0964566\ttotal: 20.9s\tremaining: 1m 56s\n",
      "152:\tlearn: 0.0963470\ttotal: 21.1s\tremaining: 1m 56s\n",
      "153:\tlearn: 0.0962604\ttotal: 21.2s\tremaining: 1m 56s\n",
      "154:\tlearn: 0.0961738\ttotal: 21.4s\tremaining: 1m 56s\n",
      "155:\tlearn: 0.0961334\ttotal: 21.6s\tremaining: 1m 56s\n",
      "156:\tlearn: 0.0960353\ttotal: 21.7s\tremaining: 1m 56s\n",
      "157:\tlearn: 0.0959084\ttotal: 21.9s\tremaining: 1m 56s\n",
      "158:\tlearn: 0.0957987\ttotal: 22.1s\tremaining: 1m 56s\n",
      "159:\tlearn: 0.0956429\ttotal: 22.2s\tremaining: 1m 56s\n",
      "160:\tlearn: 0.0955159\ttotal: 22.4s\tremaining: 1m 56s\n",
      "161:\tlearn: 0.0954120\ttotal: 22.5s\tremaining: 1m 56s\n",
      "162:\tlearn: 0.0953947\ttotal: 22.7s\tremaining: 1m 56s\n",
      "163:\tlearn: 0.0951408\ttotal: 22.8s\tremaining: 1m 56s\n",
      "164:\tlearn: 0.0951235\ttotal: 23s\tremaining: 1m 56s\n",
      "165:\tlearn: 0.0950139\ttotal: 23.1s\tremaining: 1m 56s\n",
      "166:\tlearn: 0.0949792\ttotal: 23.3s\tremaining: 1m 56s\n",
      "167:\tlearn: 0.0949388\ttotal: 23.5s\tremaining: 1m 56s\n",
      "168:\tlearn: 0.0947888\ttotal: 23.7s\tremaining: 1m 56s\n",
      "169:\tlearn: 0.0947830\ttotal: 23.9s\tremaining: 1m 56s\n",
      "170:\tlearn: 0.0947022\ttotal: 24.1s\tremaining: 1m 57s\n",
      "171:\tlearn: 0.0946618\ttotal: 24.3s\tremaining: 1m 57s\n",
      "172:\tlearn: 0.0945983\ttotal: 24.5s\tremaining: 1m 57s\n",
      "173:\tlearn: 0.0945060\ttotal: 24.6s\tremaining: 1m 56s\n",
      "174:\tlearn: 0.0944310\ttotal: 24.8s\tremaining: 1m 56s\n",
      "175:\tlearn: 0.0943271\ttotal: 24.9s\tremaining: 1m 56s\n",
      "176:\tlearn: 0.0942867\ttotal: 25.1s\tremaining: 1m 56s\n",
      "177:\tlearn: 0.0942001\ttotal: 25.3s\tremaining: 1m 56s\n",
      "178:\tlearn: 0.0940674\ttotal: 25.4s\tremaining: 1m 56s\n",
      "179:\tlearn: 0.0940212\ttotal: 25.5s\tremaining: 1m 56s\n",
      "180:\tlearn: 0.0939578\ttotal: 25.7s\tremaining: 1m 56s\n",
      "181:\tlearn: 0.0938539\ttotal: 25.8s\tremaining: 1m 56s\n",
      "182:\tlearn: 0.0937846\ttotal: 26s\tremaining: 1m 55s\n",
      "183:\tlearn: 0.0936519\ttotal: 26.1s\tremaining: 1m 55s\n",
      "184:\tlearn: 0.0935884\ttotal: 26.2s\tremaining: 1m 55s\n",
      "185:\tlearn: 0.0934037\ttotal: 26.4s\tremaining: 1m 55s\n",
      "186:\tlearn: 0.0933576\ttotal: 26.5s\tremaining: 1m 55s\n",
      "187:\tlearn: 0.0932883\ttotal: 26.6s\tremaining: 1m 55s\n",
      "188:\tlearn: 0.0932768\ttotal: 26.8s\tremaining: 1m 54s\n",
      "189:\tlearn: 0.0931210\ttotal: 26.9s\tremaining: 1m 54s\n",
      "190:\tlearn: 0.0931152\ttotal: 27.1s\tremaining: 1m 54s\n",
      "191:\tlearn: 0.0930690\ttotal: 27.2s\tremaining: 1m 54s\n",
      "192:\tlearn: 0.0929247\ttotal: 27.4s\tremaining: 1m 54s\n",
      "193:\tlearn: 0.0929132\ttotal: 27.5s\tremaining: 1m 54s\n",
      "194:\tlearn: 0.0928093\ttotal: 27.6s\tremaining: 1m 54s\n",
      "195:\tlearn: 0.0927112\ttotal: 27.8s\tremaining: 1m 53s\n",
      "196:\tlearn: 0.0926073\ttotal: 27.9s\tremaining: 1m 53s\n",
      "197:\tlearn: 0.0924400\ttotal: 28s\tremaining: 1m 53s\n",
      "198:\tlearn: 0.0924169\ttotal: 28.2s\tremaining: 1m 53s\n",
      "199:\tlearn: 0.0923765\ttotal: 28.3s\tremaining: 1m 53s\n",
      "200:\tlearn: 0.0923072\ttotal: 28.4s\tremaining: 1m 53s\n",
      "201:\tlearn: 0.0922842\ttotal: 28.6s\tremaining: 1m 52s\n",
      "202:\tlearn: 0.0921861\ttotal: 28.7s\tremaining: 1m 52s\n",
      "203:\tlearn: 0.0921687\ttotal: 28.8s\tremaining: 1m 52s\n",
      "204:\tlearn: 0.0921630\ttotal: 29s\tremaining: 1m 52s\n",
      "205:\tlearn: 0.0920187\ttotal: 29.1s\tremaining: 1m 52s\n",
      "206:\tlearn: 0.0919783\ttotal: 29.3s\tremaining: 1m 52s\n",
      "207:\tlearn: 0.0919264\ttotal: 29.4s\tremaining: 1m 51s\n",
      "208:\tlearn: 0.0917994\ttotal: 29.5s\tremaining: 1m 51s\n",
      "209:\tlearn: 0.0917186\ttotal: 29.7s\tremaining: 1m 51s\n",
      "210:\tlearn: 0.0916724\ttotal: 29.8s\tremaining: 1m 51s\n",
      "211:\tlearn: 0.0916090\ttotal: 29.9s\tremaining: 1m 51s\n",
      "212:\tlearn: 0.0914531\ttotal: 30.1s\tremaining: 1m 51s\n",
      "213:\tlearn: 0.0913781\ttotal: 30.2s\tremaining: 1m 50s\n",
      "214:\tlearn: 0.0912973\ttotal: 30.3s\tremaining: 1m 50s\n",
      "215:\tlearn: 0.0912685\ttotal: 30.5s\tremaining: 1m 50s\n",
      "216:\tlearn: 0.0912569\ttotal: 30.6s\tremaining: 1m 50s\n",
      "217:\tlearn: 0.0912396\ttotal: 30.7s\tremaining: 1m 50s\n",
      "218:\tlearn: 0.0912512\ttotal: 30.9s\tremaining: 1m 50s\n",
      "219:\tlearn: 0.0911588\ttotal: 31s\tremaining: 1m 49s\n",
      "220:\tlearn: 0.0911646\ttotal: 31.2s\tremaining: 1m 49s\n",
      "221:\tlearn: 0.0911127\ttotal: 31.3s\tremaining: 1m 49s\n",
      "222:\tlearn: 0.0911242\ttotal: 31.4s\tremaining: 1m 49s\n",
      "223:\tlearn: 0.0910492\ttotal: 31.6s\tremaining: 1m 49s\n",
      "224:\tlearn: 0.0908414\ttotal: 31.7s\tremaining: 1m 49s\n",
      "225:\tlearn: 0.0907202\ttotal: 31.8s\tremaining: 1m 49s\n",
      "226:\tlearn: 0.0907375\ttotal: 32s\tremaining: 1m 48s\n",
      "227:\tlearn: 0.0906567\ttotal: 32.1s\tremaining: 1m 48s\n",
      "228:\tlearn: 0.0906337\ttotal: 32.2s\tremaining: 1m 48s\n",
      "229:\tlearn: 0.0906163\ttotal: 32.4s\tremaining: 1m 48s\n",
      "230:\tlearn: 0.0905529\ttotal: 32.5s\tremaining: 1m 48s\n",
      "231:\tlearn: 0.0905586\ttotal: 32.6s\tremaining: 1m 48s\n",
      "232:\tlearn: 0.0905298\ttotal: 32.8s\tremaining: 1m 47s\n",
      "233:\tlearn: 0.0904778\ttotal: 32.9s\tremaining: 1m 47s\n",
      "234:\tlearn: 0.0904432\ttotal: 33s\tremaining: 1m 47s\n",
      "235:\tlearn: 0.0903509\ttotal: 33.2s\tremaining: 1m 47s\n",
      "236:\tlearn: 0.0902412\ttotal: 33.3s\tremaining: 1m 47s\n",
      "237:\tlearn: 0.0901316\ttotal: 33.5s\tremaining: 1m 47s\n",
      "238:\tlearn: 0.0900970\ttotal: 33.6s\tremaining: 1m 47s\n",
      "239:\tlearn: 0.0900046\ttotal: 33.8s\tremaining: 1m 46s\n",
      "240:\tlearn: 0.0899584\ttotal: 33.9s\tremaining: 1m 46s\n",
      "241:\tlearn: 0.0898199\ttotal: 34s\tremaining: 1m 46s\n",
      "242:\tlearn: 0.0897680\ttotal: 34.2s\tremaining: 1m 46s\n",
      "243:\tlearn: 0.0896410\ttotal: 34.3s\tremaining: 1m 46s\n",
      "244:\tlearn: 0.0895660\ttotal: 34.4s\tremaining: 1m 46s\n",
      "245:\tlearn: 0.0895199\ttotal: 34.6s\tremaining: 1m 45s\n",
      "246:\tlearn: 0.0893583\ttotal: 34.7s\tremaining: 1m 45s\n",
      "247:\tlearn: 0.0892659\ttotal: 34.8s\tremaining: 1m 45s\n",
      "248:\tlearn: 0.0892140\ttotal: 35s\tremaining: 1m 45s\n",
      "249:\tlearn: 0.0891678\ttotal: 35.1s\tremaining: 1m 45s\n",
      "250:\tlearn: 0.0891678\ttotal: 35.3s\tremaining: 1m 45s\n",
      "251:\tlearn: 0.0890639\ttotal: 35.4s\tremaining: 1m 45s\n",
      "252:\tlearn: 0.0888966\ttotal: 35.5s\tremaining: 1m 44s\n",
      "253:\tlearn: 0.0888620\ttotal: 35.7s\tremaining: 1m 44s\n",
      "254:\tlearn: 0.0888216\ttotal: 35.8s\tremaining: 1m 44s\n",
      "255:\tlearn: 0.0887869\ttotal: 35.9s\tremaining: 1m 44s\n",
      "256:\tlearn: 0.0887292\ttotal: 36.1s\tremaining: 1m 44s\n",
      "257:\tlearn: 0.0886542\ttotal: 36.2s\tremaining: 1m 44s\n",
      "258:\tlearn: 0.0886138\ttotal: 36.3s\tremaining: 1m 43s\n",
      "259:\tlearn: 0.0884984\ttotal: 36.5s\tremaining: 1m 43s\n",
      "260:\tlearn: 0.0884811\ttotal: 36.6s\tremaining: 1m 43s\n",
      "261:\tlearn: 0.0884003\ttotal: 36.7s\tremaining: 1m 43s\n",
      "262:\tlearn: 0.0883772\ttotal: 36.9s\tremaining: 1m 43s\n",
      "263:\tlearn: 0.0882733\ttotal: 37s\tremaining: 1m 43s\n",
      "264:\tlearn: 0.0881348\ttotal: 37.1s\tremaining: 1m 43s\n",
      "265:\tlearn: 0.0881521\ttotal: 37.3s\tremaining: 1m 42s\n",
      "266:\tlearn: 0.0881233\ttotal: 37.4s\tremaining: 1m 42s\n",
      "267:\tlearn: 0.0880309\ttotal: 37.5s\tremaining: 1m 42s\n",
      "268:\tlearn: 0.0879732\ttotal: 37.7s\tremaining: 1m 42s\n",
      "269:\tlearn: 0.0879386\ttotal: 37.8s\tremaining: 1m 42s\n",
      "270:\tlearn: 0.0879617\ttotal: 37.9s\tremaining: 1m 42s\n",
      "271:\tlearn: 0.0878636\ttotal: 38.1s\tremaining: 1m 41s\n",
      "272:\tlearn: 0.0877886\ttotal: 38.2s\tremaining: 1m 41s\n",
      "273:\tlearn: 0.0877655\ttotal: 38.3s\tremaining: 1m 41s\n",
      "274:\tlearn: 0.0875981\ttotal: 38.5s\tremaining: 1m 41s\n",
      "275:\tlearn: 0.0876039\ttotal: 38.6s\tremaining: 1m 41s\n",
      "276:\tlearn: 0.0875462\ttotal: 38.7s\tremaining: 1m 41s\n",
      "277:\tlearn: 0.0875404\ttotal: 38.9s\tremaining: 1m 40s\n",
      "278:\tlearn: 0.0874365\ttotal: 39s\tremaining: 1m 40s\n",
      "279:\tlearn: 0.0873904\ttotal: 39.1s\tremaining: 1m 40s\n",
      "280:\tlearn: 0.0873326\ttotal: 39.3s\tremaining: 1m 40s\n",
      "281:\tlearn: 0.0873038\ttotal: 39.4s\tremaining: 1m 40s\n",
      "282:\tlearn: 0.0873096\ttotal: 39.5s\tremaining: 1m 40s\n",
      "283:\tlearn: 0.0872749\ttotal: 39.7s\tremaining: 1m 40s\n",
      "284:\tlearn: 0.0872749\ttotal: 39.8s\tremaining: 1m 39s\n",
      "285:\tlearn: 0.0871999\ttotal: 40s\tremaining: 1m 39s\n",
      "286:\tlearn: 0.0870903\ttotal: 40.1s\tremaining: 1m 39s\n",
      "287:\tlearn: 0.0870960\ttotal: 40.2s\tremaining: 1m 39s\n",
      "288:\tlearn: 0.0870499\ttotal: 40.4s\tremaining: 1m 39s\n",
      "289:\tlearn: 0.0869979\ttotal: 40.5s\tremaining: 1m 39s\n",
      "290:\tlearn: 0.0869056\ttotal: 40.6s\tremaining: 1m 39s\n",
      "291:\tlearn: 0.0868017\ttotal: 40.8s\tremaining: 1m 38s\n",
      "292:\tlearn: 0.0867440\ttotal: 40.9s\tremaining: 1m 38s\n",
      "293:\tlearn: 0.0867844\ttotal: 41s\tremaining: 1m 38s\n",
      "294:\tlearn: 0.0867498\ttotal: 41.2s\tremaining: 1m 38s\n",
      "295:\tlearn: 0.0866863\ttotal: 41.3s\tremaining: 1m 38s\n",
      "296:\tlearn: 0.0865766\ttotal: 41.4s\tremaining: 1m 38s\n",
      "297:\tlearn: 0.0864670\ttotal: 41.6s\tremaining: 1m 37s\n",
      "298:\tlearn: 0.0864439\ttotal: 41.7s\tremaining: 1m 37s\n",
      "299:\tlearn: 0.0864324\ttotal: 41.8s\tremaining: 1m 37s\n",
      "300:\tlearn: 0.0863285\ttotal: 42s\tremaining: 1m 37s\n",
      "301:\tlearn: 0.0862881\ttotal: 42.1s\tremaining: 1m 37s\n",
      "302:\tlearn: 0.0862304\ttotal: 42.3s\tremaining: 1m 37s\n",
      "303:\tlearn: 0.0862304\ttotal: 42.4s\tremaining: 1m 37s\n",
      "304:\tlearn: 0.0861958\ttotal: 42.5s\tremaining: 1m 36s\n",
      "305:\tlearn: 0.0861092\ttotal: 42.7s\tremaining: 1m 36s\n",
      "306:\tlearn: 0.0860226\ttotal: 42.8s\tremaining: 1m 36s\n",
      "307:\tlearn: 0.0860342\ttotal: 42.9s\tremaining: 1m 36s\n",
      "308:\tlearn: 0.0859476\ttotal: 43.1s\tremaining: 1m 36s\n",
      "309:\tlearn: 0.0858553\ttotal: 43.2s\tremaining: 1m 36s\n",
      "310:\tlearn: 0.0858149\ttotal: 43.3s\tremaining: 1m 35s\n",
      "311:\tlearn: 0.0857687\ttotal: 43.5s\tremaining: 1m 35s\n",
      "312:\tlearn: 0.0856994\ttotal: 43.6s\tremaining: 1m 35s\n",
      "313:\tlearn: 0.0856821\ttotal: 43.7s\tremaining: 1m 35s\n",
      "314:\tlearn: 0.0856071\ttotal: 43.9s\tremaining: 1m 35s\n",
      "315:\tlearn: 0.0855840\ttotal: 44s\tremaining: 1m 35s\n",
      "316:\tlearn: 0.0855436\ttotal: 44.1s\tremaining: 1m 35s\n",
      "317:\tlearn: 0.0855205\ttotal: 44.3s\tremaining: 1m 34s\n",
      "318:\tlearn: 0.0854859\ttotal: 44.4s\tremaining: 1m 34s\n",
      "319:\tlearn: 0.0853994\ttotal: 44.5s\tremaining: 1m 34s\n",
      "320:\tlearn: 0.0852724\ttotal: 44.7s\tremaining: 1m 34s\n",
      "321:\tlearn: 0.0852551\ttotal: 44.8s\tremaining: 1m 34s\n",
      "322:\tlearn: 0.0852897\ttotal: 44.9s\tremaining: 1m 34s\n",
      "323:\tlearn: 0.0852031\ttotal: 45.1s\tremaining: 1m 34s\n",
      "324:\tlearn: 0.0851858\ttotal: 45.2s\tremaining: 1m 33s\n",
      "325:\tlearn: 0.0851223\ttotal: 45.4s\tremaining: 1m 33s\n",
      "326:\tlearn: 0.0850416\ttotal: 45.5s\tremaining: 1m 33s\n",
      "327:\tlearn: 0.0849608\ttotal: 45.6s\tremaining: 1m 33s\n",
      "328:\tlearn: 0.0849088\ttotal: 45.8s\tremaining: 1m 33s\n",
      "329:\tlearn: 0.0848627\ttotal: 45.9s\tremaining: 1m 33s\n",
      "330:\tlearn: 0.0847761\ttotal: 46s\tremaining: 1m 33s\n",
      "331:\tlearn: 0.0847068\ttotal: 46.2s\tremaining: 1m 32s\n",
      "332:\tlearn: 0.0846664\ttotal: 46.3s\tremaining: 1m 32s\n",
      "333:\tlearn: 0.0846203\ttotal: 46.4s\tremaining: 1m 32s\n",
      "334:\tlearn: 0.0845856\ttotal: 46.6s\tremaining: 1m 32s\n",
      "335:\tlearn: 0.0844529\ttotal: 46.7s\tremaining: 1m 32s\n",
      "336:\tlearn: 0.0844356\ttotal: 46.8s\tremaining: 1m 32s\n",
      "337:\tlearn: 0.0844125\ttotal: 47s\tremaining: 1m 32s\n",
      "338:\tlearn: 0.0844125\ttotal: 47.1s\tremaining: 1m 31s\n",
      "339:\tlearn: 0.0843548\ttotal: 47.2s\tremaining: 1m 31s\n",
      "340:\tlearn: 0.0842740\ttotal: 47.4s\tremaining: 1m 31s\n",
      "341:\tlearn: 0.0841874\ttotal: 47.5s\tremaining: 1m 31s\n",
      "342:\tlearn: 0.0841874\ttotal: 47.6s\tremaining: 1m 31s\n",
      "343:\tlearn: 0.0841586\ttotal: 47.8s\tremaining: 1m 31s\n",
      "344:\tlearn: 0.0840605\ttotal: 47.9s\tremaining: 1m 30s\n",
      "345:\tlearn: 0.0839912\ttotal: 48s\tremaining: 1m 30s\n",
      "346:\tlearn: 0.0839970\ttotal: 48.2s\tremaining: 1m 30s\n",
      "347:\tlearn: 0.0839220\ttotal: 48.3s\tremaining: 1m 30s\n",
      "348:\tlearn: 0.0838816\ttotal: 48.5s\tremaining: 1m 30s\n",
      "349:\tlearn: 0.0838989\ttotal: 48.6s\tremaining: 1m 30s\n",
      "350:\tlearn: 0.0838181\ttotal: 48.8s\tremaining: 1m 30s\n",
      "351:\tlearn: 0.0837373\ttotal: 48.9s\tremaining: 1m 30s\n",
      "352:\tlearn: 0.0836623\ttotal: 49s\tremaining: 1m 29s\n",
      "353:\tlearn: 0.0836623\ttotal: 49.2s\tremaining: 1m 29s\n",
      "354:\tlearn: 0.0836507\ttotal: 49.3s\tremaining: 1m 29s\n",
      "355:\tlearn: 0.0835873\ttotal: 49.5s\tremaining: 1m 29s\n",
      "356:\tlearn: 0.0835873\ttotal: 49.6s\tremaining: 1m 29s\n",
      "357:\tlearn: 0.0835411\ttotal: 49.7s\tremaining: 1m 29s\n",
      "358:\tlearn: 0.0835065\ttotal: 49.8s\tremaining: 1m 29s\n",
      "359:\tlearn: 0.0834488\ttotal: 50s\tremaining: 1m 28s\n",
      "360:\tlearn: 0.0834488\ttotal: 50.1s\tremaining: 1m 28s\n",
      "361:\tlearn: 0.0833910\ttotal: 50.3s\tremaining: 1m 28s\n",
      "362:\tlearn: 0.0832814\ttotal: 50.4s\tremaining: 1m 28s\n",
      "363:\tlearn: 0.0832525\ttotal: 50.5s\tremaining: 1m 28s\n",
      "364:\tlearn: 0.0831775\ttotal: 50.7s\tremaining: 1m 28s\n",
      "365:\tlearn: 0.0831717\ttotal: 50.8s\tremaining: 1m 28s\n",
      "366:\tlearn: 0.0831660\ttotal: 50.9s\tremaining: 1m 27s\n",
      "367:\tlearn: 0.0830679\ttotal: 51.1s\tremaining: 1m 27s\n",
      "368:\tlearn: 0.0829813\ttotal: 51.2s\tremaining: 1m 27s\n",
      "369:\tlearn: 0.0828601\ttotal: 51.3s\tremaining: 1m 27s\n",
      "370:\tlearn: 0.0828082\ttotal: 51.5s\tremaining: 1m 27s\n",
      "371:\tlearn: 0.0827389\ttotal: 51.6s\tremaining: 1m 27s\n",
      "372:\tlearn: 0.0826350\ttotal: 51.7s\tremaining: 1m 26s\n",
      "373:\tlearn: 0.0826062\ttotal: 51.9s\tremaining: 1m 26s\n",
      "374:\tlearn: 0.0825427\ttotal: 52s\tremaining: 1m 26s\n",
      "375:\tlearn: 0.0824850\ttotal: 52.2s\tremaining: 1m 26s\n",
      "376:\tlearn: 0.0824735\ttotal: 52.3s\tremaining: 1m 26s\n",
      "377:\tlearn: 0.0823753\ttotal: 52.4s\tremaining: 1m 26s\n",
      "378:\tlearn: 0.0823292\ttotal: 52.6s\tremaining: 1m 26s\n",
      "379:\tlearn: 0.0823349\ttotal: 52.7s\tremaining: 1m 25s\n",
      "380:\tlearn: 0.0821964\ttotal: 52.8s\tremaining: 1m 25s\n",
      "381:\tlearn: 0.0821618\ttotal: 53s\tremaining: 1m 25s\n",
      "382:\tlearn: 0.0820464\ttotal: 53.1s\tremaining: 1m 25s\n",
      "383:\tlearn: 0.0819945\ttotal: 53.2s\tremaining: 1m 25s\n",
      "384:\tlearn: 0.0820002\ttotal: 53.4s\tremaining: 1m 25s\n",
      "385:\tlearn: 0.0818906\ttotal: 53.5s\tremaining: 1m 25s\n",
      "386:\tlearn: 0.0818213\ttotal: 53.7s\tremaining: 1m 24s\n",
      "387:\tlearn: 0.0817925\ttotal: 53.8s\tremaining: 1m 24s\n",
      "388:\tlearn: 0.0817752\ttotal: 53.9s\tremaining: 1m 24s\n",
      "389:\tlearn: 0.0817348\ttotal: 54.1s\tremaining: 1m 24s\n",
      "390:\tlearn: 0.0817232\ttotal: 54.2s\tremaining: 1m 24s\n",
      "391:\tlearn: 0.0815905\ttotal: 54.3s\tremaining: 1m 24s\n",
      "392:\tlearn: 0.0816309\ttotal: 54.5s\tremaining: 1m 24s\n",
      "393:\tlearn: 0.0815328\ttotal: 54.6s\tremaining: 1m 23s\n",
      "394:\tlearn: 0.0814174\ttotal: 54.7s\tremaining: 1m 23s\n",
      "395:\tlearn: 0.0814058\ttotal: 54.9s\tremaining: 1m 23s\n",
      "396:\tlearn: 0.0813077\ttotal: 55s\tremaining: 1m 23s\n",
      "397:\tlearn: 0.0812385\ttotal: 55.1s\tremaining: 1m 23s\n",
      "398:\tlearn: 0.0811865\ttotal: 55.3s\tremaining: 1m 23s\n",
      "399:\tlearn: 0.0811404\ttotal: 55.4s\tremaining: 1m 23s\n",
      "400:\tlearn: 0.0811173\ttotal: 55.5s\tremaining: 1m 22s\n",
      "401:\tlearn: 0.0811000\ttotal: 55.7s\tremaining: 1m 22s\n",
      "402:\tlearn: 0.0810018\ttotal: 55.8s\tremaining: 1m 22s\n",
      "403:\tlearn: 0.0809037\ttotal: 55.9s\tremaining: 1m 22s\n",
      "404:\tlearn: 0.0807825\ttotal: 56.1s\tremaining: 1m 22s\n",
      "405:\tlearn: 0.0807768\ttotal: 56.2s\tremaining: 1m 22s\n",
      "406:\tlearn: 0.0807191\ttotal: 56.3s\tremaining: 1m 22s\n",
      "407:\tlearn: 0.0806902\ttotal: 56.5s\tremaining: 1m 21s\n",
      "408:\tlearn: 0.0805748\ttotal: 56.6s\tremaining: 1m 21s\n",
      "409:\tlearn: 0.0805517\ttotal: 56.7s\tremaining: 1m 21s\n",
      "410:\tlearn: 0.0805113\ttotal: 56.9s\tremaining: 1m 21s\n",
      "411:\tlearn: 0.0804594\ttotal: 57s\tremaining: 1m 21s\n",
      "412:\tlearn: 0.0803497\ttotal: 57.2s\tremaining: 1m 21s\n",
      "413:\tlearn: 0.0803266\ttotal: 57.3s\tremaining: 1m 21s\n",
      "414:\tlearn: 0.0802747\ttotal: 57.4s\tremaining: 1m 20s\n",
      "415:\tlearn: 0.0801593\ttotal: 57.6s\tremaining: 1m 20s\n",
      "416:\tlearn: 0.0800900\ttotal: 57.7s\tremaining: 1m 20s\n",
      "417:\tlearn: 0.0800727\ttotal: 57.8s\tremaining: 1m 20s\n",
      "418:\tlearn: 0.0800265\ttotal: 57.9s\tremaining: 1m 20s\n",
      "419:\tlearn: 0.0799631\ttotal: 58.1s\tremaining: 1m 20s\n",
      "420:\tlearn: 0.0798938\ttotal: 58.2s\tremaining: 1m 20s\n",
      "421:\tlearn: 0.0799227\ttotal: 58.4s\tremaining: 1m 19s\n",
      "422:\tlearn: 0.0799400\ttotal: 58.5s\tremaining: 1m 19s\n",
      "423:\tlearn: 0.0798823\ttotal: 58.6s\tremaining: 1m 19s\n",
      "424:\tlearn: 0.0797438\ttotal: 58.8s\tremaining: 1m 19s\n",
      "425:\tlearn: 0.0796283\ttotal: 58.9s\tremaining: 1m 19s\n",
      "426:\tlearn: 0.0795533\ttotal: 59s\tremaining: 1m 19s\n",
      "427:\tlearn: 0.0795418\ttotal: 59.2s\tremaining: 1m 19s\n",
      "428:\tlearn: 0.0795245\ttotal: 59.3s\tremaining: 1m 18s\n",
      "429:\tlearn: 0.0794668\ttotal: 59.4s\tremaining: 1m 18s\n",
      "430:\tlearn: 0.0793687\ttotal: 59.6s\tremaining: 1m 18s\n",
      "431:\tlearn: 0.0792936\ttotal: 59.7s\tremaining: 1m 18s\n",
      "432:\tlearn: 0.0792879\ttotal: 59.8s\tremaining: 1m 18s\n",
      "433:\tlearn: 0.0791667\ttotal: 60s\tremaining: 1m 18s\n",
      "434:\tlearn: 0.0791898\ttotal: 1m\tremaining: 1m 18s\n",
      "435:\tlearn: 0.0791320\ttotal: 1m\tremaining: 1m 17s\n",
      "436:\tlearn: 0.0790570\ttotal: 1m\tremaining: 1m 17s\n",
      "437:\tlearn: 0.0790859\ttotal: 1m\tremaining: 1m 17s\n",
      "438:\tlearn: 0.0790397\ttotal: 1m\tremaining: 1m 17s\n",
      "439:\tlearn: 0.0789589\ttotal: 1m\tremaining: 1m 17s\n",
      "440:\tlearn: 0.0789070\ttotal: 1m\tremaining: 1m 17s\n",
      "441:\tlearn: 0.0788319\ttotal: 1m 1s\tremaining: 1m 17s\n",
      "442:\tlearn: 0.0788550\ttotal: 1m 1s\tremaining: 1m 16s\n",
      "443:\tlearn: 0.0787454\ttotal: 1m 1s\tremaining: 1m 16s\n",
      "444:\tlearn: 0.0786646\ttotal: 1m 1s\tremaining: 1m 16s\n",
      "445:\tlearn: 0.0786357\ttotal: 1m 1s\tremaining: 1m 16s\n",
      "446:\tlearn: 0.0785953\ttotal: 1m 1s\tremaining: 1m 16s\n",
      "447:\tlearn: 0.0785376\ttotal: 1m 1s\tremaining: 1m 16s\n",
      "448:\tlearn: 0.0784568\ttotal: 1m 1s\tremaining: 1m 16s\n",
      "449:\tlearn: 0.0783760\ttotal: 1m 2s\tremaining: 1m 15s\n",
      "450:\tlearn: 0.0783241\ttotal: 1m 2s\tremaining: 1m 15s\n",
      "451:\tlearn: 0.0782433\ttotal: 1m 2s\tremaining: 1m 15s\n",
      "452:\tlearn: 0.0782029\ttotal: 1m 2s\tremaining: 1m 15s\n",
      "453:\tlearn: 0.0781798\ttotal: 1m 2s\tremaining: 1m 15s\n",
      "454:\tlearn: 0.0780644\ttotal: 1m 2s\tremaining: 1m 15s\n",
      "455:\tlearn: 0.0780009\ttotal: 1m 2s\tremaining: 1m 15s\n",
      "456:\tlearn: 0.0779086\ttotal: 1m 3s\tremaining: 1m 14s\n",
      "457:\tlearn: 0.0778682\ttotal: 1m 3s\tremaining: 1m 14s\n",
      "458:\tlearn: 0.0778913\ttotal: 1m 3s\tremaining: 1m 14s\n",
      "459:\tlearn: 0.0777701\ttotal: 1m 3s\tremaining: 1m 14s\n",
      "460:\tlearn: 0.0777239\ttotal: 1m 3s\tremaining: 1m 14s\n",
      "461:\tlearn: 0.0776258\ttotal: 1m 3s\tremaining: 1m 14s\n",
      "462:\tlearn: 0.0776547\ttotal: 1m 3s\tremaining: 1m 14s\n",
      "463:\tlearn: 0.0775623\ttotal: 1m 4s\tremaining: 1m 14s\n",
      "464:\tlearn: 0.0774931\ttotal: 1m 4s\tremaining: 1m 13s\n",
      "465:\tlearn: 0.0774988\ttotal: 1m 4s\tremaining: 1m 13s\n",
      "466:\tlearn: 0.0774238\ttotal: 1m 4s\tremaining: 1m 13s\n",
      "467:\tlearn: 0.0773257\ttotal: 1m 4s\tremaining: 1m 13s\n",
      "468:\tlearn: 0.0773142\ttotal: 1m 4s\tremaining: 1m 13s\n",
      "469:\tlearn: 0.0773084\ttotal: 1m 4s\tremaining: 1m 13s\n",
      "470:\tlearn: 0.0773257\ttotal: 1m 5s\tremaining: 1m 13s\n",
      "471:\tlearn: 0.0771699\ttotal: 1m 5s\tremaining: 1m 12s\n",
      "472:\tlearn: 0.0771699\ttotal: 1m 5s\tremaining: 1m 12s\n",
      "473:\tlearn: 0.0770949\ttotal: 1m 5s\tremaining: 1m 12s\n",
      "474:\tlearn: 0.0770141\ttotal: 1m 5s\tremaining: 1m 12s\n",
      "475:\tlearn: 0.0770083\ttotal: 1m 5s\tremaining: 1m 12s\n",
      "476:\tlearn: 0.0769910\ttotal: 1m 5s\tremaining: 1m 12s\n",
      "477:\tlearn: 0.0769852\ttotal: 1m 5s\tremaining: 1m 12s\n",
      "478:\tlearn: 0.0769391\ttotal: 1m 6s\tremaining: 1m 11s\n",
      "479:\tlearn: 0.0769102\ttotal: 1m 6s\tremaining: 1m 11s\n",
      "480:\tlearn: 0.0768987\ttotal: 1m 6s\tremaining: 1m 11s\n",
      "481:\tlearn: 0.0768756\ttotal: 1m 6s\tremaining: 1m 11s\n",
      "482:\tlearn: 0.0768179\ttotal: 1m 6s\tremaining: 1m 11s\n",
      "483:\tlearn: 0.0767198\ttotal: 1m 6s\tremaining: 1m 11s\n",
      "484:\tlearn: 0.0766620\ttotal: 1m 6s\tremaining: 1m 11s\n",
      "485:\tlearn: 0.0765928\ttotal: 1m 7s\tremaining: 1m 10s\n",
      "486:\tlearn: 0.0765813\ttotal: 1m 7s\tremaining: 1m 10s\n",
      "487:\tlearn: 0.0765466\ttotal: 1m 7s\tremaining: 1m 10s\n",
      "488:\tlearn: 0.0764312\ttotal: 1m 7s\tremaining: 1m 10s\n",
      "489:\tlearn: 0.0763504\ttotal: 1m 7s\tremaining: 1m 10s\n",
      "490:\tlearn: 0.0763620\ttotal: 1m 7s\tremaining: 1m 10s\n",
      "491:\tlearn: 0.0763158\ttotal: 1m 7s\tremaining: 1m 10s\n",
      "492:\tlearn: 0.0762408\ttotal: 1m 7s\tremaining: 1m 9s\n",
      "493:\tlearn: 0.0762119\ttotal: 1m 8s\tremaining: 1m 9s\n",
      "494:\tlearn: 0.0761369\ttotal: 1m 8s\tremaining: 1m 9s\n",
      "495:\tlearn: 0.0760907\ttotal: 1m 8s\tremaining: 1m 9s\n",
      "496:\tlearn: 0.0760099\ttotal: 1m 8s\tremaining: 1m 9s\n",
      "497:\tlearn: 0.0759753\ttotal: 1m 8s\tremaining: 1m 9s\n",
      "498:\tlearn: 0.0759060\ttotal: 1m 8s\tremaining: 1m 9s\n",
      "499:\tlearn: 0.0758310\ttotal: 1m 8s\tremaining: 1m 8s\n",
      "500:\tlearn: 0.0757214\ttotal: 1m 9s\tremaining: 1m 8s\n",
      "501:\tlearn: 0.0757156\ttotal: 1m 9s\tremaining: 1m 8s\n",
      "502:\tlearn: 0.0756867\ttotal: 1m 9s\tremaining: 1m 8s\n",
      "503:\tlearn: 0.0755713\ttotal: 1m 9s\tremaining: 1m 8s\n",
      "504:\tlearn: 0.0755598\ttotal: 1m 9s\tremaining: 1m 8s\n",
      "505:\tlearn: 0.0754848\ttotal: 1m 9s\tremaining: 1m 8s\n",
      "506:\tlearn: 0.0754905\ttotal: 1m 9s\tremaining: 1m 7s\n",
      "507:\tlearn: 0.0754848\ttotal: 1m 9s\tremaining: 1m 7s\n",
      "508:\tlearn: 0.0754617\ttotal: 1m 10s\tremaining: 1m 7s\n",
      "509:\tlearn: 0.0753982\ttotal: 1m 10s\tremaining: 1m 7s\n",
      "510:\tlearn: 0.0753174\ttotal: 1m 10s\tremaining: 1m 7s\n",
      "511:\tlearn: 0.0752482\ttotal: 1m 10s\tremaining: 1m 7s\n",
      "512:\tlearn: 0.0752308\ttotal: 1m 10s\tremaining: 1m 7s\n",
      "513:\tlearn: 0.0751731\ttotal: 1m 10s\tremaining: 1m 6s\n",
      "514:\tlearn: 0.0751096\ttotal: 1m 10s\tremaining: 1m 6s\n",
      "515:\tlearn: 0.0750577\ttotal: 1m 11s\tremaining: 1m 6s\n",
      "516:\tlearn: 0.0749942\ttotal: 1m 11s\tremaining: 1m 6s\n",
      "517:\tlearn: 0.0749769\ttotal: 1m 11s\tremaining: 1m 6s\n",
      "518:\tlearn: 0.0749596\ttotal: 1m 11s\tremaining: 1m 6s\n",
      "519:\tlearn: 0.0748730\ttotal: 1m 11s\tremaining: 1m 6s\n",
      "520:\tlearn: 0.0747865\ttotal: 1m 11s\tremaining: 1m 6s\n",
      "521:\tlearn: 0.0747461\ttotal: 1m 11s\tremaining: 1m 5s\n",
      "522:\tlearn: 0.0746480\ttotal: 1m 12s\tremaining: 1m 5s\n",
      "523:\tlearn: 0.0746307\ttotal: 1m 12s\tremaining: 1m 5s\n",
      "524:\tlearn: 0.0745095\ttotal: 1m 12s\tremaining: 1m 5s\n",
      "525:\tlearn: 0.0744748\ttotal: 1m 12s\tremaining: 1m 5s\n",
      "526:\tlearn: 0.0744287\ttotal: 1m 12s\tremaining: 1m 5s\n",
      "527:\tlearn: 0.0744287\ttotal: 1m 12s\tremaining: 1m 5s\n",
      "528:\tlearn: 0.0744229\ttotal: 1m 12s\tremaining: 1m 4s\n",
      "529:\tlearn: 0.0743594\ttotal: 1m 12s\tremaining: 1m 4s\n",
      "530:\tlearn: 0.0743017\ttotal: 1m 13s\tremaining: 1m 4s\n",
      "531:\tlearn: 0.0742267\ttotal: 1m 13s\tremaining: 1m 4s\n",
      "532:\tlearn: 0.0741921\ttotal: 1m 13s\tremaining: 1m 4s\n",
      "533:\tlearn: 0.0741805\ttotal: 1m 13s\tremaining: 1m 4s\n",
      "534:\tlearn: 0.0741228\ttotal: 1m 13s\tremaining: 1m 4s\n",
      "535:\tlearn: 0.0741113\ttotal: 1m 13s\tremaining: 1m 3s\n",
      "536:\tlearn: 0.0740709\ttotal: 1m 13s\tremaining: 1m 3s\n",
      "537:\tlearn: 0.0739497\ttotal: 1m 14s\tremaining: 1m 3s\n",
      "538:\tlearn: 0.0739728\ttotal: 1m 14s\tremaining: 1m 3s\n",
      "539:\tlearn: 0.0738920\ttotal: 1m 14s\tremaining: 1m 3s\n",
      "540:\tlearn: 0.0738516\ttotal: 1m 14s\tremaining: 1m 3s\n",
      "541:\tlearn: 0.0738631\ttotal: 1m 14s\tremaining: 1m 3s\n",
      "542:\tlearn: 0.0738400\ttotal: 1m 14s\tremaining: 1m 2s\n",
      "543:\tlearn: 0.0737823\ttotal: 1m 14s\tremaining: 1m 2s\n",
      "544:\tlearn: 0.0737881\ttotal: 1m 15s\tremaining: 1m 2s\n",
      "545:\tlearn: 0.0737535\ttotal: 1m 15s\tremaining: 1m 2s\n",
      "546:\tlearn: 0.0737188\ttotal: 1m 15s\tremaining: 1m 2s\n",
      "547:\tlearn: 0.0736496\ttotal: 1m 15s\tremaining: 1m 2s\n",
      "548:\tlearn: 0.0735976\ttotal: 1m 15s\tremaining: 1m 2s\n",
      "549:\tlearn: 0.0735803\ttotal: 1m 15s\tremaining: 1m 1s\n",
      "550:\tlearn: 0.0734995\ttotal: 1m 15s\tremaining: 1m 1s\n",
      "551:\tlearn: 0.0734765\ttotal: 1m 15s\tremaining: 1m 1s\n",
      "552:\tlearn: 0.0734072\ttotal: 1m 16s\tremaining: 1m 1s\n",
      "553:\tlearn: 0.0733264\ttotal: 1m 16s\tremaining: 1m 1s\n",
      "554:\tlearn: 0.0732225\ttotal: 1m 16s\tremaining: 1m 1s\n",
      "555:\tlearn: 0.0732168\ttotal: 1m 16s\tremaining: 1m 1s\n",
      "556:\tlearn: 0.0732398\ttotal: 1m 16s\tremaining: 1m\n",
      "557:\tlearn: 0.0731648\ttotal: 1m 16s\tremaining: 1m\n",
      "558:\tlearn: 0.0731302\ttotal: 1m 16s\tremaining: 1m\n",
      "559:\tlearn: 0.0730436\ttotal: 1m 17s\tremaining: 1m\n",
      "560:\tlearn: 0.0730148\ttotal: 1m 17s\tremaining: 1m\n",
      "561:\tlearn: 0.0729686\ttotal: 1m 17s\tremaining: 1m\n",
      "562:\tlearn: 0.0729282\ttotal: 1m 17s\tremaining: 1m\n",
      "563:\tlearn: 0.0729224\ttotal: 1m 17s\tremaining: 60s\n",
      "564:\tlearn: 0.0728416\ttotal: 1m 17s\tremaining: 59.8s\n",
      "565:\tlearn: 0.0727089\ttotal: 1m 17s\tremaining: 59.7s\n",
      "566:\tlearn: 0.0726974\ttotal: 1m 18s\tremaining: 59.6s\n",
      "567:\tlearn: 0.0726801\ttotal: 1m 18s\tremaining: 59.4s\n",
      "568:\tlearn: 0.0726397\ttotal: 1m 18s\tremaining: 59.3s\n",
      "569:\tlearn: 0.0726108\ttotal: 1m 18s\tremaining: 59.2s\n",
      "570:\tlearn: 0.0725646\ttotal: 1m 18s\tremaining: 59s\n",
      "571:\tlearn: 0.0725012\ttotal: 1m 18s\tremaining: 58.9s\n",
      "572:\tlearn: 0.0724550\ttotal: 1m 18s\tremaining: 58.8s\n",
      "573:\tlearn: 0.0724088\ttotal: 1m 19s\tremaining: 58.6s\n",
      "574:\tlearn: 0.0723511\ttotal: 1m 19s\tremaining: 58.5s\n",
      "575:\tlearn: 0.0723857\ttotal: 1m 19s\tremaining: 58.4s\n",
      "576:\tlearn: 0.0723338\ttotal: 1m 19s\tremaining: 58.2s\n",
      "577:\tlearn: 0.0722819\ttotal: 1m 19s\tremaining: 58.1s\n",
      "578:\tlearn: 0.0721895\ttotal: 1m 19s\tremaining: 57.9s\n",
      "579:\tlearn: 0.0721664\ttotal: 1m 19s\tremaining: 57.8s\n",
      "580:\tlearn: 0.0720856\ttotal: 1m 19s\tremaining: 57.7s\n",
      "581:\tlearn: 0.0720568\ttotal: 1m 20s\tremaining: 57.5s\n",
      "582:\tlearn: 0.0719818\ttotal: 1m 20s\tremaining: 57.4s\n",
      "583:\tlearn: 0.0719645\ttotal: 1m 20s\tremaining: 57.2s\n",
      "584:\tlearn: 0.0719010\ttotal: 1m 20s\tremaining: 57.1s\n",
      "585:\tlearn: 0.0718433\ttotal: 1m 20s\tremaining: 57s\n",
      "586:\tlearn: 0.0717278\ttotal: 1m 20s\tremaining: 56.8s\n",
      "587:\tlearn: 0.0717048\ttotal: 1m 20s\tremaining: 56.7s\n",
      "588:\tlearn: 0.0716355\ttotal: 1m 21s\tremaining: 56.5s\n",
      "589:\tlearn: 0.0716009\ttotal: 1m 21s\tremaining: 56.4s\n",
      "590:\tlearn: 0.0715720\ttotal: 1m 21s\tremaining: 56.3s\n",
      "591:\tlearn: 0.0715259\ttotal: 1m 21s\tremaining: 56.1s\n",
      "592:\tlearn: 0.0715259\ttotal: 1m 21s\tremaining: 56s\n",
      "593:\tlearn: 0.0715085\ttotal: 1m 21s\tremaining: 55.8s\n",
      "594:\tlearn: 0.0714335\ttotal: 1m 21s\tremaining: 55.7s\n",
      "595:\tlearn: 0.0714047\ttotal: 1m 21s\tremaining: 55.6s\n",
      "596:\tlearn: 0.0714220\ttotal: 1m 22s\tremaining: 55.4s\n",
      "597:\tlearn: 0.0713931\ttotal: 1m 22s\tremaining: 55.3s\n",
      "598:\tlearn: 0.0711911\ttotal: 1m 22s\tremaining: 55.2s\n",
      "599:\tlearn: 0.0711507\ttotal: 1m 22s\tremaining: 55s\n",
      "600:\tlearn: 0.0711277\ttotal: 1m 22s\tremaining: 54.9s\n",
      "601:\tlearn: 0.0710699\ttotal: 1m 22s\tremaining: 54.7s\n",
      "602:\tlearn: 0.0710238\ttotal: 1m 22s\tremaining: 54.6s\n",
      "603:\tlearn: 0.0709949\ttotal: 1m 23s\tremaining: 54.4s\n",
      "604:\tlearn: 0.0709430\ttotal: 1m 23s\tremaining: 54.3s\n",
      "605:\tlearn: 0.0709141\ttotal: 1m 23s\tremaining: 54.2s\n",
      "606:\tlearn: 0.0709488\ttotal: 1m 23s\tremaining: 54s\n",
      "607:\tlearn: 0.0709488\ttotal: 1m 23s\tremaining: 53.9s\n",
      "608:\tlearn: 0.0709026\ttotal: 1m 23s\tremaining: 53.7s\n",
      "609:\tlearn: 0.0708218\ttotal: 1m 23s\tremaining: 53.6s\n",
      "610:\tlearn: 0.0707352\ttotal: 1m 23s\tremaining: 53.5s\n",
      "611:\tlearn: 0.0707237\ttotal: 1m 24s\tremaining: 53.3s\n",
      "612:\tlearn: 0.0706429\ttotal: 1m 24s\tremaining: 53.2s\n",
      "613:\tlearn: 0.0705967\ttotal: 1m 24s\tremaining: 53s\n",
      "614:\tlearn: 0.0705621\ttotal: 1m 24s\tremaining: 52.9s\n",
      "615:\tlearn: 0.0704582\ttotal: 1m 24s\tremaining: 52.8s\n",
      "616:\tlearn: 0.0704236\ttotal: 1m 24s\tremaining: 52.6s\n",
      "617:\tlearn: 0.0703601\ttotal: 1m 24s\tremaining: 52.5s\n",
      "618:\tlearn: 0.0702735\ttotal: 1m 25s\tremaining: 52.4s\n",
      "619:\tlearn: 0.0701985\ttotal: 1m 25s\tremaining: 52.2s\n",
      "620:\tlearn: 0.0701870\ttotal: 1m 25s\tremaining: 52.1s\n",
      "621:\tlearn: 0.0702158\ttotal: 1m 25s\tremaining: 51.9s\n",
      "622:\tlearn: 0.0701177\ttotal: 1m 25s\tremaining: 51.8s\n",
      "623:\tlearn: 0.0700773\ttotal: 1m 25s\tremaining: 51.7s\n",
      "624:\tlearn: 0.0700139\ttotal: 1m 25s\tremaining: 51.5s\n",
      "625:\tlearn: 0.0699965\ttotal: 1m 26s\tremaining: 51.4s\n",
      "626:\tlearn: 0.0699388\ttotal: 1m 26s\tremaining: 51.2s\n",
      "627:\tlearn: 0.0698869\ttotal: 1m 26s\tremaining: 51.1s\n",
      "628:\tlearn: 0.0699042\ttotal: 1m 26s\tremaining: 51s\n",
      "629:\tlearn: 0.0697599\ttotal: 1m 26s\tremaining: 50.8s\n",
      "630:\tlearn: 0.0697542\ttotal: 1m 26s\tremaining: 50.7s\n",
      "631:\tlearn: 0.0697022\ttotal: 1m 26s\tremaining: 50.5s\n",
      "632:\tlearn: 0.0696791\ttotal: 1m 26s\tremaining: 50.4s\n",
      "633:\tlearn: 0.0696099\ttotal: 1m 27s\tremaining: 50.3s\n",
      "634:\tlearn: 0.0695118\ttotal: 1m 27s\tremaining: 50.1s\n",
      "635:\tlearn: 0.0695406\ttotal: 1m 27s\tremaining: 50s\n",
      "636:\tlearn: 0.0694829\ttotal: 1m 27s\tremaining: 49.9s\n",
      "637:\tlearn: 0.0694194\ttotal: 1m 27s\tremaining: 49.7s\n",
      "638:\tlearn: 0.0694079\ttotal: 1m 27s\tremaining: 49.6s\n",
      "639:\tlearn: 0.0693213\ttotal: 1m 27s\tremaining: 49.5s\n",
      "640:\tlearn: 0.0693040\ttotal: 1m 28s\tremaining: 49.4s\n",
      "641:\tlearn: 0.0692405\ttotal: 1m 28s\tremaining: 49.2s\n",
      "642:\tlearn: 0.0692463\ttotal: 1m 28s\tremaining: 49.1s\n",
      "643:\tlearn: 0.0691944\ttotal: 1m 28s\tremaining: 49s\n",
      "644:\tlearn: 0.0691424\ttotal: 1m 28s\tremaining: 48.8s\n",
      "645:\tlearn: 0.0690732\ttotal: 1m 28s\tremaining: 48.7s\n",
      "646:\tlearn: 0.0690039\ttotal: 1m 29s\tremaining: 48.6s\n",
      "647:\tlearn: 0.0689578\ttotal: 1m 29s\tremaining: 48.4s\n",
      "648:\tlearn: 0.0689347\ttotal: 1m 29s\tremaining: 48.3s\n",
      "649:\tlearn: 0.0689520\ttotal: 1m 29s\tremaining: 48.2s\n",
      "650:\tlearn: 0.0688481\ttotal: 1m 29s\tremaining: 48s\n",
      "651:\tlearn: 0.0688019\ttotal: 1m 29s\tremaining: 47.9s\n",
      "652:\tlearn: 0.0686807\ttotal: 1m 29s\tremaining: 47.7s\n",
      "653:\tlearn: 0.0686923\ttotal: 1m 29s\tremaining: 47.6s\n",
      "654:\tlearn: 0.0685711\ttotal: 1m 30s\tremaining: 47.5s\n",
      "655:\tlearn: 0.0685365\ttotal: 1m 30s\tremaining: 47.3s\n",
      "656:\tlearn: 0.0685076\ttotal: 1m 30s\tremaining: 47.2s\n",
      "657:\tlearn: 0.0685076\ttotal: 1m 30s\tremaining: 47s\n",
      "658:\tlearn: 0.0685018\ttotal: 1m 30s\tremaining: 46.9s\n",
      "659:\tlearn: 0.0684384\ttotal: 1m 30s\tremaining: 46.8s\n",
      "660:\tlearn: 0.0684326\ttotal: 1m 30s\tremaining: 46.6s\n",
      "661:\tlearn: 0.0684268\ttotal: 1m 31s\tremaining: 46.5s\n",
      "662:\tlearn: 0.0683576\ttotal: 1m 31s\tremaining: 46.3s\n",
      "663:\tlearn: 0.0683114\ttotal: 1m 31s\tremaining: 46.2s\n",
      "664:\tlearn: 0.0682652\ttotal: 1m 31s\tremaining: 46.1s\n",
      "665:\tlearn: 0.0683056\ttotal: 1m 31s\tremaining: 45.9s\n",
      "666:\tlearn: 0.0682999\ttotal: 1m 31s\tremaining: 45.8s\n",
      "667:\tlearn: 0.0682941\ttotal: 1m 31s\tremaining: 45.7s\n",
      "668:\tlearn: 0.0682652\ttotal: 1m 32s\tremaining: 45.5s\n",
      "669:\tlearn: 0.0681902\ttotal: 1m 32s\tremaining: 45.4s\n",
      "670:\tlearn: 0.0681094\ttotal: 1m 32s\tremaining: 45.2s\n",
      "671:\tlearn: 0.0680748\ttotal: 1m 32s\tremaining: 45.1s\n",
      "672:\tlearn: 0.0680517\ttotal: 1m 32s\tremaining: 45s\n",
      "673:\tlearn: 0.0679882\ttotal: 1m 32s\tremaining: 44.8s\n",
      "674:\tlearn: 0.0679594\ttotal: 1m 32s\tremaining: 44.7s\n",
      "675:\tlearn: 0.0679074\ttotal: 1m 32s\tremaining: 44.5s\n",
      "676:\tlearn: 0.0677632\ttotal: 1m 33s\tremaining: 44.4s\n",
      "677:\tlearn: 0.0677574\ttotal: 1m 33s\tremaining: 44.3s\n",
      "678:\tlearn: 0.0676939\ttotal: 1m 33s\tremaining: 44.1s\n",
      "679:\tlearn: 0.0676189\ttotal: 1m 33s\tremaining: 44s\n",
      "680:\tlearn: 0.0676477\ttotal: 1m 33s\tremaining: 43.9s\n",
      "681:\tlearn: 0.0676535\ttotal: 1m 33s\tremaining: 43.7s\n",
      "682:\tlearn: 0.0675727\ttotal: 1m 33s\tremaining: 43.6s\n",
      "683:\tlearn: 0.0675092\ttotal: 1m 34s\tremaining: 43.5s\n",
      "684:\tlearn: 0.0674284\ttotal: 1m 34s\tremaining: 43.3s\n",
      "685:\tlearn: 0.0673476\ttotal: 1m 34s\tremaining: 43.2s\n",
      "686:\tlearn: 0.0673015\ttotal: 1m 34s\tremaining: 43.1s\n",
      "687:\tlearn: 0.0672322\ttotal: 1m 34s\tremaining: 43s\n",
      "688:\tlearn: 0.0672149\ttotal: 1m 34s\tremaining: 42.8s\n",
      "689:\tlearn: 0.0672380\ttotal: 1m 35s\tremaining: 42.7s\n",
      "690:\tlearn: 0.0671803\ttotal: 1m 35s\tremaining: 42.6s\n",
      "691:\tlearn: 0.0671976\ttotal: 1m 35s\tremaining: 42.5s\n",
      "692:\tlearn: 0.0671918\ttotal: 1m 35s\tremaining: 42.3s\n",
      "693:\tlearn: 0.0671803\ttotal: 1m 35s\tremaining: 42.2s\n",
      "694:\tlearn: 0.0671168\ttotal: 1m 35s\tremaining: 42.1s\n",
      "695:\tlearn: 0.0671053\ttotal: 1m 36s\tremaining: 41.9s\n",
      "696:\tlearn: 0.0671053\ttotal: 1m 36s\tremaining: 41.8s\n",
      "697:\tlearn: 0.0671053\ttotal: 1m 36s\tremaining: 41.7s\n",
      "698:\tlearn: 0.0671110\ttotal: 1m 36s\tremaining: 41.5s\n",
      "699:\tlearn: 0.0670418\ttotal: 1m 36s\tremaining: 41.4s\n",
      "700:\tlearn: 0.0670129\ttotal: 1m 36s\tremaining: 41.3s\n",
      "701:\tlearn: 0.0669783\ttotal: 1m 36s\tremaining: 41.1s\n",
      "702:\tlearn: 0.0668340\ttotal: 1m 37s\tremaining: 41s\n",
      "703:\tlearn: 0.0668283\ttotal: 1m 37s\tremaining: 40.9s\n",
      "704:\tlearn: 0.0667705\ttotal: 1m 37s\tremaining: 40.7s\n",
      "705:\tlearn: 0.0667013\ttotal: 1m 37s\tremaining: 40.6s\n",
      "706:\tlearn: 0.0666551\ttotal: 1m 37s\tremaining: 40.5s\n",
      "707:\tlearn: 0.0665686\ttotal: 1m 37s\tremaining: 40.3s\n",
      "708:\tlearn: 0.0665743\ttotal: 1m 37s\tremaining: 40.2s\n",
      "709:\tlearn: 0.0665282\ttotal: 1m 38s\tremaining: 40.1s\n",
      "710:\tlearn: 0.0664993\ttotal: 1m 38s\tremaining: 40s\n",
      "711:\tlearn: 0.0664185\ttotal: 1m 38s\tremaining: 39.8s\n",
      "712:\tlearn: 0.0664185\ttotal: 1m 38s\tremaining: 39.7s\n",
      "713:\tlearn: 0.0663723\ttotal: 1m 38s\tremaining: 39.6s\n",
      "714:\tlearn: 0.0662973\ttotal: 1m 39s\tremaining: 39.5s\n",
      "715:\tlearn: 0.0662800\ttotal: 1m 39s\tremaining: 39.3s\n",
      "716:\tlearn: 0.0662858\ttotal: 1m 39s\tremaining: 39.2s\n",
      "717:\tlearn: 0.0661530\ttotal: 1m 39s\tremaining: 39.1s\n",
      "718:\tlearn: 0.0660723\ttotal: 1m 39s\tremaining: 39s\n",
      "719:\tlearn: 0.0660492\ttotal: 1m 39s\tremaining: 38.9s\n",
      "720:\tlearn: 0.0659741\ttotal: 1m 40s\tremaining: 38.8s\n",
      "721:\tlearn: 0.0659395\ttotal: 1m 40s\tremaining: 38.6s\n",
      "722:\tlearn: 0.0659164\ttotal: 1m 40s\tremaining: 38.5s\n",
      "723:\tlearn: 0.0659107\ttotal: 1m 40s\tremaining: 38.4s\n",
      "724:\tlearn: 0.0658299\ttotal: 1m 40s\tremaining: 38.2s\n",
      "725:\tlearn: 0.0657779\ttotal: 1m 40s\tremaining: 38.1s\n",
      "726:\tlearn: 0.0657375\ttotal: 1m 41s\tremaining: 37.9s\n",
      "727:\tlearn: 0.0656798\ttotal: 1m 41s\tremaining: 37.8s\n",
      "728:\tlearn: 0.0657087\ttotal: 1m 41s\tremaining: 37.7s\n",
      "729:\tlearn: 0.0656741\ttotal: 1m 41s\tremaining: 37.5s\n",
      "730:\tlearn: 0.0655586\ttotal: 1m 41s\tremaining: 37.4s\n",
      "731:\tlearn: 0.0655009\ttotal: 1m 41s\tremaining: 37.3s\n",
      "732:\tlearn: 0.0655067\ttotal: 1m 41s\tremaining: 37.1s\n",
      "733:\tlearn: 0.0654144\ttotal: 1m 42s\tremaining: 37s\n",
      "734:\tlearn: 0.0654317\ttotal: 1m 42s\tremaining: 36.8s\n",
      "735:\tlearn: 0.0653624\ttotal: 1m 42s\tremaining: 36.7s\n",
      "736:\tlearn: 0.0653278\ttotal: 1m 42s\tremaining: 36.6s\n",
      "737:\tlearn: 0.0652874\ttotal: 1m 42s\tremaining: 36.4s\n",
      "738:\tlearn: 0.0652470\ttotal: 1m 42s\tremaining: 36.3s\n",
      "739:\tlearn: 0.0652412\ttotal: 1m 42s\tremaining: 36.1s\n",
      "740:\tlearn: 0.0651720\ttotal: 1m 42s\tremaining: 36s\n",
      "741:\tlearn: 0.0651431\ttotal: 1m 43s\tremaining: 35.9s\n",
      "742:\tlearn: 0.0650970\ttotal: 1m 43s\tremaining: 35.7s\n",
      "743:\tlearn: 0.0650219\ttotal: 1m 43s\tremaining: 35.6s\n",
      "744:\tlearn: 0.0649642\ttotal: 1m 43s\tremaining: 35.4s\n",
      "745:\tlearn: 0.0649007\ttotal: 1m 43s\tremaining: 35.3s\n",
      "746:\tlearn: 0.0648719\ttotal: 1m 43s\tremaining: 35.2s\n",
      "747:\tlearn: 0.0647622\ttotal: 1m 43s\tremaining: 35s\n",
      "748:\tlearn: 0.0647738\ttotal: 1m 44s\tremaining: 34.9s\n",
      "749:\tlearn: 0.0647392\ttotal: 1m 44s\tremaining: 34.7s\n",
      "750:\tlearn: 0.0647103\ttotal: 1m 44s\tremaining: 34.6s\n",
      "751:\tlearn: 0.0646641\ttotal: 1m 44s\tremaining: 34.4s\n",
      "752:\tlearn: 0.0646237\ttotal: 1m 44s\tremaining: 34.3s\n",
      "753:\tlearn: 0.0645487\ttotal: 1m 44s\tremaining: 34.2s\n",
      "754:\tlearn: 0.0645141\ttotal: 1m 44s\tremaining: 34s\n",
      "755:\tlearn: 0.0644852\ttotal: 1m 44s\tremaining: 33.9s\n",
      "756:\tlearn: 0.0645199\ttotal: 1m 45s\tremaining: 33.8s\n",
      "757:\tlearn: 0.0644795\ttotal: 1m 45s\tremaining: 33.6s\n",
      "758:\tlearn: 0.0644333\ttotal: 1m 45s\tremaining: 33.5s\n",
      "759:\tlearn: 0.0644217\ttotal: 1m 45s\tremaining: 33.3s\n",
      "760:\tlearn: 0.0643467\ttotal: 1m 45s\tremaining: 33.2s\n",
      "761:\tlearn: 0.0642832\ttotal: 1m 45s\tremaining: 33.1s\n",
      "762:\tlearn: 0.0642428\ttotal: 1m 45s\tremaining: 32.9s\n",
      "763:\tlearn: 0.0642371\ttotal: 1m 46s\tremaining: 32.8s\n",
      "764:\tlearn: 0.0641967\ttotal: 1m 46s\tremaining: 32.6s\n",
      "765:\tlearn: 0.0641505\ttotal: 1m 46s\tremaining: 32.5s\n",
      "766:\tlearn: 0.0641159\ttotal: 1m 46s\tremaining: 32.4s\n",
      "767:\tlearn: 0.0641043\ttotal: 1m 46s\tremaining: 32.2s\n",
      "768:\tlearn: 0.0640697\ttotal: 1m 46s\tremaining: 32.1s\n",
      "769:\tlearn: 0.0639543\ttotal: 1m 46s\tremaining: 31.9s\n",
      "770:\tlearn: 0.0639831\ttotal: 1m 47s\tremaining: 31.8s\n",
      "771:\tlearn: 0.0639774\ttotal: 1m 47s\tremaining: 31.7s\n",
      "772:\tlearn: 0.0639312\ttotal: 1m 47s\tremaining: 31.5s\n",
      "773:\tlearn: 0.0638562\ttotal: 1m 47s\tremaining: 31.4s\n",
      "774:\tlearn: 0.0638562\ttotal: 1m 47s\tremaining: 31.2s\n",
      "775:\tlearn: 0.0638158\ttotal: 1m 47s\tremaining: 31.1s\n",
      "776:\tlearn: 0.0638504\ttotal: 1m 47s\tremaining: 31s\n",
      "777:\tlearn: 0.0638504\ttotal: 1m 47s\tremaining: 30.8s\n",
      "778:\tlearn: 0.0638216\ttotal: 1m 48s\tremaining: 30.7s\n",
      "779:\tlearn: 0.0637408\ttotal: 1m 48s\tremaining: 30.5s\n",
      "780:\tlearn: 0.0637292\ttotal: 1m 48s\tremaining: 30.4s\n",
      "781:\tlearn: 0.0636600\ttotal: 1m 48s\tremaining: 30.3s\n",
      "782:\tlearn: 0.0636715\ttotal: 1m 48s\tremaining: 30.1s\n",
      "783:\tlearn: 0.0636369\ttotal: 1m 48s\tremaining: 30s\n",
      "784:\tlearn: 0.0636427\ttotal: 1m 49s\tremaining: 29.9s\n",
      "785:\tlearn: 0.0636023\ttotal: 1m 49s\tremaining: 29.7s\n",
      "786:\tlearn: 0.0635503\ttotal: 1m 49s\tremaining: 29.6s\n",
      "787:\tlearn: 0.0634811\ttotal: 1m 49s\tremaining: 29.4s\n",
      "788:\tlearn: 0.0634868\ttotal: 1m 49s\tremaining: 29.3s\n",
      "789:\tlearn: 0.0634176\ttotal: 1m 49s\tremaining: 29.2s\n",
      "790:\tlearn: 0.0634291\ttotal: 1m 49s\tremaining: 29s\n",
      "791:\tlearn: 0.0634003\ttotal: 1m 49s\tremaining: 28.9s\n",
      "792:\tlearn: 0.0633426\ttotal: 1m 50s\tremaining: 28.7s\n",
      "793:\tlearn: 0.0632675\ttotal: 1m 50s\tremaining: 28.6s\n",
      "794:\tlearn: 0.0632387\ttotal: 1m 50s\tremaining: 28.5s\n",
      "795:\tlearn: 0.0632098\ttotal: 1m 50s\tremaining: 28.3s\n",
      "796:\tlearn: 0.0631521\ttotal: 1m 50s\tremaining: 28.2s\n",
      "797:\tlearn: 0.0631060\ttotal: 1m 50s\tremaining: 28s\n",
      "798:\tlearn: 0.0630425\ttotal: 1m 50s\tremaining: 27.9s\n",
      "799:\tlearn: 0.0630078\ttotal: 1m 51s\tremaining: 27.8s\n",
      "800:\tlearn: 0.0629617\ttotal: 1m 51s\tremaining: 27.6s\n",
      "801:\tlearn: 0.0628809\ttotal: 1m 51s\tremaining: 27.5s\n",
      "802:\tlearn: 0.0628116\ttotal: 1m 51s\tremaining: 27.3s\n",
      "803:\tlearn: 0.0627597\ttotal: 1m 51s\tremaining: 27.2s\n",
      "804:\tlearn: 0.0626962\ttotal: 1m 51s\tremaining: 27.1s\n",
      "805:\tlearn: 0.0626616\ttotal: 1m 51s\tremaining: 26.9s\n",
      "806:\tlearn: 0.0626558\ttotal: 1m 51s\tremaining: 26.8s\n",
      "807:\tlearn: 0.0626327\ttotal: 1m 52s\tremaining: 26.6s\n",
      "808:\tlearn: 0.0626096\ttotal: 1m 52s\tremaining: 26.5s\n",
      "809:\tlearn: 0.0625404\ttotal: 1m 52s\tremaining: 26.4s\n",
      "810:\tlearn: 0.0624827\ttotal: 1m 52s\tremaining: 26.2s\n",
      "811:\tlearn: 0.0624307\ttotal: 1m 52s\tremaining: 26.1s\n",
      "812:\tlearn: 0.0623730\ttotal: 1m 52s\tremaining: 25.9s\n",
      "813:\tlearn: 0.0623269\ttotal: 1m 52s\tremaining: 25.8s\n",
      "814:\tlearn: 0.0623038\ttotal: 1m 53s\tremaining: 25.7s\n",
      "815:\tlearn: 0.0623038\ttotal: 1m 53s\tremaining: 25.5s\n",
      "816:\tlearn: 0.0622461\ttotal: 1m 53s\tremaining: 25.4s\n",
      "817:\tlearn: 0.0622518\ttotal: 1m 53s\tremaining: 25.2s\n",
      "818:\tlearn: 0.0622172\ttotal: 1m 53s\tremaining: 25.1s\n",
      "819:\tlearn: 0.0622288\ttotal: 1m 53s\tremaining: 25s\n",
      "820:\tlearn: 0.0621653\ttotal: 1m 53s\tremaining: 24.8s\n",
      "821:\tlearn: 0.0621653\ttotal: 1m 53s\tremaining: 24.7s\n",
      "822:\tlearn: 0.0621711\ttotal: 1m 54s\tremaining: 24.5s\n",
      "823:\tlearn: 0.0621537\ttotal: 1m 54s\tremaining: 24.4s\n",
      "824:\tlearn: 0.0621191\ttotal: 1m 54s\tremaining: 24.3s\n",
      "825:\tlearn: 0.0621076\ttotal: 1m 54s\tremaining: 24.1s\n",
      "826:\tlearn: 0.0620903\ttotal: 1m 54s\tremaining: 24s\n",
      "827:\tlearn: 0.0620499\ttotal: 1m 54s\tremaining: 23.8s\n",
      "828:\tlearn: 0.0619229\ttotal: 1m 54s\tremaining: 23.7s\n",
      "829:\tlearn: 0.0619056\ttotal: 1m 55s\tremaining: 23.6s\n",
      "830:\tlearn: 0.0618883\ttotal: 1m 55s\tremaining: 23.4s\n",
      "831:\tlearn: 0.0618594\ttotal: 1m 55s\tremaining: 23.3s\n",
      "832:\tlearn: 0.0617959\ttotal: 1m 55s\tremaining: 23.1s\n",
      "833:\tlearn: 0.0617671\ttotal: 1m 55s\tremaining: 23s\n",
      "834:\tlearn: 0.0617440\ttotal: 1m 55s\tremaining: 22.9s\n",
      "835:\tlearn: 0.0616690\ttotal: 1m 55s\tremaining: 22.7s\n",
      "836:\tlearn: 0.0615709\ttotal: 1m 56s\tremaining: 22.6s\n",
      "837:\tlearn: 0.0615305\ttotal: 1m 56s\tremaining: 22.5s\n",
      "838:\tlearn: 0.0614670\ttotal: 1m 56s\tremaining: 22.3s\n",
      "839:\tlearn: 0.0614497\ttotal: 1m 56s\tremaining: 22.2s\n",
      "840:\tlearn: 0.0614324\ttotal: 1m 56s\tremaining: 22s\n",
      "841:\tlearn: 0.0614266\ttotal: 1m 56s\tremaining: 21.9s\n",
      "842:\tlearn: 0.0613804\ttotal: 1m 56s\tremaining: 21.8s\n",
      "843:\tlearn: 0.0613689\ttotal: 1m 56s\tremaining: 21.6s\n",
      "844:\tlearn: 0.0613227\ttotal: 1m 57s\tremaining: 21.5s\n",
      "845:\tlearn: 0.0612477\ttotal: 1m 57s\tremaining: 21.3s\n",
      "846:\tlearn: 0.0612073\ttotal: 1m 57s\tremaining: 21.2s\n",
      "847:\tlearn: 0.0611323\ttotal: 1m 57s\tremaining: 21.1s\n",
      "848:\tlearn: 0.0611265\ttotal: 1m 57s\tremaining: 20.9s\n",
      "849:\tlearn: 0.0610572\ttotal: 1m 57s\tremaining: 20.8s\n",
      "850:\tlearn: 0.0609418\ttotal: 1m 57s\tremaining: 20.6s\n",
      "851:\tlearn: 0.0609591\ttotal: 1m 58s\tremaining: 20.5s\n",
      "852:\tlearn: 0.0608783\ttotal: 1m 58s\tremaining: 20.4s\n",
      "853:\tlearn: 0.0608726\ttotal: 1m 58s\tremaining: 20.2s\n",
      "854:\tlearn: 0.0608380\ttotal: 1m 58s\tremaining: 20.1s\n",
      "855:\tlearn: 0.0608033\ttotal: 1m 58s\tremaining: 19.9s\n",
      "856:\tlearn: 0.0607514\ttotal: 1m 58s\tremaining: 19.8s\n",
      "857:\tlearn: 0.0607398\ttotal: 1m 58s\tremaining: 19.7s\n",
      "858:\tlearn: 0.0607341\ttotal: 1m 58s\tremaining: 19.5s\n",
      "859:\tlearn: 0.0606302\ttotal: 1m 59s\tremaining: 19.4s\n",
      "860:\tlearn: 0.0605436\ttotal: 1m 59s\tremaining: 19.2s\n",
      "861:\tlearn: 0.0605552\ttotal: 1m 59s\tremaining: 19.1s\n",
      "862:\tlearn: 0.0605494\ttotal: 1m 59s\tremaining: 19s\n",
      "863:\tlearn: 0.0604859\ttotal: 1m 59s\tremaining: 18.8s\n",
      "864:\tlearn: 0.0604340\ttotal: 1m 59s\tremaining: 18.7s\n",
      "865:\tlearn: 0.0603820\ttotal: 1m 59s\tremaining: 18.6s\n",
      "866:\tlearn: 0.0603301\ttotal: 2m\tremaining: 18.4s\n",
      "867:\tlearn: 0.0602205\ttotal: 2m\tremaining: 18.3s\n",
      "868:\tlearn: 0.0602031\ttotal: 2m\tremaining: 18.1s\n",
      "869:\tlearn: 0.0601974\ttotal: 2m\tremaining: 18s\n",
      "870:\tlearn: 0.0601974\ttotal: 2m\tremaining: 17.9s\n",
      "871:\tlearn: 0.0602320\ttotal: 2m\tremaining: 17.7s\n",
      "872:\tlearn: 0.0601916\ttotal: 2m\tremaining: 17.6s\n",
      "873:\tlearn: 0.0601454\ttotal: 2m\tremaining: 17.4s\n",
      "874:\tlearn: 0.0601339\ttotal: 2m 1s\tremaining: 17.3s\n",
      "875:\tlearn: 0.0600012\ttotal: 2m 1s\tremaining: 17.2s\n",
      "876:\tlearn: 0.0599608\ttotal: 2m 1s\tremaining: 17s\n",
      "877:\tlearn: 0.0598742\ttotal: 2m 1s\tremaining: 16.9s\n",
      "878:\tlearn: 0.0598742\ttotal: 2m 1s\tremaining: 16.7s\n",
      "879:\tlearn: 0.0598857\ttotal: 2m 1s\tremaining: 16.6s\n",
      "880:\tlearn: 0.0598511\ttotal: 2m 1s\tremaining: 16.5s\n",
      "881:\tlearn: 0.0598223\ttotal: 2m 2s\tremaining: 16.3s\n",
      "882:\tlearn: 0.0598165\ttotal: 2m 2s\tremaining: 16.2s\n",
      "883:\tlearn: 0.0597241\ttotal: 2m 2s\tremaining: 16.1s\n",
      "884:\tlearn: 0.0597126\ttotal: 2m 2s\tremaining: 15.9s\n",
      "885:\tlearn: 0.0596837\ttotal: 2m 2s\tremaining: 15.8s\n",
      "886:\tlearn: 0.0596318\ttotal: 2m 2s\tremaining: 15.6s\n",
      "887:\tlearn: 0.0596376\ttotal: 2m 2s\tremaining: 15.5s\n",
      "888:\tlearn: 0.0595799\ttotal: 2m 3s\tremaining: 15.4s\n",
      "889:\tlearn: 0.0595395\ttotal: 2m 3s\tremaining: 15.2s\n",
      "890:\tlearn: 0.0594991\ttotal: 2m 3s\tremaining: 15.1s\n",
      "891:\tlearn: 0.0594818\ttotal: 2m 3s\tremaining: 14.9s\n",
      "892:\tlearn: 0.0594702\ttotal: 2m 3s\tremaining: 14.8s\n",
      "893:\tlearn: 0.0593779\ttotal: 2m 3s\tremaining: 14.7s\n",
      "894:\tlearn: 0.0593548\ttotal: 2m 3s\tremaining: 14.5s\n",
      "895:\tlearn: 0.0593606\ttotal: 2m 4s\tremaining: 14.4s\n",
      "896:\tlearn: 0.0593375\ttotal: 2m 4s\tremaining: 14.3s\n",
      "897:\tlearn: 0.0592682\ttotal: 2m 4s\tremaining: 14.1s\n",
      "898:\tlearn: 0.0592163\ttotal: 2m 4s\tremaining: 14s\n",
      "899:\tlearn: 0.0591586\ttotal: 2m 4s\tremaining: 13.8s\n",
      "900:\tlearn: 0.0591240\ttotal: 2m 4s\tremaining: 13.7s\n",
      "901:\tlearn: 0.0590489\ttotal: 2m 4s\tremaining: 13.6s\n",
      "902:\tlearn: 0.0590143\ttotal: 2m 4s\tremaining: 13.4s\n",
      "903:\tlearn: 0.0589912\ttotal: 2m 5s\tremaining: 13.3s\n",
      "904:\tlearn: 0.0589508\ttotal: 2m 5s\tremaining: 13.1s\n",
      "905:\tlearn: 0.0589162\ttotal: 2m 5s\tremaining: 13s\n",
      "906:\tlearn: 0.0589104\ttotal: 2m 5s\tremaining: 12.9s\n",
      "907:\tlearn: 0.0588123\ttotal: 2m 5s\tremaining: 12.7s\n",
      "908:\tlearn: 0.0588354\ttotal: 2m 5s\tremaining: 12.6s\n",
      "909:\tlearn: 0.0587488\ttotal: 2m 5s\tremaining: 12.5s\n",
      "910:\tlearn: 0.0587084\ttotal: 2m 6s\tremaining: 12.3s\n",
      "911:\tlearn: 0.0586277\ttotal: 2m 6s\tremaining: 12.2s\n",
      "912:\tlearn: 0.0586334\ttotal: 2m 6s\tremaining: 12s\n",
      "913:\tlearn: 0.0586103\ttotal: 2m 6s\tremaining: 11.9s\n",
      "914:\tlearn: 0.0586334\ttotal: 2m 6s\tremaining: 11.8s\n",
      "915:\tlearn: 0.0585469\ttotal: 2m 6s\tremaining: 11.6s\n",
      "916:\tlearn: 0.0585007\ttotal: 2m 6s\tremaining: 11.5s\n",
      "917:\tlearn: 0.0584661\ttotal: 2m 6s\tremaining: 11.3s\n",
      "918:\tlearn: 0.0584372\ttotal: 2m 7s\tremaining: 11.2s\n",
      "919:\tlearn: 0.0584257\ttotal: 2m 7s\tremaining: 11.1s\n",
      "920:\tlearn: 0.0583853\ttotal: 2m 7s\tremaining: 10.9s\n",
      "921:\tlearn: 0.0583449\ttotal: 2m 7s\tremaining: 10.8s\n",
      "922:\tlearn: 0.0583045\ttotal: 2m 7s\tremaining: 10.7s\n",
      "923:\tlearn: 0.0582410\ttotal: 2m 7s\tremaining: 10.5s\n",
      "924:\tlearn: 0.0582179\ttotal: 2m 7s\tremaining: 10.4s\n",
      "925:\tlearn: 0.0581775\ttotal: 2m 8s\tremaining: 10.2s\n",
      "926:\tlearn: 0.0581313\ttotal: 2m 8s\tremaining: 10.1s\n",
      "927:\tlearn: 0.0580967\ttotal: 2m 8s\tremaining: 9.96s\n",
      "928:\tlearn: 0.0580621\ttotal: 2m 8s\tremaining: 9.82s\n",
      "929:\tlearn: 0.0580217\ttotal: 2m 8s\tremaining: 9.68s\n",
      "930:\tlearn: 0.0579351\ttotal: 2m 8s\tremaining: 9.54s\n",
      "931:\tlearn: 0.0579063\ttotal: 2m 8s\tremaining: 9.4s\n",
      "932:\tlearn: 0.0578601\ttotal: 2m 9s\tremaining: 9.26s\n",
      "933:\tlearn: 0.0578601\ttotal: 2m 9s\tremaining: 9.13s\n",
      "934:\tlearn: 0.0578370\ttotal: 2m 9s\tremaining: 8.99s\n",
      "935:\tlearn: 0.0577966\ttotal: 2m 9s\tremaining: 8.85s\n",
      "936:\tlearn: 0.0577447\ttotal: 2m 9s\tremaining: 8.71s\n",
      "937:\tlearn: 0.0577043\ttotal: 2m 9s\tremaining: 8.57s\n",
      "938:\tlearn: 0.0576639\ttotal: 2m 9s\tremaining: 8.43s\n",
      "939:\tlearn: 0.0576581\ttotal: 2m 9s\tremaining: 8.29s\n",
      "940:\tlearn: 0.0576235\ttotal: 2m 10s\tremaining: 8.16s\n",
      "941:\tlearn: 0.0575831\ttotal: 2m 10s\tremaining: 8.02s\n",
      "942:\tlearn: 0.0575773\ttotal: 2m 10s\tremaining: 7.88s\n",
      "943:\tlearn: 0.0575427\ttotal: 2m 10s\tremaining: 7.74s\n",
      "944:\tlearn: 0.0574908\ttotal: 2m 10s\tremaining: 7.6s\n",
      "945:\tlearn: 0.0574504\ttotal: 2m 10s\tremaining: 7.46s\n",
      "946:\tlearn: 0.0574446\ttotal: 2m 10s\tremaining: 7.33s\n",
      "947:\tlearn: 0.0574331\ttotal: 2m 11s\tremaining: 7.19s\n",
      "948:\tlearn: 0.0573753\ttotal: 2m 11s\tremaining: 7.05s\n",
      "949:\tlearn: 0.0573638\ttotal: 2m 11s\tremaining: 6.91s\n",
      "950:\tlearn: 0.0573407\ttotal: 2m 11s\tremaining: 6.77s\n",
      "951:\tlearn: 0.0572715\ttotal: 2m 11s\tremaining: 6.63s\n",
      "952:\tlearn: 0.0572599\ttotal: 2m 11s\tremaining: 6.49s\n",
      "953:\tlearn: 0.0571676\ttotal: 2m 11s\tremaining: 6.36s\n",
      "954:\tlearn: 0.0571964\ttotal: 2m 11s\tremaining: 6.22s\n",
      "955:\tlearn: 0.0571157\ttotal: 2m 12s\tremaining: 6.08s\n",
      "956:\tlearn: 0.0571157\ttotal: 2m 12s\tremaining: 5.94s\n",
      "957:\tlearn: 0.0570637\ttotal: 2m 12s\tremaining: 5.8s\n",
      "958:\tlearn: 0.0570464\ttotal: 2m 12s\tremaining: 5.67s\n",
      "959:\tlearn: 0.0570579\ttotal: 2m 12s\tremaining: 5.53s\n",
      "960:\tlearn: 0.0570233\ttotal: 2m 12s\tremaining: 5.39s\n",
      "961:\tlearn: 0.0570522\ttotal: 2m 12s\tremaining: 5.25s\n",
      "962:\tlearn: 0.0569771\ttotal: 2m 13s\tremaining: 5.11s\n",
      "963:\tlearn: 0.0569771\ttotal: 2m 13s\tremaining: 4.97s\n",
      "964:\tlearn: 0.0569367\ttotal: 2m 13s\tremaining: 4.83s\n",
      "965:\tlearn: 0.0568848\ttotal: 2m 13s\tremaining: 4.7s\n",
      "966:\tlearn: 0.0568964\ttotal: 2m 13s\tremaining: 4.56s\n",
      "967:\tlearn: 0.0568790\ttotal: 2m 13s\tremaining: 4.42s\n",
      "968:\tlearn: 0.0568098\ttotal: 2m 13s\tremaining: 4.28s\n",
      "969:\tlearn: 0.0567636\ttotal: 2m 13s\tremaining: 4.14s\n",
      "970:\tlearn: 0.0567117\ttotal: 2m 14s\tremaining: 4s\n",
      "971:\tlearn: 0.0567521\ttotal: 2m 14s\tremaining: 3.87s\n",
      "972:\tlearn: 0.0567463\ttotal: 2m 14s\tremaining: 3.73s\n",
      "973:\tlearn: 0.0567348\ttotal: 2m 14s\tremaining: 3.59s\n",
      "974:\tlearn: 0.0566886\ttotal: 2m 14s\tremaining: 3.45s\n",
      "975:\tlearn: 0.0566251\ttotal: 2m 14s\tremaining: 3.31s\n",
      "976:\tlearn: 0.0565789\ttotal: 2m 14s\tremaining: 3.18s\n",
      "977:\tlearn: 0.0565559\ttotal: 2m 15s\tremaining: 3.04s\n",
      "978:\tlearn: 0.0565328\ttotal: 2m 15s\tremaining: 2.9s\n",
      "979:\tlearn: 0.0565386\ttotal: 2m 15s\tremaining: 2.76s\n",
      "980:\tlearn: 0.0565039\ttotal: 2m 15s\tremaining: 2.62s\n",
      "981:\tlearn: 0.0564347\ttotal: 2m 15s\tremaining: 2.48s\n",
      "982:\tlearn: 0.0563770\ttotal: 2m 15s\tremaining: 2.35s\n",
      "983:\tlearn: 0.0563712\ttotal: 2m 15s\tremaining: 2.21s\n",
      "984:\tlearn: 0.0563308\ttotal: 2m 16s\tremaining: 2.07s\n",
      "985:\tlearn: 0.0562673\ttotal: 2m 16s\tremaining: 1.93s\n",
      "986:\tlearn: 0.0562385\ttotal: 2m 16s\tremaining: 1.79s\n",
      "987:\tlearn: 0.0561923\ttotal: 2m 16s\tremaining: 1.66s\n",
      "988:\tlearn: 0.0561461\ttotal: 2m 16s\tremaining: 1.52s\n",
      "989:\tlearn: 0.0560653\ttotal: 2m 16s\tremaining: 1.38s\n",
      "990:\tlearn: 0.0561057\ttotal: 2m 16s\tremaining: 1.24s\n",
      "991:\tlearn: 0.0560365\ttotal: 2m 16s\tremaining: 1.1s\n",
      "992:\tlearn: 0.0560365\ttotal: 2m 17s\tremaining: 966ms\n",
      "993:\tlearn: 0.0560422\ttotal: 2m 17s\tremaining: 828ms\n",
      "994:\tlearn: 0.0559961\ttotal: 2m 17s\tremaining: 690ms\n",
      "995:\tlearn: 0.0559788\ttotal: 2m 17s\tremaining: 552ms\n",
      "996:\tlearn: 0.0559384\ttotal: 2m 17s\tremaining: 414ms\n",
      "997:\tlearn: 0.0558576\ttotal: 2m 17s\tremaining: 276ms\n",
      "998:\tlearn: 0.0558518\ttotal: 2m 17s\tremaining: 138ms\n",
      "999:\tlearn: 0.0557883\ttotal: 2m 18s\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "# cross_validate the baseline model on the accuracy, precision, recall and f1\n",
    "cat_clf_scores = cross_validate(cat_clf,x_train,y_train, cv=5, scoring =calculate_scores_multi_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "049e9460-fc48-4e74-b6d0-38e0bf279c44",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_accuracy': 90.48,\n",
       " 'test_precision': 78.54,\n",
       " 'test_recall': 65.63,\n",
       " 'test_f1': 66.89}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = ['test_accuracy', 'test_precision','test_recall', 'test_f1']\n",
    "validation_scores = {}\n",
    "for score in scores:\n",
    "    validation_scores[score] = round(cat_clf_scores[score].mean(), 2)\n",
    "validation_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fde5795-028c-441d-851b-81570f30e207",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Log Cat Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5339e0fb-bf03-4160-97c0-f3b02847b910",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Log the model's dataset train and test indices\n",
    "log_data(x_train,y_train,x_test,y_test)\n",
    "# Log the model, model description\n",
    "model = log_model(cat_clf,'Cat Boost, multilabel, Data resampled')\n",
    "# Log the model's train and test scores\n",
    "log_metrics(train_scores, validation_scores)\n",
    "# track the model artifacts, validation scores with mlflow \n",
    "track_model(model,validation_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ca91a1-0a3d-4acf-ad3d-df0d4e700ccb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1ecc8f98-817d-48ac-b3ac-a209c0fd1de1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['memory',\n",
       " 'steps',\n",
       " 'verbose',\n",
       " 'randomforestclassifier',\n",
       " 'randomforestclassifier__bootstrap',\n",
       " 'randomforestclassifier__ccp_alpha',\n",
       " 'randomforestclassifier__class_weight',\n",
       " 'randomforestclassifier__criterion',\n",
       " 'randomforestclassifier__max_depth',\n",
       " 'randomforestclassifier__max_features',\n",
       " 'randomforestclassifier__max_leaf_nodes',\n",
       " 'randomforestclassifier__max_samples',\n",
       " 'randomforestclassifier__min_impurity_decrease',\n",
       " 'randomforestclassifier__min_samples_leaf',\n",
       " 'randomforestclassifier__min_samples_split',\n",
       " 'randomforestclassifier__min_weight_fraction_leaf',\n",
       " 'randomforestclassifier__n_estimators',\n",
       " 'randomforestclassifier__n_jobs',\n",
       " 'randomforestclassifier__oob_score',\n",
       " 'randomforestclassifier__random_state',\n",
       " 'randomforestclassifier__verbose',\n",
       " 'randomforestclassifier__warm_start']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(rf_clf.get_params().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ee3cd1-8385-4758-8dc8-b43a63e0add0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "rf_param_grid = [\n",
    "    {'randomforestclassifier__n_estimators':[80,90,100,110,120,130],\n",
    "     'randomforestclassifier__max_depth':[30,35,40,45,50],\n",
    "     'randomforestclassifier__min_samples_split':[2,3,4,5,6,7,8],\n",
    "     'randomforestclassifier__min_samples_leaf':[1,3,5,7,9],\n",
    "     'randomforestclassifier__class_weight':['balanced',None],\n",
    "     'randomforestclassifier__max_features':['sqrt','log2'],\n",
    "     'randomforestclassifier__verbose': [0],\n",
    "    }]\n",
    "    \n",
    "\n",
    "rf_clf_grid_search = RandomizedSearchCV(rf_clf, rf_param_grid,cv= 3,n_iter=100, scoring=precision_score_multi_label, return_train_score=True,refit=True,verbose=2)\n",
    "\n",
    "rf_clf_grid_search.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b80de654-e2ed-473b-a62f-59dfe0f9131d",
   "metadata": {
    "tags": []
   },
   "source": [
    "best_params {n_estimators = 100,\n",
    "            max_depth=50,\n",
    "            min_samples_split=2,\n",
    "            max_features='sqrt',\n",
    "            class_weight=None,\n",
    "            min_samples_leaf=1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28f5ae6-92cf-45ac-927a-0931b7b47bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log the model's dataset train and test indices\n",
    "log_data(x_train,y_train,x_test,y_test)\n",
    "# Log the model, model description\n",
    "model = log_model(rf_clf_grid_search.best_estimator_,'Random Forest, Tuned, multilabel, Data resampled')\n",
    "# Log the model's train and test scores\n",
    "log_metrics(train_scores, validation_scores)\n",
    "# track the model artifacts, validation scores with mlflow \n",
    "track_model(model,validation_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a25a7e-1c05-4884-9b28-1e0ff397fedf",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "61f7a726",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultiOutputClassifier(estimator=VotingClassifier(estimators=[(&#x27;rf&#x27;,\n",
       "                                                              RandomForestClassifier(max_depth=50,\n",
       "                                                                                     n_jobs=-1,\n",
       "                                                                                     random_state=42)),\n",
       "                                                             (&#x27;gd&#x27;,\n",
       "                                                              GradientBoostingClassifier(max_features=&#x27;sqrt&#x27;,\n",
       "                                                                                         random_state=42)),\n",
       "                                                             (&#x27;cat&#x27;,\n",
       "                                                              &lt;catboost.core.CatBoostClassifier object at 0x000001B4836572D0&gt;)],\n",
       "                                                 voting=&#x27;soft&#x27;))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultiOutputClassifier</label><div class=\"sk-toggleable__content\"><pre>MultiOutputClassifier(estimator=VotingClassifier(estimators=[(&#x27;rf&#x27;,\n",
       "                                                              RandomForestClassifier(max_depth=50,\n",
       "                                                                                     n_jobs=-1,\n",
       "                                                                                     random_state=42)),\n",
       "                                                             (&#x27;gd&#x27;,\n",
       "                                                              GradientBoostingClassifier(max_features=&#x27;sqrt&#x27;,\n",
       "                                                                                         random_state=42)),\n",
       "                                                             (&#x27;cat&#x27;,\n",
       "                                                              &lt;catboost.core.CatBoostClassifier object at 0x000001B4836572D0&gt;)],\n",
       "                                                 voting=&#x27;soft&#x27;))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: VotingClassifier</label><div class=\"sk-toggleable__content\"><pre>VotingClassifier(estimators=[(&#x27;rf&#x27;,\n",
       "                              RandomForestClassifier(max_depth=50, n_jobs=-1,\n",
       "                                                     random_state=42)),\n",
       "                             (&#x27;gd&#x27;,\n",
       "                              GradientBoostingClassifier(max_features=&#x27;sqrt&#x27;,\n",
       "                                                         random_state=42)),\n",
       "                             (&#x27;cat&#x27;,\n",
       "                              &lt;catboost.core.CatBoostClassifier object at 0x000001B4836572D0&gt;)],\n",
       "                 voting=&#x27;soft&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>rf</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=50, n_jobs=-1, random_state=42)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>gd</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(max_features=&#x27;sqrt&#x27;, random_state=42)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>cat</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CatBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>&lt;catboost.core.CatBoostClassifier object at 0x000001B4836572D0&gt;</pre></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultiOutputClassifier(estimator=VotingClassifier(estimators=[('rf',\n",
       "                                                              RandomForestClassifier(max_depth=50,\n",
       "                                                                                     n_jobs=-1,\n",
       "                                                                                     random_state=42)),\n",
       "                                                             ('gd',\n",
       "                                                              GradientBoostingClassifier(max_features='sqrt',\n",
       "                                                                                         random_state=42)),\n",
       "                                                             ('cat',\n",
       "                                                              <catboost.core.CatBoostClassifier object at 0x000001B4836572D0>)],\n",
       "                                                 voting='soft'))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_clf = make_pipeline(StandardScaler(),\n",
    "                    LogisticRegression(max_iter=1000))\n",
    "\n",
    "gd_clf = GradientBoostingClassifier(n_estimators=100,\n",
    "                                    max_depth=3,\n",
    "                                    max_features='sqrt',\n",
    "                                    random_state=42,\n",
    "                                    verbose=0)\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_jobs=-1,\n",
    "                                n_estimators = 100,\n",
    "                                max_depth=50,\n",
    "                                min_samples_split=2,\n",
    "                                max_features='sqrt',\n",
    "                                min_samples_leaf=1,\n",
    "                                verbose=0,\n",
    "                                random_state=42)\n",
    "\n",
    "cat_clf = CatBoostClassifier(verbose=0)\n",
    "\n",
    "voting_clf = MultiOutputClassifier(VotingClassifier(\n",
    "    estimators=[\n",
    "        # ('log', log_clf),\n",
    "        ('rf', rf_clf),\n",
    "        ('gd', gd_clf),\n",
    "        ('cat', cat_clf)\n",
    "    ] \n",
    ",voting = \"soft\"))\n",
    "\n",
    "\n",
    "voting_clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9506fee5-2e5e-4022-80cc-c7215c1f9671",
   "metadata": {},
   "source": [
    "### Evaluate Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "187d15ce-c682-4adc-a6d3-b40e4cfd420b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cross_validate the baseline model on the accuracy, precision, recall and f1\n",
    "voting_clf_scores = cross_validate(voting_clf,x_train,y_train, cv=5, scoring =calculate_scores_multi_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8009c2fb-9094-4436-83c2-9dc31fa0e90c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_accuracy': 91.03,\n",
       " 'test_precision': 82.38,\n",
       " 'test_recall': 68.35,\n",
       " 'test_f1': 70.04}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = ['test_accuracy', 'test_precision','test_recall', 'test_f1']\n",
    "validation_scores = {}\n",
    "for score in scores:\n",
    "    validation_scores[score] = round(voting_clf_scores[score].mean(), 2)\n",
    "validation_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e7cd83-9a0c-4d18-a4ce-829a0cfdce40",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Log voting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "62f39767",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Log the model's dataset train and test indices\n",
    "log_data(x_train,y_train,x_test,y_test)\n",
    "# Log the model, model description\n",
    "model = log_model(voting_clf,'Voting Classifier')\n",
    "# Log the model's train and test scores\n",
    "log_metrics(train_scores, validation_scores)\n",
    "# track the model artifacts, validation scores with mlflow \n",
    "track_model(model,validation_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95872fb-f226-4268-966f-eb54fad08346",
   "metadata": {},
   "source": [
    "## Precision/ Recall trade_off"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1d3a36-5b35-44ca-bb51-7afbbf7aa825",
   "metadata": {},
   "source": [
    "## Error analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68354bfe-be9e-47f6-98a8-9bd7b1bf7aff",
   "metadata": {},
   "source": [
    "## Evaluate on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f86a99-40de-453c-8459-e4324779b68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics=[accuracy_score, precision_score, recall_score, f1_score]\n",
    "train_scores, mean_train_scores= calculate_metrics(gd_clf,x_train,y_train, metrics)\n",
    "\n",
    "print(mean_train_scores)\n",
    "train_scores.sort_values(\"precision_score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b948782-b3bf-4fcf-b1d8-15837748adec",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Retrieve Runs and best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e2c5e639-1225-474d-b9e6-7c0f76947f7f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>tags.mlflow.runName</th>\n",
       "      <th>metrics.test_precision</th>\n",
       "      <th>metrics.test_recall</th>\n",
       "      <th>metrics.test_f1</th>\n",
       "      <th>metrics.test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b6aaed9a2e3d498fae2f1f2e653ea3f1</td>\n",
       "      <td>Voting Classifier</td>\n",
       "      <td>82.38</td>\n",
       "      <td>68.35</td>\n",
       "      <td>70.04</td>\n",
       "      <td>91.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7c9c703026bf4599a1511aac4ed069b4</td>\n",
       "      <td>Cat Boost, multilabel, Data resampled</td>\n",
       "      <td>78.54</td>\n",
       "      <td>65.63</td>\n",
       "      <td>66.89</td>\n",
       "      <td>90.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5e9a2bdf773e4eaba816db1031f65b83</td>\n",
       "      <td>Gradient Boost, multilabel, Data resampled</td>\n",
       "      <td>71.08</td>\n",
       "      <td>60.74</td>\n",
       "      <td>60.94</td>\n",
       "      <td>89.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dcdc4868f2544bd8860fb1fbdc057933</td>\n",
       "      <td>Decision Tree, multilabel, Data resampled</td>\n",
       "      <td>66.54</td>\n",
       "      <td>76.80</td>\n",
       "      <td>66.70</td>\n",
       "      <td>87.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>465c94b53d7040648b0e701c656fd424</td>\n",
       "      <td>Random Forest, multilabel, Data resampled</td>\n",
       "      <td>89.16</td>\n",
       "      <td>76.29</td>\n",
       "      <td>78.92</td>\n",
       "      <td>92.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>e84c07550d2549c6ad9a232fb24a5054</td>\n",
       "      <td>Baseline model: Logistic Regression, multilabe...</td>\n",
       "      <td>67.04</td>\n",
       "      <td>61.54</td>\n",
       "      <td>61.12</td>\n",
       "      <td>89.21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             run_id  \\\n",
       "0  b6aaed9a2e3d498fae2f1f2e653ea3f1   \n",
       "1  7c9c703026bf4599a1511aac4ed069b4   \n",
       "2  5e9a2bdf773e4eaba816db1031f65b83   \n",
       "3  dcdc4868f2544bd8860fb1fbdc057933   \n",
       "4  465c94b53d7040648b0e701c656fd424   \n",
       "5  e84c07550d2549c6ad9a232fb24a5054   \n",
       "\n",
       "                                 tags.mlflow.runName  metrics.test_precision  \\\n",
       "0                                  Voting Classifier                   82.38   \n",
       "1              Cat Boost, multilabel, Data resampled                   78.54   \n",
       "2         Gradient Boost, multilabel, Data resampled                   71.08   \n",
       "3          Decision Tree, multilabel, Data resampled                   66.54   \n",
       "4          Random Forest, multilabel, Data resampled                   89.16   \n",
       "5  Baseline model: Logistic Regression, multilabe...                   67.04   \n",
       "\n",
       "   metrics.test_recall  metrics.test_f1  metrics.test_accuracy  \n",
       "0                68.35            70.04                  91.03  \n",
       "1                65.63            66.89                  90.48  \n",
       "2                60.74            60.94                  89.61  \n",
       "3                76.80            66.70                  87.78  \n",
       "4                76.29            78.92                  92.15  \n",
       "5                61.54            61.12                  89.21  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runs = mlflow.search_runs([exp.experiment_id])\n",
    "runs[['run_id','tags.mlflow.runName','metrics.test_precision','metrics.test_recall','metrics.test_f1','metrics.test_accuracy']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ac1499ba-f70b-4df3-b7bf-38fa6037681f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_run= runs.sort_values('metrics.test_precision',ascending=False).iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "215caf8b-5637-4df1-8522-edc9bf2ece4b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "run_id                                      465c94b53d7040648b0e701c656fd424\n",
       "experiment_id                                             996200319116358272\n",
       "status                                                              FINISHED\n",
       "artifact_uri               file:///C:/Users/Ali/Desktop/DS Projects/Tech ...\n",
       "start_time                                  2024-01-28 20:19:46.125000+00:00\n",
       "end_time                                    2024-01-28 20:19:46.394000+00:00\n",
       "metrics.test_accuracy                                                  92.15\n",
       "metrics.test_recall                                                    76.29\n",
       "metrics.test_f1                                                        78.92\n",
       "metrics.test_precision                                                 89.16\n",
       "tags.mlflow.user                                                         Ali\n",
       "tags.mlflow.source.type                                                LOCAL\n",
       "tags.mlflow.source.name    C:\\Users\\Ali\\mambaforge-pypy3\\envs\\env1\\Lib\\si...\n",
       "tags.mlflow.runName                Random Forest, multilabel, Data resampled\n",
       "Name: 4, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5eab144d-3849-4cea-9546-e4f568606dfd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "artifact_path = best_run[\"artifact_uri\"].replace(\"file:///\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c08f9997-e4ce-47e8-b862-61bbd3365228",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;randomforestclassifier&#x27;,\n",
       "                 RandomForestClassifier(n_jobs=-1, random_state=42,\n",
       "                                        verbose=1))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;randomforestclassifier&#x27;,\n",
       "                 RandomForestClassifier(n_jobs=-1, random_state=42,\n",
       "                                        verbose=1))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_jobs=-1, random_state=42, verbose=1)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('randomforestclassifier',\n",
       "                 RandomForestClassifier(n_jobs=-1, random_state=42,\n",
       "                                        verbose=1))])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pkl = os.path.join(artifact_path, LOG_MODEL_PKL)\n",
    "with open(model_pkl, \"rb\") as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "model['model_object']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c69cc12-a327-400b-a747-d118c5d3c1ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
