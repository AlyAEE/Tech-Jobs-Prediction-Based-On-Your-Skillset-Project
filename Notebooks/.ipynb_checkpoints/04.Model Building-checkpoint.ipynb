{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "414f139d-1690-4a6a-8a9b-bc9abcc54dbb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Constants\n",
    "DATA_PATH   = \"../Data/Processed/3_engineered_df.pkl\"\n",
    "\n",
    "TECH_JOBS = ['Techjobs']\n",
    "\n",
    "CORE_COLS = ['VersionControlSystem',\n",
    "             'Languages',\n",
    "             'Databases',\n",
    "             'Platforms',\n",
    "             'WebFrameworks',\n",
    "             'MiscTech',\n",
    "             'ToolsTech',\n",
    "             'CollabTools'\n",
    "]\n",
    "\n",
    "\n",
    "MLFLOW_TRACKING_URI = '../models/mlruns'\n",
    "MLFLOW_EXPERIMENT_NAME = \"tech_jobs_predictions\"\n",
    "\n",
    "LOG_PATH = \"../models/temp/\"\n",
    "LOG_DATA_PKL    =  \"data.pkl\"\n",
    "LOG_MODEL_PKL   =  \"model.pkl\"\n",
    "LOG_METRICS_PKL =  \"metrics.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "479545cb-df3d-4d79-b24a-f12d1945d453",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load packages\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import os\n",
    "\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    " \n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler,RobustScaler\n",
    "\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import auc, accuracy_score, confusion_matrix, f1_score, precision_score, recall_score,ConfusionMatrixDisplay,classification_report\n",
    "from sklearn.model_selection import train_test_split,cross_val_score, cross_validate,cross_val_predict, GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "pd.options.display.max_rows = 1000\n",
    "pd.options.display.max_columns = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8796ec-a3a5-4ce6-aa68-5489f03d4364",
   "metadata": {},
   "source": [
    "_____"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b303da-94c0-4c3c-81a6-4ede2d19d9c4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d025650b-bca6-408e-b551-8bbd87b15859",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Functions to calculate metric functions across all columns in a multi-label dataset\n",
    "def calculate_metrics(clf, x, y, metrics=[accuracy_score, precision_score, recall_score, f1_score]):\n",
    "    #create a dataframe contains the predictions \n",
    "    predictions =  pd.DataFrame(clf.predict(x),\n",
    "                                columns=y.columns)\n",
    "    \n",
    "    #create a dict for each type of metric contains a dicts of each label and its value \n",
    "    final_scores = {metric.__name__: predictions_per_col(predictions, y, metric) \n",
    "            for metric in metrics}\n",
    "    \n",
    "    #Convert the dict to dataframe\n",
    "    final_scores = pd.concat(final_scores,axis=1)\n",
    "    mean_final_scores = final_scores.mean()\n",
    "    \n",
    "    return final_scores, mean_final_scores\n",
    "\n",
    "def predictions_per_col(predictions, y, metric_function):\n",
    "    metric_scores = {}\n",
    "    for col in predictions.columns:\n",
    "        truth = y[col].copy()\n",
    "        pred  = predictions[col].copy()\n",
    "        \n",
    "        metric_scores[col] = calculate_metric(truth, pred, metric_function)\n",
    "\n",
    "    metric_scores = pd.Series(metric_scores.values(), index=metric_scores.keys())\n",
    "    \n",
    "    return metric_scores\n",
    "\n",
    "def calculate_metric(truth, pred, metric_function):\n",
    "    if metric_function == accuracy_score:\n",
    "        metric_score = round(metric_function(truth, pred) * 100, 2)\n",
    "    else: \n",
    "        metric_score = round(metric_function(truth, pred,zero_division=0,average='macro') * 100, 2)\n",
    "    return metric_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5aee1817-0500-4631-adf9-64dcc67f2e7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function that calculate all metrics for a cross_validate function for multiclass classification\n",
    "def calculate_scores(clf, x, y):\n",
    "    y_pred = clf.predict(x)\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    precision = precision_score(y, y_pred, average='macro',zero_division=0.0)\n",
    "    recall = recall_score(y, y_pred, average='macro',zero_division=0.0)\n",
    "    f1 = f1_score(y, y_pred, average='macro',zero_division=0.0)\n",
    "    \n",
    "    return {'accuracy': accuracy,\n",
    "            'precision':precision,\n",
    "            'recall': recall,\n",
    "           'f1' : f1}\n",
    "\n",
    "# Function that calculate all metrics for a cross_validate function for multi-label classification\n",
    "def calculate_scores_multi_label(clf, x, y, metrics=[accuracy_score, precision_score, recall_score, f1_score]):\n",
    "    #create a dataframe contains the predictions \n",
    "    predictions =  pd.DataFrame(clf.predict(x),\n",
    "                                columns=y.columns)\n",
    "    \n",
    "    #create a dict for each type of metric contains a dicts of each label and its value \n",
    "    final_scores = {metric.__name__: predictions_per_col(predictions, y, metric) \n",
    "            for metric in metrics}\n",
    "    \n",
    "    #Convert the dict to dataframe\n",
    "    final_scores = pd.concat(final_scores,axis=1)\n",
    "    mean_final_scores = final_scores.mean()\n",
    "    \n",
    "    return {'accuracy': mean_final_scores[0],\n",
    "            'precision':mean_final_scores[1],\n",
    "            'recall': mean_final_scores[2],\n",
    "           'f1' : mean_final_scores[3]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38d203ad-1aa0-4110-b7ff-4a735985c905",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Functions responisble for Grid_search wtih multi_label dataset\n",
    "def f1_score_multi_label(clf, x, y):\n",
    "    quality_scores = {}\n",
    "    predictions =  pd.DataFrame(clf.predict(x),\n",
    "                            columns=y.columns)\n",
    "    \n",
    "    for col in predictions.columns:\n",
    "        job_pred  = predictions[col].copy()\n",
    "        job_truth = y[col].copy()\n",
    "\n",
    "        quality_scores[col] = round(f1_score(job_truth, job_pred,zero_division=0,average='macro') * 100, 2)\n",
    "        \n",
    "    quality_scores = pd.Series(quality_scores.values(), index=quality_scores.keys())\n",
    "    \n",
    "    # train_scores = pd.concat(train_scores,axis=1)\n",
    "    mean_f1_score = quality_scores.mean()\n",
    "    return mean_f1_score\n",
    "\n",
    "def precision_score_multi_label(clf, x, y):\n",
    "    quality_scores = {}\n",
    "    predictions =  pd.DataFrame(clf.predict(x),\n",
    "                            columns=y.columns)\n",
    "    \n",
    "    for col in predictions.columns:\n",
    "        job_pred  = predictions[col].copy()\n",
    "        job_truth = y[col].copy()\n",
    "\n",
    "        quality_scores[col] = round(precision_score(job_truth, job_pred,zero_division=0,average='macro') * 100, 2)\n",
    "        \n",
    "    quality_scores = pd.Series(quality_scores.values(), index=quality_scores.keys())\n",
    "    \n",
    "    # train_scores = pd.concat(train_scores,axis=1)\n",
    "    mean_f1_score = quality_scores.mean()\n",
    "    return mean_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd630a5c-eb8f-4e6c-97d0-e56a2109894f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to log Data, Model, Metrics and Track models.\n",
    "def log_data(x_train,y_train,x_test,y_test):\n",
    "    # Save the model's dataset trained on\n",
    "    data_details = {\n",
    "    #For multilabel Dataset\n",
    "                    \"data_path\": DATA_PATH,\n",
    "                    \"training_set\": x_train.index.tolist(),\n",
    "                    \"test_indices\":     x_test.index.tolist(), \n",
    "                    \"features_names\":   x_train.columns.tolist(),\n",
    "                    \"targets_names\":    y_train.columns.tolist()\n",
    "    #For multiclass Dataset    \n",
    "                    # \"x_train\": x_train,\n",
    "                    # \"x_test\":x_test,\n",
    "                    # \"y_train\":y_train,\n",
    "                    # \"y_test\": y_test\n",
    "    }\n",
    "\n",
    "    with open(os.path.join(LOG_PATH, LOG_DATA_PKL), \"wb\") as output_file:\n",
    "        pickle.dump(data_details, output_file)\n",
    "        \n",
    "        \n",
    "def log_model(clf,model_description=''):\n",
    "    # save the model, model details and model's description\n",
    "    model = {\"model_description\": model_description,\n",
    "             \"model_details\": str(clf),\n",
    "             \"model_object\": clf} \n",
    "\n",
    "    with open(os.path.join(LOG_PATH, LOG_MODEL_PKL), \"wb\") as output_file:\n",
    "        pickle.dump(model, output_file)\n",
    "        \n",
    "    return model\n",
    "        \n",
    "def log_metrics(train_scores, test_scores):\n",
    "    # save the model metrics\n",
    "    classes_metrics = {\"train_scores\": train_scores,\n",
    "                        \"test_scores\" : test_scores} \n",
    "\n",
    "\n",
    "    with open(os.path.join(LOG_PATH, LOG_METRICS_PKL), \"wb\") as output_file:\n",
    "        pickle.dump(classes_metrics, output_file)\n",
    "\n",
    "def track_model(model, scores):\n",
    "    # Start a run in the experiment and track current model\n",
    "    with mlflow.start_run(experiment_id=exp.experiment_id, run_name=model[\"model_description\"]):\n",
    "        # Track pickle files\n",
    "        mlflow.log_artifacts(LOG_PATH)\n",
    "\n",
    "        # Track metrics \n",
    "        for metric, score in scores.items():\n",
    "            mlflow.log_metric(metric, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571b17b8-74c5-4506-872e-3fd7f4c83cdd",
   "metadata": {},
   "source": [
    "_____"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52187dcd-5537-48f9-bd88-92467bdc88a8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6a14ea2-0e58-4a2d-8fd8-90adfd22c3c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load dataset and make a copy\n",
    "eng_df = pd.read_pickle(DATA_PATH)\n",
    "df = eng_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3aaf3f6-1a80-401a-a9d9-dbabdcd58898",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"19\" halign=\"left\">Techjobs</th>\n",
       "      <th colspan=\"3\" halign=\"left\">VersionControlSystem</th>\n",
       "      <th colspan=\"42\" halign=\"left\">Languages</th>\n",
       "      <th colspan=\"17\" halign=\"left\">Databases</th>\n",
       "      <th colspan=\"14\" halign=\"left\">Platforms</th>\n",
       "      <th colspan=\"25\" halign=\"left\">WebFrameworks</th>\n",
       "      <th colspan=\"23\" halign=\"left\">MiscTech</th>\n",
       "      <th colspan=\"13\" halign=\"left\">ToolsTech</th>\n",
       "      <th colspan=\"27\" halign=\"left\">CollabTools</th>\n",
       "      <th colspan=\"38\" halign=\"left\">Skills_Clusters</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Data scientist or machine learning specialist</th>\n",
       "      <th>Engineer, data</th>\n",
       "      <th>Data or business analyst</th>\n",
       "      <th>Developer, back-end</th>\n",
       "      <th>Database administrator</th>\n",
       "      <th>Developer, mobile</th>\n",
       "      <th>Developer, full-stack</th>\n",
       "      <th>Cloud infrastructure engineer</th>\n",
       "      <th>Developer, embedded applications or devices</th>\n",
       "      <th>Developer, QA or test</th>\n",
       "      <th>System administrator</th>\n",
       "      <th>Scientist</th>\n",
       "      <th>Security professional</th>\n",
       "      <th>Developer, game or graphics</th>\n",
       "      <th>Developer, front-end</th>\n",
       "      <th>Blockchain</th>\n",
       "      <th>Developer, desktop or enterprise applications</th>\n",
       "      <th>DevOps specialist</th>\n",
       "      <th>Academic researcher</th>\n",
       "      <th>Git</th>\n",
       "      <th>Mercurial</th>\n",
       "      <th>SVN</th>\n",
       "      <th>APL</th>\n",
       "      <th>Assembly</th>\n",
       "      <th>Bash/Shell</th>\n",
       "      <th>C</th>\n",
       "      <th>C#</th>\n",
       "      <th>C++</th>\n",
       "      <th>COBOL</th>\n",
       "      <th>Clojure</th>\n",
       "      <th>Crystal</th>\n",
       "      <th>Dart</th>\n",
       "      <th>Delphi</th>\n",
       "      <th>Elixir</th>\n",
       "      <th>Erlang</th>\n",
       "      <th>F#</th>\n",
       "      <th>Fortran</th>\n",
       "      <th>Go</th>\n",
       "      <th>Groovy</th>\n",
       "      <th>HTML/CSS</th>\n",
       "      <th>Haskell</th>\n",
       "      <th>Java</th>\n",
       "      <th>JavaScript</th>\n",
       "      <th>Julia</th>\n",
       "      <th>Kotlin</th>\n",
       "      <th>LISP</th>\n",
       "      <th>Lua</th>\n",
       "      <th>MATLAB</th>\n",
       "      <th>OCaml</th>\n",
       "      <th>Objective-C</th>\n",
       "      <th>PHP</th>\n",
       "      <th>Perl</th>\n",
       "      <th>PowerShell</th>\n",
       "      <th>Python</th>\n",
       "      <th>R</th>\n",
       "      <th>Ruby</th>\n",
       "      <th>Rust</th>\n",
       "      <th>SAS</th>\n",
       "      <th>SQL</th>\n",
       "      <th>Scala</th>\n",
       "      <th>Solidity</th>\n",
       "      <th>Swift</th>\n",
       "      <th>TypeScript</th>\n",
       "      <th>VBA</th>\n",
       "      <th>Cassandra</th>\n",
       "      <th>Cloud Firestore</th>\n",
       "      <th>CouchDB</th>\n",
       "      <th>Couchbase</th>\n",
       "      <th>DynamoDB</th>\n",
       "      <th>Elasticsearch</th>\n",
       "      <th>Firebase Realtime Database</th>\n",
       "      <th>IBM DB2</th>\n",
       "      <th>MariaDB</th>\n",
       "      <th>Microsoft SQL Server</th>\n",
       "      <th>MongoDB</th>\n",
       "      <th>MySQL</th>\n",
       "      <th>Neo4j</th>\n",
       "      <th>Oracle</th>\n",
       "      <th>PostgreSQL</th>\n",
       "      <th>Redis</th>\n",
       "      <th>SQLite</th>\n",
       "      <th>AWS</th>\n",
       "      <th>Colocation</th>\n",
       "      <th>DigitalOcean</th>\n",
       "      <th>Firebase</th>\n",
       "      <th>Google Cloud</th>\n",
       "      <th>Heroku</th>\n",
       "      <th>IBM Cloud or Watson</th>\n",
       "      <th>Linode</th>\n",
       "      <th>Managed Hosting</th>\n",
       "      <th>Microsoft Azure</th>\n",
       "      <th>OVH</th>\n",
       "      <th>OpenStack</th>\n",
       "      <th>Oracle Cloud Infrastructure</th>\n",
       "      <th>VMware</th>\n",
       "      <th>ASP.NET</th>\n",
       "      <th>ASP.NET Core</th>\n",
       "      <th>Angular</th>\n",
       "      <th>Angular.js</th>\n",
       "      <th>Blazor</th>\n",
       "      <th>Deno</th>\n",
       "      <th>Django</th>\n",
       "      <th>Drupal</th>\n",
       "      <th>Express</th>\n",
       "      <th>FastAPI</th>\n",
       "      <th>Fastify</th>\n",
       "      <th>Flask</th>\n",
       "      <th>Gatsby</th>\n",
       "      <th>Laravel</th>\n",
       "      <th>Next.js</th>\n",
       "      <th>Node.js</th>\n",
       "      <th>Nuxt.js</th>\n",
       "      <th>Phoenix</th>\n",
       "      <th>Play Framework</th>\n",
       "      <th>React.js</th>\n",
       "      <th>Ruby on Rails</th>\n",
       "      <th>Svelte</th>\n",
       "      <th>Symfony</th>\n",
       "      <th>Vue.js</th>\n",
       "      <th>jQuery</th>\n",
       "      <th>.NET</th>\n",
       "      <th>Apache Kafka</th>\n",
       "      <th>Apache Spark</th>\n",
       "      <th>Capacitor</th>\n",
       "      <th>Cordova</th>\n",
       "      <th>Electron</th>\n",
       "      <th>Flutter</th>\n",
       "      <th>GTK</th>\n",
       "      <th>Hadoop</th>\n",
       "      <th>Hugging Face Transformers</th>\n",
       "      <th>Ionic</th>\n",
       "      <th>Keras</th>\n",
       "      <th>NumPy</th>\n",
       "      <th>Pandas</th>\n",
       "      <th>Qt</th>\n",
       "      <th>React Native</th>\n",
       "      <th>Scikit-learn</th>\n",
       "      <th>Spring</th>\n",
       "      <th>TensorFlow</th>\n",
       "      <th>Tidyverse</th>\n",
       "      <th>Torch/PyTorch</th>\n",
       "      <th>Uno Platform</th>\n",
       "      <th>Xamarin</th>\n",
       "      <th>Ansible</th>\n",
       "      <th>Chef</th>\n",
       "      <th>Docker</th>\n",
       "      <th>Flow</th>\n",
       "      <th>Homebrew</th>\n",
       "      <th>Kubernetes</th>\n",
       "      <th>Pulumi</th>\n",
       "      <th>Puppet</th>\n",
       "      <th>Terraform</th>\n",
       "      <th>Unity 3D</th>\n",
       "      <th>Unreal Engine</th>\n",
       "      <th>Yarn</th>\n",
       "      <th>npm</th>\n",
       "      <th>Android Studio</th>\n",
       "      <th>Atom</th>\n",
       "      <th>CLion</th>\n",
       "      <th>Eclipse</th>\n",
       "      <th>Emacs</th>\n",
       "      <th>GoLand</th>\n",
       "      <th>IPython/Jupyter</th>\n",
       "      <th>IntelliJ</th>\n",
       "      <th>Nano</th>\n",
       "      <th>Neovim</th>\n",
       "      <th>NetBeans</th>\n",
       "      <th>Notepad++</th>\n",
       "      <th>PhpStorm</th>\n",
       "      <th>PyCharm</th>\n",
       "      <th>Qt Creator</th>\n",
       "      <th>RAD Studio (Delphi, C++ Builder)</th>\n",
       "      <th>RStudio</th>\n",
       "      <th>Rider</th>\n",
       "      <th>RubyMine</th>\n",
       "      <th>Spyder</th>\n",
       "      <th>Sublime Text</th>\n",
       "      <th>TextMate</th>\n",
       "      <th>Vim</th>\n",
       "      <th>Visual Studio</th>\n",
       "      <th>Visual Studio Code</th>\n",
       "      <th>Webstorm</th>\n",
       "      <th>Xcode</th>\n",
       "      <th>skills_group_0</th>\n",
       "      <th>skills_group_1</th>\n",
       "      <th>skills_group_10</th>\n",
       "      <th>skills_group_11</th>\n",
       "      <th>skills_group_12</th>\n",
       "      <th>skills_group_13</th>\n",
       "      <th>skills_group_14</th>\n",
       "      <th>skills_group_15</th>\n",
       "      <th>skills_group_16</th>\n",
       "      <th>skills_group_17</th>\n",
       "      <th>skills_group_18</th>\n",
       "      <th>skills_group_19</th>\n",
       "      <th>skills_group_2</th>\n",
       "      <th>skills_group_20</th>\n",
       "      <th>skills_group_21</th>\n",
       "      <th>skills_group_22</th>\n",
       "      <th>skills_group_23</th>\n",
       "      <th>skills_group_24</th>\n",
       "      <th>skills_group_25</th>\n",
       "      <th>skills_group_26</th>\n",
       "      <th>skills_group_27</th>\n",
       "      <th>skills_group_28</th>\n",
       "      <th>skills_group_29</th>\n",
       "      <th>skills_group_3</th>\n",
       "      <th>skills_group_30</th>\n",
       "      <th>skills_group_31</th>\n",
       "      <th>skills_group_32</th>\n",
       "      <th>skills_group_33</th>\n",
       "      <th>skills_group_34</th>\n",
       "      <th>skills_group_35</th>\n",
       "      <th>skills_group_36</th>\n",
       "      <th>skills_group_37</th>\n",
       "      <th>skills_group_4</th>\n",
       "      <th>skills_group_5</th>\n",
       "      <th>skills_group_6</th>\n",
       "      <th>skills_group_7</th>\n",
       "      <th>skills_group_8</th>\n",
       "      <th>skills_group_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73262</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73263</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73264</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73265</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73266</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42246 rows × 221 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Techjobs                 \\\n",
       "      Data scientist or machine learning specialist Engineer, data   \n",
       "2                                                 1              1   \n",
       "3                                                 0              0   \n",
       "9                                                 0              0   \n",
       "10                                                0              0   \n",
       "12                                                0              0   \n",
       "...                                             ...            ...   \n",
       "73262                                             0              0   \n",
       "73263                                             0              0   \n",
       "73264                                             1              0   \n",
       "73265                                             0              0   \n",
       "73266                                             0              0   \n",
       "\n",
       "                                                                           \\\n",
       "      Data or business analyst Developer, back-end Database administrator   \n",
       "2                            0                   0                      0   \n",
       "3                            0                   0                      0   \n",
       "9                            0                   0                      0   \n",
       "10                           0                   1                      0   \n",
       "12                           0                   0                      0   \n",
       "...                        ...                 ...                    ...   \n",
       "73262                        0                   0                      0   \n",
       "73263                        0                   1                      0   \n",
       "73264                        0                   0                      0   \n",
       "73265                        0                   0                      0   \n",
       "73266                        0                   0                      0   \n",
       "\n",
       "                                                                             \\\n",
       "      Developer, mobile Developer, full-stack Cloud infrastructure engineer   \n",
       "2                     0                     0                             0   \n",
       "3                     0                     1                             0   \n",
       "9                     1                     0                             0   \n",
       "10                    0                     1                             0   \n",
       "12                    0                     1                             0   \n",
       "...                 ...                   ...                           ...   \n",
       "73262                 0                     0                             0   \n",
       "73263                 0                     0                             0   \n",
       "73264                 0                     0                             0   \n",
       "73265                 0                     1                             0   \n",
       "73266                 0                     0                             0   \n",
       "\n",
       "                                                                         \\\n",
       "      Developer, embedded applications or devices Developer, QA or test   \n",
       "2                                               0                     0   \n",
       "3                                               0                     0   \n",
       "9                                               0                     0   \n",
       "10                                              0                     0   \n",
       "12                                              0                     0   \n",
       "...                                           ...                   ...   \n",
       "73262                                           0                     0   \n",
       "73263                                           0                     0   \n",
       "73264                                           0                     0   \n",
       "73265                                           0                     0   \n",
       "73266                                           0                     0   \n",
       "\n",
       "                                                            \\\n",
       "      System administrator Scientist Security professional   \n",
       "2                        0         0                     0   \n",
       "3                        0         0                     0   \n",
       "9                        0         0                     0   \n",
       "10                       0         0                     0   \n",
       "12                       0         0                     0   \n",
       "...                    ...       ...                   ...   \n",
       "73262                    0         0                     0   \n",
       "73263                    0         0                     0   \n",
       "73264                    0         0                     0   \n",
       "73265                    1         0                     0   \n",
       "73266                    0         0                     0   \n",
       "\n",
       "                                                                   \\\n",
       "      Developer, game or graphics Developer, front-end Blockchain   \n",
       "2                               0                    1          0   \n",
       "3                               0                    0          0   \n",
       "9                               0                    0          0   \n",
       "10                              0                    0          0   \n",
       "12                              0                    0          0   \n",
       "...                           ...                  ...        ...   \n",
       "73262                           0                    1          0   \n",
       "73263                           0                    0          0   \n",
       "73264                           0                    0          0   \n",
       "73265                           0                    0          0   \n",
       "73266                           0                    1          0   \n",
       "\n",
       "                                                                       \\\n",
       "      Developer, desktop or enterprise applications DevOps specialist   \n",
       "2                                                 0                 0   \n",
       "3                                                 0                 0   \n",
       "9                                                 1                 0   \n",
       "10                                                0                 0   \n",
       "12                                                0                 0   \n",
       "...                                             ...               ...   \n",
       "73262                                             0                 0   \n",
       "73263                                             0                 0   \n",
       "73264                                             0                 0   \n",
       "73265                                             1                 0   \n",
       "73266                                             1                 0   \n",
       "\n",
       "                          VersionControlSystem               Languages  \\\n",
       "      Academic researcher                  Git Mercurial SVN       APL   \n",
       "2                       0                    1         0   0         0   \n",
       "3                       0                    1         0   0         0   \n",
       "9                       0                    1         0   0         0   \n",
       "10                      0                    1         0   0         0   \n",
       "12                      0                    1         0   0         0   \n",
       "...                   ...                  ...       ...  ..       ...   \n",
       "73262                   0                    1         0   0         0   \n",
       "73263                   0                    1         0   0         0   \n",
       "73264                   0                    1         0   0         0   \n",
       "73265                   0                    1         0   0         0   \n",
       "73266                   0                    0         0   1         0   \n",
       "\n",
       "                                                                              \\\n",
       "      Assembly Bash/Shell  C C# C++ COBOL Clojure Crystal Dart Delphi Elixir   \n",
       "2            0          0  0  1   1     0       0       0    0      0      0   \n",
       "3            0          0  0  1   0     0       0       0    0      0      0   \n",
       "9            0          0  0  0   0     0       0       0    0      1      0   \n",
       "10           0          1  0  1   0     0       0       0    0      0      0   \n",
       "12           0          0  1  0   0     0       0       0    0      0      0   \n",
       "...        ...        ... .. ..  ..   ...     ...     ...  ...    ...    ...   \n",
       "73262        1          0  1  0   1     0       0       0    0      0      0   \n",
       "73263        0          1  0  0   0     0       0       0    1      0      0   \n",
       "73264        0          1  0  0   0     0       0       0    0      0      0   \n",
       "73265        0          0  0  1   0     0       0       0    0      0      0   \n",
       "73266        0          0  0  1   0     0       0       0    0      1      0   \n",
       "\n",
       "                                                                          \\\n",
       "      Erlang F# Fortran Go Groovy HTML/CSS Haskell Java JavaScript Julia   \n",
       "2          0  0       0  0      0        1       0    0          1     0   \n",
       "3          0  0       0  0      0        0       0    0          1     0   \n",
       "9          0  0       0  0      0        0       0    1          0     0   \n",
       "10         0  0       0  1      0        1       0    0          1     0   \n",
       "12         0  0       0  0      0        1       1    0          0     0   \n",
       "...      ... ..     ... ..    ...      ...     ...  ...        ...   ...   \n",
       "73262      0  0       0  0      0        0       0    1          0     0   \n",
       "73263      0  0       0  1      0        0       0    0          1     0   \n",
       "73264      0  0       0  0      0        1       0    0          1     0   \n",
       "73265      0  0       0  0      0        1       0    0          1     0   \n",
       "73266      0  0       0  0      0        0       0    0          0     0   \n",
       "\n",
       "                                                                              \\\n",
       "      Kotlin LISP Lua MATLAB OCaml Objective-C PHP Perl PowerShell Python  R   \n",
       "2          0    0   0      0     0           0   0    0          0      1  0   \n",
       "3          0    0   0      0     0           0   0    0          0      0  0   \n",
       "9          0    0   0      0     0           0   0    0          0      0  0   \n",
       "10         0    0   0      0     0           0   0    0          1      0  0   \n",
       "12         0    0   0      0     0           0   0    0          0      0  0   \n",
       "...      ...  ...  ..    ...   ...         ...  ..  ...        ...    ... ..   \n",
       "73262      0    0   0      0     0           0   0    0          0      0  0   \n",
       "73263      0    0   0      0     0           0   1    0          0      1  0   \n",
       "73264      0    0   0      0     0           0   0    0          0      1  0   \n",
       "73265      0    0   0      0     0           0   1    0          0      1  0   \n",
       "73266      0    0   0      0     0           0   0    0          0      0  0   \n",
       "\n",
       "                                                            Databases  \\\n",
       "      Ruby Rust SAS SQL Scala Solidity Swift TypeScript VBA Cassandra   \n",
       "2        0    0   0   0     0        0     0          1   0         0   \n",
       "3        0    0   0   1     0        0     0          1   0         0   \n",
       "9        0    0   0   0     0        0     1          0   0         0   \n",
       "10       0    0   0   1     0        0     0          0   0         0   \n",
       "12       0    1   0   1     0        0     1          1   0         0   \n",
       "...    ...  ...  ..  ..   ...      ...   ...        ...  ..       ...   \n",
       "73262    0    0   0   0     0        0     0          1   0         0   \n",
       "73263    0    0   0   1     0        0     0          1   0         0   \n",
       "73264    0    0   0   1     0        0     0          0   0         0   \n",
       "73265    0    0   0   1     0        0     0          0   0         0   \n",
       "73266    0    0   0   0     0        0     0          0   1         0   \n",
       "\n",
       "                                                                \\\n",
       "      Cloud Firestore CouchDB Couchbase DynamoDB Elasticsearch   \n",
       "2                   0       0         0        0             0   \n",
       "3                   0       0         0        0             0   \n",
       "9                   0       0         0        0             0   \n",
       "10                  0       0         0        0             0   \n",
       "12                  0       0         0        0             1   \n",
       "...               ...     ...       ...      ...           ...   \n",
       "73262               0       0         0        0             0   \n",
       "73263               0       0         0        0             1   \n",
       "73264               0       0         0        0             1   \n",
       "73265               0       0         0        0             0   \n",
       "73266               0       0         0        0             0   \n",
       "\n",
       "                                                                               \\\n",
       "      Firebase Realtime Database IBM DB2 MariaDB Microsoft SQL Server MongoDB   \n",
       "2                              0       0       0                    1       0   \n",
       "3                              0       0       0                    1       0   \n",
       "9                              0       0       0                    0       0   \n",
       "10                             0       0       0                    1       0   \n",
       "12                             0       0       0                    0       0   \n",
       "...                          ...     ...     ...                  ...     ...   \n",
       "73262                          0       0       0                    0       0   \n",
       "73263                          0       0       0                    0       0   \n",
       "73264                          0       0       0                    0       1   \n",
       "73265                          0       0       1                    1       0   \n",
       "73266                          0       0       0                    1       1   \n",
       "\n",
       "                                                 Platforms             \\\n",
       "      MySQL Neo4j Oracle PostgreSQL Redis SQLite       AWS Colocation   \n",
       "2         0     0      0          0     0      0         0          0   \n",
       "3         0     0      0          0     0      0         0          0   \n",
       "9         0     0      0          0     0      0         0          0   \n",
       "10        0     0      0          0     0      0         1          0   \n",
       "12        0     0      0          1     1      0         1          0   \n",
       "...     ...   ...    ...        ...   ...    ...       ...        ...   \n",
       "73262     0     0      0          0     0      0         0          0   \n",
       "73263     1     0      0          1     1      0         1          0   \n",
       "73264     0     1      1          0     0      1         0          0   \n",
       "73265     1     0      0          1     0      1         0          0   \n",
       "73266     0     0      1          0     0      0         0          0   \n",
       "\n",
       "                                                                            \\\n",
       "      DigitalOcean Firebase Google Cloud Heroku IBM Cloud or Watson Linode   \n",
       "2                0        0            0      0                   0      0   \n",
       "3                0        0            0      0                   0      0   \n",
       "9                1        1            0      0                   0      0   \n",
       "10               0        0            0      0                   0      0   \n",
       "12               0        0            0      0                   0      0   \n",
       "...            ...      ...          ...    ...                 ...    ...   \n",
       "73262            0        0            0      0                   0      0   \n",
       "73263            1        0            1      0                   0      0   \n",
       "73264            0        0            0      0                   0      0   \n",
       "73265            0        1            0      0                   0      1   \n",
       "73266            0        0            0      0                   0      0   \n",
       "\n",
       "                                                     \\\n",
       "      Managed Hosting Microsoft Azure OVH OpenStack   \n",
       "2                   0               0   0         0   \n",
       "3                   0               0   0         0   \n",
       "9                   0               0   0         0   \n",
       "10                  0               1   0         0   \n",
       "12                  0               0   0         0   \n",
       "...               ...             ...  ..       ...   \n",
       "73262               0               0   0         0   \n",
       "73263               0               0   0         0   \n",
       "73264               0               0   0         0   \n",
       "73265               1               1   0         0   \n",
       "73266               0               0   0         0   \n",
       "\n",
       "                                         WebFrameworks                        \\\n",
       "      Oracle Cloud Infrastructure VMware       ASP.NET ASP.NET Core  Angular   \n",
       "2                               0      0             0             0       1   \n",
       "3                               0      0             1             1       0   \n",
       "9                               0      0             0             0       0   \n",
       "10                              0      0             1             1       0   \n",
       "12                              0      0             0             0       0   \n",
       "...                           ...    ...           ...           ...     ...   \n",
       "73262                           0      0             0             0       0   \n",
       "73263                           0      0             0             0       0   \n",
       "73264                           0      0             0             0       0   \n",
       "73265                           0      1             1             1       0   \n",
       "73266                           0      0             0             0       0   \n",
       "\n",
       "                                                                          \\\n",
       "      Angular.js Blazor Deno Django Drupal Express FastAPI Fastify Flask   \n",
       "2              1      0    0      0      0       0       0       0     0   \n",
       "3              0      0    0      0      0       0       0       0     0   \n",
       "9              0      0    0      0      0       0       0       0     0   \n",
       "10             0      1    0      0      0       0       0       0     0   \n",
       "12             0      0    0      0      0       0       0       0     0   \n",
       "...          ...    ...  ...    ...    ...     ...     ...     ...   ...   \n",
       "73262          0      0    0      0      0       0       0       0     0   \n",
       "73263          0      0    0      0      0       1       1       0     0   \n",
       "73264          0      0    0      0      0       0       1       0     1   \n",
       "73265          0      1    0      0      0       0       0       0     0   \n",
       "73266          0      0    0      0      0       0       0       0     0   \n",
       "\n",
       "                                                                              \\\n",
       "      Gatsby Laravel Next.js Node.js Nuxt.js Phoenix Play Framework React.js   \n",
       "2          0       0       0       0       0       0              0        0   \n",
       "3          0       0       0       0       0       0              0        0   \n",
       "9          0       0       0       0       0       0              0        0   \n",
       "10         0       0       0       0       0       0              0        0   \n",
       "12         0       0       0       0       0       0              0        1   \n",
       "...      ...     ...     ...     ...     ...     ...            ...      ...   \n",
       "73262      0       0       0       1       0       0              0        0   \n",
       "73263      0       0       0       1       0       0              0        0   \n",
       "73264      0       0       0       0       0       0              0        1   \n",
       "73265      0       1       1       0       0       0              0        1   \n",
       "73266      0       0       0       0       0       0              0        0   \n",
       "\n",
       "                                                 MiscTech               \\\n",
       "      Ruby on Rails Svelte Symfony Vue.js jQuery     .NET Apache Kafka   \n",
       "2                 0      0       0      0      0        1            0   \n",
       "3                 0      0       0      0      0        1            0   \n",
       "9                 0      0       0      0      0        0            0   \n",
       "10                0      0       0      1      0        1            0   \n",
       "12                0      0       0      0      0        0            0   \n",
       "...             ...    ...     ...    ...    ...      ...          ...   \n",
       "73262             0      0       0      0      0        0            0   \n",
       "73263             0      0       0      0      0        0            0   \n",
       "73264             0      0       0      0      0        0            0   \n",
       "73265             0      1       0      0      0        1            0   \n",
       "73266             0      0       0      0      0        0            0   \n",
       "\n",
       "                                                                  \\\n",
       "      Apache Spark Capacitor Cordova Electron Flutter GTK Hadoop   \n",
       "2                0         0       0        0       0   0      0   \n",
       "3                0         0       0        0       0   0      0   \n",
       "9                0         0       0        0       0   0      0   \n",
       "10               0         0       0        0       0   0      0   \n",
       "12               0         0       0        0       0   0      0   \n",
       "...            ...       ...     ...      ...     ...  ..    ...   \n",
       "73262            0         0       0        0       0   0      0   \n",
       "73263            0         0       0        0       1   0      0   \n",
       "73264            0         0       0        0       0   0      0   \n",
       "73265            0         0       1        0       0   0      0   \n",
       "73266            0         0       0        0       0   0      0   \n",
       "\n",
       "                                                                          \\\n",
       "      Hugging Face Transformers Ionic Keras NumPy Pandas Qt React Native   \n",
       "2                             0     0     0     0      1  0            0   \n",
       "3                             0     0     0     0      0  0            0   \n",
       "9                             0     0     0     0      0  0            0   \n",
       "10                            0     0     0     0      0  0            0   \n",
       "12                            0     0     0     0      0  0            0   \n",
       "...                         ...   ...   ...   ...    ... ..          ...   \n",
       "73262                         0     0     0     0      0  0            0   \n",
       "73263                         0     0     0     0      0  0            0   \n",
       "73264                         1     0     1     1      1  0            0   \n",
       "73265                         0     1     0     0      1  0            1   \n",
       "73266                         0     0     0     0      0  0            0   \n",
       "\n",
       "                                                                           \\\n",
       "      Scikit-learn Spring TensorFlow Tidyverse Torch/PyTorch Uno Platform   \n",
       "2                0      0          0         0             0            0   \n",
       "3                0      0          0         0             0            0   \n",
       "9                0      0          0         0             0            0   \n",
       "10               0      0          0         0             0            0   \n",
       "12               0      0          0         0             1            0   \n",
       "...            ...    ...        ...       ...           ...          ...   \n",
       "73262            0      0          0         0             0            0   \n",
       "73263            0      0          0         0             0            0   \n",
       "73264            1      0          1         0             1            0   \n",
       "73265            0      0          0         0             0            0   \n",
       "73266            0      0          0         0             0            0   \n",
       "\n",
       "              ToolsTech                                                     \\\n",
       "      Xamarin   Ansible Chef Docker Flow Homebrew Kubernetes Pulumi Puppet   \n",
       "2           0         0    0      0    0        0          0      0      0   \n",
       "3           0         0    0      0    0        0          0      0      0   \n",
       "9           0         0    0      0    0        0          0      0      0   \n",
       "10          0         0    0      1    0        0          0      0      0   \n",
       "12          0         0    0      1    0        0          0      0      0   \n",
       "...       ...       ...  ...    ...  ...      ...        ...    ...    ...   \n",
       "73262       0         0    0      0    0        0          0      0      0   \n",
       "73263       0         0    0      1    0        1          1      0      0   \n",
       "73264       0         0    0      0    0        0          0      0      0   \n",
       "73265       1         0    0      0    0        0          0      0      0   \n",
       "73266       0         0    0      0    0        0          0      0      0   \n",
       "\n",
       "                                                   CollabTools             \\\n",
       "      Terraform Unity 3D Unreal Engine Yarn npm Android Studio Atom CLion   \n",
       "2             0        0             0    0   0              0    0     0   \n",
       "3             0        0             0    0   0              0    0     0   \n",
       "9             0        0             0    0   0              1    0     0   \n",
       "10            1        0             0    0   1              0    0     0   \n",
       "12            0        0             0    0   0              0    0     0   \n",
       "...         ...      ...           ...  ...  ..            ...  ...   ...   \n",
       "73262         0        0             0    0   1              1    0     0   \n",
       "73263         0        0             0    0   1              0    0     0   \n",
       "73264         0        0             0    0   0              0    0     0   \n",
       "73265         0        0             1    0   1              0    0     0   \n",
       "73266         0        0             0    0   0              0    0     0   \n",
       "\n",
       "                                                                          \\\n",
       "      Eclipse Emacs GoLand IPython/Jupyter IntelliJ Nano Neovim NetBeans   \n",
       "2           0     0      0               0        0    0      0        0   \n",
       "3           0     0      0               0        0    0      0        0   \n",
       "9           0     0      0               0        0    0      0        0   \n",
       "10          0     0      0               0        0    0      0        0   \n",
       "12          0     0      0               0        0    0      0        0   \n",
       "...       ...   ...    ...             ...      ...  ...    ...      ...   \n",
       "73262       1     0      0               0        0    0      0        0   \n",
       "73263       0     0      0               1        0    0      0        0   \n",
       "73264       0     0      0               1        0    0      0        0   \n",
       "73265       0     0      0               0        0    0      0        0   \n",
       "73266       0     0      0               0        0    0      0        0   \n",
       "\n",
       "                                                                              \\\n",
       "      Notepad++ PhpStorm PyCharm Qt Creator RAD Studio (Delphi, C++ Builder)   \n",
       "2             1        0       0          0                                0   \n",
       "3             1        0       0          0                                0   \n",
       "9             0        0       0          0                                1   \n",
       "10            0        0       0          0                                0   \n",
       "12            0        0       0          0                                0   \n",
       "...         ...      ...     ...        ...                              ...   \n",
       "73262         0        0       0          0                                0   \n",
       "73263         0        0       0          0                                0   \n",
       "73264         1        0       0          0                                0   \n",
       "73265         0        0       0          0                                0   \n",
       "73266         0        0       0          0                                1   \n",
       "\n",
       "                                                                             \\\n",
       "      RStudio Rider RubyMine Spyder Sublime Text TextMate Vim Visual Studio   \n",
       "2           0     0        0      0            0        0   0             1   \n",
       "3           0     0        0      0            0        0   0             1   \n",
       "9           0     0        0      0            0        0   0             0   \n",
       "10          0     1        0      0            0        0   0             1   \n",
       "12          0     0        0      0            0        0   1             1   \n",
       "...       ...   ...      ...    ...          ...      ...  ..           ...   \n",
       "73262       0     0        0      0            0        0   0             0   \n",
       "73263       0     0        0      0            1        0   1             0   \n",
       "73264       0     0        0      1            0        0   1             0   \n",
       "73265       0     0        0      1            0        0   0             1   \n",
       "73266       0     0        0      0            0        0   0             1   \n",
       "\n",
       "                                        Skills_Clusters                 \\\n",
       "      Visual Studio Code Webstorm Xcode  skills_group_0 skills_group_1   \n",
       "2                      0        0     0               1              0   \n",
       "3                      1        0     0               0              0   \n",
       "9                      1        0     1               0              0   \n",
       "10                     1        0     0               0              0   \n",
       "12                     0        0     0               1              0   \n",
       "...                  ...      ...   ...             ...            ...   \n",
       "73262                  1        0     0               0              0   \n",
       "73263                  1        0     0               1              2   \n",
       "73264                  1        0     0               9              0   \n",
       "73265                  1        0     0               2              4   \n",
       "73266                  0        0     0               0              0   \n",
       "\n",
       "                                                                       \\\n",
       "      skills_group_10 skills_group_11 skills_group_12 skills_group_13   \n",
       "2                   0               3               0               1   \n",
       "3                   0               3               0               0   \n",
       "9                   0               1               2               0   \n",
       "10                  0               4               0               0   \n",
       "12                  0               3               1               1   \n",
       "...               ...             ...             ...             ...   \n",
       "73262               0               3               0               3   \n",
       "73263               0               4               1               0   \n",
       "73264               1               4               0               0   \n",
       "73265               0               5               0               0   \n",
       "73266               1               0               0               0   \n",
       "\n",
       "                                                                       \\\n",
       "      skills_group_14 skills_group_15 skills_group_16 skills_group_17   \n",
       "2                   1               0               0               0   \n",
       "3                   1               0               0               0   \n",
       "9                   1               0               0               0   \n",
       "10                  3               0               0               0   \n",
       "12                  2               1               0               1   \n",
       "...               ...             ...             ...             ...   \n",
       "73262               1               0               1               0   \n",
       "73263               3               0               1               0   \n",
       "73264               1               0               0               0   \n",
       "73265               1               0               0               0   \n",
       "73266               0               0               0               0   \n",
       "\n",
       "                                                                      \\\n",
       "      skills_group_18 skills_group_19 skills_group_2 skills_group_20   \n",
       "2                   0               0              0               0   \n",
       "3                   0               0              0               0   \n",
       "9                   0               0              0               0   \n",
       "10                  0               0              0               0   \n",
       "12                  0               0              0               0   \n",
       "...               ...             ...            ...             ...   \n",
       "73262               0               0              0               0   \n",
       "73263               0               0              0               0   \n",
       "73264               0               0              1               0   \n",
       "73265               1               2              0               1   \n",
       "73266               0               0              0               0   \n",
       "\n",
       "                                                                       \\\n",
       "      skills_group_21 skills_group_22 skills_group_23 skills_group_24   \n",
       "2                   0               0               0               1   \n",
       "3                   0               0               0               0   \n",
       "9                   2               0               0               0   \n",
       "10                  0               0               1               0   \n",
       "12                  0               0               1               0   \n",
       "...               ...             ...             ...             ...   \n",
       "73262               0               0               0               0   \n",
       "73263               0               0               2               2   \n",
       "73264               0               0               0               3   \n",
       "73265               0               0               0               1   \n",
       "73266               3               0               0               0   \n",
       "\n",
       "                                                                       \\\n",
       "      skills_group_25 skills_group_26 skills_group_27 skills_group_28   \n",
       "2                   0               0               0               0   \n",
       "3                   0               0               0               0   \n",
       "9                   0               1               0               0   \n",
       "10                  0               0               0               0   \n",
       "12                  0               0               0               0   \n",
       "...               ...             ...             ...             ...   \n",
       "73262               0               0               0               1   \n",
       "73263               0               1               0               2   \n",
       "73264               0               0               0               1   \n",
       "73265               1               1               0               1   \n",
       "73266               0               0               0               1   \n",
       "\n",
       "                                                                      \\\n",
       "      skills_group_29 skills_group_3 skills_group_30 skills_group_31   \n",
       "2                   0              0               0               0   \n",
       "3                   0              0               0               0   \n",
       "9                   1              0               0               1   \n",
       "10                  0              0               0               0   \n",
       "12                  0              0               0               0   \n",
       "...               ...            ...             ...             ...   \n",
       "73262               1              0               0               0   \n",
       "73263               0              0               0               0   \n",
       "73264               0              0               0               0   \n",
       "73265               0              2               0               1   \n",
       "73266               0              0               0               0   \n",
       "\n",
       "                                                                       \\\n",
       "      skills_group_32 skills_group_33 skills_group_34 skills_group_35   \n",
       "2                   0               0               2               0   \n",
       "3                   0               0               0               0   \n",
       "9                   0               0               0               0   \n",
       "10                  1               1               0               0   \n",
       "12                  0               1               0               3   \n",
       "...               ...             ...             ...             ...   \n",
       "73262               0               0               0               0   \n",
       "73263               0               2               0               3   \n",
       "73264               0               2               0               1   \n",
       "73265               0               0               0               1   \n",
       "73266               0               0               0               0   \n",
       "\n",
       "                                                                     \\\n",
       "      skills_group_36 skills_group_37 skills_group_4 skills_group_5   \n",
       "2                   0               0              3              2   \n",
       "3                   0               0              5              3   \n",
       "9                   0               0              0              0   \n",
       "10                  0               1              7              4   \n",
       "12                  0               0              1              1   \n",
       "...               ...             ...            ...            ...   \n",
       "73262               0               0              0              0   \n",
       "73263               0               1              0              1   \n",
       "73264               0               0              0              2   \n",
       "73265               0               0              7              3   \n",
       "73266               0               0              2              2   \n",
       "\n",
       "                                                                   \n",
       "      skills_group_6 skills_group_7 skills_group_8 skills_group_9  \n",
       "2                  0              0              0              0  \n",
       "3                  0              0              0              0  \n",
       "9                  0              1              0              0  \n",
       "10                 0              0              0              0  \n",
       "12                 0              0              0              0  \n",
       "...              ...            ...            ...            ...  \n",
       "73262              0              1              0              0  \n",
       "73263              0              2              0              0  \n",
       "73264              0              1              0              0  \n",
       "73265              0              1              0              0  \n",
       "73266              0              0              0              0  \n",
       "\n",
       "[42246 rows x 221 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "456e9c3f-1dd0-4f03-bcba-702746ff49aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = df.drop(df[TECH_JOBS],axis = 1).droplevel(0,axis=1).copy()\n",
    "y = df[TECH_JOBS]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc54c52e-8d70-4e11-8df4-f99ae2e240ce",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Deal with Imbalanced Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c84cf9-bd58-4304-8fdf-a19f3e7eb66e",
   "metadata": {},
   "source": [
    "- **To deal with imbalance, I tried different methods to see which one performs the best**\n",
    "    - **SMOTE by converting the Dataset to multiclass instead of mutilabel by taking rows that have only 1 value.**\n",
    "    - **Using random sample method by pandas that returns random samples to try to balance the dataset.** `Best Performer`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3140f1f3-55ed-4312-ad5a-a4286fef3a6f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1.Random Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4fa103c3-c6e1-4c70-9ffb-8bafae3118d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a dataframes contains rows with only one job per row\n",
    "one_job_df = y[y['Techjobs'].sum(axis=1) ==1].droplevel(0,axis=1)\n",
    "# Create a dataframes contains rows with only multiple job per row\n",
    "multi_job_df = y[y['Techjobs'].sum(axis=1) !=1].droplevel(0,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d67f79b-d05c-42d8-bd03-3791793254b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Blockchain', 'Database administrator', 'Scientist',\n",
       "       'Security professional', 'Cloud infrastructure engineer',\n",
       "       'Developer, game or graphics', 'System administrator',\n",
       "       'DevOps specialist', 'Data or business analyst',\n",
       "       'Developer, QA or test', 'Engineer, data', 'Academic researcher',\n",
       "       'Data scientist or machine learning specialist',\n",
       "       'Developer, embedded applications or devices',\n",
       "       'Developer, desktop or enterprise applications', 'Developer, mobile',\n",
       "       'Developer, front-end', 'Developer, back-end', 'Developer, full-stack'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a list of labels sorted in ascending order\n",
    "jobs = one_job_df.sum(axis=0).sort_values().index\n",
    "jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de4b314b-4fd5-4d59-89f6-3313e4e78ef5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# oversample the minority classes from the multi_job dataframe\n",
    "# downsample the majority classes if they are above the threshold number.\n",
    "samples_per_class = 800\n",
    "resampled_jobs = []\n",
    "\n",
    "for job in jobs:\n",
    "    #get the one job rows of this class\n",
    "    sub_df = one_job_df.loc[one_job_df[job] == 1].copy()\n",
    "    \n",
    "    # if no. of sub_df < threshold\n",
    "    if len(sub_df) < samples_per_class:\n",
    "        # get multi_job rows of this class \n",
    "        temp_df = multi_job_df.loc[multi_job_df[job] ==1].copy()\n",
    "        # oversample no. of rows from multi_job df\n",
    "        no_rows = min(samples_per_class - len(sub_df), len(temp_df))\n",
    "        temp_df = temp_df.sample(no_rows,random_state=42)\n",
    "        # merge both dfs\n",
    "        sub_df = pd.concat([sub_df,temp_df])\n",
    "        \n",
    "    else:\n",
    "        #if no. of sub_df > threshold, down sample this class\n",
    "        sub_df = sub_df.sample(samples_per_class, random_state=42) \n",
    "    \n",
    "    resampled_jobs.append(sub_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb462083-4488-4c54-a46f-9d26ef054d11",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Blockchain                                        651\n",
       "Security professional                             728\n",
       "Developer, game or graphics                       870\n",
       "Developer, QA or test                             928\n",
       "Database administrator                           1056\n",
       "Developer, embedded applications or devices      1060\n",
       "Scientist                                        1104\n",
       "Data or business analyst                         1116\n",
       "Developer, mobile                                1120\n",
       "Developer, front-end                             1174\n",
       "Engineer, data                                   1194\n",
       "System administrator                             1248\n",
       "Cloud infrastructure engineer                    1294\n",
       "DevOps specialist                                1385\n",
       "Data scientist or machine learning specialist    1425\n",
       "Academic researcher                              1451\n",
       "Developer, desktop or enterprise applications    1465\n",
       "Developer, full-stack                            2707\n",
       "Developer, back-end                              2940\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.concat(resampled_jobs)\n",
    "X = X.loc[y.index].copy()\n",
    "y.sum(axis=0).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b97ec1d2-c21a-4642-9c4b-b40c5851da82",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14761"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641ed3a9-09f3-4e22-ac2d-eeb6d5f92165",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2- MultiClass with SMOTE"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2dc7da9e-a3d1-477c-8ced-4449b939f14d",
   "metadata": {
    "tags": []
   },
   "source": [
    "one_job_df = df[df['Techjobs'].sum(axis=1) ==1]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3853fcdd-21b4-4dee-8a22-3f4200a167d7",
   "metadata": {
    "tags": []
   },
   "source": [
    "one_job_df[TECH_JOBS].sum(axis=0).sort_values()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b1be3b91-e571-488b-b0b0-3f89a9cc4910",
   "metadata": {
    "tags": []
   },
   "source": [
    "X = one_job_df.drop(one_job_df[TECH_JOBS],axis = 1).droplevel(0,axis=1).reset_index(drop=True)\n",
    "y = one_job_df[TECH_JOBS].droplevel(0,axis = 1).copy()\n",
    "y = pd.from_dummies(y)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "51b1312a-e0fd-4bec-b5c7-589150d6d09b",
   "metadata": {
    "tags": []
   },
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "# Create StratifiedKFold object.\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    x_train, x_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7320a1cd-8f26-433f-8bcd-acae093329fc",
   "metadata": {
    "tags": []
   },
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6227e701-ac01-45c3-b7b7-b2b3a5286faf",
   "metadata": {
    "tags": []
   },
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dfa26f32-d5bc-4936-8f6c-1fa5d6438515",
   "metadata": {
    "tags": []
   },
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "over = SMOTE(random_state=42, k_neighbors=5)\n",
    "under= RandomUnderSampler(random_state=42 ,sampling_strategy={'Developer, full-stack':1000,'Developer, back-end':1000,'Developer, front-end':1000,'Developer, mobile':1000})\n",
    "x_under, y_under= under.fit_resample(x_train, y_train)\n",
    "x_over, y_over = over.fit_resample(x_under, y_under)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "affadf2e-6a21-47f8-9c6b-0ca3aa74bd1e",
   "metadata": {
    "tags": []
   },
   "source": [
    "y_over.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a30631-6b78-4cc6-b7e0-8c7cd57ea6e4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create a Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2db8d87a-188d-4ceb-b204-495cd85ad7cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert dfs to arrays\n",
    "y_array = y.values\n",
    "x_array = X.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8941723-2216-4bec-a042-09336d3a6306",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split the dataset using stratified split using iterative_train_test_split\n",
    "from skmultilearn.model_selection import iterative_train_test_split\n",
    "x_train, y_train, x_test, y_test = iterative_train_test_split(x_array, y_array, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1df2e7f4-31ae-4755-a05f-042ad13918e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Convert back to dfs\n",
    "y_train = pd.DataFrame(y_train,columns=y.columns)\n",
    "y_test = pd.DataFrame(y_test,columns=y.columns)\n",
    "x_train = pd.DataFrame(x_train,columns=X.columns)\n",
    "x_test = pd.DataFrame(x_test,columns=X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f7d168-c648-4a29-a9d9-4e56a951ebe2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Intialize MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a0716b2-2897-4136-acd0-8c39e16d4fcf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create Directories\n",
    "Path(MLFLOW_TRACKING_URI).mkdir(parents=True, exist_ok=True)\n",
    "Path(LOG_PATH).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2acd1b21-0876-4bf8-9d0c-4e3f795a9226",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize client and experiment\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "client = MlflowClient()\n",
    "mlflow.set_experiment(MLFLOW_EXPERIMENT_NAME)\n",
    "exp = client.get_experiment_by_name(MLFLOW_EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413ed77a-59a6-4187-927c-ffc4bd28497f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create a Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c2b0d967-8f29-41df-b4a2-06f57582e5a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),\n",
       "                (&#x27;multioutputclassifier&#x27;,\n",
       "                 MultiOutputClassifier(estimator=LogisticRegression(max_iter=1000)))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),\n",
       "                (&#x27;multioutputclassifier&#x27;,\n",
       "                 MultiOutputClassifier(estimator=LogisticRegression(max_iter=1000)))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">multioutputclassifier: MultiOutputClassifier</label><div class=\"sk-toggleable__content\"><pre>MultiOutputClassifier(estimator=LogisticRegression(max_iter=1000))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('multioutputclassifier',\n",
       "                 MultiOutputClassifier(estimator=LogisticRegression(max_iter=1000)))])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a Logistic Regression Classifier, Used StandardScaler because logistic Regression uses l2 regression by default\n",
    "log_clf = make_pipeline(StandardScaler(),\n",
    "                    MultiOutputClassifier(LogisticRegression(max_iter=1000)))\n",
    "log_clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe68e04-4f72-4085-a57a-bb7060d2e475",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Evaluating the multilabel dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "959e35f5-e1a0-4868-b954-58b9c1ee6f07",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score     92.453158\n",
      "precision_score    79.076316\n",
      "recall_score       63.610000\n",
      "f1_score           66.825263\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Developer, full-stack</th>\n",
       "      <td>83.03</td>\n",
       "      <td>71.44</td>\n",
       "      <td>62.03</td>\n",
       "      <td>64.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Database administrator</th>\n",
       "      <td>92.88</td>\n",
       "      <td>72.26</td>\n",
       "      <td>52.03</td>\n",
       "      <td>52.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, QA or test</th>\n",
       "      <td>93.74</td>\n",
       "      <td>72.91</td>\n",
       "      <td>50.82</td>\n",
       "      <td>50.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, back-end</th>\n",
       "      <td>82.55</td>\n",
       "      <td>74.26</td>\n",
       "      <td>61.84</td>\n",
       "      <td>64.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cloud infrastructure engineer</th>\n",
       "      <td>91.79</td>\n",
       "      <td>75.04</td>\n",
       "      <td>61.65</td>\n",
       "      <td>65.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Security professional</th>\n",
       "      <td>95.13</td>\n",
       "      <td>76.57</td>\n",
       "      <td>51.82</td>\n",
       "      <td>52.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data or business analyst</th>\n",
       "      <td>92.98</td>\n",
       "      <td>76.82</td>\n",
       "      <td>60.05</td>\n",
       "      <td>63.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Engineer, data</th>\n",
       "      <td>92.56</td>\n",
       "      <td>77.69</td>\n",
       "      <td>59.61</td>\n",
       "      <td>63.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>System administrator</th>\n",
       "      <td>92.17</td>\n",
       "      <td>78.02</td>\n",
       "      <td>58.06</td>\n",
       "      <td>61.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, desktop or enterprise applications</th>\n",
       "      <td>91.24</td>\n",
       "      <td>78.87</td>\n",
       "      <td>61.46</td>\n",
       "      <td>65.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scientist</th>\n",
       "      <td>93.38</td>\n",
       "      <td>79.19</td>\n",
       "      <td>62.17</td>\n",
       "      <td>66.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Academic researcher</th>\n",
       "      <td>91.79</td>\n",
       "      <td>80.13</td>\n",
       "      <td>65.09</td>\n",
       "      <td>69.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DevOps specialist</th>\n",
       "      <td>92.34</td>\n",
       "      <td>80.76</td>\n",
       "      <td>66.31</td>\n",
       "      <td>70.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, embedded applications or devices</th>\n",
       "      <td>94.34</td>\n",
       "      <td>81.82</td>\n",
       "      <td>68.98</td>\n",
       "      <td>73.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data scientist or machine learning specialist</th>\n",
       "      <td>93.09</td>\n",
       "      <td>82.19</td>\n",
       "      <td>73.96</td>\n",
       "      <td>77.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blockchain</th>\n",
       "      <td>96.28</td>\n",
       "      <td>82.65</td>\n",
       "      <td>64.09</td>\n",
       "      <td>69.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, game or graphics</th>\n",
       "      <td>95.45</td>\n",
       "      <td>83.90</td>\n",
       "      <td>68.35</td>\n",
       "      <td>73.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, front-end</th>\n",
       "      <td>94.60</td>\n",
       "      <td>85.32</td>\n",
       "      <td>73.27</td>\n",
       "      <td>77.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, mobile</th>\n",
       "      <td>97.27</td>\n",
       "      <td>92.61</td>\n",
       "      <td>87.00</td>\n",
       "      <td>89.57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               accuracy_score  \\\n",
       "Developer, full-stack                                   83.03   \n",
       "Database administrator                                  92.88   \n",
       "Developer, QA or test                                   93.74   \n",
       "Developer, back-end                                     82.55   \n",
       "Cloud infrastructure engineer                           91.79   \n",
       "Security professional                                   95.13   \n",
       "Data or business analyst                                92.98   \n",
       "Engineer, data                                          92.56   \n",
       "System administrator                                    92.17   \n",
       "Developer, desktop or enterprise applications           91.24   \n",
       "Scientist                                               93.38   \n",
       "Academic researcher                                     91.79   \n",
       "DevOps specialist                                       92.34   \n",
       "Developer, embedded applications or devices             94.34   \n",
       "Data scientist or machine learning specialist           93.09   \n",
       "Blockchain                                              96.28   \n",
       "Developer, game or graphics                             95.45   \n",
       "Developer, front-end                                    94.60   \n",
       "Developer, mobile                                       97.27   \n",
       "\n",
       "                                               precision_score  recall_score  \\\n",
       "Developer, full-stack                                    71.44         62.03   \n",
       "Database administrator                                   72.26         52.03   \n",
       "Developer, QA or test                                    72.91         50.82   \n",
       "Developer, back-end                                      74.26         61.84   \n",
       "Cloud infrastructure engineer                            75.04         61.65   \n",
       "Security professional                                    76.57         51.82   \n",
       "Data or business analyst                                 76.82         60.05   \n",
       "Engineer, data                                           77.69         59.61   \n",
       "System administrator                                     78.02         58.06   \n",
       "Developer, desktop or enterprise applications            78.87         61.46   \n",
       "Scientist                                                79.19         62.17   \n",
       "Academic researcher                                      80.13         65.09   \n",
       "DevOps specialist                                        80.76         66.31   \n",
       "Developer, embedded applications or devices              81.82         68.98   \n",
       "Data scientist or machine learning specialist            82.19         73.96   \n",
       "Blockchain                                               82.65         64.09   \n",
       "Developer, game or graphics                              83.90         68.35   \n",
       "Developer, front-end                                     85.32         73.27   \n",
       "Developer, mobile                                        92.61         87.00   \n",
       "\n",
       "                                               f1_score  \n",
       "Developer, full-stack                             64.28  \n",
       "Database administrator                            52.18  \n",
       "Developer, QA or test                             50.08  \n",
       "Developer, back-end                               64.16  \n",
       "Cloud infrastructure engineer                     65.23  \n",
       "Security professional                             52.30  \n",
       "Data or business analyst                          63.84  \n",
       "Engineer, data                                    63.34  \n",
       "System administrator                              61.35  \n",
       "Developer, desktop or enterprise applications     65.38  \n",
       "Scientist                                         66.49  \n",
       "Academic researcher                               69.41  \n",
       "DevOps specialist                                 70.73  \n",
       "Developer, embedded applications or devices       73.46  \n",
       "Data scientist or machine learning specialist     77.29  \n",
       "Blockchain                                        69.31  \n",
       "Developer, game or graphics                       73.48  \n",
       "Developer, front-end                              77.80  \n",
       "Developer, mobile                                 89.57  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics=[accuracy_score, precision_score, recall_score, f1_score]\n",
    "train_scores, mean_train_score= calculate_metrics(log_clf,x_train,y_train, metrics)\n",
    "\n",
    "print(mean_train_score)\n",
    "train_scores.sort_values(\"precision_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "23983855-a229-4a85-8725-9d7fa2587e53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cross_validate the baseline model on the accuracy, precision, recall and f1\n",
    "log_clf_scores = cross_validate(log_clf,x_train,y_train, cv=3, scoring =calculate_scores_multi_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4c0d23c7-0449-454a-b182-db0bf71ba15e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_accuracy': 90.5,\n",
       " 'test_precision': 66.03,\n",
       " 'test_recall': 61.0,\n",
       " 'test_f1': 58.93}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = ['test_accuracy', 'test_precision','test_recall', 'test_f1']\n",
    "validation_scores = {}\n",
    "for score in scores:\n",
    "    validation_scores[score] = round(log_clf_scores[score].mean(), 2)\n",
    "validation_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7d4998-4a31-42f9-b82c-e6135b04bb99",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Evaluating the multiclass Dataset"
   ]
  },
  {
   "cell_type": "raw",
   "id": "30636f5f-d84e-4d42-8279-c39497262d98",
   "metadata": {
    "tags": []
   },
   "source": [
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_train, predictions))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9b72fdc8-8fcb-4e68-8ccb-a60dade5c1a9",
   "metadata": {
    "tags": []
   },
   "source": [
    "y_train_pred = cross_val_predict(log_clf, x_train, y_train, cv=3)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "279c5eef-2fa9-4fa2-8de3-944a6c7212db",
   "metadata": {
    "tags": []
   },
   "source": [
    "fig, ax = plt.subplots(figsize=(15,10))\n",
    "cmp = ConfusionMatrixDisplay.from_predictions(y_train, predictions,normalize=\"true\", values_format=\".0%\",xticks_rotation=90,ax=ax)\n",
    "plt.rc('font', size=12)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "21c7c373-7f3d-4ae9-8c28-f52980f24f97",
   "metadata": {
    "tags": []
   },
   "source": [
    "# cross_validate the baseline model on the accuracy, precision, recall and f1\n",
    "log_clf_scores = cross_validate(log_clf,x_train,y_train, cv=4, scoring =calculate_scores)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b85f82cb-cc12-42db-8351-9f0b93efd876",
   "metadata": {
    "tags": []
   },
   "source": [
    "scores = ['test_accuracy', 'test_precision','test_recall', 'test_f1']\n",
    "validation_scores = {}\n",
    "for score in scores:\n",
    "    validation_scores[score] = round(log_clf_scores[score].mean()* 100, 2)\n",
    "validation_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11fcaa54-0d6c-435d-adf6-1a66e27a3821",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Log Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "78296fa5-7917-42a4-b861-6317d618932d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Log the model's dataset train and test indices\n",
    "log_data(x_train,y_train,x_test,y_test)\n",
    "# Log the model, model description\n",
    "model = log_model(log_clf,'Baseline model: Logistic Regression, multilabel, Data Resampled ')\n",
    "# Log the model's train and test scores\n",
    "log_metrics(train_scores, validation_scores)\n",
    "# track the model artifacts, validation scores with mlflow\n",
    "track_model(model,validation_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a089c091-e3b4-4e85-bd03-a44b42df1992",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c3313a9a-bd04-4a95-bbb7-13a1fdadb8a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    2.8s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;randomforestclassifier&#x27;,\n",
       "                 RandomForestClassifier(n_jobs=-1, random_state=42,\n",
       "                                        verbose=1))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;randomforestclassifier&#x27;,\n",
       "                 RandomForestClassifier(n_jobs=-1, random_state=42,\n",
       "                                        verbose=1))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_jobs=-1, random_state=42, verbose=1)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('randomforestclassifier',\n",
       "                 RandomForestClassifier(n_jobs=-1, random_state=42,\n",
       "                                        verbose=1))])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a random forest classifier\n",
    "rf_clf = make_pipeline(#StandardScaler(),\n",
    "                       #PCA(n_components=0.95),\n",
    "                       RandomForestClassifier(n_jobs=-1,\n",
    "                                              verbose=1,\n",
    "                                              random_state=42))\n",
    "\n",
    "rf_clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73083653-d9c9-4c55-9ca0-c5e769eaf8d8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Evaluating the multilabel dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9a2b367d-d343-4072-85f4-180025ef02a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score     99.990526\n",
      "precision_score    99.994737\n",
      "recall_score       99.952105\n",
      "f1_score           99.972632\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Developer, desktop or enterprise applications</th>\n",
       "      <td>99.97</td>\n",
       "      <td>99.95</td>\n",
       "      <td>99.91</td>\n",
       "      <td>99.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, full-stack</th>\n",
       "      <td>99.97</td>\n",
       "      <td>99.98</td>\n",
       "      <td>99.93</td>\n",
       "      <td>99.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, back-end</th>\n",
       "      <td>99.99</td>\n",
       "      <td>99.99</td>\n",
       "      <td>99.98</td>\n",
       "      <td>99.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Database administrator</th>\n",
       "      <td>99.97</td>\n",
       "      <td>99.99</td>\n",
       "      <td>99.82</td>\n",
       "      <td>99.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, game or graphics</th>\n",
       "      <td>99.98</td>\n",
       "      <td>99.99</td>\n",
       "      <td>99.86</td>\n",
       "      <td>99.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data scientist or machine learning specialist</th>\n",
       "      <td>99.99</td>\n",
       "      <td>100.00</td>\n",
       "      <td>99.96</td>\n",
       "      <td>99.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blockchain</th>\n",
       "      <td>99.99</td>\n",
       "      <td>100.00</td>\n",
       "      <td>99.90</td>\n",
       "      <td>99.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, front-end</th>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Security professional</th>\n",
       "      <td>99.99</td>\n",
       "      <td>100.00</td>\n",
       "      <td>99.91</td>\n",
       "      <td>99.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scientist</th>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, QA or test</th>\n",
       "      <td>99.99</td>\n",
       "      <td>100.00</td>\n",
       "      <td>99.93</td>\n",
       "      <td>99.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DevOps specialist</th>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, embedded applications or devices</th>\n",
       "      <td>99.99</td>\n",
       "      <td>100.00</td>\n",
       "      <td>99.94</td>\n",
       "      <td>99.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cloud infrastructure engineer</th>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, mobile</th>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data or business analyst</th>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Engineer, data</th>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>System administrator</th>\n",
       "      <td>99.99</td>\n",
       "      <td>100.00</td>\n",
       "      <td>99.95</td>\n",
       "      <td>99.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Academic researcher</th>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               accuracy_score  \\\n",
       "Developer, desktop or enterprise applications           99.97   \n",
       "Developer, full-stack                                   99.97   \n",
       "Developer, back-end                                     99.99   \n",
       "Database administrator                                  99.97   \n",
       "Developer, game or graphics                             99.98   \n",
       "Data scientist or machine learning specialist           99.99   \n",
       "Blockchain                                              99.99   \n",
       "Developer, front-end                                   100.00   \n",
       "Security professional                                   99.99   \n",
       "Scientist                                              100.00   \n",
       "Developer, QA or test                                   99.99   \n",
       "DevOps specialist                                      100.00   \n",
       "Developer, embedded applications or devices             99.99   \n",
       "Cloud infrastructure engineer                          100.00   \n",
       "Developer, mobile                                      100.00   \n",
       "Data or business analyst                               100.00   \n",
       "Engineer, data                                         100.00   \n",
       "System administrator                                    99.99   \n",
       "Academic researcher                                    100.00   \n",
       "\n",
       "                                               precision_score  recall_score  \\\n",
       "Developer, desktop or enterprise applications            99.95         99.91   \n",
       "Developer, full-stack                                    99.98         99.93   \n",
       "Developer, back-end                                      99.99         99.98   \n",
       "Database administrator                                   99.99         99.82   \n",
       "Developer, game or graphics                              99.99         99.86   \n",
       "Data scientist or machine learning specialist           100.00         99.96   \n",
       "Blockchain                                              100.00         99.90   \n",
       "Developer, front-end                                    100.00        100.00   \n",
       "Security professional                                   100.00         99.91   \n",
       "Scientist                                               100.00        100.00   \n",
       "Developer, QA or test                                   100.00         99.93   \n",
       "DevOps specialist                                       100.00        100.00   \n",
       "Developer, embedded applications or devices             100.00         99.94   \n",
       "Cloud infrastructure engineer                           100.00        100.00   \n",
       "Developer, mobile                                       100.00        100.00   \n",
       "Data or business analyst                                100.00        100.00   \n",
       "Engineer, data                                          100.00        100.00   \n",
       "System administrator                                    100.00         99.95   \n",
       "Academic researcher                                     100.00        100.00   \n",
       "\n",
       "                                               f1_score  \n",
       "Developer, desktop or enterprise applications     99.93  \n",
       "Developer, full-stack                             99.96  \n",
       "Developer, back-end                               99.99  \n",
       "Database administrator                            99.90  \n",
       "Developer, game or graphics                       99.92  \n",
       "Data scientist or machine learning specialist     99.98  \n",
       "Blockchain                                        99.95  \n",
       "Developer, front-end                             100.00  \n",
       "Security professional                             99.95  \n",
       "Scientist                                        100.00  \n",
       "Developer, QA or test                             99.96  \n",
       "DevOps specialist                                100.00  \n",
       "Developer, embedded applications or devices       99.97  \n",
       "Cloud infrastructure engineer                    100.00  \n",
       "Developer, mobile                                100.00  \n",
       "Data or business analyst                         100.00  \n",
       "Engineer, data                                   100.00  \n",
       "System administrator                              99.97  \n",
       "Academic researcher                              100.00  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics=[accuracy_score, precision_score, recall_score, f1_score]\n",
    "train_scores, mean_train_scores= calculate_metrics(rf_clf,x_train,y_train, metrics)\n",
    "\n",
    "print(mean_train_scores)\n",
    "train_scores.sort_values(\"precision_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7ea7fa2d-d319-43c9-8d58-51211e882d96",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    4.5s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.3s finished\n"
     ]
    }
   ],
   "source": [
    "# cross_validate the baseline model on the accuracy, precision, recall and f1\n",
    "rf_clf_scores = cross_validate(rf_clf,x_train,y_train, cv=3, scoring =calculate_scores_multi_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "60f412cd-13b9-49c5-bb6c-e2d926035f79",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_accuracy': 91.8,\n",
       " 'test_precision': 80.84,\n",
       " 'test_recall': 66.31,\n",
       " 'test_f1': 65.28}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = ['test_accuracy', 'test_precision','test_recall', 'test_f1']\n",
    "validation_scores = {}\n",
    "for score in scores:\n",
    "    validation_scores[score] = round(rf_clf_scores[score].mean(), 2)\n",
    "validation_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab07fc61-8005-4f78-bdb0-12b1a770d6ca",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Evaluating the multiclass Dataset"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1cc8faeb-89a4-4fef-980c-1bf2e25bb79b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# cross_validate the baseline model on the accuracy, precision, recall and f1\n",
    "rf_clf_scores = cross_validate(rf_clf,x_train,y_train, cv=4, scoring =calculate_scores)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "489d7fda-b338-42f9-8a1c-3dd1f35ca242",
   "metadata": {
    "tags": []
   },
   "source": [
    "scores = ['test_accuracy', 'test_precision','test_recall', 'test_f1']\n",
    "validation_scores = {}\n",
    "for score in scores:\n",
    "    validation_scores[score] = round(rf_clf_scores[score].mean()* 100, 2)\n",
    "validation_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08be589a-56b8-4afb-85cc-f6a099f27aee",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Log RandomForest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "faecb94d-80e5-4c33-b189-d8133ee5bfa6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Log the model's dataset train and test indices\n",
    "log_data(x_train,y_train,x_test,y_test)\n",
    "# Log the model, model description\n",
    "model = log_model(rf_clf,'Random Forest, multilabel, Data resampled')\n",
    "# Log the model's train and test scores\n",
    "log_metrics(train_scores, validation_scores)\n",
    "# track the model artifacts, validation scores with mlflow\n",
    "track_model(model,validation_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6286b3d5-58e6-4cd9-a89a-942400bd0bbe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(random_state=42)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dec_clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "dec_clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8872ee16-c43c-4aca-be72-be55ab63b099",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Evaluating the multilabel dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1285304f-64ad-444f-a587-3372c61f0f96",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score     99.997368\n",
      "precision_score    99.995263\n",
      "recall_score       99.990526\n",
      "f1_score           99.992105\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Security professional</th>\n",
       "      <td>99.99</td>\n",
       "      <td>99.93</td>\n",
       "      <td>100.00</td>\n",
       "      <td>99.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, desktop or enterprise applications</th>\n",
       "      <td>99.99</td>\n",
       "      <td>99.99</td>\n",
       "      <td>99.97</td>\n",
       "      <td>99.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, back-end</th>\n",
       "      <td>99.99</td>\n",
       "      <td>99.99</td>\n",
       "      <td>99.99</td>\n",
       "      <td>99.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data scientist or machine learning specialist</th>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blockchain</th>\n",
       "      <td>99.99</td>\n",
       "      <td>100.00</td>\n",
       "      <td>99.93</td>\n",
       "      <td>99.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, front-end</th>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, game or graphics</th>\n",
       "      <td>99.99</td>\n",
       "      <td>100.00</td>\n",
       "      <td>99.93</td>\n",
       "      <td>99.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scientist</th>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>System administrator</th>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, QA or test</th>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, embedded applications or devices</th>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cloud infrastructure engineer</th>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, full-stack</th>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, mobile</th>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Database administrator</th>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data or business analyst</th>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Engineer, data</th>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DevOps specialist</th>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Academic researcher</th>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               accuracy_score  \\\n",
       "Security professional                                   99.99   \n",
       "Developer, desktop or enterprise applications           99.99   \n",
       "Developer, back-end                                     99.99   \n",
       "Data scientist or machine learning specialist          100.00   \n",
       "Blockchain                                              99.99   \n",
       "Developer, front-end                                   100.00   \n",
       "Developer, game or graphics                             99.99   \n",
       "Scientist                                              100.00   \n",
       "System administrator                                   100.00   \n",
       "Developer, QA or test                                  100.00   \n",
       "Developer, embedded applications or devices            100.00   \n",
       "Cloud infrastructure engineer                          100.00   \n",
       "Developer, full-stack                                  100.00   \n",
       "Developer, mobile                                      100.00   \n",
       "Database administrator                                 100.00   \n",
       "Data or business analyst                               100.00   \n",
       "Engineer, data                                         100.00   \n",
       "DevOps specialist                                      100.00   \n",
       "Academic researcher                                    100.00   \n",
       "\n",
       "                                               precision_score  recall_score  \\\n",
       "Security professional                                    99.93        100.00   \n",
       "Developer, desktop or enterprise applications            99.99         99.97   \n",
       "Developer, back-end                                      99.99         99.99   \n",
       "Data scientist or machine learning specialist           100.00        100.00   \n",
       "Blockchain                                              100.00         99.93   \n",
       "Developer, front-end                                    100.00        100.00   \n",
       "Developer, game or graphics                             100.00         99.93   \n",
       "Scientist                                               100.00        100.00   \n",
       "System administrator                                    100.00        100.00   \n",
       "Developer, QA or test                                   100.00        100.00   \n",
       "Developer, embedded applications or devices             100.00        100.00   \n",
       "Cloud infrastructure engineer                           100.00        100.00   \n",
       "Developer, full-stack                                   100.00        100.00   \n",
       "Developer, mobile                                       100.00        100.00   \n",
       "Database administrator                                  100.00        100.00   \n",
       "Data or business analyst                                100.00        100.00   \n",
       "Engineer, data                                          100.00        100.00   \n",
       "DevOps specialist                                       100.00        100.00   \n",
       "Academic researcher                                     100.00        100.00   \n",
       "\n",
       "                                               f1_score  \n",
       "Security professional                             99.96  \n",
       "Developer, desktop or enterprise applications     99.98  \n",
       "Developer, back-end                               99.99  \n",
       "Data scientist or machine learning specialist    100.00  \n",
       "Blockchain                                        99.96  \n",
       "Developer, front-end                             100.00  \n",
       "Developer, game or graphics                       99.96  \n",
       "Scientist                                        100.00  \n",
       "System administrator                             100.00  \n",
       "Developer, QA or test                            100.00  \n",
       "Developer, embedded applications or devices      100.00  \n",
       "Cloud infrastructure engineer                    100.00  \n",
       "Developer, full-stack                            100.00  \n",
       "Developer, mobile                                100.00  \n",
       "Database administrator                           100.00  \n",
       "Data or business analyst                         100.00  \n",
       "Engineer, data                                   100.00  \n",
       "DevOps specialist                                100.00  \n",
       "Academic researcher                              100.00  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics=[accuracy_score, precision_score, recall_score, f1_score]\n",
    "train_scores, mean_train_scores= calculate_metrics(dec_clf,x_train,y_train, metrics)\n",
    "\n",
    "print(mean_train_scores)\n",
    "train_scores.sort_values(\"precision_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "806d0077-4db9-44cc-ae01-8869a393691d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cross_validate the baseline model on the accuracy, precision, recall and f1\n",
    "dec_clf_scores = cross_validate(dec_clf,x_train,y_train, cv=5, scoring =calculate_scores_multi_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ea4dc513-b85f-49f9-b697-2e6d825e6b8b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_accuracy': 87.78,\n",
       " 'test_precision': 66.54,\n",
       " 'test_recall': 76.8,\n",
       " 'test_f1': 66.7}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = ['test_accuracy', 'test_precision','test_recall', 'test_f1']\n",
    "validation_scores = {}\n",
    "for score in scores:\n",
    "    validation_scores[score] = round(dec_clf_scores[score].mean(), 2)\n",
    "validation_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65361901-8a85-4865-b32b-6dbda4656295",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Log Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8f0c1e1c-9368-4276-8427-addc50cbac31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Log the model's dataset train and test indices\n",
    "log_data(x_train,y_train,x_test,y_test)\n",
    "# Log the model, model description\n",
    "model = log_model(dec_clf,'Decision Tree, multilabel, Data resampled')\n",
    "# Log the model's train and test scores\n",
    "log_metrics(train_scores, validation_scores)\n",
    "# track the model artifacts, validation scores with mlflow \n",
    "track_model(model,validation_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64ac9b1-87a5-40fe-b39e-1355517f9dda",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Evaluating the multiclass Dataset"
   ]
  },
  {
   "cell_type": "raw",
   "id": "474090ba-6ad1-48de-8094-6eacb76ebc1e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# cross_validate the baseline model on the accuracy, precision, recall and f1\n",
    "rf_clf_scores = cross_validate(dec_clf,x_train,y_train, cv=4, scoring =calculate_scores)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0ac6056e-d7ed-4aa5-b45f-019725e7c152",
   "metadata": {
    "tags": []
   },
   "source": [
    "scores = ['test_accuracy', 'test_precision','test_recall', 'test_f1']\n",
    "validation_scores = {}\n",
    "for score in scores:\n",
    "    validation_scores[score] = round(rf_clf_scores[score].mean()* 100, 2)\n",
    "validation_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b70d24-5714-46cf-a29a-6f9df5235005",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c49a5656-c618-439c-8235-4e4a71cfe306",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.5670            9.88s\n",
      "         2           0.5287            7.92s\n",
      "         3           0.4992            8.61s\n",
      "         4           0.4773            8.34s\n",
      "         5           0.4587            7.87s\n",
      "         6           0.4440            7.78s\n",
      "         7           0.4310            7.68s\n",
      "         8           0.4199            7.42s\n",
      "         9           0.4112            7.31s\n",
      "        10           0.4025            7.13s\n",
      "        20           0.3591            6.46s\n",
      "        30           0.3427            5.60s\n",
      "        40           0.3302            4.90s\n",
      "        50           0.3228            4.10s\n",
      "        60           0.3168            3.25s\n",
      "        70           0.3107            2.44s\n",
      "        80           0.3048            1.65s\n",
      "        90           0.3001            0.82s\n",
      "       100           0.2954            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.5326            6.79s\n",
      "         2           0.5168            8.28s\n",
      "         3           0.5058            8.18s\n",
      "         4           0.4972            8.15s\n",
      "         5           0.4903            7.81s\n",
      "         6           0.4843            7.60s\n",
      "         7           0.4795            7.78s\n",
      "         8           0.4754            7.69s\n",
      "         9           0.4719            7.54s\n",
      "        10           0.4687            7.54s\n",
      "        20           0.4470            6.54s\n",
      "        30           0.4325            5.70s\n",
      "        40           0.4230            4.90s\n",
      "        50           0.4154            4.11s\n",
      "        60           0.4091            3.26s\n",
      "        70           0.4044            2.46s\n",
      "        80           0.3980            1.63s\n",
      "        90           0.3940            0.82s\n",
      "       100           0.3902            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.5140            7.98s\n",
      "         2           0.4995            7.49s\n",
      "         3           0.4878            7.37s\n",
      "         4           0.4792            7.49s\n",
      "         5           0.4701            7.51s\n",
      "         6           0.4621            7.49s\n",
      "         7           0.4557            7.68s\n",
      "         8           0.4498            7.40s\n",
      "         9           0.4447            7.36s\n",
      "        10           0.4404            7.30s\n",
      "        20           0.4093            6.40s\n",
      "        30           0.3931            5.50s\n",
      "        40           0.3814            4.69s\n",
      "        50           0.3718            3.89s\n",
      "        60           0.3644            3.10s\n",
      "        70           0.3586            2.31s\n",
      "        80           0.3538            1.54s\n",
      "        90           0.3485            0.77s\n",
      "       100           0.3440            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.9779            7.78s\n",
      "         2           0.9629            7.51s\n",
      "         3           0.9506            7.29s\n",
      "         4           0.9405            7.14s\n",
      "         5           0.9312            7.02s\n",
      "         6           0.9231            7.05s\n",
      "         7           0.9151            6.93s\n",
      "         8           0.9087            6.73s\n",
      "         9           0.9026            6.77s\n",
      "        10           0.8974            6.69s\n",
      "        20           0.8614            5.93s\n",
      "        30           0.8377            5.24s\n",
      "        40           0.8201            4.55s\n",
      "        50           0.8058            3.79s\n",
      "        60           0.7949            3.04s\n",
      "        70           0.7849            2.29s\n",
      "        80           0.7760            1.55s\n",
      "        90           0.7676            0.77s\n",
      "       100           0.7608            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.5014            7.08s\n",
      "         2           0.4914            7.01s\n",
      "         3           0.4836            7.27s\n",
      "         4           0.4772            7.16s\n",
      "         5           0.4719            7.11s\n",
      "         6           0.4673            6.92s\n",
      "         7           0.4633            6.96s\n",
      "         8           0.4595            6.86s\n",
      "         9           0.4561            6.73s\n",
      "        10           0.4534            6.66s\n",
      "        20           0.4342            5.99s\n",
      "        30           0.4209            5.26s\n",
      "        40           0.4108            4.49s\n",
      "        50           0.4033            3.75s\n",
      "        60           0.3962            3.01s\n",
      "        70           0.3895            2.27s\n",
      "        80           0.3832            1.50s\n",
      "        90           0.3783            0.75s\n",
      "       100           0.3736            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.4565            7.98s\n",
      "         2           0.4163            9.30s\n",
      "         3           0.3888            9.47s\n",
      "         4           0.3651            9.09s\n",
      "         5           0.3466            8.68s\n",
      "         6           0.3314            8.80s\n",
      "         7           0.3170            8.61s\n",
      "         8           0.3053            8.68s\n",
      "         9           0.2949            8.44s\n",
      "        10           0.2862            8.35s\n",
      "        20           0.2313            7.20s\n",
      "        30           0.2066            6.29s\n",
      "        40           0.1920            5.52s\n",
      "        50           0.1810            4.53s\n",
      "        60           0.1744            3.58s\n",
      "        70           0.1680            2.63s\n",
      "        80           0.1629            1.72s\n",
      "        90           0.1586            0.85s\n",
      "       100           0.1551            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.9190            7.10s\n",
      "         2           0.8910            7.08s\n",
      "         3           0.8698            6.93s\n",
      "         4           0.8525            7.05s\n",
      "         5           0.8372            6.78s\n",
      "         6           0.8234            6.77s\n",
      "         7           0.8122            6.88s\n",
      "         8           0.8023            6.69s\n",
      "         9           0.7944            6.69s\n",
      "        10           0.7870            6.56s\n",
      "        20           0.7428            5.87s\n",
      "        30           0.7221            5.17s\n",
      "        40           0.7088            4.47s\n",
      "        50           0.6988            3.74s\n",
      "        60           0.6897            3.00s\n",
      "        70           0.6836            2.27s\n",
      "        80           0.6765            1.51s\n",
      "        90           0.6707            0.76s\n",
      "       100           0.6662            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.5586            8.71s\n",
      "         2           0.5356            8.10s\n",
      "         3           0.5190            7.55s\n",
      "         4           0.5057            7.40s\n",
      "         5           0.4953            7.25s\n",
      "         6           0.4865            7.05s\n",
      "         7           0.4793            6.96s\n",
      "         8           0.4725            6.94s\n",
      "         9           0.4670            6.81s\n",
      "        10           0.4622            6.76s\n",
      "        20           0.4342            6.22s\n",
      "        30           0.4183            5.35s\n",
      "        40           0.4077            4.54s\n",
      "        50           0.4000            3.78s\n",
      "        60           0.3944            3.10s\n",
      "        70           0.3888            2.33s\n",
      "        80           0.3833            1.55s\n",
      "        90           0.3789            0.78s\n",
      "       100           0.3744            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.4791            6.91s\n",
      "         2           0.4544            6.77s\n",
      "         3           0.4368            7.23s\n",
      "         4           0.4230            6.90s\n",
      "         5           0.4117            6.86s\n",
      "         6           0.4022            6.92s\n",
      "         7           0.3938            6.90s\n",
      "         8           0.3868            6.97s\n",
      "         9           0.3811            6.85s\n",
      "        10           0.3758            6.68s\n",
      "        20           0.3462            5.97s\n",
      "        30           0.3301            5.24s\n",
      "        40           0.3182            4.57s\n",
      "        50           0.3096            3.83s\n",
      "        60           0.3025            3.06s\n",
      "        70           0.2962            2.29s\n",
      "        80           0.2912            1.53s\n",
      "        90           0.2860            0.76s\n",
      "       100           0.2816            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.4637            8.12s\n",
      "         2           0.4601            7.81s\n",
      "         3           0.4570            7.49s\n",
      "         4           0.4538            7.43s\n",
      "         5           0.4509            7.14s\n",
      "         6           0.4485            7.26s\n",
      "         7           0.4465            7.18s\n",
      "         8           0.4447            7.07s\n",
      "         9           0.4430            7.05s\n",
      "        10           0.4412            6.93s\n",
      "        20           0.4274            6.14s\n",
      "        30           0.4180            5.39s\n",
      "        40           0.4100            4.61s\n",
      "        50           0.4025            3.87s\n",
      "        60           0.3962            3.12s\n",
      "        70           0.3910            2.33s\n",
      "        80           0.3854            1.55s\n",
      "        90           0.3807            0.78s\n",
      "       100           0.3763            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.5625            7.82s\n",
      "         2           0.5506            7.58s\n",
      "         3           0.5419            7.68s\n",
      "         4           0.5338            7.56s\n",
      "         5           0.5277            7.42s\n",
      "         6           0.5218            7.27s\n",
      "         7           0.5164            7.13s\n",
      "         8           0.5120            7.10s\n",
      "         9           0.5083            6.99s\n",
      "        10           0.5046            6.94s\n",
      "        20           0.4802            6.11s\n",
      "        30           0.4641            5.34s\n",
      "        40           0.4529            4.57s\n",
      "        50           0.4433            3.81s\n",
      "        60           0.4355            3.04s\n",
      "        70           0.4284            2.28s\n",
      "        80           0.4217            1.52s\n",
      "        90           0.4162            0.76s\n",
      "       100           0.4110            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.4975            7.33s\n",
      "         2           0.4763            6.66s\n",
      "         3           0.4605            7.85s\n",
      "         4           0.4494            8.06s\n",
      "         5           0.4391            8.09s\n",
      "         6           0.4310            7.84s\n",
      "         7           0.4248            7.75s\n",
      "         8           0.4187            7.56s\n",
      "         9           0.4138            7.35s\n",
      "        10           0.4098            7.21s\n",
      "        20           0.3773            6.16s\n",
      "        30           0.3608            5.33s\n",
      "        40           0.3493            4.53s\n",
      "        50           0.3412            3.82s\n",
      "        60           0.3340            3.06s\n",
      "        70           0.3269            2.29s\n",
      "        80           0.3206            1.53s\n",
      "        90           0.3157            0.77s\n",
      "       100           0.3107            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.3829            7.74s\n",
      "         2           0.3775            7.32s\n",
      "         3           0.3726            7.55s\n",
      "         4           0.3689            7.21s\n",
      "         5           0.3657            7.29s\n",
      "         6           0.3627            7.36s\n",
      "         7           0.3602            7.47s\n",
      "         8           0.3581            7.27s\n",
      "         9           0.3552            7.27s\n",
      "        10           0.3531            7.19s\n",
      "        20           0.3368            6.51s\n",
      "        30           0.3258            5.60s\n",
      "        40           0.3179            4.76s\n",
      "        50           0.3120            3.94s\n",
      "        60           0.3059            3.14s\n",
      "        70           0.3012            2.36s\n",
      "        80           0.2960            1.59s\n",
      "        90           0.2916            0.80s\n",
      "       100           0.2880            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.3999            8.22s\n",
      "         2           0.3765            7.24s\n",
      "         3           0.3607            7.53s\n",
      "         4           0.3492            7.22s\n",
      "         5           0.3399            7.26s\n",
      "         6           0.3322            7.30s\n",
      "         7           0.3258            7.31s\n",
      "         8           0.3207            7.31s\n",
      "         9           0.3152            7.43s\n",
      "        10           0.3107            7.35s\n",
      "        20           0.2854            6.61s\n",
      "        30           0.2721            5.79s\n",
      "        40           0.2617            5.00s\n",
      "        50           0.2549            4.23s\n",
      "        60           0.2494            3.39s\n",
      "        70           0.2446            2.55s\n",
      "        80           0.2390            1.69s\n",
      "        90           0.2344            0.84s\n",
      "       100           0.2303            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.5111            8.25s\n",
      "         2           0.4868            8.30s\n",
      "         3           0.4667            8.07s\n",
      "         4           0.4520            8.00s\n",
      "         5           0.4384            7.90s\n",
      "         6           0.4273            7.76s\n",
      "         7           0.4177            7.49s\n",
      "         8           0.4100            7.44s\n",
      "         9           0.4027            7.30s\n",
      "        10           0.3959            7.25s\n",
      "        20           0.3558            6.39s\n",
      "        30           0.3342            5.99s\n",
      "        40           0.3199            4.98s\n",
      "        50           0.3097            4.08s\n",
      "        60           0.3026            3.21s\n",
      "        70           0.2956            2.44s\n",
      "        80           0.2898            1.66s\n",
      "        90           0.2845            0.83s\n",
      "       100           0.2790            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.3225           10.60s\n",
      "         2           0.3096           10.09s\n",
      "         3           0.3008            9.81s\n",
      "         4           0.2943            9.53s\n",
      "         5           0.2891            9.14s\n",
      "         6           0.2845            9.03s\n",
      "         7           0.2810            8.52s\n",
      "         8           0.2780            8.56s\n",
      "         9           0.2755            8.52s\n",
      "        10           0.2732            8.38s\n",
      "        20           0.2591            7.26s\n",
      "        30           0.2472            6.12s\n",
      "        40           0.2393            5.17s\n",
      "        50           0.2331            4.29s\n",
      "        60           0.2267            3.37s\n",
      "        70           0.2210            2.49s\n",
      "        80           0.2166            1.67s\n",
      "        90           0.2120            0.83s\n",
      "       100           0.2087            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.6156            7.98s\n",
      "         2           0.5973            8.09s\n",
      "         3           0.5829            8.22s\n",
      "         4           0.5716            8.12s\n",
      "         5           0.5612            7.69s\n",
      "         6           0.5532            7.92s\n",
      "         7           0.5458            7.81s\n",
      "         8           0.5400            7.71s\n",
      "         9           0.5340            7.62s\n",
      "        10           0.5290            7.55s\n",
      "        20           0.4986            6.65s\n",
      "        30           0.4815            5.64s\n",
      "        40           0.4700            4.79s\n",
      "        50           0.4607            3.95s\n",
      "        60           0.4540            3.14s\n",
      "        70           0.4487            2.35s\n",
      "        80           0.4429            1.56s\n",
      "        90           0.4375            0.78s\n",
      "       100           0.4329            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.5819            7.65s\n",
      "         2           0.5578            7.20s\n",
      "         3           0.5402            7.09s\n",
      "         4           0.5255            6.81s\n",
      "         5           0.5142            6.90s\n",
      "         6           0.5049            7.11s\n",
      "         7           0.4969            7.05s\n",
      "         8           0.4904            6.92s\n",
      "         9           0.4845            6.92s\n",
      "        10           0.4796            6.74s\n",
      "        20           0.4467            5.94s\n",
      "        30           0.4301            5.18s\n",
      "        40           0.4195            4.51s\n",
      "        50           0.4112            3.79s\n",
      "        60           0.4043            3.04s\n",
      "        70           0.3983            2.30s\n",
      "        80           0.3937            1.53s\n",
      "        90           0.3880            0.77s\n",
      "       100           0.3833            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.6028            6.66s\n",
      "         2           0.5789            7.06s\n",
      "         3           0.5610            6.63s\n",
      "         4           0.5470            6.80s\n",
      "         5           0.5354            6.59s\n",
      "         6           0.5251            6.58s\n",
      "         7           0.5169            6.64s\n",
      "         8           0.5100            6.73s\n",
      "         9           0.5036            6.63s\n",
      "        10           0.4989            6.58s\n",
      "        20           0.4603            5.88s\n",
      "        30           0.4388            5.17s\n",
      "        40           0.4263            4.46s\n",
      "        50           0.4155            3.77s\n",
      "        60           0.4076            3.03s\n",
      "        70           0.4006            2.28s\n",
      "        80           0.3944            1.52s\n",
      "        90           0.3892            0.76s\n",
      "       100           0.3846            0.00s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-12 {color: black;}#sk-container-id-12 pre{padding: 0;}#sk-container-id-12 div.sk-toggleable {background-color: white;}#sk-container-id-12 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-12 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-12 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-12 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-12 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-12 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-12 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-12 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-12 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-12 div.sk-item {position: relative;z-index: 1;}#sk-container-id-12 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-12 div.sk-item::before, #sk-container-id-12 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-12 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-12 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-12 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-12 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-12 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-12 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-12 div.sk-label-container {text-align: center;}#sk-container-id-12 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-12 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultiOutputClassifier(estimator=GradientBoostingClassifier(random_state=42,\n",
       "                                                           verbose=1))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-35\" type=\"checkbox\" ><label for=\"sk-estimator-id-35\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultiOutputClassifier</label><div class=\"sk-toggleable__content\"><pre>MultiOutputClassifier(estimator=GradientBoostingClassifier(random_state=42,\n",
       "                                                           verbose=1))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-36\" type=\"checkbox\" ><label for=\"sk-estimator-id-36\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(random_state=42, verbose=1)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-37\" type=\"checkbox\" ><label for=\"sk-estimator-id-37\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(random_state=42, verbose=1)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultiOutputClassifier(estimator=GradientBoostingClassifier(random_state=42,\n",
       "                                                           verbose=1))"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a Gradient Boosting Classifier\n",
    "gd_clf = MultiOutputClassifier(estimator=GradientBoostingClassifier(n_estimators=100,max_depth=3,verbose=1,random_state=42))\n",
    "gd_clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57600566-7013-423f-b9df-8b1d9b86df86",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Evaluating the multilabal Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d50ab758-e2c6-4ff2-aa85-8b2757d8c050",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score     92.770000\n",
      "precision_score    85.544737\n",
      "recall_score       63.216842\n",
      "f1_score           66.781053\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Developer, full-stack</th>\n",
       "      <td>84.49</td>\n",
       "      <td>76.57</td>\n",
       "      <td>63.30</td>\n",
       "      <td>66.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cloud infrastructure engineer</th>\n",
       "      <td>92.24</td>\n",
       "      <td>79.55</td>\n",
       "      <td>61.07</td>\n",
       "      <td>65.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, back-end</th>\n",
       "      <td>83.18</td>\n",
       "      <td>79.76</td>\n",
       "      <td>60.36</td>\n",
       "      <td>62.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data or business analyst</th>\n",
       "      <td>93.08</td>\n",
       "      <td>79.79</td>\n",
       "      <td>58.21</td>\n",
       "      <td>61.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scientist</th>\n",
       "      <td>93.74</td>\n",
       "      <td>82.11</td>\n",
       "      <td>63.72</td>\n",
       "      <td>68.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DevOps specialist</th>\n",
       "      <td>92.44</td>\n",
       "      <td>82.32</td>\n",
       "      <td>65.44</td>\n",
       "      <td>70.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, desktop or enterprise applications</th>\n",
       "      <td>91.64</td>\n",
       "      <td>83.18</td>\n",
       "      <td>61.53</td>\n",
       "      <td>65.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Academic researcher</th>\n",
       "      <td>92.34</td>\n",
       "      <td>83.71</td>\n",
       "      <td>66.12</td>\n",
       "      <td>71.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data scientist or machine learning specialist</th>\n",
       "      <td>93.50</td>\n",
       "      <td>83.76</td>\n",
       "      <td>75.21</td>\n",
       "      <td>78.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Engineer, data</th>\n",
       "      <td>92.99</td>\n",
       "      <td>83.95</td>\n",
       "      <td>59.65</td>\n",
       "      <td>63.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>System administrator</th>\n",
       "      <td>92.35</td>\n",
       "      <td>84.43</td>\n",
       "      <td>56.57</td>\n",
       "      <td>59.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, embedded applications or devices</th>\n",
       "      <td>94.42</td>\n",
       "      <td>85.76</td>\n",
       "      <td>65.60</td>\n",
       "      <td>71.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, game or graphics</th>\n",
       "      <td>95.79</td>\n",
       "      <td>87.01</td>\n",
       "      <td>69.61</td>\n",
       "      <td>75.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, front-end</th>\n",
       "      <td>94.50</td>\n",
       "      <td>87.05</td>\n",
       "      <td>70.44</td>\n",
       "      <td>75.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blockchain</th>\n",
       "      <td>96.58</td>\n",
       "      <td>89.34</td>\n",
       "      <td>64.15</td>\n",
       "      <td>70.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Database administrator</th>\n",
       "      <td>93.07</td>\n",
       "      <td>89.40</td>\n",
       "      <td>51.75</td>\n",
       "      <td>51.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, mobile</th>\n",
       "      <td>97.18</td>\n",
       "      <td>93.12</td>\n",
       "      <td>85.67</td>\n",
       "      <td>88.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, QA or test</th>\n",
       "      <td>93.82</td>\n",
       "      <td>96.91</td>\n",
       "      <td>50.74</td>\n",
       "      <td>49.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Security professional</th>\n",
       "      <td>95.28</td>\n",
       "      <td>97.63</td>\n",
       "      <td>51.98</td>\n",
       "      <td>52.59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               accuracy_score  \\\n",
       "Developer, full-stack                                   84.49   \n",
       "Cloud infrastructure engineer                           92.24   \n",
       "Developer, back-end                                     83.18   \n",
       "Data or business analyst                                93.08   \n",
       "Scientist                                               93.74   \n",
       "DevOps specialist                                       92.44   \n",
       "Developer, desktop or enterprise applications           91.64   \n",
       "Academic researcher                                     92.34   \n",
       "Data scientist or machine learning specialist           93.50   \n",
       "Engineer, data                                          92.99   \n",
       "System administrator                                    92.35   \n",
       "Developer, embedded applications or devices             94.42   \n",
       "Developer, game or graphics                             95.79   \n",
       "Developer, front-end                                    94.50   \n",
       "Blockchain                                              96.58   \n",
       "Database administrator                                  93.07   \n",
       "Developer, mobile                                       97.18   \n",
       "Developer, QA or test                                   93.82   \n",
       "Security professional                                   95.28   \n",
       "\n",
       "                                               precision_score  recall_score  \\\n",
       "Developer, full-stack                                    76.57         63.30   \n",
       "Cloud infrastructure engineer                            79.55         61.07   \n",
       "Developer, back-end                                      79.76         60.36   \n",
       "Data or business analyst                                 79.79         58.21   \n",
       "Scientist                                                82.11         63.72   \n",
       "DevOps specialist                                        82.32         65.44   \n",
       "Developer, desktop or enterprise applications            83.18         61.53   \n",
       "Academic researcher                                      83.71         66.12   \n",
       "Data scientist or machine learning specialist            83.76         75.21   \n",
       "Engineer, data                                           83.95         59.65   \n",
       "System administrator                                     84.43         56.57   \n",
       "Developer, embedded applications or devices              85.76         65.60   \n",
       "Developer, game or graphics                              87.01         69.61   \n",
       "Developer, front-end                                     87.05         70.44   \n",
       "Blockchain                                               89.34         64.15   \n",
       "Database administrator                                   89.40         51.75   \n",
       "Developer, mobile                                        93.12         85.67   \n",
       "Developer, QA or test                                    96.91         50.74   \n",
       "Security professional                                    97.63         51.98   \n",
       "\n",
       "                                               f1_score  \n",
       "Developer, full-stack                             66.20  \n",
       "Cloud infrastructure engineer                     65.15  \n",
       "Developer, back-end                               62.52  \n",
       "Data or business analyst                          61.78  \n",
       "Scientist                                         68.54  \n",
       "DevOps specialist                                 70.16  \n",
       "Developer, desktop or enterprise applications     65.88  \n",
       "Academic researcher                               71.02  \n",
       "Data scientist or machine learning specialist     78.68  \n",
       "Engineer, data                                    63.85  \n",
       "System administrator                              59.48  \n",
       "Developer, embedded applications or devices       71.08  \n",
       "Developer, game or graphics                       75.27  \n",
       "Developer, front-end                              75.88  \n",
       "Blockchain                                        70.31  \n",
       "Database administrator                            51.61  \n",
       "Developer, mobile                                 88.97  \n",
       "Developer, QA or test                             49.87  \n",
       "Security professional                             52.59  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics=[accuracy_score, precision_score, recall_score, f1_score]\n",
    "train_scores, mean_train_scores= calculate_metrics(gd_clf,x_train,y_train, metrics)\n",
    "\n",
    "print(mean_train_scores)\n",
    "train_scores.sort_values(\"precision_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2e33c81e-a828-4f6d-bd62-c47065b7dc6f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.6960            0.63s\n",
      "         2           0.6482            0.54s\n",
      "         3           0.6153            0.36s\n",
      "         4           0.5918            0.61s\n",
      "         5           0.5677            0.60s\n",
      "         6           0.5453            0.59s\n",
      "         7           0.5297            0.59s\n",
      "         8           0.5150            0.64s\n",
      "         9           0.5040            0.64s\n",
      "        10           0.4935            0.59s\n",
      "        20           0.4391            0.52s\n",
      "        30           0.4088            0.40s\n",
      "        40           0.3938            0.34s\n",
      "        50           0.3837            0.29s\n",
      "        60           0.3762            0.22s\n",
      "        70           0.3696            0.17s\n",
      "        80           0.3635            0.11s\n",
      "        90           0.3575            0.06s\n",
      "       100           0.3523            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.6483            0.00s\n",
      "         2           0.6393            0.81s\n",
      "         3           0.6316            0.54s\n",
      "         4           0.6211            0.40s\n",
      "         5           0.6114            0.62s\n",
      "         6           0.6046            0.51s\n",
      "         7           0.5978            0.43s\n",
      "         8           0.5944            0.59s\n",
      "         9           0.5843            0.56s\n",
      "        10           0.5777            0.56s\n",
      "        20           0.5472            0.45s\n",
      "        30           0.5289            0.40s\n",
      "        40           0.5172            0.33s\n",
      "        50           0.5051            0.27s\n",
      "        60           0.4964            0.21s\n",
      "        70           0.4886            0.16s\n",
      "        80           0.4820            0.10s\n",
      "        90           0.4772            0.05s\n",
      "       100           0.4709            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.6294            2.24s\n",
      "         2           0.6199            1.43s\n",
      "         3           0.6068            1.11s\n",
      "         4           0.5970            0.82s\n",
      "         5           0.5891            0.65s\n",
      "         6           0.5793            0.83s\n",
      "         7           0.5704            0.77s\n",
      "         8           0.5650            0.72s\n",
      "         9           0.5573            0.70s\n",
      "        10           0.5507            0.67s\n",
      "        20           0.5167            0.46s\n",
      "        30           0.4931            0.38s\n",
      "        40           0.4796            0.32s\n",
      "        50           0.4683            0.29s\n",
      "        60           0.4582            0.22s\n",
      "        70           0.4501            0.17s\n",
      "        80           0.4434            0.11s\n",
      "        90           0.4373            0.06s\n",
      "       100           0.4318            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.9010            0.00s\n",
      "         2           0.8870            0.00s\n",
      "         3           0.8785            0.54s\n",
      "         4           0.8701            0.40s\n",
      "         5           0.8625            0.32s\n",
      "         6           0.8544            0.52s\n",
      "         7           0.8476            0.44s\n",
      "         8           0.8404            0.38s\n",
      "         9           0.8362            0.51s\n",
      "        10           0.8313            0.45s\n",
      "        20           0.7911            0.49s\n",
      "        30           0.7641            0.40s\n",
      "        40           0.7460            0.35s\n",
      "        50           0.7295            0.28s\n",
      "        60           0.7181            0.22s\n",
      "        70           0.7077            0.17s\n",
      "        80           0.6980            0.11s\n",
      "        90           0.6892            0.06s\n",
      "       100           0.6817            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.1564            0.00s\n",
      "         2           0.1535            0.00s\n",
      "         3           0.1516            0.53s\n",
      "         4           0.1495            0.52s\n",
      "         5           0.1468            0.41s\n",
      "         6           0.1456            0.54s\n",
      "         7           0.1446            0.55s\n",
      "         8           0.1433            0.55s\n",
      "         9           0.1416            0.50s\n",
      "        10           0.1394            0.44s\n",
      "        20           0.1283            0.47s\n",
      "        30           0.1215            0.39s\n",
      "        40           0.1166            0.32s\n",
      "        50           0.1121            0.28s\n",
      "        60           0.1084            0.23s\n",
      "        70           0.1047            0.16s\n",
      "        80           0.1025            0.11s\n",
      "        90           0.0996            0.06s\n",
      "       100           0.0969            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.5780            0.82s\n",
      "         2           0.5445            0.78s\n",
      "         3           0.5262            0.77s\n",
      "         4           0.4898            0.75s\n",
      "         5           0.4530            0.71s\n",
      "         6           0.4258            0.61s\n",
      "         7           0.4098            0.52s\n",
      "         8           0.3876            0.45s\n",
      "         9           0.3738            0.59s\n",
      "        10           0.3575            0.54s\n",
      "        20           0.2612            0.48s\n",
      "        30           0.2212            0.39s\n",
      "        40           0.1957            0.33s\n",
      "        50           0.1803            0.27s\n",
      "        60           0.1678            0.22s\n",
      "        70           0.1592            0.17s\n",
      "        80           0.1513            0.11s\n",
      "        90           0.1442            0.06s\n",
      "       100           0.1394            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.8339            0.40s\n",
      "         2           0.8162            0.66s\n",
      "         3           0.8003            0.64s\n",
      "         4           0.7843            0.60s\n",
      "         5           0.7701            0.59s\n",
      "         6           0.7624            0.59s\n",
      "         7           0.7498            0.50s\n",
      "         8           0.7393            0.60s\n",
      "         9           0.7337            0.58s\n",
      "        10           0.7246            0.57s\n",
      "        20           0.6740            0.49s\n",
      "        30           0.6465            0.42s\n",
      "        40           0.6298            0.35s\n",
      "        50           0.6183            0.30s\n",
      "        60           0.6100            0.23s\n",
      "        70           0.6041            0.17s\n",
      "        80           0.5975            0.12s\n",
      "        90           0.5913            0.06s\n",
      "       100           0.5859            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.2564            0.00s\n",
      "         2           0.2492            0.00s\n",
      "         3           0.2433            0.51s\n",
      "         4           0.2389            0.38s\n",
      "         5           0.2318            0.30s\n",
      "         6           0.2281            0.49s\n",
      "         7           0.2258            0.42s\n",
      "         8           0.2228            0.36s\n",
      "         9           0.2212            0.51s\n",
      "        10           0.2190            0.47s\n",
      "        20           0.2011            0.43s\n",
      "        30           0.1908            0.36s\n",
      "        40           0.1836            0.32s\n",
      "        50           0.1780            0.27s\n",
      "        60           0.1729            0.22s\n",
      "        70           0.1683            0.16s\n",
      "        80           0.1635            0.11s\n",
      "        90           0.1597            0.05s\n",
      "       100           0.1562            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.5860            0.60s\n",
      "         2           0.5546            0.75s\n",
      "         3           0.5290            0.86s\n",
      "         4           0.5188            0.63s\n",
      "         5           0.5095            0.81s\n",
      "         6           0.4980            0.72s\n",
      "         7           0.4842            0.72s\n",
      "         8           0.4730            0.78s\n",
      "         9           0.4679            0.77s\n",
      "        10           0.4614            0.69s\n",
      "        20           0.4094            0.55s\n",
      "        30           0.3807            0.43s\n",
      "        40           0.3630            0.38s\n",
      "        50           0.3499            0.31s\n",
      "        60           0.3414            0.24s\n",
      "        70           0.3327            0.17s\n",
      "        80           0.3258            0.12s\n",
      "        90           0.3200            0.06s\n",
      "       100           0.3154            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.5898            0.00s\n",
      "         2           0.5874            0.00s\n",
      "         3           0.5834            0.00s\n",
      "         4           0.5807            0.38s\n",
      "         5           0.5773            0.30s\n",
      "         6           0.5748            0.25s\n",
      "         7           0.5717            0.42s\n",
      "         8           0.5691            0.37s\n",
      "         9           0.5668            0.32s\n",
      "        10           0.5645            0.43s\n",
      "        20           0.5480            0.39s\n",
      "        30           0.5357            0.33s\n",
      "        40           0.5267            0.29s\n",
      "        50           0.5188            0.25s\n",
      "        60           0.5124            0.20s\n",
      "        70           0.5052            0.15s\n",
      "        80           0.4994            0.10s\n",
      "        90           0.4944            0.05s\n",
      "       100           0.4897            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.2209            1.57s\n",
      "         2           0.2163            0.78s\n",
      "         3           0.2121            0.51s\n",
      "         4           0.2091            0.76s\n",
      "         5           0.2069            0.60s\n",
      "         6           0.2042            0.50s\n",
      "         7           0.2018            0.63s\n",
      "         8           0.1995            0.54s\n",
      "         9           0.1988            0.48s\n",
      "        10           0.1975            0.43s\n",
      "        20           0.1836            0.40s\n",
      "        30           0.1767            0.35s\n",
      "        40           0.1710            0.31s\n",
      "        50           0.1665            0.25s\n",
      "        60           0.1621            0.20s\n",
      "        70           0.1578            0.16s\n",
      "        80           0.1538            0.10s\n",
      "        90           0.1509            0.05s\n",
      "       100           0.1469            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.2788            0.00s\n",
      "         2           0.2710            0.78s\n",
      "         3           0.2593            0.51s\n",
      "         4           0.2546            0.38s\n",
      "         5           0.2491            0.60s\n",
      "         6           0.2432            0.50s\n",
      "         7           0.2390            0.42s\n",
      "         8           0.2364            0.37s\n",
      "         9           0.2343            0.49s\n",
      "        10           0.2308            0.47s\n",
      "        20           0.2120            0.38s\n",
      "        30           0.2001            0.36s\n",
      "        40           0.1934            0.30s\n",
      "        50           0.1877            0.25s\n",
      "        60           0.1829            0.20s\n",
      "        70           0.1791            0.15s\n",
      "        80           0.1762            0.10s\n",
      "        90           0.1729            0.05s\n",
      "       100           0.1691            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.0636            0.00s\n",
      "         2           0.0617            0.00s\n",
      "         3           0.0596            0.51s\n",
      "         4           0.0579            0.38s\n",
      "         5           0.0570            0.30s\n",
      "         6           0.0563            0.50s\n",
      "         7           0.0554            0.52s\n",
      "         8           0.0533            0.47s\n",
      "         9           0.0529            0.50s\n",
      "        10           0.0518            0.46s\n",
      "        20           0.0450            0.41s\n",
      "        30           0.0400            0.36s\n",
      "        40           0.0372            0.31s\n",
      "        50           0.0349            0.26s\n",
      "        60           0.0323            0.21s\n",
      "        70           0.0304            0.16s\n",
      "        80           0.0286            0.11s\n",
      "        90           0.0274            0.05s\n",
      "       100           0.0259            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.0398            1.16s\n",
      "         2           0.0378            0.81s\n",
      "         3           0.0364            0.60s\n",
      "         4           0.0357            0.68s\n",
      "         5           0.0343            0.58s\n",
      "         6           0.0335            0.61s\n",
      "         7           0.0329            0.61s\n",
      "         8           0.0313            0.62s\n",
      "         9           0.0297            0.60s\n",
      "        10           0.0292            0.59s\n",
      "        20           0.0242            0.45s\n",
      "        30           0.0214            0.42s\n",
      "        40           0.0195            0.34s\n",
      "        50           0.0176            0.31s\n",
      "        60           0.0156            0.25s\n",
      "        70           0.0139            0.18s\n",
      "        80           0.0124            0.12s\n",
      "        90           0.0112            0.06s\n",
      "       100           0.0104            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.6082            0.00s\n",
      "         2           0.5821            0.82s\n",
      "         3           0.5542            0.54s\n",
      "         4           0.5362            0.81s\n",
      "         5           0.5177            0.64s\n",
      "         6           0.5008            0.53s\n",
      "         7           0.4885            0.70s\n",
      "         8           0.4781            0.62s\n",
      "         9           0.4676            0.55s\n",
      "        10           0.4620            0.49s\n",
      "        20           0.3976            0.47s\n",
      "        30           0.3632            0.43s\n",
      "        40           0.3443            0.37s\n",
      "        50           0.3301            0.31s\n",
      "        60           0.3198            0.25s\n",
      "        70           0.3113            0.18s\n",
      "        80           0.3040            0.12s\n",
      "        90           0.2973            0.06s\n",
      "       100           0.2910            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.0452            0.50s\n",
      "         2           0.0445            0.25s\n",
      "         3           0.0419            0.16s\n",
      "         4           0.0352            0.50s\n",
      "         5           0.0325            0.41s\n",
      "         6           0.0319            0.34s\n",
      "         7           0.0310            0.29s\n",
      "         8           0.0300            0.48s\n",
      "         9           0.0279            0.45s\n",
      "        10           0.0269            0.40s\n",
      "        20           0.0194            0.40s\n",
      "        30           0.0167            0.33s\n",
      "        40           0.0136            0.31s\n",
      "        50           0.0115            0.26s\n",
      "        60           0.0105            0.21s\n",
      "        70           0.0088            0.15s\n",
      "        80           0.0075            0.10s\n",
      "        90           0.0067            0.05s\n",
      "       100           0.0058            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.6821            0.00s\n",
      "         2           0.6666            0.77s\n",
      "         3           0.6510            0.51s\n",
      "         4           0.6304            0.38s\n",
      "         5           0.6145            0.30s\n",
      "         6           0.6016            0.49s\n",
      "         7           0.5925            0.42s\n",
      "         8           0.5841            0.54s\n",
      "         9           0.5764            0.47s\n",
      "        10           0.5717            0.42s\n",
      "        20           0.5370            0.45s\n",
      "        30           0.5151            0.38s\n",
      "        40           0.5007            0.34s\n",
      "        50           0.4911            0.28s\n",
      "        60           0.4838            0.23s\n",
      "        70           0.4757            0.16s\n",
      "        80           0.4689            0.11s\n",
      "        90           0.4624            0.05s\n",
      "       100           0.4566            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.5897            1.63s\n",
      "         2           0.5663            0.81s\n",
      "         3           0.5535            0.53s\n",
      "         4           0.5422            0.80s\n",
      "         5           0.5268            0.81s\n",
      "         6           0.5183            0.78s\n",
      "         7           0.5097            0.66s\n",
      "         8           0.5029            0.57s\n",
      "         9           0.4987            0.68s\n",
      "        10           0.4918            0.61s\n",
      "        20           0.4475            0.53s\n",
      "        30           0.4229            0.43s\n",
      "        40           0.4084            0.36s\n",
      "        50           0.3966            0.28s\n",
      "        60           0.3876            0.23s\n",
      "        70           0.3806            0.17s\n",
      "        80           0.3742            0.11s\n",
      "        90           0.3680            0.06s\n",
      "       100           0.3629            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.6290            0.60s\n",
      "         2           0.6160            0.64s\n",
      "         3           0.5948            0.65s\n",
      "         4           0.5860            0.54s\n",
      "         5           0.5761            0.42s\n",
      "         6           0.5642            0.60s\n",
      "         7           0.5580            0.59s\n",
      "         8           0.5516            0.58s\n",
      "         9           0.5461            0.55s\n",
      "        10           0.5360            0.55s\n",
      "        20           0.4983            0.40s\n",
      "        30           0.4725            0.37s\n",
      "        40           0.4571            0.32s\n",
      "        50           0.4443            0.26s\n",
      "        60           0.4340            0.21s\n",
      "        70           0.4261            0.15s\n",
      "        80           0.4186            0.10s\n",
      "        90           0.4129            0.05s\n",
      "       100           0.4074            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.2655            1.89s\n",
      "         2           0.2460            1.38s\n",
      "         3           0.2359            1.04s\n",
      "         4           0.2291            0.89s\n",
      "         5           0.2223            0.81s\n",
      "         6           0.2156            0.77s\n",
      "         7           0.2104            0.72s\n",
      "         8           0.2056            0.67s\n",
      "         9           0.2027            0.59s\n",
      "        10           0.1995            0.52s\n",
      "        20           0.1799            0.47s\n",
      "        30           0.1685            0.41s\n",
      "        40           0.1623            0.34s\n",
      "        50           0.1569            0.29s\n",
      "        60           0.1522            0.23s\n",
      "        70           0.1481            0.17s\n",
      "        80           0.1444            0.11s\n",
      "        90           0.1401            0.06s\n",
      "       100           0.1366            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.1781            0.72s\n",
      "         2           0.1748            0.36s\n",
      "         3           0.1706            0.53s\n",
      "         4           0.1675            0.59s\n",
      "         5           0.1663            0.46s\n",
      "         6           0.1644            0.54s\n",
      "         7           0.1623            0.54s\n",
      "         8           0.1603            0.47s\n",
      "         9           0.1579            0.41s\n",
      "        10           0.1560            0.52s\n",
      "        20           0.1459            0.43s\n",
      "        30           0.1391            0.41s\n",
      "        40           0.1349            0.34s\n",
      "        50           0.1314            0.29s\n",
      "        60           0.1279            0.23s\n",
      "        70           0.1249            0.17s\n",
      "        80           0.1222            0.11s\n",
      "        90           0.1197            0.05s\n",
      "       100           0.1159            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.1532            0.41s\n",
      "         2           0.1509            0.20s\n",
      "         3           0.1470            0.14s\n",
      "         4           0.1441            0.48s\n",
      "         5           0.1413            0.38s\n",
      "         6           0.1380            0.31s\n",
      "         7           0.1342            0.47s\n",
      "         8           0.1324            0.41s\n",
      "         9           0.1308            0.36s\n",
      "        10           0.1290            0.47s\n",
      "        20           0.1179            0.41s\n",
      "        30           0.1110            0.35s\n",
      "        40           0.1055            0.30s\n",
      "        50           0.1003            0.25s\n",
      "        60           0.0965            0.20s\n",
      "        70           0.0925            0.16s\n",
      "        80           0.0904            0.10s\n",
      "        90           0.0880            0.05s\n",
      "       100           0.0855            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.0284            0.76s\n",
      "         2           1.0132            0.37s\n",
      "         3           1.0060            0.25s\n",
      "         4           0.9982            0.71s\n",
      "         5           0.9905            0.56s\n",
      "         6           0.9814            0.64s\n",
      "         7           0.9726            0.54s\n",
      "         8           0.9646            0.47s\n",
      "         9           0.9603            0.58s\n",
      "        10           0.9544            0.52s\n",
      "        20           0.9020            0.50s\n",
      "        30           0.8756            0.41s\n",
      "        40           0.8544            0.36s\n",
      "        50           0.8353            0.29s\n",
      "        60           0.8216            0.23s\n",
      "        70           0.8108            0.18s\n",
      "        80           0.8012            0.11s\n",
      "        90           0.7916            0.06s\n",
      "       100           0.7842            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.6063            0.62s\n",
      "         2           0.6005            0.45s\n",
      "         3           0.5959            0.49s\n",
      "         4           0.5925            0.36s\n",
      "         5           0.5809            0.29s\n",
      "         6           0.5735            0.60s\n",
      "         7           0.5703            0.55s\n",
      "         8           0.5667            0.58s\n",
      "         9           0.5593            0.51s\n",
      "        10           0.5505            0.45s\n",
      "        20           0.5214            0.47s\n",
      "        30           0.5017            0.39s\n",
      "        40           0.4911            0.35s\n",
      "        50           0.4801            0.28s\n",
      "        60           0.4726            0.22s\n",
      "        70           0.4645            0.16s\n",
      "        80           0.4580            0.11s\n",
      "        90           0.4517            0.05s\n",
      "       100           0.4465            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.6385            1.68s\n",
      "         2           0.6116            0.83s\n",
      "         3           0.5922            0.55s\n",
      "         4           0.5587            0.80s\n",
      "         5           0.5257            0.63s\n",
      "         6           0.5031            0.77s\n",
      "         7           0.4857            0.66s\n",
      "         8           0.4676            0.57s\n",
      "         9           0.4541            0.68s\n",
      "        10           0.4323            0.60s\n",
      "        20           0.3349            0.47s\n",
      "        30           0.2913            0.43s\n",
      "        40           0.2619            0.36s\n",
      "        50           0.2428            0.30s\n",
      "        60           0.2294            0.22s\n",
      "        70           0.2179            0.16s\n",
      "        80           0.2106            0.11s\n",
      "        90           0.2037            0.06s\n",
      "       100           0.1975            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.0081            0.00s\n",
      "         2           0.9900            0.51s\n",
      "         3           0.9772            0.33s\n",
      "         4           0.9607            0.50s\n",
      "         5           0.9455            0.40s\n",
      "         6           0.9358            0.49s\n",
      "         7           0.9226            0.42s\n",
      "         8           0.9116            0.48s\n",
      "         9           0.9042            0.42s\n",
      "        10           0.8960            0.47s\n",
      "        20           0.8385            0.41s\n",
      "        30           0.8095            0.36s\n",
      "        40           0.7912            0.29s\n",
      "        50           0.7790            0.25s\n",
      "        60           0.7704            0.21s\n",
      "        70           0.7625            0.15s\n",
      "        80           0.7558            0.10s\n",
      "        90           0.7484            0.05s\n",
      "       100           0.7434            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.6229            0.54s\n",
      "         2           0.6016            0.33s\n",
      "         3           0.5875            0.48s\n",
      "         4           0.5763            0.36s\n",
      "         5           0.5582            0.49s\n",
      "         6           0.5507            0.41s\n",
      "         7           0.5432            0.47s\n",
      "         8           0.5352            0.41s\n",
      "         9           0.5297            0.46s\n",
      "        10           0.5228            0.48s\n",
      "        20           0.4799            0.43s\n",
      "        30           0.4586            0.39s\n",
      "        40           0.4432            0.33s\n",
      "        50           0.4318            0.28s\n",
      "        60           0.4233            0.23s\n",
      "        70           0.4174            0.17s\n",
      "        80           0.4126            0.11s\n",
      "        90           0.4075            0.05s\n",
      "       100           0.4028            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.6163            0.00s\n",
      "         2           0.5892            0.51s\n",
      "         3           0.5664            0.33s\n",
      "         4           0.5566            0.51s\n",
      "         5           0.5485            0.40s\n",
      "         6           0.5369            0.48s\n",
      "         7           0.5252            0.41s\n",
      "         8           0.5148            0.48s\n",
      "         9           0.5096            0.42s\n",
      "        10           0.5030            0.47s\n",
      "        20           0.4564            0.41s\n",
      "        30           0.4275            0.36s\n",
      "        40           0.4085            0.31s\n",
      "        50           0.3939            0.26s\n",
      "        60           0.3847            0.21s\n",
      "        70           0.3764            0.16s\n",
      "        80           0.3696            0.11s\n",
      "        90           0.3641            0.05s\n",
      "       100           0.3591            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.0861            1.69s\n",
      "         2           0.0838            0.84s\n",
      "         3           0.0823            0.55s\n",
      "         4           0.0808            0.93s\n",
      "         5           0.0803            0.89s\n",
      "         6           0.0799            0.89s\n",
      "         7           0.0783            0.79s\n",
      "         8           0.0775            0.81s\n",
      "         9           0.0773            0.71s\n",
      "        10           0.0767            0.78s\n",
      "        20           0.0695            0.63s\n",
      "        30           0.0661            0.50s\n",
      "        40           0.0625            0.43s\n",
      "        50           0.0598            0.36s\n",
      "        60           0.0575            0.29s\n",
      "        70           0.0548            0.22s\n",
      "        80           0.0524            0.15s\n",
      "        90           0.0505            0.07s\n",
      "       100           0.0484            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.6539            0.87s\n",
      "         2           0.6449            0.60s\n",
      "         3           0.6353            0.91s\n",
      "         4           0.6271            0.77s\n",
      "         5           0.6210            0.85s\n",
      "         6           0.6141            0.70s\n",
      "         7           0.6076            0.59s\n",
      "         8           0.6035            0.68s\n",
      "         9           0.6002            0.76s\n",
      "        10           0.5968            0.68s\n",
      "        20           0.5666            0.60s\n",
      "        30           0.5435            0.51s\n",
      "        40           0.5305            0.39s\n",
      "        50           0.5188            0.33s\n",
      "        60           0.5089            0.25s\n",
      "        70           0.5013            0.19s\n",
      "        80           0.4947            0.12s\n",
      "        90           0.4878            0.06s\n",
      "       100           0.4820            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.5407            1.02s\n",
      "         2           0.5176            0.51s\n",
      "         3           0.4880            0.67s\n",
      "         4           0.4768            0.50s\n",
      "         5           0.4639            0.59s\n",
      "         6           0.4487            0.49s\n",
      "         7           0.4398            0.55s\n",
      "         8           0.4327            0.48s\n",
      "         9           0.4269            0.52s\n",
      "        10           0.4171            0.47s\n",
      "        20           0.3757            0.41s\n",
      "        30           0.3503            0.38s\n",
      "        40           0.3344            0.31s\n",
      "        50           0.3206            0.26s\n",
      "        60           0.3114            0.21s\n",
      "        70           0.3026            0.16s\n",
      "        80           0.2963            0.10s\n",
      "        90           0.2911            0.05s\n",
      "       100           0.2856            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.4957            0.91s\n",
      "         2           0.4881            0.67s\n",
      "         3           0.4832            0.67s\n",
      "         4           0.4785            0.49s\n",
      "         5           0.4753            0.59s\n",
      "         6           0.4709            0.49s\n",
      "         7           0.4689            0.55s\n",
      "         8           0.4661            0.48s\n",
      "         9           0.4627            0.54s\n",
      "        10           0.4606            0.49s\n",
      "        20           0.4436            0.41s\n",
      "        30           0.4317            0.36s\n",
      "        40           0.4216            0.31s\n",
      "        50           0.4137            0.26s\n",
      "        60           0.4070            0.21s\n",
      "        70           0.4017            0.16s\n",
      "        80           0.3958            0.10s\n",
      "        90           0.3914            0.05s\n",
      "       100           0.3865            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.5611            0.00s\n",
      "         2           0.5441            0.51s\n",
      "         3           0.5327            0.33s\n",
      "         4           0.5214            0.50s\n",
      "         5           0.5018            0.39s\n",
      "         6           0.4932            0.49s\n",
      "         7           0.4871            0.41s\n",
      "         8           0.4825            0.48s\n",
      "         9           0.4663            0.42s\n",
      "        10           0.4610            0.47s\n",
      "        20           0.4084            0.41s\n",
      "        30           0.3867            0.36s\n",
      "        40           0.3731            0.30s\n",
      "        50           0.3601            0.25s\n",
      "        60           0.3518            0.20s\n",
      "        70           0.3454            0.15s\n",
      "        80           0.3393            0.10s\n",
      "        90           0.3340            0.05s\n",
      "       100           0.3292            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.6540            1.94s\n",
      "         2           0.6352            1.04s\n",
      "         3           0.6120            0.68s\n",
      "         4           0.5960            0.51s\n",
      "         5           0.5805            0.70s\n",
      "         6           0.5716            0.58s\n",
      "         7           0.5589            0.49s\n",
      "         8           0.5470            0.62s\n",
      "         9           0.5368            0.54s\n",
      "        10           0.5308            0.48s\n",
      "        20           0.4633            0.49s\n",
      "        30           0.4264            0.40s\n",
      "        40           0.4060            0.33s\n",
      "        50           0.3902            0.27s\n",
      "        60           0.3788            0.21s\n",
      "        70           0.3709            0.16s\n",
      "        80           0.3622            0.11s\n",
      "        90           0.3548            0.05s\n",
      "       100           0.3483            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.4632            0.00s\n",
      "         2           0.4573            0.77s\n",
      "         3           0.4527            0.51s\n",
      "         4           0.4204            0.38s\n",
      "         5           0.4146            0.60s\n",
      "         6           0.4057            0.49s\n",
      "         7           0.4022            0.42s\n",
      "         8           0.3996            0.55s\n",
      "         9           0.3885            0.48s\n",
      "        10           0.3847            0.43s\n",
      "        20           0.3555            0.47s\n",
      "        30           0.3414            0.41s\n",
      "        40           0.3312            0.35s\n",
      "        50           0.3242            0.30s\n",
      "        60           0.3184            0.24s\n",
      "        70           0.3116            0.18s\n",
      "        80           0.3053            0.12s\n",
      "        90           0.3004            0.06s\n",
      "       100           0.2957            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.7488            0.80s\n",
      "         2           0.7347            0.45s\n",
      "         3           0.7217            0.29s\n",
      "         4           0.7028            0.60s\n",
      "         5           0.6856            0.51s\n",
      "         6           0.6727            0.42s\n",
      "         7           0.6634            0.56s\n",
      "         8           0.6541            0.48s\n",
      "         9           0.6451            0.42s\n",
      "        10           0.6396            0.53s\n",
      "        20           0.6001            0.51s\n",
      "        30           0.5798            0.41s\n",
      "        40           0.5663            0.33s\n",
      "        50           0.5557            0.28s\n",
      "        60           0.5472            0.22s\n",
      "        70           0.5403            0.16s\n",
      "        80           0.5338            0.11s\n",
      "        90           0.5282            0.05s\n",
      "       100           0.5229            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.3393            0.00s\n",
      "         2           0.3269            0.00s\n",
      "         3           0.3192            0.59s\n",
      "         4           0.3136            0.44s\n",
      "         5           0.3056            0.61s\n",
      "         6           0.3009            0.52s\n",
      "         7           0.2972            0.44s\n",
      "         8           0.2939            0.58s\n",
      "         9           0.2918            0.51s\n",
      "        10           0.2887            0.45s\n",
      "        20           0.2690            0.47s\n",
      "        30           0.2567            0.40s\n",
      "        40           0.2489            0.35s\n",
      "        50           0.2426            0.28s\n",
      "        60           0.2377            0.23s\n",
      "        70           0.2340            0.16s\n",
      "        80           0.2303            0.11s\n",
      "        90           0.2267            0.06s\n",
      "       100           0.2222            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.3953            1.65s\n",
      "         2           0.3780            0.82s\n",
      "         3           0.3548            0.54s\n",
      "         4           0.3472            0.80s\n",
      "         5           0.3387            0.63s\n",
      "         6           0.3293            0.76s\n",
      "         7           0.3228            0.65s\n",
      "         8           0.3176            0.57s\n",
      "         9           0.3136            0.66s\n",
      "        10           0.3082            0.64s\n",
      "        20           0.2790            0.46s\n",
      "        30           0.2620            0.37s\n",
      "        40           0.2509            0.33s\n",
      "        50           0.2412            0.27s\n",
      "        60           0.2356            0.21s\n",
      "        70           0.2293            0.16s\n",
      "        80           0.2247            0.11s\n",
      "        90           0.2196            0.05s\n",
      "       100           0.2157            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.7484            0.92s\n",
      "         2           0.7055            0.48s\n",
      "         3           0.6754            0.32s\n",
      "         4           0.6541            0.63s\n",
      "         5           0.6312            0.50s\n",
      "         6           0.6107            0.41s\n",
      "         7           0.5968            0.57s\n",
      "         8           0.5820            0.49s\n",
      "         9           0.5710            0.43s\n",
      "        10           0.5607            0.53s\n",
      "        20           0.5054            0.44s\n",
      "        30           0.4737            0.41s\n",
      "        40           0.4579            0.32s\n",
      "        50           0.4472            0.28s\n",
      "        60           0.4394            0.22s\n",
      "        70           0.4316            0.16s\n",
      "        80           0.4254            0.11s\n",
      "        90           0.4190            0.05s\n",
      "       100           0.4135            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.7114            0.00s\n",
      "         2           0.7031            0.00s\n",
      "         3           0.6953            0.51s\n",
      "         4           0.6869            0.38s\n",
      "         5           0.6798            0.30s\n",
      "         6           0.6732            0.25s\n",
      "         7           0.6682            0.52s\n",
      "         8           0.6660            0.48s\n",
      "         9           0.6561            0.48s\n",
      "        10           0.6514            0.43s\n",
      "        20           0.6234            0.42s\n",
      "        30           0.6053            0.36s\n",
      "        40           0.5925            0.31s\n",
      "        50           0.5804            0.26s\n",
      "        60           0.5714            0.21s\n",
      "        70           0.5638            0.16s\n",
      "        80           0.5567            0.10s\n",
      "        90           0.5506            0.05s\n",
      "       100           0.5447            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.6826            0.39s\n",
      "         2           0.6758            0.40s\n",
      "         3           0.6654            0.59s\n",
      "         4           0.6571            0.59s\n",
      "         5           0.6484            0.54s\n",
      "         6           0.6392            0.60s\n",
      "         7           0.6297            0.57s\n",
      "         8           0.6241            0.59s\n",
      "         9           0.6166            0.58s\n",
      "        10           0.6096            0.57s\n",
      "        20           0.5729            0.48s\n",
      "        30           0.5470            0.40s\n",
      "        40           0.5326            0.34s\n",
      "        50           0.5201            0.29s\n",
      "        60           0.5120            0.23s\n",
      "        70           0.5041            0.17s\n",
      "        80           0.4970            0.11s\n",
      "        90           0.4905            0.06s\n",
      "       100           0.4844            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.0123            0.60s\n",
      "         2           1.0023            0.64s\n",
      "         3           0.9953            0.72s\n",
      "         4           0.9893            0.65s\n",
      "         5           0.9838            0.64s\n",
      "         6           0.9773            0.52s\n",
      "         7           0.9705            0.44s\n",
      "         8           0.9660            0.57s\n",
      "         9           0.9619            0.50s\n",
      "        10           0.9583            0.44s\n",
      "        20           0.9206            0.41s\n",
      "        30           0.8979            0.39s\n",
      "        40           0.8824            0.31s\n",
      "        50           0.8672            0.26s\n",
      "        60           0.8562            0.21s\n",
      "        70           0.8454            0.16s\n",
      "        80           0.8366            0.11s\n",
      "        90           0.8289            0.06s\n",
      "       100           0.8215            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.6730            1.56s\n",
      "         2           0.6668            0.77s\n",
      "         3           0.6608            0.51s\n",
      "         4           0.6558            0.77s\n",
      "         5           0.6440            0.61s\n",
      "         6           0.6375            0.50s\n",
      "         7           0.6334            0.65s\n",
      "         8           0.6301            0.62s\n",
      "         9           0.6229            0.55s\n",
      "        10           0.6146            0.49s\n",
      "        20           0.5867            0.41s\n",
      "        30           0.5603            0.36s\n",
      "        40           0.5478            0.33s\n",
      "        50           0.5355            0.29s\n",
      "        60           0.5270            0.22s\n",
      "        70           0.5183            0.17s\n",
      "        80           0.5101            0.12s\n",
      "        90           0.5043            0.06s\n",
      "       100           0.4980            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.2600            0.00s\n",
      "         2           0.2496            0.00s\n",
      "         3           0.2445            0.63s\n",
      "         4           0.2353            0.51s\n",
      "         5           0.2262            0.60s\n",
      "         6           0.2192            0.52s\n",
      "         7           0.2147            0.44s\n",
      "         8           0.2085            0.59s\n",
      "         9           0.2018            0.53s\n",
      "        10           0.1978            0.47s\n",
      "        20           0.1681            0.47s\n",
      "        30           0.1553            0.43s\n",
      "        40           0.1453            0.38s\n",
      "        50           0.1378            0.32s\n",
      "        60           0.1323            0.25s\n",
      "        70           0.1270            0.19s\n",
      "        80           0.1231            0.13s\n",
      "        90           0.1199            0.06s\n",
      "       100           0.1170            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.9490            0.00s\n",
      "         2           0.9268            0.82s\n",
      "         3           0.9107            0.54s\n",
      "         4           0.8930            0.83s\n",
      "         5           0.8769            0.66s\n",
      "         6           0.8652            0.54s\n",
      "         7           0.8508            0.68s\n",
      "         8           0.8396            0.59s\n",
      "         9           0.8301            0.72s\n",
      "        10           0.8207            0.71s\n",
      "        20           0.7656            0.52s\n",
      "        30           0.7382            0.42s\n",
      "        40           0.7205            0.35s\n",
      "        50           0.7087            0.30s\n",
      "        60           0.6989            0.23s\n",
      "        70           0.6909            0.17s\n",
      "        80           0.6849            0.11s\n",
      "        90           0.6779            0.06s\n",
      "       100           0.6718            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.7437            0.00s\n",
      "         2           0.7237            0.00s\n",
      "         3           0.7098            0.51s\n",
      "         4           0.6970            0.38s\n",
      "         5           0.6786            0.30s\n",
      "         6           0.6692            0.49s\n",
      "         7           0.6617            0.42s\n",
      "         8           0.6542            0.36s\n",
      "         9           0.6477            0.50s\n",
      "        10           0.6406            0.44s\n",
      "        20           0.5951            0.42s\n",
      "        30           0.5708            0.36s\n",
      "        40           0.5559            0.30s\n",
      "        50           0.5448            0.25s\n",
      "        60           0.5356            0.21s\n",
      "        70           0.5292            0.15s\n",
      "        80           0.5233            0.10s\n",
      "        90           0.5163            0.05s\n",
      "       100           0.5111            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.2217            1.30s\n",
      "         2           0.2159            0.90s\n",
      "         3           0.2098            0.59s\n",
      "         4           0.2076            0.68s\n",
      "         5           0.2057            0.59s\n",
      "         6           0.2021            0.61s\n",
      "         7           0.1992            0.55s\n",
      "         8           0.1966            0.57s\n",
      "         9           0.1955            0.52s\n",
      "        10           0.1937            0.54s\n",
      "        20           0.1780            0.45s\n",
      "        30           0.1685            0.39s\n",
      "        40           0.1621            0.32s\n",
      "        50           0.1572            0.27s\n",
      "        60           0.1530            0.21s\n",
      "        70           0.1490            0.16s\n",
      "        80           0.1457            0.11s\n",
      "        90           0.1411            0.05s\n",
      "       100           0.1377            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.6159            0.91s\n",
      "         2           0.6125            0.45s\n",
      "         3           0.6064            0.63s\n",
      "         4           0.6025            0.47s\n",
      "         5           0.5976            0.58s\n",
      "         6           0.5950            0.48s\n",
      "         7           0.5908            0.53s\n",
      "         8           0.5880            0.46s\n",
      "         9           0.5852            0.51s\n",
      "        10           0.5831            0.46s\n",
      "        20           0.5652            0.41s\n",
      "        30           0.5508            0.38s\n",
      "        40           0.5406            0.34s\n",
      "        50           0.5317            0.29s\n",
      "        60           0.5239            0.24s\n",
      "        70           0.5168            0.17s\n",
      "        80           0.5095            0.12s\n",
      "        90           0.5026            0.06s\n",
      "       100           0.4973            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.7443            0.00s\n",
      "         2           0.7351            0.82s\n",
      "         3           0.7244            0.54s\n",
      "         4           0.7148            0.69s\n",
      "         5           0.7085            0.63s\n",
      "         6           0.7003            0.52s\n",
      "         7           0.6930            0.67s\n",
      "         8           0.6878            0.58s\n",
      "         9           0.6837            0.51s\n",
      "        10           0.6802            0.60s\n",
      "        20           0.6453            0.46s\n",
      "        30           0.6225            0.43s\n",
      "        40           0.6078            0.38s\n",
      "        50           0.5932            0.32s\n",
      "        60           0.5833            0.24s\n",
      "        70           0.5750            0.19s\n",
      "        80           0.5683            0.12s\n",
      "        90           0.5607            0.06s\n",
      "       100           0.5538            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.6751            0.00s\n",
      "         2           0.6608            0.00s\n",
      "         3           0.6407            0.55s\n",
      "         4           0.6292            0.41s\n",
      "         5           0.6179            0.32s\n",
      "         6           0.6042            0.27s\n",
      "         7           0.5959            0.45s\n",
      "         8           0.5867            0.39s\n",
      "         9           0.5798            0.34s\n",
      "        10           0.5705            0.44s\n",
      "        20           0.5243            0.40s\n",
      "        30           0.4986            0.36s\n",
      "        40           0.4826            0.32s\n",
      "        50           0.4703            0.27s\n",
      "        60           0.4617            0.21s\n",
      "        70           0.4541            0.16s\n",
      "        80           0.4486            0.10s\n",
      "        90           0.4423            0.05s\n",
      "       100           0.4363            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.5128            0.00s\n",
      "         2           0.5074            0.00s\n",
      "         3           0.5020            0.51s\n",
      "         4           0.4978            0.38s\n",
      "         5           0.4940            0.30s\n",
      "         6           0.4906            0.50s\n",
      "         7           0.4871            0.42s\n",
      "         8           0.4847            0.36s\n",
      "         9           0.4808            0.48s\n",
      "        10           0.4784            0.43s\n",
      "        20           0.4599            0.42s\n",
      "        30           0.4453            0.37s\n",
      "        40           0.4342            0.30s\n",
      "        50           0.4245            0.26s\n",
      "        60           0.4166            0.22s\n",
      "        70           0.4100            0.16s\n",
      "        80           0.4038            0.10s\n",
      "        90           0.3974            0.05s\n",
      "       100           0.3926            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.5570            0.00s\n",
      "         2           0.5350            0.81s\n",
      "         3           0.5201            0.53s\n",
      "         4           0.5067            0.40s\n",
      "         5           0.4812            0.62s\n",
      "         6           0.4650            0.56s\n",
      "         7           0.4576            0.47s\n",
      "         8           0.4457            0.41s\n",
      "         9           0.4314            0.52s\n",
      "        10           0.4260            0.46s\n",
      "        20           0.3698            0.44s\n",
      "        30           0.3389            0.40s\n",
      "        40           0.3210            0.35s\n",
      "        50           0.3073            0.28s\n",
      "        60           0.2972            0.24s\n",
      "        70           0.2888            0.18s\n",
      "        80           0.2825            0.12s\n",
      "        90           0.2763            0.06s\n",
      "       100           0.2704            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.3016            1.02s\n",
      "         2           0.2924            0.50s\n",
      "         3           0.2855            0.67s\n",
      "         4           0.2801            0.50s\n",
      "         5           0.2748            0.59s\n",
      "         6           0.2703            0.49s\n",
      "         7           0.2673            0.57s\n",
      "         8           0.2650            0.57s\n",
      "         9           0.2622            0.59s\n",
      "        10           0.2591            0.58s\n",
      "        20           0.2363            0.52s\n",
      "        30           0.2217            0.45s\n",
      "        40           0.2133            0.39s\n",
      "        50           0.2064            0.32s\n",
      "        60           0.2011            0.25s\n",
      "        70           0.1959            0.18s\n",
      "        80           0.1907            0.12s\n",
      "        90           0.1862            0.06s\n",
      "       100           0.1818            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.4708            1.56s\n",
      "         2           0.4600            1.02s\n",
      "         3           0.4505            0.86s\n",
      "         4           0.4178            0.78s\n",
      "         5           0.4102            0.63s\n",
      "         6           0.4012            0.52s\n",
      "         7           0.3968            0.68s\n",
      "         8           0.3934            0.64s\n",
      "         9           0.3820            0.62s\n",
      "        10           0.3773            0.60s\n",
      "        20           0.3433            0.44s\n",
      "        30           0.3233            0.41s\n",
      "        40           0.3103            0.33s\n",
      "        50           0.3005            0.27s\n",
      "        60           0.2932            0.22s\n",
      "        70           0.2851            0.16s\n",
      "        80           0.2785            0.11s\n",
      "        90           0.2726            0.05s\n",
      "       100           0.2667            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.4491            0.20s\n",
      "         2           0.4408            0.45s\n",
      "         3           0.4322            0.39s\n",
      "         4           0.4207            0.52s\n",
      "         5           0.4115            0.47s\n",
      "         6           0.4037            0.46s\n",
      "         7           0.3982            0.53s\n",
      "         8           0.3935            0.50s\n",
      "         9           0.3887            0.52s\n",
      "        10           0.3854            0.46s\n",
      "        20           0.3644            0.42s\n",
      "        30           0.3496            0.37s\n",
      "        40           0.3414            0.31s\n",
      "        50           0.3346            0.26s\n",
      "        60           0.3295            0.21s\n",
      "        70           0.3241            0.16s\n",
      "        80           0.3192            0.10s\n",
      "        90           0.3152            0.05s\n",
      "       100           0.3116            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.7666            1.11s\n",
      "         2           0.7417            0.55s\n",
      "         3           0.7272            0.67s\n",
      "         4           0.7154            0.49s\n",
      "         5           0.6994            0.63s\n",
      "         6           0.6874            0.52s\n",
      "         7           0.6770            0.56s\n",
      "         8           0.6698            0.48s\n",
      "         9           0.6637            0.53s\n",
      "        10           0.6561            0.47s\n",
      "        20           0.6082            0.45s\n",
      "        30           0.5806            0.39s\n",
      "        40           0.5643            0.32s\n",
      "        50           0.5528            0.27s\n",
      "        60           0.5435            0.21s\n",
      "        70           0.5347            0.16s\n",
      "        80           0.5277            0.11s\n",
      "        90           0.5219            0.05s\n",
      "       100           0.5165            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.8073            0.79s\n",
      "         2           0.7899            0.82s\n",
      "         3           0.7651            0.76s\n",
      "         4           0.7535            0.72s\n",
      "         5           0.7427            0.72s\n",
      "         6           0.7262            0.59s\n",
      "         7           0.7165            0.67s\n",
      "         8           0.7060            0.66s\n",
      "         9           0.6981            0.63s\n",
      "        10           0.6862            0.63s\n",
      "        20           0.6305            0.47s\n",
      "        30           0.5968            0.43s\n",
      "        40           0.5761            0.35s\n",
      "        50           0.5610            0.30s\n",
      "        60           0.5489            0.23s\n",
      "        70           0.5379            0.18s\n",
      "        80           0.5290            0.12s\n",
      "        90           0.5214            0.06s\n",
      "       100           0.5140            0.00s\n"
     ]
    }
   ],
   "source": [
    "# cross_validate the baseline model on the accuracy, precision, recall and f1\n",
    "gd_clf_scores = cross_validate(gd_clf,x_train,y_train, cv=3, scoring =calculate_scores_multi_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "916a2314-3913-4f5e-8f95-dd5dc8097015",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_accuracy': 90.98,\n",
       " 'test_precision': 68.63,\n",
       " 'test_recall': 59.93,\n",
       " 'test_f1': 58.44}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = ['test_accuracy', 'test_precision','test_recall', 'test_f1']\n",
    "validation_scores = {}\n",
    "for score in scores:\n",
    "    validation_scores[score] = round(gd_clf_scores[score].mean(), 2)\n",
    "validation_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec75eb54-9cd0-4628-9623-a5b7bed49266",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Log Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3c4ef00e-1d51-4fbf-94ec-535cadf8732f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Log the model's dataset train and test indices\n",
    "log_data(x_train,y_train,x_test,y_test)\n",
    "# Log the model, model description\n",
    "model = log_model(gd_clf,'Gradient Boost, multilabel, Data resampled')\n",
    "# Log the model's train and test scores\n",
    "log_metrics(train_scores, validation_scores)\n",
    "# track the model artifacts, validation scores with mlflow \n",
    "track_model(model,validation_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a18298-b423-415f-a724-92cb7794ff49",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Cat Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b9577466-a37a-4aec-a789-e8dc7cf1525b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.029592\n",
      "0:\tlearn: 0.0878972\ttotal: 141ms\tremaining: 2m 20s\n",
      "1:\tlearn: 0.0886043\ttotal: 295ms\tremaining: 2m 27s\n",
      "2:\tlearn: 0.0885909\ttotal: 429ms\tremaining: 2m 22s\n",
      "3:\tlearn: 0.0886399\ttotal: 526ms\tremaining: 2m 10s\n",
      "4:\tlearn: 0.0886399\ttotal: 662ms\tremaining: 2m 11s\n",
      "5:\tlearn: 0.0886354\ttotal: 793ms\tremaining: 2m 11s\n",
      "6:\tlearn: 0.0886221\ttotal: 923ms\tremaining: 2m 10s\n",
      "7:\tlearn: 0.0886354\ttotal: 1.07s\tremaining: 2m 12s\n",
      "8:\tlearn: 0.0886399\ttotal: 1.2s\tremaining: 2m 12s\n",
      "9:\tlearn: 0.0886399\ttotal: 1.33s\tremaining: 2m 12s\n",
      "10:\tlearn: 0.0886399\ttotal: 1.48s\tremaining: 2m 12s\n",
      "11:\tlearn: 0.0886399\ttotal: 1.62s\tremaining: 2m 13s\n",
      "12:\tlearn: 0.0886399\ttotal: 1.75s\tremaining: 2m 13s\n",
      "13:\tlearn: 0.0886354\ttotal: 1.89s\tremaining: 2m 12s\n",
      "14:\tlearn: 0.0886399\ttotal: 2.02s\tremaining: 2m 12s\n",
      "15:\tlearn: 0.0886399\ttotal: 2.16s\tremaining: 2m 12s\n",
      "16:\tlearn: 0.0886399\ttotal: 2.32s\tremaining: 2m 14s\n",
      "17:\tlearn: 0.0886399\ttotal: 2.46s\tremaining: 2m 13s\n",
      "18:\tlearn: 0.0886399\ttotal: 2.59s\tremaining: 2m 13s\n",
      "19:\tlearn: 0.0886399\ttotal: 2.73s\tremaining: 2m 13s\n",
      "20:\tlearn: 0.0886399\ttotal: 2.86s\tremaining: 2m 13s\n",
      "21:\tlearn: 0.0886399\ttotal: 3s\tremaining: 2m 13s\n",
      "22:\tlearn: 0.0886399\ttotal: 3.15s\tremaining: 2m 13s\n",
      "23:\tlearn: 0.0886399\ttotal: 3.29s\tremaining: 2m 13s\n",
      "24:\tlearn: 0.0886265\ttotal: 3.43s\tremaining: 2m 13s\n",
      "25:\tlearn: 0.0886176\ttotal: 3.56s\tremaining: 2m 13s\n",
      "26:\tlearn: 0.0886176\ttotal: 3.71s\tremaining: 2m 13s\n",
      "27:\tlearn: 0.0886221\ttotal: 3.85s\tremaining: 2m 13s\n",
      "28:\tlearn: 0.0886087\ttotal: 4s\tremaining: 2m 13s\n",
      "29:\tlearn: 0.0885820\ttotal: 4.13s\tremaining: 2m 13s\n",
      "30:\tlearn: 0.0885909\ttotal: 4.26s\tremaining: 2m 13s\n",
      "31:\tlearn: 0.0885909\ttotal: 4.4s\tremaining: 2m 13s\n",
      "32:\tlearn: 0.0885687\ttotal: 4.54s\tremaining: 2m 13s\n",
      "33:\tlearn: 0.0885554\ttotal: 4.68s\tremaining: 2m 13s\n",
      "34:\tlearn: 0.0885598\ttotal: 4.82s\tremaining: 2m 12s\n",
      "35:\tlearn: 0.0885331\ttotal: 4.96s\tremaining: 2m 12s\n",
      "36:\tlearn: 0.0884931\ttotal: 5.09s\tremaining: 2m 12s\n",
      "37:\tlearn: 0.0885020\ttotal: 5.23s\tremaining: 2m 12s\n",
      "38:\tlearn: 0.0884664\ttotal: 5.36s\tremaining: 2m 12s\n",
      "39:\tlearn: 0.0884575\ttotal: 5.5s\tremaining: 2m 12s\n",
      "40:\tlearn: 0.0884531\ttotal: 5.65s\tremaining: 2m 12s\n",
      "41:\tlearn: 0.0884353\ttotal: 5.79s\tremaining: 2m 12s\n",
      "42:\tlearn: 0.0884353\ttotal: 5.93s\tremaining: 2m 11s\n",
      "43:\tlearn: 0.0883953\ttotal: 6.07s\tremaining: 2m 11s\n",
      "44:\tlearn: 0.0883730\ttotal: 6.2s\tremaining: 2m 11s\n",
      "45:\tlearn: 0.0883686\ttotal: 6.34s\tremaining: 2m 11s\n",
      "46:\tlearn: 0.0883330\ttotal: 6.47s\tremaining: 2m 11s\n",
      "47:\tlearn: 0.0882618\ttotal: 6.61s\tremaining: 2m 11s\n",
      "48:\tlearn: 0.0882396\ttotal: 6.75s\tremaining: 2m 10s\n",
      "49:\tlearn: 0.0881862\ttotal: 6.88s\tremaining: 2m 10s\n",
      "50:\tlearn: 0.0881284\ttotal: 7.02s\tremaining: 2m 10s\n",
      "51:\tlearn: 0.0880973\ttotal: 7.15s\tremaining: 2m 10s\n",
      "52:\tlearn: 0.0880662\ttotal: 7.29s\tremaining: 2m 10s\n",
      "53:\tlearn: 0.0880439\ttotal: 7.47s\tremaining: 2m 10s\n",
      "54:\tlearn: 0.0880173\ttotal: 7.64s\tremaining: 2m 11s\n",
      "55:\tlearn: 0.0879550\ttotal: 7.79s\tremaining: 2m 11s\n",
      "56:\tlearn: 0.0879150\ttotal: 7.95s\tremaining: 2m 11s\n",
      "57:\tlearn: 0.0878794\ttotal: 8.12s\tremaining: 2m 11s\n",
      "58:\tlearn: 0.0878216\ttotal: 8.27s\tremaining: 2m 11s\n",
      "59:\tlearn: 0.0877727\ttotal: 8.41s\tremaining: 2m 11s\n",
      "60:\tlearn: 0.0876926\ttotal: 8.55s\tremaining: 2m 11s\n",
      "61:\tlearn: 0.0876170\ttotal: 8.71s\tremaining: 2m 11s\n",
      "62:\tlearn: 0.0875414\ttotal: 8.85s\tremaining: 2m 11s\n",
      "63:\tlearn: 0.0875370\ttotal: 9s\tremaining: 2m 11s\n",
      "64:\tlearn: 0.0874969\ttotal: 9.14s\tremaining: 2m 11s\n",
      "65:\tlearn: 0.0874347\ttotal: 9.28s\tremaining: 2m 11s\n",
      "66:\tlearn: 0.0873813\ttotal: 9.44s\tremaining: 2m 11s\n",
      "67:\tlearn: 0.0872390\ttotal: 9.59s\tremaining: 2m 11s\n",
      "68:\tlearn: 0.0871901\ttotal: 9.73s\tremaining: 2m 11s\n",
      "69:\tlearn: 0.0871234\ttotal: 9.86s\tremaining: 2m 11s\n",
      "70:\tlearn: 0.0871189\ttotal: 10s\tremaining: 2m 10s\n",
      "71:\tlearn: 0.0870789\ttotal: 10.2s\tremaining: 2m 10s\n",
      "72:\tlearn: 0.0870478\ttotal: 10.3s\tremaining: 2m 10s\n",
      "73:\tlearn: 0.0869633\ttotal: 10.4s\tremaining: 2m 10s\n",
      "74:\tlearn: 0.0869544\ttotal: 10.6s\tremaining: 2m 10s\n",
      "75:\tlearn: 0.0868699\ttotal: 10.7s\tremaining: 2m 10s\n",
      "76:\tlearn: 0.0867543\ttotal: 10.9s\tremaining: 2m 10s\n",
      "77:\tlearn: 0.0866564\ttotal: 11s\tremaining: 2m 10s\n",
      "78:\tlearn: 0.0865986\ttotal: 11.2s\tremaining: 2m 10s\n",
      "79:\tlearn: 0.0864519\ttotal: 11.3s\tremaining: 2m 10s\n",
      "80:\tlearn: 0.0863362\ttotal: 11.5s\tremaining: 2m 10s\n",
      "81:\tlearn: 0.0863007\ttotal: 11.6s\tremaining: 2m 9s\n",
      "82:\tlearn: 0.0861984\ttotal: 11.8s\tremaining: 2m 9s\n",
      "83:\tlearn: 0.0861584\ttotal: 11.9s\tremaining: 2m 9s\n",
      "84:\tlearn: 0.0860694\ttotal: 12.1s\tremaining: 2m 9s\n",
      "85:\tlearn: 0.0859983\ttotal: 12.2s\tremaining: 2m 9s\n",
      "86:\tlearn: 0.0859760\ttotal: 12.4s\tremaining: 2m 9s\n",
      "87:\tlearn: 0.0859360\ttotal: 12.5s\tremaining: 2m 9s\n",
      "88:\tlearn: 0.0857893\ttotal: 12.7s\tremaining: 2m 9s\n",
      "89:\tlearn: 0.0856825\ttotal: 12.8s\tremaining: 2m 9s\n",
      "90:\tlearn: 0.0855536\ttotal: 12.9s\tremaining: 2m 9s\n",
      "91:\tlearn: 0.0854957\ttotal: 13.1s\tremaining: 2m 9s\n",
      "92:\tlearn: 0.0853890\ttotal: 13.2s\tremaining: 2m 8s\n",
      "93:\tlearn: 0.0853268\ttotal: 13.4s\tremaining: 2m 8s\n",
      "94:\tlearn: 0.0852734\ttotal: 13.5s\tremaining: 2m 8s\n",
      "95:\tlearn: 0.0852156\ttotal: 13.7s\tremaining: 2m 8s\n",
      "96:\tlearn: 0.0850866\ttotal: 13.8s\tremaining: 2m 8s\n",
      "97:\tlearn: 0.0849754\ttotal: 14s\tremaining: 2m 8s\n",
      "98:\tlearn: 0.0848865\ttotal: 14.1s\tremaining: 2m 8s\n",
      "99:\tlearn: 0.0847575\ttotal: 14.3s\tremaining: 2m 8s\n",
      "100:\tlearn: 0.0846819\ttotal: 14.4s\tremaining: 2m 8s\n",
      "101:\tlearn: 0.0845841\ttotal: 14.5s\tremaining: 2m 7s\n",
      "102:\tlearn: 0.0844507\ttotal: 14.7s\tremaining: 2m 7s\n",
      "103:\tlearn: 0.0844240\ttotal: 14.8s\tremaining: 2m 7s\n",
      "104:\tlearn: 0.0843262\ttotal: 15s\tremaining: 2m 7s\n",
      "105:\tlearn: 0.0842372\ttotal: 15.1s\tremaining: 2m 7s\n",
      "106:\tlearn: 0.0841794\ttotal: 15.3s\tremaining: 2m 7s\n",
      "107:\tlearn: 0.0841349\ttotal: 15.4s\tremaining: 2m 7s\n",
      "108:\tlearn: 0.0840504\ttotal: 15.5s\tremaining: 2m 6s\n",
      "109:\tlearn: 0.0839793\ttotal: 15.7s\tremaining: 2m 6s\n",
      "110:\tlearn: 0.0838903\ttotal: 15.8s\tremaining: 2m 6s\n",
      "111:\tlearn: 0.0838058\ttotal: 15.9s\tremaining: 2m 6s\n",
      "112:\tlearn: 0.0837169\ttotal: 16.1s\tremaining: 2m 6s\n",
      "113:\tlearn: 0.0836457\ttotal: 16.2s\tremaining: 2m 6s\n",
      "114:\tlearn: 0.0835524\ttotal: 16.4s\tremaining: 2m 5s\n",
      "115:\tlearn: 0.0834367\ttotal: 16.5s\tremaining: 2m 5s\n",
      "116:\tlearn: 0.0833789\ttotal: 16.6s\tremaining: 2m 5s\n",
      "117:\tlearn: 0.0833167\ttotal: 16.8s\tremaining: 2m 5s\n",
      "118:\tlearn: 0.0832455\ttotal: 16.9s\tremaining: 2m 5s\n",
      "119:\tlearn: 0.0831966\ttotal: 17s\tremaining: 2m 5s\n",
      "120:\tlearn: 0.0831432\ttotal: 17.2s\tremaining: 2m 4s\n",
      "121:\tlearn: 0.0830632\ttotal: 17.3s\tremaining: 2m 4s\n",
      "122:\tlearn: 0.0830098\ttotal: 17.5s\tremaining: 2m 4s\n",
      "123:\tlearn: 0.0828808\ttotal: 17.6s\tremaining: 2m 4s\n",
      "124:\tlearn: 0.0828097\ttotal: 17.7s\tremaining: 2m 4s\n",
      "125:\tlearn: 0.0827786\ttotal: 17.9s\tremaining: 2m 4s\n",
      "126:\tlearn: 0.0827341\ttotal: 18s\tremaining: 2m 3s\n",
      "127:\tlearn: 0.0826318\ttotal: 18.2s\tremaining: 2m 3s\n",
      "128:\tlearn: 0.0825695\ttotal: 18.3s\tremaining: 2m 3s\n",
      "129:\tlearn: 0.0824717\ttotal: 18.4s\tremaining: 2m 3s\n",
      "130:\tlearn: 0.0823605\ttotal: 18.6s\tremaining: 2m 3s\n",
      "131:\tlearn: 0.0823205\ttotal: 18.7s\tremaining: 2m 2s\n",
      "132:\tlearn: 0.0822405\ttotal: 18.8s\tremaining: 2m 2s\n",
      "133:\tlearn: 0.0821604\ttotal: 19s\tremaining: 2m 2s\n",
      "134:\tlearn: 0.0820448\ttotal: 19.1s\tremaining: 2m 2s\n",
      "135:\tlearn: 0.0819425\ttotal: 19.3s\tremaining: 2m 2s\n",
      "136:\tlearn: 0.0818358\ttotal: 19.4s\tremaining: 2m 2s\n",
      "137:\tlearn: 0.0816935\ttotal: 19.5s\tremaining: 2m 2s\n",
      "138:\tlearn: 0.0816268\ttotal: 19.7s\tremaining: 2m 1s\n",
      "139:\tlearn: 0.0815912\ttotal: 19.8s\tremaining: 2m 1s\n",
      "140:\tlearn: 0.0815334\ttotal: 20s\tremaining: 2m 1s\n",
      "141:\tlearn: 0.0814311\ttotal: 20.1s\tremaining: 2m 1s\n",
      "142:\tlearn: 0.0813555\ttotal: 20.2s\tremaining: 2m 1s\n",
      "143:\tlearn: 0.0812710\ttotal: 20.4s\tremaining: 2m 1s\n",
      "144:\tlearn: 0.0811820\ttotal: 20.5s\tremaining: 2m 1s\n",
      "145:\tlearn: 0.0811109\ttotal: 20.7s\tremaining: 2m\n",
      "146:\tlearn: 0.0810086\ttotal: 20.8s\tremaining: 2m\n",
      "147:\tlearn: 0.0809241\ttotal: 21s\tremaining: 2m\n",
      "148:\tlearn: 0.0808485\ttotal: 21.1s\tremaining: 2m\n",
      "149:\tlearn: 0.0807596\ttotal: 21.3s\tremaining: 2m\n",
      "150:\tlearn: 0.0806884\ttotal: 21.4s\tremaining: 2m\n",
      "151:\tlearn: 0.0806350\ttotal: 21.5s\tremaining: 2m\n",
      "152:\tlearn: 0.0805105\ttotal: 21.7s\tremaining: 2m\n",
      "153:\tlearn: 0.0804349\ttotal: 21.8s\tremaining: 1m 59s\n",
      "154:\tlearn: 0.0803638\ttotal: 21.9s\tremaining: 1m 59s\n",
      "155:\tlearn: 0.0802793\ttotal: 22.1s\tremaining: 1m 59s\n",
      "156:\tlearn: 0.0802348\ttotal: 22.2s\tremaining: 1m 59s\n",
      "157:\tlearn: 0.0801370\ttotal: 22.4s\tremaining: 1m 59s\n",
      "158:\tlearn: 0.0800525\ttotal: 22.5s\tremaining: 1m 59s\n",
      "159:\tlearn: 0.0800036\ttotal: 22.6s\tremaining: 1m 58s\n",
      "160:\tlearn: 0.0799680\ttotal: 22.8s\tremaining: 1m 58s\n",
      "161:\tlearn: 0.0798568\ttotal: 23s\tremaining: 1m 58s\n",
      "162:\tlearn: 0.0798079\ttotal: 23.1s\tremaining: 1m 58s\n",
      "163:\tlearn: 0.0796967\ttotal: 23.2s\tremaining: 1m 58s\n",
      "164:\tlearn: 0.0796078\ttotal: 23.4s\tremaining: 1m 58s\n",
      "165:\tlearn: 0.0795677\ttotal: 23.5s\tremaining: 1m 58s\n",
      "166:\tlearn: 0.0795010\ttotal: 23.7s\tremaining: 1m 58s\n",
      "167:\tlearn: 0.0794877\ttotal: 23.8s\tremaining: 1m 58s\n",
      "168:\tlearn: 0.0793988\ttotal: 24s\tremaining: 1m 57s\n",
      "169:\tlearn: 0.0793454\ttotal: 24.1s\tremaining: 1m 57s\n",
      "170:\tlearn: 0.0793009\ttotal: 24.2s\tremaining: 1m 57s\n",
      "171:\tlearn: 0.0792431\ttotal: 24.4s\tremaining: 1m 57s\n",
      "172:\tlearn: 0.0791008\ttotal: 24.5s\tremaining: 1m 57s\n",
      "173:\tlearn: 0.0790830\ttotal: 24.7s\tremaining: 1m 57s\n",
      "174:\tlearn: 0.0789941\ttotal: 24.8s\tremaining: 1m 56s\n",
      "175:\tlearn: 0.0789318\ttotal: 25s\tremaining: 1m 56s\n",
      "176:\tlearn: 0.0788295\ttotal: 25.1s\tremaining: 1m 56s\n",
      "177:\tlearn: 0.0787228\ttotal: 25.2s\tremaining: 1m 56s\n",
      "178:\tlearn: 0.0786516\ttotal: 25.4s\tremaining: 1m 56s\n",
      "179:\tlearn: 0.0785671\ttotal: 25.5s\tremaining: 1m 56s\n",
      "180:\tlearn: 0.0785671\ttotal: 25.6s\tremaining: 1m 56s\n",
      "181:\tlearn: 0.0784782\ttotal: 25.8s\tremaining: 1m 55s\n",
      "182:\tlearn: 0.0784204\ttotal: 25.9s\tremaining: 1m 55s\n",
      "183:\tlearn: 0.0783893\ttotal: 26.1s\tremaining: 1m 55s\n",
      "184:\tlearn: 0.0782914\ttotal: 26.2s\tremaining: 1m 55s\n",
      "185:\tlearn: 0.0782959\ttotal: 26.3s\tremaining: 1m 55s\n",
      "186:\tlearn: 0.0782381\ttotal: 26.5s\tremaining: 1m 55s\n",
      "187:\tlearn: 0.0781669\ttotal: 26.6s\tremaining: 1m 54s\n",
      "188:\tlearn: 0.0781313\ttotal: 26.8s\tremaining: 1m 54s\n",
      "189:\tlearn: 0.0779757\ttotal: 26.9s\tremaining: 1m 54s\n",
      "190:\tlearn: 0.0779445\ttotal: 27s\tremaining: 1m 54s\n",
      "191:\tlearn: 0.0779223\ttotal: 27.2s\tremaining: 1m 54s\n",
      "192:\tlearn: 0.0778556\ttotal: 27.3s\tremaining: 1m 54s\n",
      "193:\tlearn: 0.0778022\ttotal: 27.4s\tremaining: 1m 54s\n",
      "194:\tlearn: 0.0777489\ttotal: 27.6s\tremaining: 1m 53s\n",
      "195:\tlearn: 0.0776688\ttotal: 27.7s\tremaining: 1m 53s\n",
      "196:\tlearn: 0.0775754\ttotal: 27.9s\tremaining: 1m 53s\n",
      "197:\tlearn: 0.0775310\ttotal: 28s\tremaining: 1m 53s\n",
      "198:\tlearn: 0.0774687\ttotal: 28.2s\tremaining: 1m 53s\n",
      "199:\tlearn: 0.0774598\ttotal: 28.3s\tremaining: 1m 53s\n",
      "200:\tlearn: 0.0774242\ttotal: 28.4s\tremaining: 1m 53s\n",
      "201:\tlearn: 0.0773887\ttotal: 28.6s\tremaining: 1m 52s\n",
      "202:\tlearn: 0.0773219\ttotal: 28.7s\tremaining: 1m 52s\n",
      "203:\tlearn: 0.0772686\ttotal: 28.9s\tremaining: 1m 52s\n",
      "204:\tlearn: 0.0771885\ttotal: 29s\tremaining: 1m 52s\n",
      "205:\tlearn: 0.0771485\ttotal: 29.1s\tremaining: 1m 52s\n",
      "206:\tlearn: 0.0771129\ttotal: 29.3s\tremaining: 1m 52s\n",
      "207:\tlearn: 0.0770774\ttotal: 29.4s\tremaining: 1m 51s\n",
      "208:\tlearn: 0.0769884\ttotal: 29.5s\tremaining: 1m 51s\n",
      "209:\tlearn: 0.0768683\ttotal: 29.7s\tremaining: 1m 51s\n",
      "210:\tlearn: 0.0768372\ttotal: 29.8s\tremaining: 1m 51s\n",
      "211:\tlearn: 0.0767972\ttotal: 30s\tremaining: 1m 51s\n",
      "212:\tlearn: 0.0766994\ttotal: 30.1s\tremaining: 1m 51s\n",
      "213:\tlearn: 0.0766905\ttotal: 30.2s\tremaining: 1m 51s\n",
      "214:\tlearn: 0.0766149\ttotal: 30.4s\tremaining: 1m 50s\n",
      "215:\tlearn: 0.0765926\ttotal: 30.5s\tremaining: 1m 50s\n",
      "216:\tlearn: 0.0764992\ttotal: 30.6s\tremaining: 1m 50s\n",
      "217:\tlearn: 0.0764592\ttotal: 30.8s\tremaining: 1m 50s\n",
      "218:\tlearn: 0.0763925\ttotal: 31s\tremaining: 1m 50s\n",
      "219:\tlearn: 0.0763703\ttotal: 31.1s\tremaining: 1m 50s\n",
      "220:\tlearn: 0.0763703\ttotal: 31.2s\tremaining: 1m 50s\n",
      "221:\tlearn: 0.0762858\ttotal: 31.4s\tremaining: 1m 49s\n",
      "222:\tlearn: 0.0762013\ttotal: 31.5s\tremaining: 1m 49s\n",
      "223:\tlearn: 0.0762191\ttotal: 31.6s\tremaining: 1m 49s\n",
      "224:\tlearn: 0.0762146\ttotal: 31.8s\tremaining: 1m 49s\n",
      "225:\tlearn: 0.0761924\ttotal: 31.9s\tremaining: 1m 49s\n",
      "226:\tlearn: 0.0761390\ttotal: 32s\tremaining: 1m 48s\n",
      "227:\tlearn: 0.0760812\ttotal: 32.1s\tremaining: 1m 48s\n",
      "228:\tlearn: 0.0760812\ttotal: 32.3s\tremaining: 1m 48s\n",
      "229:\tlearn: 0.0760234\ttotal: 32.4s\tremaining: 1m 48s\n",
      "230:\tlearn: 0.0760012\ttotal: 32.5s\tremaining: 1m 48s\n",
      "231:\tlearn: 0.0759167\ttotal: 32.7s\tremaining: 1m 48s\n",
      "232:\tlearn: 0.0758411\ttotal: 32.8s\tremaining: 1m 48s\n",
      "233:\tlearn: 0.0757388\ttotal: 33s\tremaining: 1m 47s\n",
      "234:\tlearn: 0.0757032\ttotal: 33.1s\tremaining: 1m 47s\n",
      "235:\tlearn: 0.0756676\ttotal: 33.2s\tremaining: 1m 47s\n",
      "236:\tlearn: 0.0756187\ttotal: 33.4s\tremaining: 1m 47s\n",
      "237:\tlearn: 0.0755876\ttotal: 33.5s\tremaining: 1m 47s\n",
      "238:\tlearn: 0.0755164\ttotal: 33.7s\tremaining: 1m 47s\n",
      "239:\tlearn: 0.0754719\ttotal: 33.8s\tremaining: 1m 47s\n",
      "240:\tlearn: 0.0753963\ttotal: 33.9s\tremaining: 1m 46s\n",
      "241:\tlearn: 0.0753341\ttotal: 34.1s\tremaining: 1m 46s\n",
      "242:\tlearn: 0.0752540\ttotal: 34.2s\tremaining: 1m 46s\n",
      "243:\tlearn: 0.0752007\ttotal: 34.3s\tremaining: 1m 46s\n",
      "244:\tlearn: 0.0751695\ttotal: 34.5s\tremaining: 1m 46s\n",
      "245:\tlearn: 0.0751295\ttotal: 34.6s\tremaining: 1m 46s\n",
      "246:\tlearn: 0.0750806\ttotal: 34.7s\tremaining: 1m 45s\n",
      "247:\tlearn: 0.0750361\ttotal: 34.9s\tremaining: 1m 45s\n",
      "248:\tlearn: 0.0749872\ttotal: 35s\tremaining: 1m 45s\n",
      "249:\tlearn: 0.0749516\ttotal: 35.1s\tremaining: 1m 45s\n",
      "250:\tlearn: 0.0748894\ttotal: 35.3s\tremaining: 1m 45s\n",
      "251:\tlearn: 0.0748405\ttotal: 35.4s\tremaining: 1m 45s\n",
      "252:\tlearn: 0.0747871\ttotal: 35.6s\tremaining: 1m 45s\n",
      "253:\tlearn: 0.0747649\ttotal: 35.7s\tremaining: 1m 44s\n",
      "254:\tlearn: 0.0746893\ttotal: 35.8s\tremaining: 1m 44s\n",
      "255:\tlearn: 0.0746181\ttotal: 36s\tremaining: 1m 44s\n",
      "256:\tlearn: 0.0745647\ttotal: 36.1s\tremaining: 1m 44s\n",
      "257:\tlearn: 0.0745203\ttotal: 36.3s\tremaining: 1m 44s\n",
      "258:\tlearn: 0.0744625\ttotal: 36.4s\tremaining: 1m 44s\n",
      "259:\tlearn: 0.0743913\ttotal: 36.5s\tremaining: 1m 43s\n",
      "260:\tlearn: 0.0743557\ttotal: 36.7s\tremaining: 1m 43s\n",
      "261:\tlearn: 0.0742757\ttotal: 36.8s\tremaining: 1m 43s\n",
      "262:\tlearn: 0.0742757\ttotal: 37s\tremaining: 1m 43s\n",
      "263:\tlearn: 0.0742223\ttotal: 37.1s\tremaining: 1m 43s\n",
      "264:\tlearn: 0.0741778\ttotal: 37.2s\tremaining: 1m 43s\n",
      "265:\tlearn: 0.0741022\ttotal: 37.4s\tremaining: 1m 43s\n",
      "266:\tlearn: 0.0740622\ttotal: 37.6s\tremaining: 1m 43s\n",
      "267:\tlearn: 0.0740133\ttotal: 37.8s\tremaining: 1m 43s\n",
      "268:\tlearn: 0.0740133\ttotal: 37.9s\tremaining: 1m 43s\n",
      "269:\tlearn: 0.0739866\ttotal: 38.1s\tremaining: 1m 42s\n",
      "270:\tlearn: 0.0739288\ttotal: 38.2s\tremaining: 1m 42s\n",
      "271:\tlearn: 0.0738843\ttotal: 38.4s\tremaining: 1m 42s\n",
      "272:\tlearn: 0.0738576\ttotal: 38.5s\tremaining: 1m 42s\n",
      "273:\tlearn: 0.0737954\ttotal: 38.6s\tremaining: 1m 42s\n",
      "274:\tlearn: 0.0737732\ttotal: 38.8s\tremaining: 1m 42s\n",
      "275:\tlearn: 0.0736709\ttotal: 38.9s\tremaining: 1m 42s\n",
      "276:\tlearn: 0.0736486\ttotal: 39.1s\tremaining: 1m 41s\n",
      "277:\tlearn: 0.0735953\ttotal: 39.2s\tremaining: 1m 41s\n",
      "278:\tlearn: 0.0735819\ttotal: 39.3s\tremaining: 1m 41s\n",
      "279:\tlearn: 0.0735375\ttotal: 39.5s\tremaining: 1m 41s\n",
      "280:\tlearn: 0.0735286\ttotal: 39.6s\tremaining: 1m 41s\n",
      "281:\tlearn: 0.0734885\ttotal: 39.7s\tremaining: 1m 41s\n",
      "282:\tlearn: 0.0734619\ttotal: 39.9s\tremaining: 1m 41s\n",
      "283:\tlearn: 0.0734040\ttotal: 40s\tremaining: 1m 40s\n",
      "284:\tlearn: 0.0733373\ttotal: 40.2s\tremaining: 1m 40s\n",
      "285:\tlearn: 0.0733507\ttotal: 40.3s\tremaining: 1m 40s\n",
      "286:\tlearn: 0.0732306\ttotal: 40.4s\tremaining: 1m 40s\n",
      "287:\tlearn: 0.0732084\ttotal: 40.6s\tremaining: 1m 40s\n",
      "288:\tlearn: 0.0732395\ttotal: 40.7s\tremaining: 1m 40s\n",
      "289:\tlearn: 0.0731906\ttotal: 40.9s\tremaining: 1m 40s\n",
      "290:\tlearn: 0.0731194\ttotal: 41s\tremaining: 1m 39s\n",
      "291:\tlearn: 0.0730661\ttotal: 41.1s\tremaining: 1m 39s\n",
      "292:\tlearn: 0.0729949\ttotal: 41.3s\tremaining: 1m 39s\n",
      "293:\tlearn: 0.0729593\ttotal: 41.4s\tremaining: 1m 39s\n",
      "294:\tlearn: 0.0729549\ttotal: 41.5s\tremaining: 1m 39s\n",
      "295:\tlearn: 0.0729415\ttotal: 41.7s\tremaining: 1m 39s\n",
      "296:\tlearn: 0.0728971\ttotal: 41.8s\tremaining: 1m 38s\n",
      "297:\tlearn: 0.0728748\ttotal: 41.9s\tremaining: 1m 38s\n",
      "298:\tlearn: 0.0728081\ttotal: 42.1s\tremaining: 1m 38s\n",
      "299:\tlearn: 0.0728037\ttotal: 42.2s\tremaining: 1m 38s\n",
      "300:\tlearn: 0.0726925\ttotal: 42.4s\tremaining: 1m 38s\n",
      "301:\tlearn: 0.0726214\ttotal: 42.5s\tremaining: 1m 38s\n",
      "302:\tlearn: 0.0725724\ttotal: 42.6s\tremaining: 1m 38s\n",
      "303:\tlearn: 0.0725680\ttotal: 42.8s\tremaining: 1m 37s\n",
      "304:\tlearn: 0.0725057\ttotal: 42.9s\tremaining: 1m 37s\n",
      "305:\tlearn: 0.0725102\ttotal: 43.1s\tremaining: 1m 37s\n",
      "306:\tlearn: 0.0724568\ttotal: 43.2s\tremaining: 1m 37s\n",
      "307:\tlearn: 0.0724390\ttotal: 43.3s\tremaining: 1m 37s\n",
      "308:\tlearn: 0.0723679\ttotal: 43.5s\tremaining: 1m 37s\n",
      "309:\tlearn: 0.0723634\ttotal: 43.6s\tremaining: 1m 37s\n",
      "310:\tlearn: 0.0723056\ttotal: 43.8s\tremaining: 1m 36s\n",
      "311:\tlearn: 0.0722656\ttotal: 43.9s\tremaining: 1m 36s\n",
      "312:\tlearn: 0.0722300\ttotal: 44s\tremaining: 1m 36s\n",
      "313:\tlearn: 0.0721855\ttotal: 44.2s\tremaining: 1m 36s\n",
      "314:\tlearn: 0.0721366\ttotal: 44.3s\tremaining: 1m 36s\n",
      "315:\tlearn: 0.0721099\ttotal: 44.5s\tremaining: 1m 36s\n",
      "316:\tlearn: 0.0720699\ttotal: 44.6s\tremaining: 1m 36s\n",
      "317:\tlearn: 0.0719943\ttotal: 44.8s\tremaining: 1m 36s\n",
      "318:\tlearn: 0.0719365\ttotal: 44.9s\tremaining: 1m 35s\n",
      "319:\tlearn: 0.0719187\ttotal: 45.1s\tremaining: 1m 35s\n",
      "320:\tlearn: 0.0718920\ttotal: 45.2s\tremaining: 1m 35s\n",
      "321:\tlearn: 0.0718653\ttotal: 45.4s\tremaining: 1m 35s\n",
      "322:\tlearn: 0.0718031\ttotal: 45.5s\tremaining: 1m 35s\n",
      "323:\tlearn: 0.0717897\ttotal: 45.7s\tremaining: 1m 35s\n",
      "324:\tlearn: 0.0717631\ttotal: 45.9s\tremaining: 1m 35s\n",
      "325:\tlearn: 0.0716697\ttotal: 46s\tremaining: 1m 35s\n",
      "326:\tlearn: 0.0715807\ttotal: 46.1s\tremaining: 1m 34s\n",
      "327:\tlearn: 0.0716119\ttotal: 46.3s\tremaining: 1m 34s\n",
      "328:\tlearn: 0.0715763\ttotal: 46.4s\tremaining: 1m 34s\n",
      "329:\tlearn: 0.0714695\ttotal: 46.6s\tremaining: 1m 34s\n",
      "330:\tlearn: 0.0714473\ttotal: 46.7s\tremaining: 1m 34s\n",
      "331:\tlearn: 0.0714073\ttotal: 46.8s\tremaining: 1m 34s\n",
      "332:\tlearn: 0.0713939\ttotal: 47s\tremaining: 1m 34s\n",
      "333:\tlearn: 0.0713450\ttotal: 47.1s\tremaining: 1m 33s\n",
      "334:\tlearn: 0.0713450\ttotal: 47.3s\tremaining: 1m 33s\n",
      "335:\tlearn: 0.0713183\ttotal: 47.4s\tremaining: 1m 33s\n",
      "336:\tlearn: 0.0712739\ttotal: 47.6s\tremaining: 1m 33s\n",
      "337:\tlearn: 0.0712561\ttotal: 47.7s\tremaining: 1m 33s\n",
      "338:\tlearn: 0.0712339\ttotal: 47.8s\tremaining: 1m 33s\n",
      "339:\tlearn: 0.0711849\ttotal: 48s\tremaining: 1m 33s\n",
      "340:\tlearn: 0.0710826\ttotal: 48.2s\tremaining: 1m 33s\n",
      "341:\tlearn: 0.0710871\ttotal: 48.3s\tremaining: 1m 32s\n",
      "342:\tlearn: 0.0710871\ttotal: 48.4s\tremaining: 1m 32s\n",
      "343:\tlearn: 0.0710693\ttotal: 48.6s\tremaining: 1m 32s\n",
      "344:\tlearn: 0.0710248\ttotal: 48.7s\tremaining: 1m 32s\n",
      "345:\tlearn: 0.0709226\ttotal: 48.9s\tremaining: 1m 32s\n",
      "346:\tlearn: 0.0708870\ttotal: 49s\tremaining: 1m 32s\n",
      "347:\tlearn: 0.0708114\ttotal: 49.2s\tremaining: 1m 32s\n",
      "348:\tlearn: 0.0707580\ttotal: 49.3s\tremaining: 1m 32s\n",
      "349:\tlearn: 0.0707091\ttotal: 49.5s\tremaining: 1m 31s\n",
      "350:\tlearn: 0.0707358\ttotal: 49.6s\tremaining: 1m 31s\n",
      "351:\tlearn: 0.0706869\ttotal: 49.8s\tremaining: 1m 31s\n",
      "352:\tlearn: 0.0706646\ttotal: 49.9s\tremaining: 1m 31s\n",
      "353:\tlearn: 0.0706157\ttotal: 50.1s\tremaining: 1m 31s\n",
      "354:\tlearn: 0.0705846\ttotal: 50.2s\tremaining: 1m 31s\n",
      "355:\tlearn: 0.0705223\ttotal: 50.4s\tremaining: 1m 31s\n",
      "356:\tlearn: 0.0705134\ttotal: 50.5s\tremaining: 1m 31s\n",
      "357:\tlearn: 0.0704912\ttotal: 50.7s\tremaining: 1m 30s\n",
      "358:\tlearn: 0.0703978\ttotal: 50.9s\tremaining: 1m 30s\n",
      "359:\tlearn: 0.0703400\ttotal: 51s\tremaining: 1m 30s\n",
      "360:\tlearn: 0.0702644\ttotal: 51.2s\tremaining: 1m 30s\n",
      "361:\tlearn: 0.0702421\ttotal: 51.3s\tremaining: 1m 30s\n",
      "362:\tlearn: 0.0702021\ttotal: 51.5s\tremaining: 1m 30s\n",
      "363:\tlearn: 0.0701532\ttotal: 51.6s\tremaining: 1m 30s\n",
      "364:\tlearn: 0.0701265\ttotal: 51.8s\tremaining: 1m 30s\n",
      "365:\tlearn: 0.0700865\ttotal: 52s\tremaining: 1m 29s\n",
      "366:\tlearn: 0.0700732\ttotal: 52.1s\tremaining: 1m 29s\n",
      "367:\tlearn: 0.0700331\ttotal: 52.2s\tremaining: 1m 29s\n",
      "368:\tlearn: 0.0700242\ttotal: 52.4s\tremaining: 1m 29s\n",
      "369:\tlearn: 0.0699575\ttotal: 52.6s\tremaining: 1m 29s\n",
      "370:\tlearn: 0.0699131\ttotal: 52.8s\tremaining: 1m 29s\n",
      "371:\tlearn: 0.0698686\ttotal: 52.9s\tremaining: 1m 29s\n",
      "372:\tlearn: 0.0698286\ttotal: 53.1s\tremaining: 1m 29s\n",
      "373:\tlearn: 0.0698375\ttotal: 53.3s\tremaining: 1m 29s\n",
      "374:\tlearn: 0.0698108\ttotal: 53.4s\tremaining: 1m 29s\n",
      "375:\tlearn: 0.0697485\ttotal: 53.6s\tremaining: 1m 28s\n",
      "376:\tlearn: 0.0697530\ttotal: 53.8s\tremaining: 1m 28s\n",
      "377:\tlearn: 0.0696863\ttotal: 53.9s\tremaining: 1m 28s\n",
      "378:\tlearn: 0.0696284\ttotal: 54.1s\tremaining: 1m 28s\n",
      "379:\tlearn: 0.0696373\ttotal: 54.2s\tremaining: 1m 28s\n",
      "380:\tlearn: 0.0695528\ttotal: 54.4s\tremaining: 1m 28s\n",
      "381:\tlearn: 0.0695173\ttotal: 54.5s\tremaining: 1m 28s\n",
      "382:\tlearn: 0.0694639\ttotal: 54.7s\tremaining: 1m 28s\n",
      "383:\tlearn: 0.0694417\ttotal: 54.8s\tremaining: 1m 27s\n",
      "384:\tlearn: 0.0694016\ttotal: 54.9s\tremaining: 1m 27s\n",
      "385:\tlearn: 0.0693661\ttotal: 55.1s\tremaining: 1m 27s\n",
      "386:\tlearn: 0.0693038\ttotal: 55.2s\tremaining: 1m 27s\n",
      "387:\tlearn: 0.0692460\ttotal: 55.3s\tremaining: 1m 27s\n",
      "388:\tlearn: 0.0691882\ttotal: 55.5s\tremaining: 1m 27s\n",
      "389:\tlearn: 0.0691526\ttotal: 55.6s\tremaining: 1m 26s\n",
      "390:\tlearn: 0.0690859\ttotal: 55.8s\tremaining: 1m 26s\n",
      "391:\tlearn: 0.0690770\ttotal: 55.9s\tremaining: 1m 26s\n",
      "392:\tlearn: 0.0690192\ttotal: 56s\tremaining: 1m 26s\n",
      "393:\tlearn: 0.0689658\ttotal: 56.2s\tremaining: 1m 26s\n",
      "394:\tlearn: 0.0689436\ttotal: 56.3s\tremaining: 1m 26s\n",
      "395:\tlearn: 0.0689125\ttotal: 56.5s\tremaining: 1m 26s\n",
      "396:\tlearn: 0.0688947\ttotal: 56.6s\tremaining: 1m 25s\n",
      "397:\tlearn: 0.0688369\ttotal: 56.7s\tremaining: 1m 25s\n",
      "398:\tlearn: 0.0688324\ttotal: 56.9s\tremaining: 1m 25s\n",
      "399:\tlearn: 0.0687479\ttotal: 57s\tremaining: 1m 25s\n",
      "400:\tlearn: 0.0687257\ttotal: 57.1s\tremaining: 1m 25s\n",
      "401:\tlearn: 0.0686857\ttotal: 57.3s\tremaining: 1m 25s\n",
      "402:\tlearn: 0.0686901\ttotal: 57.4s\tremaining: 1m 25s\n",
      "403:\tlearn: 0.0686501\ttotal: 57.5s\tremaining: 1m 24s\n",
      "404:\tlearn: 0.0685878\ttotal: 57.7s\tremaining: 1m 24s\n",
      "405:\tlearn: 0.0685433\ttotal: 57.8s\tremaining: 1m 24s\n",
      "406:\tlearn: 0.0684811\ttotal: 58s\tremaining: 1m 24s\n",
      "407:\tlearn: 0.0684366\ttotal: 58.1s\tremaining: 1m 24s\n",
      "408:\tlearn: 0.0683877\ttotal: 58.3s\tremaining: 1m 24s\n",
      "409:\tlearn: 0.0683655\ttotal: 58.4s\tremaining: 1m 24s\n",
      "410:\tlearn: 0.0683655\ttotal: 58.6s\tremaining: 1m 23s\n",
      "411:\tlearn: 0.0683566\ttotal: 58.7s\tremaining: 1m 23s\n",
      "412:\tlearn: 0.0682899\ttotal: 58.9s\tremaining: 1m 23s\n",
      "413:\tlearn: 0.0682988\ttotal: 59s\tremaining: 1m 23s\n",
      "414:\tlearn: 0.0682543\ttotal: 59.2s\tremaining: 1m 23s\n",
      "415:\tlearn: 0.0682587\ttotal: 59.3s\tremaining: 1m 23s\n",
      "416:\tlearn: 0.0682143\ttotal: 59.5s\tremaining: 1m 23s\n",
      "417:\tlearn: 0.0681965\ttotal: 59.6s\tremaining: 1m 23s\n",
      "418:\tlearn: 0.0681520\ttotal: 59.8s\tremaining: 1m 22s\n",
      "419:\tlearn: 0.0680853\ttotal: 60s\tremaining: 1m 22s\n",
      "420:\tlearn: 0.0680230\ttotal: 1m\tremaining: 1m 22s\n",
      "421:\tlearn: 0.0680097\ttotal: 1m\tremaining: 1m 22s\n",
      "422:\tlearn: 0.0679652\ttotal: 1m\tremaining: 1m 22s\n",
      "423:\tlearn: 0.0679385\ttotal: 1m\tremaining: 1m 22s\n",
      "424:\tlearn: 0.0679074\ttotal: 1m\tremaining: 1m 22s\n",
      "425:\tlearn: 0.0679163\ttotal: 1m\tremaining: 1m 22s\n",
      "426:\tlearn: 0.0678629\ttotal: 1m 1s\tremaining: 1m 21s\n",
      "427:\tlearn: 0.0677873\ttotal: 1m 1s\tremaining: 1m 21s\n",
      "428:\tlearn: 0.0677829\ttotal: 1m 1s\tremaining: 1m 21s\n",
      "429:\tlearn: 0.0677429\ttotal: 1m 1s\tremaining: 1m 21s\n",
      "430:\tlearn: 0.0676851\ttotal: 1m 1s\tremaining: 1m 21s\n",
      "431:\tlearn: 0.0676806\ttotal: 1m 1s\tremaining: 1m 21s\n",
      "432:\tlearn: 0.0676317\ttotal: 1m 1s\tremaining: 1m 21s\n",
      "433:\tlearn: 0.0675694\ttotal: 1m 2s\tremaining: 1m 21s\n",
      "434:\tlearn: 0.0675205\ttotal: 1m 2s\tremaining: 1m 20s\n",
      "435:\tlearn: 0.0674716\ttotal: 1m 2s\tremaining: 1m 20s\n",
      "436:\tlearn: 0.0674583\ttotal: 1m 2s\tremaining: 1m 20s\n",
      "437:\tlearn: 0.0674360\ttotal: 1m 2s\tremaining: 1m 20s\n",
      "438:\tlearn: 0.0674182\ttotal: 1m 2s\tremaining: 1m 20s\n",
      "439:\tlearn: 0.0673915\ttotal: 1m 3s\tremaining: 1m 20s\n",
      "440:\tlearn: 0.0674182\ttotal: 1m 3s\tremaining: 1m 20s\n",
      "441:\tlearn: 0.0673649\ttotal: 1m 3s\tremaining: 1m 19s\n",
      "442:\tlearn: 0.0673337\ttotal: 1m 3s\tremaining: 1m 19s\n",
      "443:\tlearn: 0.0672982\ttotal: 1m 3s\tremaining: 1m 19s\n",
      "444:\tlearn: 0.0672448\ttotal: 1m 3s\tremaining: 1m 19s\n",
      "445:\tlearn: 0.0672448\ttotal: 1m 3s\tremaining: 1m 19s\n",
      "446:\tlearn: 0.0672226\ttotal: 1m 4s\tremaining: 1m 19s\n",
      "447:\tlearn: 0.0671114\ttotal: 1m 4s\tremaining: 1m 19s\n",
      "448:\tlearn: 0.0671247\ttotal: 1m 4s\tremaining: 1m 18s\n",
      "449:\tlearn: 0.0670802\ttotal: 1m 4s\tremaining: 1m 18s\n",
      "450:\tlearn: 0.0670625\ttotal: 1m 4s\tremaining: 1m 18s\n",
      "451:\tlearn: 0.0670847\ttotal: 1m 4s\tremaining: 1m 18s\n",
      "452:\tlearn: 0.0670491\ttotal: 1m 4s\tremaining: 1m 18s\n",
      "453:\tlearn: 0.0670224\ttotal: 1m 5s\tremaining: 1m 18s\n",
      "454:\tlearn: 0.0669557\ttotal: 1m 5s\tremaining: 1m 18s\n",
      "455:\tlearn: 0.0668757\ttotal: 1m 5s\tremaining: 1m 17s\n",
      "456:\tlearn: 0.0668890\ttotal: 1m 5s\tremaining: 1m 17s\n",
      "457:\tlearn: 0.0668401\ttotal: 1m 5s\tremaining: 1m 17s\n",
      "458:\tlearn: 0.0668401\ttotal: 1m 5s\tremaining: 1m 17s\n",
      "459:\tlearn: 0.0668312\ttotal: 1m 5s\tremaining: 1m 17s\n",
      "460:\tlearn: 0.0667556\ttotal: 1m 6s\tremaining: 1m 17s\n",
      "461:\tlearn: 0.0667467\ttotal: 1m 6s\tremaining: 1m 17s\n",
      "462:\tlearn: 0.0667334\ttotal: 1m 6s\tremaining: 1m 16s\n",
      "463:\tlearn: 0.0666845\ttotal: 1m 6s\tremaining: 1m 16s\n",
      "464:\tlearn: 0.0666266\ttotal: 1m 6s\tremaining: 1m 16s\n",
      "465:\tlearn: 0.0665644\ttotal: 1m 6s\tremaining: 1m 16s\n",
      "466:\tlearn: 0.0665911\ttotal: 1m 6s\tremaining: 1m 16s\n",
      "467:\tlearn: 0.0665155\ttotal: 1m 7s\tremaining: 1m 16s\n",
      "468:\tlearn: 0.0664443\ttotal: 1m 7s\tremaining: 1m 16s\n",
      "469:\tlearn: 0.0664310\ttotal: 1m 7s\tremaining: 1m 16s\n",
      "470:\tlearn: 0.0663687\ttotal: 1m 7s\tremaining: 1m 15s\n",
      "471:\tlearn: 0.0663153\ttotal: 1m 7s\tremaining: 1m 15s\n",
      "472:\tlearn: 0.0662976\ttotal: 1m 7s\tremaining: 1m 15s\n",
      "473:\tlearn: 0.0662397\ttotal: 1m 8s\tremaining: 1m 15s\n",
      "474:\tlearn: 0.0661953\ttotal: 1m 8s\tremaining: 1m 15s\n",
      "475:\tlearn: 0.0662042\ttotal: 1m 8s\tremaining: 1m 15s\n",
      "476:\tlearn: 0.0661286\ttotal: 1m 8s\tremaining: 1m 15s\n",
      "477:\tlearn: 0.0660885\ttotal: 1m 8s\tremaining: 1m 14s\n",
      "478:\tlearn: 0.0660841\ttotal: 1m 8s\tremaining: 1m 14s\n",
      "479:\tlearn: 0.0660796\ttotal: 1m 8s\tremaining: 1m 14s\n",
      "480:\tlearn: 0.0660218\ttotal: 1m 9s\tremaining: 1m 14s\n",
      "481:\tlearn: 0.0660040\ttotal: 1m 9s\tremaining: 1m 14s\n",
      "482:\tlearn: 0.0659863\ttotal: 1m 9s\tremaining: 1m 14s\n",
      "483:\tlearn: 0.0659507\ttotal: 1m 9s\tremaining: 1m 14s\n",
      "484:\tlearn: 0.0659240\ttotal: 1m 9s\tremaining: 1m 13s\n",
      "485:\tlearn: 0.0659551\ttotal: 1m 9s\tremaining: 1m 13s\n",
      "486:\tlearn: 0.0659062\ttotal: 1m 9s\tremaining: 1m 13s\n",
      "487:\tlearn: 0.0658617\ttotal: 1m 10s\tremaining: 1m 13s\n",
      "488:\tlearn: 0.0658751\ttotal: 1m 10s\tremaining: 1m 13s\n",
      "489:\tlearn: 0.0657817\ttotal: 1m 10s\tremaining: 1m 13s\n",
      "490:\tlearn: 0.0657372\ttotal: 1m 10s\tremaining: 1m 13s\n",
      "491:\tlearn: 0.0657239\ttotal: 1m 10s\tremaining: 1m 12s\n",
      "492:\tlearn: 0.0657016\ttotal: 1m 10s\tremaining: 1m 12s\n",
      "493:\tlearn: 0.0657194\ttotal: 1m 10s\tremaining: 1m 12s\n",
      "494:\tlearn: 0.0656661\ttotal: 1m 11s\tremaining: 1m 12s\n",
      "495:\tlearn: 0.0656483\ttotal: 1m 11s\tremaining: 1m 12s\n",
      "496:\tlearn: 0.0656216\ttotal: 1m 11s\tremaining: 1m 12s\n",
      "497:\tlearn: 0.0655415\ttotal: 1m 11s\tremaining: 1m 12s\n",
      "498:\tlearn: 0.0655015\ttotal: 1m 11s\tremaining: 1m 11s\n",
      "499:\tlearn: 0.0654659\ttotal: 1m 11s\tremaining: 1m 11s\n",
      "500:\tlearn: 0.0654081\ttotal: 1m 12s\tremaining: 1m 11s\n",
      "501:\tlearn: 0.0653726\ttotal: 1m 12s\tremaining: 1m 11s\n",
      "502:\tlearn: 0.0653014\ttotal: 1m 12s\tremaining: 1m 11s\n",
      "503:\tlearn: 0.0652792\ttotal: 1m 12s\tremaining: 1m 11s\n",
      "504:\tlearn: 0.0652125\ttotal: 1m 12s\tremaining: 1m 11s\n",
      "505:\tlearn: 0.0651991\ttotal: 1m 12s\tremaining: 1m 11s\n",
      "506:\tlearn: 0.0651991\ttotal: 1m 13s\tremaining: 1m 10s\n",
      "507:\tlearn: 0.0651680\ttotal: 1m 13s\tremaining: 1m 10s\n",
      "508:\tlearn: 0.0651413\ttotal: 1m 13s\tremaining: 1m 10s\n",
      "509:\tlearn: 0.0651280\ttotal: 1m 13s\tremaining: 1m 10s\n",
      "510:\tlearn: 0.0651146\ttotal: 1m 13s\tremaining: 1m 10s\n",
      "511:\tlearn: 0.0651191\ttotal: 1m 13s\tremaining: 1m 10s\n",
      "512:\tlearn: 0.0650613\ttotal: 1m 13s\tremaining: 1m 10s\n",
      "513:\tlearn: 0.0650479\ttotal: 1m 14s\tremaining: 1m 10s\n",
      "514:\tlearn: 0.0650079\ttotal: 1m 14s\tremaining: 1m 9s\n",
      "515:\tlearn: 0.0649501\ttotal: 1m 14s\tremaining: 1m 9s\n",
      "516:\tlearn: 0.0648967\ttotal: 1m 14s\tremaining: 1m 9s\n",
      "517:\tlearn: 0.0648478\ttotal: 1m 14s\tremaining: 1m 9s\n",
      "518:\tlearn: 0.0648434\ttotal: 1m 14s\tremaining: 1m 9s\n",
      "519:\tlearn: 0.0648345\ttotal: 1m 15s\tremaining: 1m 9s\n",
      "520:\tlearn: 0.0647944\ttotal: 1m 15s\tremaining: 1m 9s\n",
      "521:\tlearn: 0.0647366\ttotal: 1m 15s\tremaining: 1m 9s\n",
      "522:\tlearn: 0.0646788\ttotal: 1m 15s\tremaining: 1m 9s\n",
      "523:\tlearn: 0.0646299\ttotal: 1m 15s\tremaining: 1m 8s\n",
      "524:\tlearn: 0.0646343\ttotal: 1m 16s\tremaining: 1m 8s\n",
      "525:\tlearn: 0.0645810\ttotal: 1m 16s\tremaining: 1m 8s\n",
      "526:\tlearn: 0.0645498\ttotal: 1m 16s\tremaining: 1m 8s\n",
      "527:\tlearn: 0.0645098\ttotal: 1m 16s\tremaining: 1m 8s\n",
      "528:\tlearn: 0.0644565\ttotal: 1m 16s\tremaining: 1m 8s\n",
      "529:\tlearn: 0.0644253\ttotal: 1m 17s\tremaining: 1m 8s\n",
      "530:\tlearn: 0.0644031\ttotal: 1m 17s\tremaining: 1m 8s\n",
      "531:\tlearn: 0.0643364\ttotal: 1m 17s\tremaining: 1m 8s\n",
      "532:\tlearn: 0.0643097\ttotal: 1m 17s\tremaining: 1m 8s\n",
      "533:\tlearn: 0.0642964\ttotal: 1m 18s\tremaining: 1m 8s\n",
      "534:\tlearn: 0.0642652\ttotal: 1m 18s\tremaining: 1m 7s\n",
      "535:\tlearn: 0.0641629\ttotal: 1m 18s\tremaining: 1m 7s\n",
      "536:\tlearn: 0.0641629\ttotal: 1m 18s\tremaining: 1m 7s\n",
      "537:\tlearn: 0.0641007\ttotal: 1m 18s\tremaining: 1m 7s\n",
      "538:\tlearn: 0.0640784\ttotal: 1m 18s\tremaining: 1m 7s\n",
      "539:\tlearn: 0.0640696\ttotal: 1m 18s\tremaining: 1m 7s\n",
      "540:\tlearn: 0.0640384\ttotal: 1m 19s\tremaining: 1m 7s\n",
      "541:\tlearn: 0.0639806\ttotal: 1m 19s\tremaining: 1m 6s\n",
      "542:\tlearn: 0.0639673\ttotal: 1m 19s\tremaining: 1m 6s\n",
      "543:\tlearn: 0.0639406\ttotal: 1m 19s\tremaining: 1m 6s\n",
      "544:\tlearn: 0.0639095\ttotal: 1m 19s\tremaining: 1m 6s\n",
      "545:\tlearn: 0.0638650\ttotal: 1m 19s\tremaining: 1m 6s\n",
      "546:\tlearn: 0.0638561\ttotal: 1m 19s\tremaining: 1m 6s\n",
      "547:\tlearn: 0.0638161\ttotal: 1m 20s\tremaining: 1m 6s\n",
      "548:\tlearn: 0.0637716\ttotal: 1m 20s\tremaining: 1m 5s\n",
      "549:\tlearn: 0.0637760\ttotal: 1m 20s\tremaining: 1m 5s\n",
      "550:\tlearn: 0.0637138\ttotal: 1m 20s\tremaining: 1m 5s\n",
      "551:\tlearn: 0.0637093\ttotal: 1m 20s\tremaining: 1m 5s\n",
      "552:\tlearn: 0.0636560\ttotal: 1m 20s\tremaining: 1m 5s\n",
      "553:\tlearn: 0.0636426\ttotal: 1m 20s\tremaining: 1m 5s\n",
      "554:\tlearn: 0.0635982\ttotal: 1m 21s\tremaining: 1m 5s\n",
      "555:\tlearn: 0.0635626\ttotal: 1m 21s\tremaining: 1m 4s\n",
      "556:\tlearn: 0.0634870\ttotal: 1m 21s\tremaining: 1m 4s\n",
      "557:\tlearn: 0.0634825\ttotal: 1m 21s\tremaining: 1m 4s\n",
      "558:\tlearn: 0.0634470\ttotal: 1m 21s\tremaining: 1m 4s\n",
      "559:\tlearn: 0.0633980\ttotal: 1m 21s\tremaining: 1m 4s\n",
      "560:\tlearn: 0.0633536\ttotal: 1m 22s\tremaining: 1m 4s\n",
      "561:\tlearn: 0.0633447\ttotal: 1m 22s\tremaining: 1m 4s\n",
      "562:\tlearn: 0.0632913\ttotal: 1m 22s\tremaining: 1m 3s\n",
      "563:\tlearn: 0.0632869\ttotal: 1m 22s\tremaining: 1m 3s\n",
      "564:\tlearn: 0.0632468\ttotal: 1m 22s\tremaining: 1m 3s\n",
      "565:\tlearn: 0.0632602\ttotal: 1m 22s\tremaining: 1m 3s\n",
      "566:\tlearn: 0.0632068\ttotal: 1m 22s\tremaining: 1m 3s\n",
      "567:\tlearn: 0.0631757\ttotal: 1m 23s\tremaining: 1m 3s\n",
      "568:\tlearn: 0.0631757\ttotal: 1m 23s\tremaining: 1m 3s\n",
      "569:\tlearn: 0.0631401\ttotal: 1m 23s\tremaining: 1m 2s\n",
      "570:\tlearn: 0.0631401\ttotal: 1m 23s\tremaining: 1m 2s\n",
      "571:\tlearn: 0.0631357\ttotal: 1m 23s\tremaining: 1m 2s\n",
      "572:\tlearn: 0.0630912\ttotal: 1m 23s\tremaining: 1m 2s\n",
      "573:\tlearn: 0.0630823\ttotal: 1m 23s\tremaining: 1m 2s\n",
      "574:\tlearn: 0.0630423\ttotal: 1m 24s\tremaining: 1m 2s\n",
      "575:\tlearn: 0.0629889\ttotal: 1m 24s\tremaining: 1m 2s\n",
      "576:\tlearn: 0.0629622\ttotal: 1m 24s\tremaining: 1m 1s\n",
      "577:\tlearn: 0.0629000\ttotal: 1m 24s\tremaining: 1m 1s\n",
      "578:\tlearn: 0.0628911\ttotal: 1m 24s\tremaining: 1m 1s\n",
      "579:\tlearn: 0.0628110\ttotal: 1m 24s\tremaining: 1m 1s\n",
      "580:\tlearn: 0.0627932\ttotal: 1m 25s\tremaining: 1m 1s\n",
      "581:\tlearn: 0.0627265\ttotal: 1m 25s\tremaining: 1m 1s\n",
      "582:\tlearn: 0.0626909\ttotal: 1m 25s\tremaining: 1m 1s\n",
      "583:\tlearn: 0.0626198\ttotal: 1m 25s\tremaining: 1m\n",
      "584:\tlearn: 0.0626242\ttotal: 1m 25s\tremaining: 1m\n",
      "585:\tlearn: 0.0625842\ttotal: 1m 25s\tremaining: 1m\n",
      "586:\tlearn: 0.0625486\ttotal: 1m 25s\tremaining: 1m\n",
      "587:\tlearn: 0.0625086\ttotal: 1m 26s\tremaining: 1m\n",
      "588:\tlearn: 0.0624819\ttotal: 1m 26s\tremaining: 1m\n",
      "589:\tlearn: 0.0624686\ttotal: 1m 26s\tremaining: 1m\n",
      "590:\tlearn: 0.0624286\ttotal: 1m 26s\tremaining: 59.9s\n",
      "591:\tlearn: 0.0623885\ttotal: 1m 26s\tremaining: 59.7s\n",
      "592:\tlearn: 0.0623307\ttotal: 1m 26s\tremaining: 59.6s\n",
      "593:\tlearn: 0.0623174\ttotal: 1m 26s\tremaining: 59.4s\n",
      "594:\tlearn: 0.0622952\ttotal: 1m 27s\tremaining: 59.3s\n",
      "595:\tlearn: 0.0623040\ttotal: 1m 27s\tremaining: 59.1s\n",
      "596:\tlearn: 0.0622284\ttotal: 1m 27s\tremaining: 59s\n",
      "597:\tlearn: 0.0621795\ttotal: 1m 27s\tremaining: 58.9s\n",
      "598:\tlearn: 0.0621395\ttotal: 1m 27s\tremaining: 58.7s\n",
      "599:\tlearn: 0.0621617\ttotal: 1m 27s\tremaining: 58.6s\n",
      "600:\tlearn: 0.0621306\ttotal: 1m 27s\tremaining: 58.4s\n",
      "601:\tlearn: 0.0621351\ttotal: 1m 28s\tremaining: 58.3s\n",
      "602:\tlearn: 0.0620772\ttotal: 1m 28s\tremaining: 58.1s\n",
      "603:\tlearn: 0.0620595\ttotal: 1m 28s\tremaining: 57.9s\n",
      "604:\tlearn: 0.0620417\ttotal: 1m 28s\tremaining: 57.8s\n",
      "605:\tlearn: 0.0620461\ttotal: 1m 28s\tremaining: 57.7s\n",
      "606:\tlearn: 0.0620283\ttotal: 1m 28s\tremaining: 57.5s\n",
      "607:\tlearn: 0.0619705\ttotal: 1m 28s\tremaining: 57.4s\n",
      "608:\tlearn: 0.0619394\ttotal: 1m 29s\tremaining: 57.2s\n",
      "609:\tlearn: 0.0618860\ttotal: 1m 29s\tremaining: 57.1s\n",
      "610:\tlearn: 0.0618238\ttotal: 1m 29s\tremaining: 56.9s\n",
      "611:\tlearn: 0.0617971\ttotal: 1m 29s\tremaining: 56.8s\n",
      "612:\tlearn: 0.0617526\ttotal: 1m 29s\tremaining: 56.6s\n",
      "613:\tlearn: 0.0617215\ttotal: 1m 29s\tremaining: 56.5s\n",
      "614:\tlearn: 0.0616992\ttotal: 1m 29s\tremaining: 56.3s\n",
      "615:\tlearn: 0.0617037\ttotal: 1m 30s\tremaining: 56.2s\n",
      "616:\tlearn: 0.0616592\ttotal: 1m 30s\tremaining: 56s\n",
      "617:\tlearn: 0.0616281\ttotal: 1m 30s\tremaining: 55.9s\n",
      "618:\tlearn: 0.0615970\ttotal: 1m 30s\tremaining: 55.7s\n",
      "619:\tlearn: 0.0616236\ttotal: 1m 30s\tremaining: 55.6s\n",
      "620:\tlearn: 0.0616236\ttotal: 1m 30s\tremaining: 55.4s\n",
      "621:\tlearn: 0.0615258\ttotal: 1m 30s\tremaining: 55.3s\n",
      "622:\tlearn: 0.0615214\ttotal: 1m 31s\tremaining: 55.1s\n",
      "623:\tlearn: 0.0615258\ttotal: 1m 31s\tremaining: 55s\n",
      "624:\tlearn: 0.0614769\ttotal: 1m 31s\tremaining: 54.9s\n",
      "625:\tlearn: 0.0614680\ttotal: 1m 31s\tremaining: 54.7s\n",
      "626:\tlearn: 0.0614013\ttotal: 1m 31s\tremaining: 54.6s\n",
      "627:\tlearn: 0.0613790\ttotal: 1m 31s\tremaining: 54.4s\n",
      "628:\tlearn: 0.0613657\ttotal: 1m 32s\tremaining: 54.3s\n",
      "629:\tlearn: 0.0613346\ttotal: 1m 32s\tremaining: 54.1s\n",
      "630:\tlearn: 0.0612901\ttotal: 1m 32s\tremaining: 54s\n",
      "631:\tlearn: 0.0612412\ttotal: 1m 32s\tremaining: 53.8s\n",
      "632:\tlearn: 0.0612278\ttotal: 1m 32s\tremaining: 53.7s\n",
      "633:\tlearn: 0.0611745\ttotal: 1m 32s\tremaining: 53.5s\n",
      "634:\tlearn: 0.0610900\ttotal: 1m 32s\tremaining: 53.4s\n",
      "635:\tlearn: 0.0610411\ttotal: 1m 32s\tremaining: 53.2s\n",
      "636:\tlearn: 0.0610366\ttotal: 1m 33s\tremaining: 53.1s\n",
      "637:\tlearn: 0.0610277\ttotal: 1m 33s\tremaining: 52.9s\n",
      "638:\tlearn: 0.0609566\ttotal: 1m 33s\tremaining: 52.8s\n",
      "639:\tlearn: 0.0609388\ttotal: 1m 33s\tremaining: 52.6s\n",
      "640:\tlearn: 0.0609388\ttotal: 1m 33s\tremaining: 52.5s\n",
      "641:\tlearn: 0.0609388\ttotal: 1m 33s\tremaining: 52.3s\n",
      "642:\tlearn: 0.0608810\ttotal: 1m 33s\tremaining: 52.2s\n",
      "643:\tlearn: 0.0608054\ttotal: 1m 34s\tremaining: 52s\n",
      "644:\tlearn: 0.0608098\ttotal: 1m 34s\tremaining: 51.9s\n",
      "645:\tlearn: 0.0607831\ttotal: 1m 34s\tremaining: 51.7s\n",
      "646:\tlearn: 0.0607831\ttotal: 1m 34s\tremaining: 51.6s\n",
      "647:\tlearn: 0.0607387\ttotal: 1m 34s\tremaining: 51.4s\n",
      "648:\tlearn: 0.0607698\ttotal: 1m 34s\tremaining: 51.3s\n",
      "649:\tlearn: 0.0607431\ttotal: 1m 34s\tremaining: 51.1s\n",
      "650:\tlearn: 0.0607031\ttotal: 1m 35s\tremaining: 51s\n",
      "651:\tlearn: 0.0606408\ttotal: 1m 35s\tremaining: 50.8s\n",
      "652:\tlearn: 0.0606141\ttotal: 1m 35s\tremaining: 50.7s\n",
      "653:\tlearn: 0.0606097\ttotal: 1m 35s\tremaining: 50.5s\n",
      "654:\tlearn: 0.0605519\ttotal: 1m 35s\tremaining: 50.4s\n",
      "655:\tlearn: 0.0605786\ttotal: 1m 35s\tremaining: 50.2s\n",
      "656:\tlearn: 0.0605208\ttotal: 1m 35s\tremaining: 50.1s\n",
      "657:\tlearn: 0.0604807\ttotal: 1m 36s\tremaining: 49.9s\n",
      "658:\tlearn: 0.0604318\ttotal: 1m 36s\tremaining: 49.8s\n",
      "659:\tlearn: 0.0603829\ttotal: 1m 36s\tremaining: 49.6s\n",
      "660:\tlearn: 0.0603473\ttotal: 1m 36s\tremaining: 49.5s\n",
      "661:\tlearn: 0.0603429\ttotal: 1m 36s\tremaining: 49.3s\n",
      "662:\tlearn: 0.0603028\ttotal: 1m 36s\tremaining: 49.2s\n",
      "663:\tlearn: 0.0602673\ttotal: 1m 36s\tremaining: 49s\n",
      "664:\tlearn: 0.0602272\ttotal: 1m 37s\tremaining: 48.9s\n",
      "665:\tlearn: 0.0602006\ttotal: 1m 37s\tremaining: 48.7s\n",
      "666:\tlearn: 0.0601516\ttotal: 1m 37s\tremaining: 48.6s\n",
      "667:\tlearn: 0.0601339\ttotal: 1m 37s\tremaining: 48.5s\n",
      "668:\tlearn: 0.0601027\ttotal: 1m 37s\tremaining: 48.3s\n",
      "669:\tlearn: 0.0600938\ttotal: 1m 37s\tremaining: 48.2s\n",
      "670:\tlearn: 0.0600405\ttotal: 1m 37s\tremaining: 48s\n",
      "671:\tlearn: 0.0600316\ttotal: 1m 38s\tremaining: 47.9s\n",
      "672:\tlearn: 0.0600449\ttotal: 1m 38s\tremaining: 47.8s\n",
      "673:\tlearn: 0.0599649\ttotal: 1m 38s\tremaining: 47.6s\n",
      "674:\tlearn: 0.0599426\ttotal: 1m 38s\tremaining: 47.5s\n",
      "675:\tlearn: 0.0598893\ttotal: 1m 38s\tremaining: 47.3s\n",
      "676:\tlearn: 0.0598893\ttotal: 1m 38s\tremaining: 47.2s\n",
      "677:\tlearn: 0.0598359\ttotal: 1m 39s\tremaining: 47s\n",
      "678:\tlearn: 0.0597781\ttotal: 1m 39s\tremaining: 46.9s\n",
      "679:\tlearn: 0.0597470\ttotal: 1m 39s\tremaining: 46.7s\n",
      "680:\tlearn: 0.0597247\ttotal: 1m 39s\tremaining: 46.6s\n",
      "681:\tlearn: 0.0597336\ttotal: 1m 39s\tremaining: 46.4s\n",
      "682:\tlearn: 0.0597292\ttotal: 1m 39s\tremaining: 46.3s\n",
      "683:\tlearn: 0.0596980\ttotal: 1m 39s\tremaining: 46.1s\n",
      "684:\tlearn: 0.0596491\ttotal: 1m 40s\tremaining: 46s\n",
      "685:\tlearn: 0.0596224\ttotal: 1m 40s\tremaining: 45.9s\n",
      "686:\tlearn: 0.0595824\ttotal: 1m 40s\tremaining: 45.7s\n",
      "687:\tlearn: 0.0595735\ttotal: 1m 40s\tremaining: 45.6s\n",
      "688:\tlearn: 0.0595068\ttotal: 1m 40s\tremaining: 45.4s\n",
      "689:\tlearn: 0.0595068\ttotal: 1m 40s\tremaining: 45.3s\n",
      "690:\tlearn: 0.0595113\ttotal: 1m 40s\tremaining: 45.1s\n",
      "691:\tlearn: 0.0594446\ttotal: 1m 41s\tremaining: 45s\n",
      "692:\tlearn: 0.0593867\ttotal: 1m 41s\tremaining: 44.8s\n",
      "693:\tlearn: 0.0593956\ttotal: 1m 41s\tremaining: 44.7s\n",
      "694:\tlearn: 0.0593423\ttotal: 1m 41s\tremaining: 44.5s\n",
      "695:\tlearn: 0.0592978\ttotal: 1m 41s\tremaining: 44.4s\n",
      "696:\tlearn: 0.0592845\ttotal: 1m 41s\tremaining: 44.2s\n",
      "697:\tlearn: 0.0592756\ttotal: 1m 41s\tremaining: 44.1s\n",
      "698:\tlearn: 0.0592044\ttotal: 1m 42s\tremaining: 43.9s\n",
      "699:\tlearn: 0.0591510\ttotal: 1m 42s\tremaining: 43.8s\n",
      "700:\tlearn: 0.0591422\ttotal: 1m 42s\tremaining: 43.6s\n",
      "701:\tlearn: 0.0591244\ttotal: 1m 42s\tremaining: 43.5s\n",
      "702:\tlearn: 0.0590754\ttotal: 1m 42s\tremaining: 43.3s\n",
      "703:\tlearn: 0.0590532\ttotal: 1m 42s\tremaining: 43.2s\n",
      "704:\tlearn: 0.0590310\ttotal: 1m 42s\tremaining: 43s\n",
      "705:\tlearn: 0.0590132\ttotal: 1m 42s\tremaining: 42.9s\n",
      "706:\tlearn: 0.0589598\ttotal: 1m 43s\tremaining: 42.7s\n",
      "707:\tlearn: 0.0589554\ttotal: 1m 43s\tremaining: 42.6s\n",
      "708:\tlearn: 0.0589198\ttotal: 1m 43s\tremaining: 42.4s\n",
      "709:\tlearn: 0.0588486\ttotal: 1m 43s\tremaining: 42.3s\n",
      "710:\tlearn: 0.0588442\ttotal: 1m 43s\tremaining: 42.1s\n",
      "711:\tlearn: 0.0588131\ttotal: 1m 43s\tremaining: 42s\n",
      "712:\tlearn: 0.0587508\ttotal: 1m 43s\tremaining: 41.9s\n",
      "713:\tlearn: 0.0587241\ttotal: 1m 44s\tremaining: 41.7s\n",
      "714:\tlearn: 0.0586974\ttotal: 1m 44s\tremaining: 41.6s\n",
      "715:\tlearn: 0.0587286\ttotal: 1m 44s\tremaining: 41.4s\n",
      "716:\tlearn: 0.0586530\ttotal: 1m 44s\tremaining: 41.3s\n",
      "717:\tlearn: 0.0586174\ttotal: 1m 44s\tremaining: 41.1s\n",
      "718:\tlearn: 0.0585907\ttotal: 1m 44s\tremaining: 41s\n",
      "719:\tlearn: 0.0586041\ttotal: 1m 44s\tremaining: 40.8s\n",
      "720:\tlearn: 0.0585729\ttotal: 1m 45s\tremaining: 40.7s\n",
      "721:\tlearn: 0.0585373\ttotal: 1m 45s\tremaining: 40.5s\n",
      "722:\tlearn: 0.0585107\ttotal: 1m 45s\tremaining: 40.4s\n",
      "723:\tlearn: 0.0584662\ttotal: 1m 45s\tremaining: 40.2s\n",
      "724:\tlearn: 0.0584306\ttotal: 1m 45s\tremaining: 40.1s\n",
      "725:\tlearn: 0.0583950\ttotal: 1m 45s\tremaining: 39.9s\n",
      "726:\tlearn: 0.0583950\ttotal: 1m 45s\tremaining: 39.8s\n",
      "727:\tlearn: 0.0583417\ttotal: 1m 46s\tremaining: 39.6s\n",
      "728:\tlearn: 0.0583105\ttotal: 1m 46s\tremaining: 39.5s\n",
      "729:\tlearn: 0.0582750\ttotal: 1m 46s\tremaining: 39.3s\n",
      "730:\tlearn: 0.0582305\ttotal: 1m 46s\tremaining: 39.2s\n",
      "731:\tlearn: 0.0582349\ttotal: 1m 46s\tremaining: 39s\n",
      "732:\tlearn: 0.0582038\ttotal: 1m 46s\tremaining: 38.9s\n",
      "733:\tlearn: 0.0582127\ttotal: 1m 46s\tremaining: 38.7s\n",
      "734:\tlearn: 0.0581860\ttotal: 1m 47s\tremaining: 38.6s\n",
      "735:\tlearn: 0.0581416\ttotal: 1m 47s\tremaining: 38.4s\n",
      "736:\tlearn: 0.0581015\ttotal: 1m 47s\tremaining: 38.3s\n",
      "737:\tlearn: 0.0580704\ttotal: 1m 47s\tremaining: 38.1s\n",
      "738:\tlearn: 0.0580037\ttotal: 1m 47s\tremaining: 38s\n",
      "739:\tlearn: 0.0579503\ttotal: 1m 47s\tremaining: 37.9s\n",
      "740:\tlearn: 0.0579637\ttotal: 1m 47s\tremaining: 37.7s\n",
      "741:\tlearn: 0.0579770\ttotal: 1m 48s\tremaining: 37.6s\n",
      "742:\tlearn: 0.0579236\ttotal: 1m 48s\tremaining: 37.4s\n",
      "743:\tlearn: 0.0578925\ttotal: 1m 48s\tremaining: 37.3s\n",
      "744:\tlearn: 0.0578747\ttotal: 1m 48s\tremaining: 37.1s\n",
      "745:\tlearn: 0.0578658\ttotal: 1m 48s\tremaining: 37s\n",
      "746:\tlearn: 0.0578436\ttotal: 1m 48s\tremaining: 36.8s\n",
      "747:\tlearn: 0.0578347\ttotal: 1m 48s\tremaining: 36.7s\n",
      "748:\tlearn: 0.0578036\ttotal: 1m 49s\tremaining: 36.5s\n",
      "749:\tlearn: 0.0578036\ttotal: 1m 49s\tremaining: 36.4s\n",
      "750:\tlearn: 0.0577947\ttotal: 1m 49s\tremaining: 36.2s\n",
      "751:\tlearn: 0.0577369\ttotal: 1m 49s\tremaining: 36.1s\n",
      "752:\tlearn: 0.0576879\ttotal: 1m 49s\tremaining: 35.9s\n",
      "753:\tlearn: 0.0576435\ttotal: 1m 49s\tremaining: 35.8s\n",
      "754:\tlearn: 0.0576435\ttotal: 1m 49s\tremaining: 35.6s\n",
      "755:\tlearn: 0.0575946\ttotal: 1m 49s\tremaining: 35.5s\n",
      "756:\tlearn: 0.0575545\ttotal: 1m 50s\tremaining: 35.4s\n",
      "757:\tlearn: 0.0575367\ttotal: 1m 50s\tremaining: 35.2s\n",
      "758:\tlearn: 0.0574567\ttotal: 1m 50s\tremaining: 35.1s\n",
      "759:\tlearn: 0.0574389\ttotal: 1m 50s\tremaining: 34.9s\n",
      "760:\tlearn: 0.0574256\ttotal: 1m 50s\tremaining: 34.8s\n",
      "761:\tlearn: 0.0573855\ttotal: 1m 50s\tremaining: 34.6s\n",
      "762:\tlearn: 0.0573544\ttotal: 1m 50s\tremaining: 34.5s\n",
      "763:\tlearn: 0.0573322\ttotal: 1m 51s\tremaining: 34.3s\n",
      "764:\tlearn: 0.0572966\ttotal: 1m 51s\tremaining: 34.2s\n",
      "765:\tlearn: 0.0572877\ttotal: 1m 51s\tremaining: 34s\n",
      "766:\tlearn: 0.0572788\ttotal: 1m 51s\tremaining: 33.9s\n",
      "767:\tlearn: 0.0571943\ttotal: 1m 51s\tremaining: 33.7s\n",
      "768:\tlearn: 0.0571543\ttotal: 1m 51s\tremaining: 33.6s\n",
      "769:\tlearn: 0.0571009\ttotal: 1m 51s\tremaining: 33.4s\n",
      "770:\tlearn: 0.0570965\ttotal: 1m 52s\tremaining: 33.3s\n",
      "771:\tlearn: 0.0570698\ttotal: 1m 52s\tremaining: 33.2s\n",
      "772:\tlearn: 0.0570565\ttotal: 1m 52s\tremaining: 33s\n",
      "773:\tlearn: 0.0570120\ttotal: 1m 52s\tremaining: 32.9s\n",
      "774:\tlearn: 0.0569631\ttotal: 1m 52s\tremaining: 32.7s\n",
      "775:\tlearn: 0.0569186\ttotal: 1m 52s\tremaining: 32.6s\n",
      "776:\tlearn: 0.0569141\ttotal: 1m 53s\tremaining: 32.4s\n",
      "777:\tlearn: 0.0569186\ttotal: 1m 53s\tremaining: 32.3s\n",
      "778:\tlearn: 0.0569230\ttotal: 1m 53s\tremaining: 32.1s\n",
      "779:\tlearn: 0.0568786\ttotal: 1m 53s\tremaining: 32s\n",
      "780:\tlearn: 0.0568163\ttotal: 1m 53s\tremaining: 31.9s\n",
      "781:\tlearn: 0.0567629\ttotal: 1m 53s\tremaining: 31.7s\n",
      "782:\tlearn: 0.0567674\ttotal: 1m 53s\tremaining: 31.6s\n",
      "783:\tlearn: 0.0567051\ttotal: 1m 53s\tremaining: 31.4s\n",
      "784:\tlearn: 0.0566562\ttotal: 1m 54s\tremaining: 31.3s\n",
      "785:\tlearn: 0.0566384\ttotal: 1m 54s\tremaining: 31.1s\n",
      "786:\tlearn: 0.0566473\ttotal: 1m 54s\tremaining: 31s\n",
      "787:\tlearn: 0.0566384\ttotal: 1m 54s\tremaining: 30.8s\n",
      "788:\tlearn: 0.0565940\ttotal: 1m 54s\tremaining: 30.7s\n",
      "789:\tlearn: 0.0565673\ttotal: 1m 54s\tremaining: 30.5s\n",
      "790:\tlearn: 0.0565495\ttotal: 1m 54s\tremaining: 30.4s\n",
      "791:\tlearn: 0.0565095\ttotal: 1m 55s\tremaining: 30.2s\n",
      "792:\tlearn: 0.0564783\ttotal: 1m 55s\tremaining: 30.1s\n",
      "793:\tlearn: 0.0564917\ttotal: 1m 55s\tremaining: 29.9s\n",
      "794:\tlearn: 0.0564961\ttotal: 1m 55s\tremaining: 29.8s\n",
      "795:\tlearn: 0.0564205\ttotal: 1m 55s\tremaining: 29.6s\n",
      "796:\tlearn: 0.0564161\ttotal: 1m 55s\tremaining: 29.5s\n",
      "797:\tlearn: 0.0563849\ttotal: 1m 55s\tremaining: 29.3s\n",
      "798:\tlearn: 0.0563672\ttotal: 1m 56s\tremaining: 29.2s\n",
      "799:\tlearn: 0.0563583\ttotal: 1m 56s\tremaining: 29s\n",
      "800:\tlearn: 0.0563049\ttotal: 1m 56s\tremaining: 28.9s\n",
      "801:\tlearn: 0.0562827\ttotal: 1m 56s\tremaining: 28.8s\n",
      "802:\tlearn: 0.0562560\ttotal: 1m 56s\tremaining: 28.6s\n",
      "803:\tlearn: 0.0561804\ttotal: 1m 56s\tremaining: 28.5s\n",
      "804:\tlearn: 0.0561581\ttotal: 1m 56s\tremaining: 28.3s\n",
      "805:\tlearn: 0.0561315\ttotal: 1m 57s\tremaining: 28.2s\n",
      "806:\tlearn: 0.0561137\ttotal: 1m 57s\tremaining: 28s\n",
      "807:\tlearn: 0.0561137\ttotal: 1m 57s\tremaining: 27.9s\n",
      "808:\tlearn: 0.0561003\ttotal: 1m 57s\tremaining: 27.7s\n",
      "809:\tlearn: 0.0560559\ttotal: 1m 57s\tremaining: 27.6s\n",
      "810:\tlearn: 0.0560559\ttotal: 1m 57s\tremaining: 27.4s\n",
      "811:\tlearn: 0.0560203\ttotal: 1m 57s\tremaining: 27.3s\n",
      "812:\tlearn: 0.0559847\ttotal: 1m 58s\tremaining: 27.1s\n",
      "813:\tlearn: 0.0559491\ttotal: 1m 58s\tremaining: 27s\n",
      "814:\tlearn: 0.0559091\ttotal: 1m 58s\tremaining: 26.8s\n",
      "815:\tlearn: 0.0558824\ttotal: 1m 58s\tremaining: 26.7s\n",
      "816:\tlearn: 0.0558824\ttotal: 1m 58s\tremaining: 26.6s\n",
      "817:\tlearn: 0.0558157\ttotal: 1m 58s\tremaining: 26.4s\n",
      "818:\tlearn: 0.0557890\ttotal: 1m 58s\tremaining: 26.3s\n",
      "819:\tlearn: 0.0557890\ttotal: 1m 58s\tremaining: 26.1s\n",
      "820:\tlearn: 0.0557757\ttotal: 1m 59s\tremaining: 26s\n",
      "821:\tlearn: 0.0557712\ttotal: 1m 59s\tremaining: 25.8s\n",
      "822:\tlearn: 0.0557223\ttotal: 1m 59s\tremaining: 25.7s\n",
      "823:\tlearn: 0.0557179\ttotal: 1m 59s\tremaining: 25.5s\n",
      "824:\tlearn: 0.0556601\ttotal: 1m 59s\tremaining: 25.4s\n",
      "825:\tlearn: 0.0556378\ttotal: 1m 59s\tremaining: 25.2s\n",
      "826:\tlearn: 0.0556156\ttotal: 1m 59s\tremaining: 25.1s\n",
      "827:\tlearn: 0.0555978\ttotal: 2m\tremaining: 24.9s\n",
      "828:\tlearn: 0.0555934\ttotal: 2m\tremaining: 24.8s\n",
      "829:\tlearn: 0.0555089\ttotal: 2m\tremaining: 24.6s\n",
      "830:\tlearn: 0.0554510\ttotal: 2m\tremaining: 24.5s\n",
      "831:\tlearn: 0.0554822\ttotal: 2m\tremaining: 24.4s\n",
      "832:\tlearn: 0.0554866\ttotal: 2m\tremaining: 24.2s\n",
      "833:\tlearn: 0.0554688\ttotal: 2m\tremaining: 24.1s\n",
      "834:\tlearn: 0.0554333\ttotal: 2m 1s\tremaining: 23.9s\n",
      "835:\tlearn: 0.0554466\ttotal: 2m 1s\tremaining: 23.8s\n",
      "836:\tlearn: 0.0554244\ttotal: 2m 1s\tremaining: 23.6s\n",
      "837:\tlearn: 0.0553710\ttotal: 2m 1s\tremaining: 23.5s\n",
      "838:\tlearn: 0.0553532\ttotal: 2m 1s\tremaining: 23.3s\n",
      "839:\tlearn: 0.0553354\ttotal: 2m 1s\tremaining: 23.2s\n",
      "840:\tlearn: 0.0553399\ttotal: 2m 1s\tremaining: 23s\n",
      "841:\tlearn: 0.0552687\ttotal: 2m 2s\tremaining: 22.9s\n",
      "842:\tlearn: 0.0552643\ttotal: 2m 2s\tremaining: 22.8s\n",
      "843:\tlearn: 0.0552732\ttotal: 2m 2s\tremaining: 22.6s\n",
      "844:\tlearn: 0.0552554\ttotal: 2m 2s\tremaining: 22.5s\n",
      "845:\tlearn: 0.0552198\ttotal: 2m 2s\tremaining: 22.3s\n",
      "846:\tlearn: 0.0551976\ttotal: 2m 2s\tremaining: 22.2s\n",
      "847:\tlearn: 0.0551842\ttotal: 2m 2s\tremaining: 22s\n",
      "848:\tlearn: 0.0551664\ttotal: 2m 3s\tremaining: 21.9s\n",
      "849:\tlearn: 0.0551042\ttotal: 2m 3s\tremaining: 21.7s\n",
      "850:\tlearn: 0.0550819\ttotal: 2m 3s\tremaining: 21.6s\n",
      "851:\tlearn: 0.0550464\ttotal: 2m 3s\tremaining: 21.4s\n",
      "852:\tlearn: 0.0550686\ttotal: 2m 3s\tremaining: 21.3s\n",
      "853:\tlearn: 0.0550464\ttotal: 2m 3s\tremaining: 21.2s\n",
      "854:\tlearn: 0.0550019\ttotal: 2m 3s\tremaining: 21s\n",
      "855:\tlearn: 0.0549530\ttotal: 2m 4s\tremaining: 20.9s\n",
      "856:\tlearn: 0.0549441\ttotal: 2m 4s\tremaining: 20.7s\n",
      "857:\tlearn: 0.0548907\ttotal: 2m 4s\tremaining: 20.6s\n",
      "858:\tlearn: 0.0548462\ttotal: 2m 4s\tremaining: 20.4s\n",
      "859:\tlearn: 0.0548018\ttotal: 2m 4s\tremaining: 20.3s\n",
      "860:\tlearn: 0.0547929\ttotal: 2m 4s\tremaining: 20.1s\n",
      "861:\tlearn: 0.0547128\ttotal: 2m 4s\tremaining: 20s\n",
      "862:\tlearn: 0.0546995\ttotal: 2m 5s\tremaining: 19.9s\n",
      "863:\tlearn: 0.0547039\ttotal: 2m 5s\tremaining: 19.7s\n",
      "864:\tlearn: 0.0546461\ttotal: 2m 5s\tremaining: 19.6s\n",
      "865:\tlearn: 0.0546372\ttotal: 2m 5s\tremaining: 19.4s\n",
      "866:\tlearn: 0.0546150\ttotal: 2m 5s\tremaining: 19.3s\n",
      "867:\tlearn: 0.0546105\ttotal: 2m 5s\tremaining: 19.1s\n",
      "868:\tlearn: 0.0545883\ttotal: 2m 6s\tremaining: 19s\n",
      "869:\tlearn: 0.0545750\ttotal: 2m 6s\tremaining: 18.9s\n",
      "870:\tlearn: 0.0545305\ttotal: 2m 6s\tremaining: 18.7s\n",
      "871:\tlearn: 0.0545172\ttotal: 2m 6s\tremaining: 18.6s\n",
      "872:\tlearn: 0.0545305\ttotal: 2m 6s\tremaining: 18.4s\n",
      "873:\tlearn: 0.0544860\ttotal: 2m 6s\tremaining: 18.3s\n",
      "874:\tlearn: 0.0544504\ttotal: 2m 6s\tremaining: 18.1s\n",
      "875:\tlearn: 0.0543926\ttotal: 2m 7s\tremaining: 18s\n",
      "876:\tlearn: 0.0543704\ttotal: 2m 7s\tremaining: 17.9s\n",
      "877:\tlearn: 0.0543215\ttotal: 2m 7s\tremaining: 17.7s\n",
      "878:\tlearn: 0.0542681\ttotal: 2m 7s\tremaining: 17.6s\n",
      "879:\tlearn: 0.0542103\ttotal: 2m 7s\tremaining: 17.4s\n",
      "880:\tlearn: 0.0541792\ttotal: 2m 7s\tremaining: 17.3s\n",
      "881:\tlearn: 0.0541925\ttotal: 2m 8s\tremaining: 17.1s\n",
      "882:\tlearn: 0.0541747\ttotal: 2m 8s\tremaining: 17s\n",
      "883:\tlearn: 0.0541836\ttotal: 2m 8s\tremaining: 16.8s\n",
      "884:\tlearn: 0.0541392\ttotal: 2m 8s\tremaining: 16.7s\n",
      "885:\tlearn: 0.0540769\ttotal: 2m 8s\tremaining: 16.6s\n",
      "886:\tlearn: 0.0540591\ttotal: 2m 8s\tremaining: 16.4s\n",
      "887:\tlearn: 0.0539968\ttotal: 2m 9s\tremaining: 16.3s\n",
      "888:\tlearn: 0.0539924\ttotal: 2m 9s\tremaining: 16.1s\n",
      "889:\tlearn: 0.0539968\ttotal: 2m 9s\tremaining: 16s\n",
      "890:\tlearn: 0.0540102\ttotal: 2m 9s\tremaining: 15.8s\n",
      "891:\tlearn: 0.0539702\ttotal: 2m 9s\tremaining: 15.7s\n",
      "892:\tlearn: 0.0539123\ttotal: 2m 9s\tremaining: 15.5s\n",
      "893:\tlearn: 0.0538990\ttotal: 2m 9s\tremaining: 15.4s\n",
      "894:\tlearn: 0.0538990\ttotal: 2m 10s\tremaining: 15.3s\n",
      "895:\tlearn: 0.0538946\ttotal: 2m 10s\tremaining: 15.1s\n",
      "896:\tlearn: 0.0538723\ttotal: 2m 10s\tremaining: 15s\n",
      "897:\tlearn: 0.0538679\ttotal: 2m 10s\tremaining: 14.8s\n",
      "898:\tlearn: 0.0538412\ttotal: 2m 10s\tremaining: 14.7s\n",
      "899:\tlearn: 0.0538412\ttotal: 2m 10s\tremaining: 14.5s\n",
      "900:\tlearn: 0.0538323\ttotal: 2m 10s\tremaining: 14.4s\n",
      "901:\tlearn: 0.0538234\ttotal: 2m 11s\tremaining: 14.2s\n",
      "902:\tlearn: 0.0538234\ttotal: 2m 11s\tremaining: 14.1s\n",
      "903:\tlearn: 0.0538056\ttotal: 2m 11s\tremaining: 13.9s\n",
      "904:\tlearn: 0.0537656\ttotal: 2m 11s\tremaining: 13.8s\n",
      "905:\tlearn: 0.0537211\ttotal: 2m 11s\tremaining: 13.7s\n",
      "906:\tlearn: 0.0536055\ttotal: 2m 11s\tremaining: 13.5s\n",
      "907:\tlearn: 0.0535788\ttotal: 2m 11s\tremaining: 13.4s\n",
      "908:\tlearn: 0.0535566\ttotal: 2m 12s\tremaining: 13.2s\n",
      "909:\tlearn: 0.0536010\ttotal: 2m 12s\tremaining: 13.1s\n",
      "910:\tlearn: 0.0535388\ttotal: 2m 12s\tremaining: 12.9s\n",
      "911:\tlearn: 0.0535166\ttotal: 2m 12s\tremaining: 12.8s\n",
      "912:\tlearn: 0.0535077\ttotal: 2m 12s\tremaining: 12.6s\n",
      "913:\tlearn: 0.0535121\ttotal: 2m 12s\tremaining: 12.5s\n",
      "914:\tlearn: 0.0534988\ttotal: 2m 12s\tremaining: 12.3s\n",
      "915:\tlearn: 0.0534632\ttotal: 2m 13s\tremaining: 12.2s\n",
      "916:\tlearn: 0.0534321\ttotal: 2m 13s\tremaining: 12.1s\n",
      "917:\tlearn: 0.0534365\ttotal: 2m 13s\tremaining: 11.9s\n",
      "918:\tlearn: 0.0533920\ttotal: 2m 13s\tremaining: 11.8s\n",
      "919:\tlearn: 0.0534098\ttotal: 2m 13s\tremaining: 11.6s\n",
      "920:\tlearn: 0.0533075\ttotal: 2m 13s\tremaining: 11.5s\n",
      "921:\tlearn: 0.0533209\ttotal: 2m 13s\tremaining: 11.3s\n",
      "922:\tlearn: 0.0532898\ttotal: 2m 13s\tremaining: 11.2s\n",
      "923:\tlearn: 0.0532586\ttotal: 2m 14s\tremaining: 11s\n",
      "924:\tlearn: 0.0532186\ttotal: 2m 14s\tremaining: 10.9s\n",
      "925:\tlearn: 0.0532097\ttotal: 2m 14s\tremaining: 10.7s\n",
      "926:\tlearn: 0.0531741\ttotal: 2m 14s\tremaining: 10.6s\n",
      "927:\tlearn: 0.0531519\ttotal: 2m 14s\tremaining: 10.4s\n",
      "928:\tlearn: 0.0531074\ttotal: 2m 14s\tremaining: 10.3s\n",
      "929:\tlearn: 0.0531119\ttotal: 2m 14s\tremaining: 10.2s\n",
      "930:\tlearn: 0.0531074\ttotal: 2m 15s\tremaining: 10s\n",
      "931:\tlearn: 0.0530541\ttotal: 2m 15s\tremaining: 9.87s\n",
      "932:\tlearn: 0.0530363\ttotal: 2m 15s\tremaining: 9.72s\n",
      "933:\tlearn: 0.0530185\ttotal: 2m 15s\tremaining: 9.57s\n",
      "934:\tlearn: 0.0529829\ttotal: 2m 15s\tremaining: 9.43s\n",
      "935:\tlearn: 0.0529740\ttotal: 2m 15s\tremaining: 9.28s\n",
      "936:\tlearn: 0.0529073\ttotal: 2m 15s\tremaining: 9.14s\n",
      "937:\tlearn: 0.0528984\ttotal: 2m 16s\tremaining: 8.99s\n",
      "938:\tlearn: 0.0528984\ttotal: 2m 16s\tremaining: 8.85s\n",
      "939:\tlearn: 0.0528851\ttotal: 2m 16s\tremaining: 8.7s\n",
      "940:\tlearn: 0.0528673\ttotal: 2m 16s\tremaining: 8.56s\n",
      "941:\tlearn: 0.0528273\ttotal: 2m 16s\tremaining: 8.41s\n",
      "942:\tlearn: 0.0528273\ttotal: 2m 16s\tremaining: 8.27s\n",
      "943:\tlearn: 0.0528050\ttotal: 2m 16s\tremaining: 8.12s\n",
      "944:\tlearn: 0.0527783\ttotal: 2m 17s\tremaining: 7.97s\n",
      "945:\tlearn: 0.0527428\ttotal: 2m 17s\tremaining: 7.83s\n",
      "946:\tlearn: 0.0527072\ttotal: 2m 17s\tremaining: 7.68s\n",
      "947:\tlearn: 0.0526761\ttotal: 2m 17s\tremaining: 7.54s\n",
      "948:\tlearn: 0.0526494\ttotal: 2m 17s\tremaining: 7.39s\n",
      "949:\tlearn: 0.0525693\ttotal: 2m 17s\tremaining: 7.25s\n",
      "950:\tlearn: 0.0525160\ttotal: 2m 17s\tremaining: 7.1s\n",
      "951:\tlearn: 0.0525248\ttotal: 2m 18s\tremaining: 6.96s\n",
      "952:\tlearn: 0.0524492\ttotal: 2m 18s\tremaining: 6.81s\n",
      "953:\tlearn: 0.0524670\ttotal: 2m 18s\tremaining: 6.67s\n",
      "954:\tlearn: 0.0524715\ttotal: 2m 18s\tremaining: 6.52s\n",
      "955:\tlearn: 0.0524092\ttotal: 2m 18s\tremaining: 6.38s\n",
      "956:\tlearn: 0.0524226\ttotal: 2m 18s\tremaining: 6.23s\n",
      "957:\tlearn: 0.0523870\ttotal: 2m 18s\tremaining: 6.09s\n",
      "958:\tlearn: 0.0523648\ttotal: 2m 18s\tremaining: 5.94s\n",
      "959:\tlearn: 0.0523425\ttotal: 2m 19s\tremaining: 5.8s\n",
      "960:\tlearn: 0.0522803\ttotal: 2m 19s\tremaining: 5.65s\n",
      "961:\tlearn: 0.0522936\ttotal: 2m 19s\tremaining: 5.51s\n",
      "962:\tlearn: 0.0522536\ttotal: 2m 19s\tremaining: 5.36s\n",
      "963:\tlearn: 0.0521958\ttotal: 2m 19s\tremaining: 5.22s\n",
      "964:\tlearn: 0.0521691\ttotal: 2m 19s\tremaining: 5.07s\n",
      "965:\tlearn: 0.0521291\ttotal: 2m 20s\tremaining: 4.93s\n",
      "966:\tlearn: 0.0521113\ttotal: 2m 20s\tremaining: 4.78s\n",
      "967:\tlearn: 0.0521379\ttotal: 2m 20s\tremaining: 4.64s\n",
      "968:\tlearn: 0.0521202\ttotal: 2m 20s\tremaining: 4.49s\n",
      "969:\tlearn: 0.0520935\ttotal: 2m 20s\tremaining: 4.35s\n",
      "970:\tlearn: 0.0520801\ttotal: 2m 20s\tremaining: 4.2s\n",
      "971:\tlearn: 0.0520490\ttotal: 2m 20s\tremaining: 4.06s\n",
      "972:\tlearn: 0.0520001\ttotal: 2m 20s\tremaining: 3.91s\n",
      "973:\tlearn: 0.0520134\ttotal: 2m 21s\tremaining: 3.77s\n",
      "974:\tlearn: 0.0519779\ttotal: 2m 21s\tremaining: 3.62s\n",
      "975:\tlearn: 0.0519467\ttotal: 2m 21s\tremaining: 3.48s\n",
      "976:\tlearn: 0.0519023\ttotal: 2m 21s\tremaining: 3.33s\n",
      "977:\tlearn: 0.0519156\ttotal: 2m 21s\tremaining: 3.19s\n",
      "978:\tlearn: 0.0518889\ttotal: 2m 21s\tremaining: 3.04s\n",
      "979:\tlearn: 0.0518622\ttotal: 2m 21s\tremaining: 2.9s\n",
      "980:\tlearn: 0.0518578\ttotal: 2m 22s\tremaining: 2.75s\n",
      "981:\tlearn: 0.0518089\ttotal: 2m 22s\tremaining: 2.61s\n",
      "982:\tlearn: 0.0518000\ttotal: 2m 22s\tremaining: 2.46s\n",
      "983:\tlearn: 0.0517777\ttotal: 2m 22s\tremaining: 2.32s\n",
      "984:\tlearn: 0.0517644\ttotal: 2m 22s\tremaining: 2.17s\n",
      "985:\tlearn: 0.0517377\ttotal: 2m 22s\tremaining: 2.03s\n",
      "986:\tlearn: 0.0517466\ttotal: 2m 22s\tremaining: 1.88s\n",
      "987:\tlearn: 0.0517422\ttotal: 2m 23s\tremaining: 1.74s\n",
      "988:\tlearn: 0.0517110\ttotal: 2m 23s\tremaining: 1.59s\n",
      "989:\tlearn: 0.0516888\ttotal: 2m 23s\tremaining: 1.45s\n",
      "990:\tlearn: 0.0516932\ttotal: 2m 23s\tremaining: 1.3s\n",
      "991:\tlearn: 0.0516577\ttotal: 2m 23s\tremaining: 1.16s\n",
      "992:\tlearn: 0.0516221\ttotal: 2m 23s\tremaining: 1.01s\n",
      "993:\tlearn: 0.0515732\ttotal: 2m 23s\tremaining: 869ms\n",
      "994:\tlearn: 0.0515687\ttotal: 2m 24s\tremaining: 724ms\n",
      "995:\tlearn: 0.0515821\ttotal: 2m 24s\tremaining: 579ms\n",
      "996:\tlearn: 0.0515776\ttotal: 2m 24s\tremaining: 434ms\n",
      "997:\tlearn: 0.0515732\ttotal: 2m 24s\tremaining: 290ms\n",
      "998:\tlearn: 0.0515509\ttotal: 2m 24s\tremaining: 145ms\n",
      "999:\tlearn: 0.0515109\ttotal: 2m 24s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x21c1c8ca5d0>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_clf = CatBoostClassifier(loss_function='MultiLogloss',\n",
    "                            eval_metric='HammingLoss',\n",
    "                            verbose=1)\n",
    "cat_clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745d4a43-e133-41b2-a3bc-855887037771",
   "metadata": {},
   "source": [
    "### Evaluate Cat Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6310bbe1-7d7b-4b2d-b59d-769c238b2405",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score     94.848421\n",
      "precision_score    93.167368\n",
      "recall_score       72.825789\n",
      "f1_score           78.231579\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Developer, back-end</th>\n",
       "      <td>87.90</td>\n",
       "      <td>88.01</td>\n",
       "      <td>71.84</td>\n",
       "      <td>76.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, full-stack</th>\n",
       "      <td>90.39</td>\n",
       "      <td>88.94</td>\n",
       "      <td>76.98</td>\n",
       "      <td>81.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, desktop or enterprise applications</th>\n",
       "      <td>92.91</td>\n",
       "      <td>89.36</td>\n",
       "      <td>66.79</td>\n",
       "      <td>72.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, embedded applications or devices</th>\n",
       "      <td>95.88</td>\n",
       "      <td>90.02</td>\n",
       "      <td>76.01</td>\n",
       "      <td>81.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Academic researcher</th>\n",
       "      <td>94.62</td>\n",
       "      <td>91.05</td>\n",
       "      <td>76.10</td>\n",
       "      <td>81.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scientist</th>\n",
       "      <td>95.67</td>\n",
       "      <td>91.75</td>\n",
       "      <td>74.24</td>\n",
       "      <td>80.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DevOps specialist</th>\n",
       "      <td>94.84</td>\n",
       "      <td>91.86</td>\n",
       "      <td>75.42</td>\n",
       "      <td>81.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cloud infrastructure engineer</th>\n",
       "      <td>94.82</td>\n",
       "      <td>92.02</td>\n",
       "      <td>73.01</td>\n",
       "      <td>79.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, front-end</th>\n",
       "      <td>96.29</td>\n",
       "      <td>92.23</td>\n",
       "      <td>80.61</td>\n",
       "      <td>85.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data scientist or machine learning specialist</th>\n",
       "      <td>96.34</td>\n",
       "      <td>92.44</td>\n",
       "      <td>85.48</td>\n",
       "      <td>88.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data or business analyst</th>\n",
       "      <td>95.18</td>\n",
       "      <td>92.44</td>\n",
       "      <td>70.30</td>\n",
       "      <td>76.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, game or graphics</th>\n",
       "      <td>96.92</td>\n",
       "      <td>93.45</td>\n",
       "      <td>76.75</td>\n",
       "      <td>82.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Engineer, data</th>\n",
       "      <td>94.90</td>\n",
       "      <td>94.35</td>\n",
       "      <td>69.57</td>\n",
       "      <td>76.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>System administrator</th>\n",
       "      <td>94.34</td>\n",
       "      <td>95.69</td>\n",
       "      <td>66.89</td>\n",
       "      <td>73.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, mobile</th>\n",
       "      <td>98.24</td>\n",
       "      <td>96.21</td>\n",
       "      <td>90.85</td>\n",
       "      <td>93.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Database administrator</th>\n",
       "      <td>94.51</td>\n",
       "      <td>97.21</td>\n",
       "      <td>61.54</td>\n",
       "      <td>67.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, QA or test</th>\n",
       "      <td>94.58</td>\n",
       "      <td>97.27</td>\n",
       "      <td>56.81</td>\n",
       "      <td>60.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blockchain</th>\n",
       "      <td>97.63</td>\n",
       "      <td>97.82</td>\n",
       "      <td>73.59</td>\n",
       "      <td>81.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Security professional</th>\n",
       "      <td>96.16</td>\n",
       "      <td>98.06</td>\n",
       "      <td>60.91</td>\n",
       "      <td>66.92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               accuracy_score  \\\n",
       "Developer, back-end                                     87.90   \n",
       "Developer, full-stack                                   90.39   \n",
       "Developer, desktop or enterprise applications           92.91   \n",
       "Developer, embedded applications or devices             95.88   \n",
       "Academic researcher                                     94.62   \n",
       "Scientist                                               95.67   \n",
       "DevOps specialist                                       94.84   \n",
       "Cloud infrastructure engineer                           94.82   \n",
       "Developer, front-end                                    96.29   \n",
       "Data scientist or machine learning specialist           96.34   \n",
       "Data or business analyst                                95.18   \n",
       "Developer, game or graphics                             96.92   \n",
       "Engineer, data                                          94.90   \n",
       "System administrator                                    94.34   \n",
       "Developer, mobile                                       98.24   \n",
       "Database administrator                                  94.51   \n",
       "Developer, QA or test                                   94.58   \n",
       "Blockchain                                              97.63   \n",
       "Security professional                                   96.16   \n",
       "\n",
       "                                               precision_score  recall_score  \\\n",
       "Developer, back-end                                      88.01         71.84   \n",
       "Developer, full-stack                                    88.94         76.98   \n",
       "Developer, desktop or enterprise applications            89.36         66.79   \n",
       "Developer, embedded applications or devices              90.02         76.01   \n",
       "Academic researcher                                      91.05         76.10   \n",
       "Scientist                                                91.75         74.24   \n",
       "DevOps specialist                                        91.86         75.42   \n",
       "Cloud infrastructure engineer                            92.02         73.01   \n",
       "Developer, front-end                                     92.23         80.61   \n",
       "Data scientist or machine learning specialist            92.44         85.48   \n",
       "Data or business analyst                                 92.44         70.30   \n",
       "Developer, game or graphics                              93.45         76.75   \n",
       "Engineer, data                                           94.35         69.57   \n",
       "System administrator                                     95.69         66.89   \n",
       "Developer, mobile                                        96.21         90.85   \n",
       "Database administrator                                   97.21         61.54   \n",
       "Developer, QA or test                                    97.27         56.81   \n",
       "Blockchain                                               97.82         73.59   \n",
       "Security professional                                    98.06         60.91   \n",
       "\n",
       "                                               f1_score  \n",
       "Developer, back-end                               76.32  \n",
       "Developer, full-stack                             81.18  \n",
       "Developer, desktop or enterprise applications     72.53  \n",
       "Developer, embedded applications or devices       81.28  \n",
       "Academic researcher                               81.50  \n",
       "Scientist                                         80.27  \n",
       "DevOps specialist                                 81.18  \n",
       "Cloud infrastructure engineer                     79.18  \n",
       "Developer, front-end                              85.31  \n",
       "Data scientist or machine learning specialist     88.56  \n",
       "Data or business analyst                          76.84  \n",
       "Developer, game or graphics                       82.86  \n",
       "Engineer, data                                    76.38  \n",
       "System administrator                              73.61  \n",
       "Developer, mobile                                 93.34  \n",
       "Database administrator                            67.31  \n",
       "Developer, QA or test                             60.58  \n",
       "Blockchain                                        81.25  \n",
       "Security professional                             66.92  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics=[accuracy_score, precision_score, recall_score, f1_score]\n",
    "train_scores, mean_train_scores= calculate_metrics(cat_clf,x_train,y_train, metrics)\n",
    "\n",
    "print(mean_train_scores)\n",
    "train_scores.sort_values(\"precision_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5413b161-26df-48e3-9a5b-745b617b3862",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.024888\n",
      "0:\tlearn: 0.0744313\ttotal: 131ms\tremaining: 2m 11s\n",
      "1:\tlearn: 0.0745047\ttotal: 266ms\tremaining: 2m 12s\n",
      "2:\tlearn: 0.0745247\ttotal: 399ms\tremaining: 2m 12s\n",
      "3:\tlearn: 0.0748649\ttotal: 499ms\tremaining: 2m 4s\n",
      "4:\tlearn: 0.0755186\ttotal: 630ms\tremaining: 2m 5s\n",
      "5:\tlearn: 0.0755186\ttotal: 755ms\tremaining: 2m 5s\n",
      "6:\tlearn: 0.0755053\ttotal: 916ms\tremaining: 2m 9s\n",
      "7:\tlearn: 0.0755186\ttotal: 1.08s\tremaining: 2m 13s\n",
      "8:\tlearn: 0.0754853\ttotal: 1.22s\tremaining: 2m 14s\n",
      "9:\tlearn: 0.0755186\ttotal: 1.35s\tremaining: 2m 13s\n",
      "10:\tlearn: 0.0755186\ttotal: 1.48s\tremaining: 2m 13s\n",
      "11:\tlearn: 0.0755186\ttotal: 1.62s\tremaining: 2m 13s\n",
      "12:\tlearn: 0.0755186\ttotal: 1.76s\tremaining: 2m 13s\n",
      "13:\tlearn: 0.0755186\ttotal: 1.91s\tremaining: 2m 14s\n",
      "14:\tlearn: 0.0755186\ttotal: 2.05s\tremaining: 2m 14s\n",
      "15:\tlearn: 0.0755186\ttotal: 2.24s\tremaining: 2m 17s\n",
      "16:\tlearn: 0.0755186\ttotal: 2.42s\tremaining: 2m 20s\n",
      "17:\tlearn: 0.0755186\ttotal: 2.61s\tremaining: 2m 22s\n",
      "18:\tlearn: 0.0755120\ttotal: 2.84s\tremaining: 2m 26s\n",
      "19:\tlearn: 0.0755053\ttotal: 3.08s\tremaining: 2m 30s\n",
      "20:\tlearn: 0.0754853\ttotal: 3.29s\tremaining: 2m 33s\n",
      "21:\tlearn: 0.0754719\ttotal: 3.48s\tremaining: 2m 34s\n",
      "22:\tlearn: 0.0753719\ttotal: 3.66s\tremaining: 2m 35s\n",
      "23:\tlearn: 0.0754453\ttotal: 3.82s\tremaining: 2m 35s\n",
      "24:\tlearn: 0.0753919\ttotal: 3.98s\tremaining: 2m 35s\n",
      "25:\tlearn: 0.0753185\ttotal: 4.13s\tremaining: 2m 34s\n",
      "26:\tlearn: 0.0752385\ttotal: 4.25s\tremaining: 2m 33s\n",
      "27:\tlearn: 0.0751918\ttotal: 4.36s\tremaining: 2m 31s\n",
      "28:\tlearn: 0.0750717\ttotal: 4.48s\tremaining: 2m 29s\n",
      "29:\tlearn: 0.0750384\ttotal: 4.59s\tremaining: 2m 28s\n",
      "30:\tlearn: 0.0750050\ttotal: 4.71s\tremaining: 2m 27s\n",
      "31:\tlearn: 0.0748783\ttotal: 4.83s\tremaining: 2m 26s\n",
      "32:\tlearn: 0.0748049\ttotal: 4.96s\tremaining: 2m 25s\n",
      "33:\tlearn: 0.0748249\ttotal: 5.08s\tremaining: 2m 24s\n",
      "34:\tlearn: 0.0748182\ttotal: 5.21s\tremaining: 2m 23s\n",
      "35:\tlearn: 0.0747715\ttotal: 5.33s\tremaining: 2m 22s\n",
      "36:\tlearn: 0.0747582\ttotal: 5.46s\tremaining: 2m 22s\n",
      "37:\tlearn: 0.0747048\ttotal: 5.6s\tremaining: 2m 21s\n",
      "38:\tlearn: 0.0746848\ttotal: 5.72s\tremaining: 2m 21s\n",
      "39:\tlearn: 0.0746114\ttotal: 5.86s\tremaining: 2m 20s\n",
      "40:\tlearn: 0.0746314\ttotal: 5.97s\tremaining: 2m 19s\n",
      "41:\tlearn: 0.0745981\ttotal: 6.1s\tremaining: 2m 19s\n",
      "42:\tlearn: 0.0745848\ttotal: 6.22s\tremaining: 2m 18s\n",
      "43:\tlearn: 0.0745180\ttotal: 6.34s\tremaining: 2m 17s\n",
      "44:\tlearn: 0.0744380\ttotal: 6.47s\tremaining: 2m 17s\n",
      "45:\tlearn: 0.0743313\ttotal: 6.59s\tremaining: 2m 16s\n",
      "46:\tlearn: 0.0742445\ttotal: 6.72s\tremaining: 2m 16s\n",
      "47:\tlearn: 0.0740978\ttotal: 6.84s\tremaining: 2m 15s\n",
      "48:\tlearn: 0.0740111\ttotal: 6.97s\tremaining: 2m 15s\n",
      "49:\tlearn: 0.0738843\ttotal: 7.1s\tremaining: 2m 14s\n",
      "50:\tlearn: 0.0738110\ttotal: 7.22s\tremaining: 2m 14s\n",
      "51:\tlearn: 0.0736442\ttotal: 7.35s\tremaining: 2m 14s\n",
      "52:\tlearn: 0.0735975\ttotal: 7.49s\tremaining: 2m 13s\n",
      "53:\tlearn: 0.0734574\ttotal: 7.61s\tremaining: 2m 13s\n",
      "54:\tlearn: 0.0733974\ttotal: 7.73s\tremaining: 2m 12s\n",
      "55:\tlearn: 0.0732973\ttotal: 7.86s\tremaining: 2m 12s\n",
      "56:\tlearn: 0.0732306\ttotal: 7.99s\tremaining: 2m 12s\n",
      "57:\tlearn: 0.0731772\ttotal: 8.11s\tremaining: 2m 11s\n",
      "58:\tlearn: 0.0730572\ttotal: 8.24s\tremaining: 2m 11s\n",
      "59:\tlearn: 0.0729704\ttotal: 8.37s\tremaining: 2m 11s\n",
      "60:\tlearn: 0.0728637\ttotal: 8.5s\tremaining: 2m 10s\n",
      "61:\tlearn: 0.0727770\ttotal: 8.62s\tremaining: 2m 10s\n",
      "62:\tlearn: 0.0726970\ttotal: 8.74s\tremaining: 2m 10s\n",
      "63:\tlearn: 0.0725369\ttotal: 8.86s\tremaining: 2m 9s\n",
      "64:\tlearn: 0.0725569\ttotal: 8.98s\tremaining: 2m 9s\n",
      "65:\tlearn: 0.0724368\ttotal: 9.11s\tremaining: 2m 8s\n",
      "66:\tlearn: 0.0723701\ttotal: 9.25s\tremaining: 2m 8s\n",
      "67:\tlearn: 0.0723234\ttotal: 9.37s\tremaining: 2m 8s\n",
      "68:\tlearn: 0.0722700\ttotal: 9.49s\tremaining: 2m 8s\n",
      "69:\tlearn: 0.0721433\ttotal: 9.63s\tremaining: 2m 8s\n",
      "70:\tlearn: 0.0721366\ttotal: 9.77s\tremaining: 2m 7s\n",
      "71:\tlearn: 0.0720499\ttotal: 9.89s\tremaining: 2m 7s\n",
      "72:\tlearn: 0.0719832\ttotal: 10s\tremaining: 2m 7s\n",
      "73:\tlearn: 0.0719098\ttotal: 10.1s\tremaining: 2m 6s\n",
      "74:\tlearn: 0.0718298\ttotal: 10.3s\tremaining: 2m 6s\n",
      "75:\tlearn: 0.0716897\ttotal: 10.4s\tremaining: 2m 6s\n",
      "76:\tlearn: 0.0716030\ttotal: 10.5s\tremaining: 2m 5s\n",
      "77:\tlearn: 0.0714695\ttotal: 10.7s\tremaining: 2m 6s\n",
      "78:\tlearn: 0.0714162\ttotal: 10.8s\tremaining: 2m 5s\n",
      "79:\tlearn: 0.0713495\ttotal: 10.9s\tremaining: 2m 5s\n",
      "80:\tlearn: 0.0712227\ttotal: 11s\tremaining: 2m 5s\n",
      "81:\tlearn: 0.0711427\ttotal: 11.2s\tremaining: 2m 4s\n",
      "82:\tlearn: 0.0709893\ttotal: 11.3s\tremaining: 2m 4s\n",
      "83:\tlearn: 0.0708425\ttotal: 11.4s\tremaining: 2m 4s\n",
      "84:\tlearn: 0.0708025\ttotal: 11.5s\tremaining: 2m 3s\n",
      "85:\tlearn: 0.0706691\ttotal: 11.6s\tremaining: 2m 3s\n",
      "86:\tlearn: 0.0706491\ttotal: 11.8s\tremaining: 2m 3s\n",
      "87:\tlearn: 0.0704689\ttotal: 11.9s\tremaining: 2m 3s\n",
      "88:\tlearn: 0.0704089\ttotal: 12s\tremaining: 2m 2s\n",
      "89:\tlearn: 0.0703022\ttotal: 12.1s\tremaining: 2m 2s\n",
      "90:\tlearn: 0.0701354\ttotal: 12.2s\tremaining: 2m 2s\n",
      "91:\tlearn: 0.0700554\ttotal: 12.4s\tremaining: 2m 1s\n",
      "92:\tlearn: 0.0699753\ttotal: 12.5s\tremaining: 2m 1s\n",
      "93:\tlearn: 0.0698152\ttotal: 12.6s\tremaining: 2m 1s\n",
      "94:\tlearn: 0.0696952\ttotal: 12.7s\tremaining: 2m 1s\n",
      "95:\tlearn: 0.0695751\ttotal: 12.8s\tremaining: 2m\n",
      "96:\tlearn: 0.0694417\ttotal: 13s\tremaining: 2m\n",
      "97:\tlearn: 0.0692949\ttotal: 13.1s\tremaining: 2m\n",
      "98:\tlearn: 0.0691682\ttotal: 13.2s\tremaining: 2m\n",
      "99:\tlearn: 0.0690281\ttotal: 13.3s\tremaining: 1m 59s\n",
      "100:\tlearn: 0.0689614\ttotal: 13.4s\tremaining: 1m 59s\n",
      "101:\tlearn: 0.0688680\ttotal: 13.6s\tremaining: 1m 59s\n",
      "102:\tlearn: 0.0687679\ttotal: 13.7s\tremaining: 1m 59s\n",
      "103:\tlearn: 0.0686879\ttotal: 13.8s\tremaining: 1m 58s\n",
      "104:\tlearn: 0.0686278\ttotal: 13.9s\tremaining: 1m 58s\n",
      "105:\tlearn: 0.0685478\ttotal: 14s\tremaining: 1m 58s\n",
      "106:\tlearn: 0.0685011\ttotal: 14.2s\tremaining: 1m 58s\n",
      "107:\tlearn: 0.0684077\ttotal: 14.3s\tremaining: 1m 57s\n",
      "108:\tlearn: 0.0683343\ttotal: 14.4s\tremaining: 1m 57s\n",
      "109:\tlearn: 0.0682943\ttotal: 14.5s\tremaining: 1m 57s\n",
      "110:\tlearn: 0.0682143\ttotal: 14.6s\tremaining: 1m 57s\n",
      "111:\tlearn: 0.0680942\ttotal: 14.8s\tremaining: 1m 57s\n",
      "112:\tlearn: 0.0679474\ttotal: 14.9s\tremaining: 1m 56s\n",
      "113:\tlearn: 0.0677607\ttotal: 15s\tremaining: 1m 56s\n",
      "114:\tlearn: 0.0676473\ttotal: 15.1s\tremaining: 1m 56s\n",
      "115:\tlearn: 0.0674872\ttotal: 15.2s\tremaining: 1m 56s\n",
      "116:\tlearn: 0.0674405\ttotal: 15.4s\tremaining: 1m 55s\n",
      "117:\tlearn: 0.0673604\ttotal: 15.5s\tremaining: 1m 55s\n",
      "118:\tlearn: 0.0673137\ttotal: 15.6s\tremaining: 1m 55s\n",
      "119:\tlearn: 0.0672003\ttotal: 15.7s\tremaining: 1m 55s\n",
      "120:\tlearn: 0.0671069\ttotal: 15.9s\tremaining: 1m 55s\n",
      "121:\tlearn: 0.0670536\ttotal: 16s\tremaining: 1m 55s\n",
      "122:\tlearn: 0.0669468\ttotal: 16.1s\tremaining: 1m 54s\n",
      "123:\tlearn: 0.0668868\ttotal: 16.2s\tremaining: 1m 54s\n",
      "124:\tlearn: 0.0667934\ttotal: 16.3s\tremaining: 1m 54s\n",
      "125:\tlearn: 0.0667934\ttotal: 16.5s\tremaining: 1m 54s\n",
      "126:\tlearn: 0.0667267\ttotal: 16.6s\tremaining: 1m 54s\n",
      "127:\tlearn: 0.0666867\ttotal: 16.7s\tremaining: 1m 54s\n",
      "128:\tlearn: 0.0665266\ttotal: 16.9s\tremaining: 1m 53s\n",
      "129:\tlearn: 0.0664465\ttotal: 17s\tremaining: 1m 53s\n",
      "130:\tlearn: 0.0662731\ttotal: 17.1s\tremaining: 1m 53s\n",
      "131:\tlearn: 0.0661397\ttotal: 17.2s\tremaining: 1m 53s\n",
      "132:\tlearn: 0.0659929\ttotal: 17.3s\tremaining: 1m 53s\n",
      "133:\tlearn: 0.0659129\ttotal: 17.5s\tremaining: 1m 52s\n",
      "134:\tlearn: 0.0658195\ttotal: 17.6s\tremaining: 1m 52s\n",
      "135:\tlearn: 0.0657728\ttotal: 17.7s\tremaining: 1m 52s\n",
      "136:\tlearn: 0.0656394\ttotal: 17.8s\tremaining: 1m 52s\n",
      "137:\tlearn: 0.0655927\ttotal: 18s\tremaining: 1m 52s\n",
      "138:\tlearn: 0.0654860\ttotal: 18.1s\tremaining: 1m 52s\n",
      "139:\tlearn: 0.0654126\ttotal: 18.2s\tremaining: 1m 52s\n",
      "140:\tlearn: 0.0653392\ttotal: 18.4s\tremaining: 1m 51s\n",
      "141:\tlearn: 0.0653325\ttotal: 18.5s\tremaining: 1m 51s\n",
      "142:\tlearn: 0.0652925\ttotal: 18.6s\tremaining: 1m 51s\n",
      "143:\tlearn: 0.0652125\ttotal: 18.7s\tremaining: 1m 51s\n",
      "144:\tlearn: 0.0651391\ttotal: 18.8s\tremaining: 1m 51s\n",
      "145:\tlearn: 0.0650590\ttotal: 19s\tremaining: 1m 50s\n",
      "146:\tlearn: 0.0649790\ttotal: 19.1s\tremaining: 1m 50s\n",
      "147:\tlearn: 0.0648656\ttotal: 19.2s\tremaining: 1m 50s\n",
      "148:\tlearn: 0.0647922\ttotal: 19.3s\tremaining: 1m 50s\n",
      "149:\tlearn: 0.0647122\ttotal: 19.4s\tremaining: 1m 50s\n",
      "150:\tlearn: 0.0646188\ttotal: 19.6s\tremaining: 1m 50s\n",
      "151:\tlearn: 0.0645787\ttotal: 19.7s\tremaining: 1m 49s\n",
      "152:\tlearn: 0.0644987\ttotal: 19.8s\tremaining: 1m 49s\n",
      "153:\tlearn: 0.0644453\ttotal: 19.9s\tremaining: 1m 49s\n",
      "154:\tlearn: 0.0643720\ttotal: 20.1s\tremaining: 1m 49s\n",
      "155:\tlearn: 0.0643253\ttotal: 20.2s\tremaining: 1m 49s\n",
      "156:\tlearn: 0.0642719\ttotal: 20.3s\tremaining: 1m 48s\n",
      "157:\tlearn: 0.0642452\ttotal: 20.4s\tremaining: 1m 48s\n",
      "158:\tlearn: 0.0642252\ttotal: 20.5s\tremaining: 1m 48s\n",
      "159:\tlearn: 0.0641385\ttotal: 20.7s\tremaining: 1m 48s\n",
      "160:\tlearn: 0.0640718\ttotal: 20.8s\tremaining: 1m 48s\n",
      "161:\tlearn: 0.0640518\ttotal: 20.9s\tremaining: 1m 48s\n",
      "162:\tlearn: 0.0640051\ttotal: 21.1s\tremaining: 1m 48s\n",
      "163:\tlearn: 0.0640051\ttotal: 21.2s\tremaining: 1m 48s\n",
      "164:\tlearn: 0.0639317\ttotal: 21.3s\tremaining: 1m 47s\n",
      "165:\tlearn: 0.0638183\ttotal: 21.4s\tremaining: 1m 47s\n",
      "166:\tlearn: 0.0637583\ttotal: 21.6s\tremaining: 1m 47s\n",
      "167:\tlearn: 0.0636982\ttotal: 21.7s\tremaining: 1m 47s\n",
      "168:\tlearn: 0.0636782\ttotal: 21.8s\tremaining: 1m 47s\n",
      "169:\tlearn: 0.0636382\ttotal: 21.9s\tremaining: 1m 47s\n",
      "170:\tlearn: 0.0635915\ttotal: 22s\tremaining: 1m 46s\n",
      "171:\tlearn: 0.0634381\ttotal: 22.2s\tremaining: 1m 46s\n",
      "172:\tlearn: 0.0633513\ttotal: 22.3s\tremaining: 1m 46s\n",
      "173:\tlearn: 0.0633180\ttotal: 22.4s\tremaining: 1m 46s\n",
      "174:\tlearn: 0.0632580\ttotal: 22.5s\tremaining: 1m 46s\n",
      "175:\tlearn: 0.0632313\ttotal: 22.7s\tremaining: 1m 46s\n",
      "176:\tlearn: 0.0632646\ttotal: 22.8s\tremaining: 1m 45s\n",
      "177:\tlearn: 0.0631779\ttotal: 22.9s\tremaining: 1m 45s\n",
      "178:\tlearn: 0.0631512\ttotal: 23s\tremaining: 1m 45s\n",
      "179:\tlearn: 0.0631579\ttotal: 23.1s\tremaining: 1m 45s\n",
      "180:\tlearn: 0.0631112\ttotal: 23.2s\tremaining: 1m 45s\n",
      "181:\tlearn: 0.0630111\ttotal: 23.4s\tremaining: 1m 45s\n",
      "182:\tlearn: 0.0628911\ttotal: 23.5s\tremaining: 1m 44s\n",
      "183:\tlearn: 0.0628777\ttotal: 23.6s\tremaining: 1m 44s\n",
      "184:\tlearn: 0.0628444\ttotal: 23.7s\tremaining: 1m 44s\n",
      "185:\tlearn: 0.0628244\ttotal: 23.8s\tremaining: 1m 44s\n",
      "186:\tlearn: 0.0627443\ttotal: 24s\tremaining: 1m 44s\n",
      "187:\tlearn: 0.0627176\ttotal: 24.1s\tremaining: 1m 44s\n",
      "188:\tlearn: 0.0626576\ttotal: 24.2s\tremaining: 1m 43s\n",
      "189:\tlearn: 0.0626242\ttotal: 24.3s\tremaining: 1m 43s\n",
      "190:\tlearn: 0.0625909\ttotal: 24.4s\tremaining: 1m 43s\n",
      "191:\tlearn: 0.0625375\ttotal: 24.6s\tremaining: 1m 43s\n",
      "192:\tlearn: 0.0624775\ttotal: 24.7s\tremaining: 1m 43s\n",
      "193:\tlearn: 0.0624641\ttotal: 24.8s\tremaining: 1m 43s\n",
      "194:\tlearn: 0.0623641\ttotal: 24.9s\tremaining: 1m 42s\n",
      "195:\tlearn: 0.0623241\ttotal: 25.1s\tremaining: 1m 42s\n",
      "196:\tlearn: 0.0623307\ttotal: 25.2s\tremaining: 1m 42s\n",
      "197:\tlearn: 0.0622240\ttotal: 25.3s\tremaining: 1m 42s\n",
      "198:\tlearn: 0.0621440\ttotal: 25.4s\tremaining: 1m 42s\n",
      "199:\tlearn: 0.0621306\ttotal: 25.6s\tremaining: 1m 42s\n",
      "200:\tlearn: 0.0620839\ttotal: 25.7s\tremaining: 1m 42s\n",
      "201:\tlearn: 0.0620639\ttotal: 25.8s\tremaining: 1m 41s\n",
      "202:\tlearn: 0.0620306\ttotal: 25.9s\tremaining: 1m 41s\n",
      "203:\tlearn: 0.0620105\ttotal: 26s\tremaining: 1m 41s\n",
      "204:\tlearn: 0.0619638\ttotal: 26.1s\tremaining: 1m 41s\n",
      "205:\tlearn: 0.0619905\ttotal: 26.3s\tremaining: 1m 41s\n",
      "206:\tlearn: 0.0618571\ttotal: 26.4s\tremaining: 1m 41s\n",
      "207:\tlearn: 0.0618371\ttotal: 26.5s\tremaining: 1m 40s\n",
      "208:\tlearn: 0.0617771\ttotal: 26.6s\tremaining: 1m 40s\n",
      "209:\tlearn: 0.0617104\ttotal: 26.8s\tremaining: 1m 40s\n",
      "210:\tlearn: 0.0616370\ttotal: 26.9s\tremaining: 1m 40s\n",
      "211:\tlearn: 0.0616170\ttotal: 27s\tremaining: 1m 40s\n",
      "212:\tlearn: 0.0616036\ttotal: 27.1s\tremaining: 1m 40s\n",
      "213:\tlearn: 0.0615769\ttotal: 27.3s\tremaining: 1m 40s\n",
      "214:\tlearn: 0.0615836\ttotal: 27.4s\tremaining: 1m 39s\n",
      "215:\tlearn: 0.0614902\ttotal: 27.5s\tremaining: 1m 39s\n",
      "216:\tlearn: 0.0614302\ttotal: 27.6s\tremaining: 1m 39s\n",
      "217:\tlearn: 0.0614102\ttotal: 27.7s\tremaining: 1m 39s\n",
      "218:\tlearn: 0.0613902\ttotal: 27.8s\tremaining: 1m 39s\n",
      "219:\tlearn: 0.0613301\ttotal: 28s\tremaining: 1m 39s\n",
      "220:\tlearn: 0.0612968\ttotal: 28.1s\tremaining: 1m 38s\n",
      "221:\tlearn: 0.0612834\ttotal: 28.2s\tremaining: 1m 38s\n",
      "222:\tlearn: 0.0612634\ttotal: 28.3s\tremaining: 1m 38s\n",
      "223:\tlearn: 0.0611967\ttotal: 28.4s\tremaining: 1m 38s\n",
      "224:\tlearn: 0.0611500\ttotal: 28.6s\tremaining: 1m 38s\n",
      "225:\tlearn: 0.0611033\ttotal: 28.7s\tremaining: 1m 38s\n",
      "226:\tlearn: 0.0610500\ttotal: 28.8s\tremaining: 1m 38s\n",
      "227:\tlearn: 0.0610233\ttotal: 28.9s\tremaining: 1m 37s\n",
      "228:\tlearn: 0.0610099\ttotal: 29s\tremaining: 1m 37s\n",
      "229:\tlearn: 0.0609632\ttotal: 29.2s\tremaining: 1m 37s\n",
      "230:\tlearn: 0.0609432\ttotal: 29.3s\tremaining: 1m 37s\n",
      "231:\tlearn: 0.0608765\ttotal: 29.4s\tremaining: 1m 37s\n",
      "232:\tlearn: 0.0608765\ttotal: 29.5s\tremaining: 1m 37s\n",
      "233:\tlearn: 0.0607898\ttotal: 29.7s\tremaining: 1m 37s\n",
      "234:\tlearn: 0.0606764\ttotal: 29.8s\tremaining: 1m 36s\n",
      "235:\tlearn: 0.0606364\ttotal: 29.9s\tremaining: 1m 36s\n",
      "236:\tlearn: 0.0605763\ttotal: 30s\tremaining: 1m 36s\n",
      "237:\tlearn: 0.0605430\ttotal: 30.1s\tremaining: 1m 36s\n",
      "238:\tlearn: 0.0605096\ttotal: 30.3s\tremaining: 1m 36s\n",
      "239:\tlearn: 0.0604896\ttotal: 30.4s\tremaining: 1m 36s\n",
      "240:\tlearn: 0.0604296\ttotal: 30.5s\tremaining: 1m 36s\n",
      "241:\tlearn: 0.0603696\ttotal: 30.6s\tremaining: 1m 35s\n",
      "242:\tlearn: 0.0603095\ttotal: 30.7s\tremaining: 1m 35s\n",
      "243:\tlearn: 0.0603229\ttotal: 30.8s\tremaining: 1m 35s\n",
      "244:\tlearn: 0.0602895\ttotal: 31s\tremaining: 1m 35s\n",
      "245:\tlearn: 0.0602695\ttotal: 31.1s\tremaining: 1m 35s\n",
      "246:\tlearn: 0.0602428\ttotal: 31.2s\tremaining: 1m 35s\n",
      "247:\tlearn: 0.0602228\ttotal: 31.3s\tremaining: 1m 34s\n",
      "248:\tlearn: 0.0601961\ttotal: 31.4s\tremaining: 1m 34s\n",
      "249:\tlearn: 0.0601561\ttotal: 31.6s\tremaining: 1m 34s\n",
      "250:\tlearn: 0.0600827\ttotal: 31.7s\tremaining: 1m 34s\n",
      "251:\tlearn: 0.0600427\ttotal: 31.8s\tremaining: 1m 34s\n",
      "252:\tlearn: 0.0599827\ttotal: 32s\tremaining: 1m 34s\n",
      "253:\tlearn: 0.0599693\ttotal: 32.1s\tremaining: 1m 34s\n",
      "254:\tlearn: 0.0599159\ttotal: 32.2s\tremaining: 1m 34s\n",
      "255:\tlearn: 0.0598626\ttotal: 32.4s\tremaining: 1m 34s\n",
      "256:\tlearn: 0.0598092\ttotal: 32.5s\tremaining: 1m 33s\n",
      "257:\tlearn: 0.0597559\ttotal: 32.6s\tremaining: 1m 33s\n",
      "258:\tlearn: 0.0597559\ttotal: 32.8s\tremaining: 1m 33s\n",
      "259:\tlearn: 0.0597358\ttotal: 32.9s\tremaining: 1m 33s\n",
      "260:\tlearn: 0.0597225\ttotal: 33s\tremaining: 1m 33s\n",
      "261:\tlearn: 0.0596425\ttotal: 33.2s\tremaining: 1m 33s\n",
      "262:\tlearn: 0.0596358\ttotal: 33.3s\tremaining: 1m 33s\n",
      "263:\tlearn: 0.0595357\ttotal: 33.4s\tremaining: 1m 33s\n",
      "264:\tlearn: 0.0595090\ttotal: 33.5s\tremaining: 1m 32s\n",
      "265:\tlearn: 0.0593956\ttotal: 33.6s\tremaining: 1m 32s\n",
      "266:\tlearn: 0.0593823\ttotal: 33.8s\tremaining: 1m 32s\n",
      "267:\tlearn: 0.0593089\ttotal: 33.9s\tremaining: 1m 32s\n",
      "268:\tlearn: 0.0592622\ttotal: 34s\tremaining: 1m 32s\n",
      "269:\tlearn: 0.0592756\ttotal: 34.1s\tremaining: 1m 32s\n",
      "270:\tlearn: 0.0592355\ttotal: 34.2s\tremaining: 1m 32s\n",
      "271:\tlearn: 0.0592022\ttotal: 34.4s\tremaining: 1m 31s\n",
      "272:\tlearn: 0.0591088\ttotal: 34.5s\tremaining: 1m 31s\n",
      "273:\tlearn: 0.0590288\ttotal: 34.6s\tremaining: 1m 31s\n",
      "274:\tlearn: 0.0589687\ttotal: 34.7s\tremaining: 1m 31s\n",
      "275:\tlearn: 0.0589821\ttotal: 34.8s\tremaining: 1m 31s\n",
      "276:\tlearn: 0.0588953\ttotal: 35s\tremaining: 1m 31s\n",
      "277:\tlearn: 0.0588220\ttotal: 35.1s\tremaining: 1m 31s\n",
      "278:\tlearn: 0.0587619\ttotal: 35.2s\tremaining: 1m 30s\n",
      "279:\tlearn: 0.0587886\ttotal: 35.3s\tremaining: 1m 30s\n",
      "280:\tlearn: 0.0587286\ttotal: 35.4s\tremaining: 1m 30s\n",
      "281:\tlearn: 0.0587352\ttotal: 35.6s\tremaining: 1m 30s\n",
      "282:\tlearn: 0.0586819\ttotal: 35.7s\tremaining: 1m 30s\n",
      "283:\tlearn: 0.0586285\ttotal: 35.8s\tremaining: 1m 30s\n",
      "284:\tlearn: 0.0585618\ttotal: 35.9s\tremaining: 1m 30s\n",
      "285:\tlearn: 0.0584417\ttotal: 36.1s\tremaining: 1m 30s\n",
      "286:\tlearn: 0.0583950\ttotal: 36.2s\tremaining: 1m 29s\n",
      "287:\tlearn: 0.0583950\ttotal: 36.3s\tremaining: 1m 29s\n",
      "288:\tlearn: 0.0583550\ttotal: 36.4s\tremaining: 1m 29s\n",
      "289:\tlearn: 0.0583283\ttotal: 36.6s\tremaining: 1m 29s\n",
      "290:\tlearn: 0.0583483\ttotal: 36.7s\tremaining: 1m 29s\n",
      "291:\tlearn: 0.0582616\ttotal: 36.8s\tremaining: 1m 29s\n",
      "292:\tlearn: 0.0582550\ttotal: 36.9s\tremaining: 1m 29s\n",
      "293:\tlearn: 0.0582016\ttotal: 37s\tremaining: 1m 28s\n",
      "294:\tlearn: 0.0581682\ttotal: 37.1s\tremaining: 1m 28s\n",
      "295:\tlearn: 0.0581749\ttotal: 37.3s\tremaining: 1m 28s\n",
      "296:\tlearn: 0.0581549\ttotal: 37.4s\tremaining: 1m 28s\n",
      "297:\tlearn: 0.0581015\ttotal: 37.5s\tremaining: 1m 28s\n",
      "298:\tlearn: 0.0581082\ttotal: 37.7s\tremaining: 1m 28s\n",
      "299:\tlearn: 0.0580482\ttotal: 37.8s\tremaining: 1m 28s\n",
      "300:\tlearn: 0.0579748\ttotal: 37.9s\tremaining: 1m 27s\n",
      "301:\tlearn: 0.0579281\ttotal: 38s\tremaining: 1m 27s\n",
      "302:\tlearn: 0.0579414\ttotal: 38.1s\tremaining: 1m 27s\n",
      "303:\tlearn: 0.0578347\ttotal: 38.2s\tremaining: 1m 27s\n",
      "304:\tlearn: 0.0578547\ttotal: 38.4s\tremaining: 1m 27s\n",
      "305:\tlearn: 0.0578414\ttotal: 38.5s\tremaining: 1m 27s\n",
      "306:\tlearn: 0.0577813\ttotal: 38.6s\tremaining: 1m 27s\n",
      "307:\tlearn: 0.0577547\ttotal: 38.7s\tremaining: 1m 27s\n",
      "308:\tlearn: 0.0577346\ttotal: 38.9s\tremaining: 1m 26s\n",
      "309:\tlearn: 0.0577280\ttotal: 39s\tremaining: 1m 26s\n",
      "310:\tlearn: 0.0576079\ttotal: 39.1s\tremaining: 1m 26s\n",
      "311:\tlearn: 0.0576012\ttotal: 39.2s\tremaining: 1m 26s\n",
      "312:\tlearn: 0.0575545\ttotal: 39.4s\tremaining: 1m 26s\n",
      "313:\tlearn: 0.0575679\ttotal: 39.5s\tremaining: 1m 26s\n",
      "314:\tlearn: 0.0575279\ttotal: 39.7s\tremaining: 1m 26s\n",
      "315:\tlearn: 0.0574745\ttotal: 39.8s\tremaining: 1m 26s\n",
      "316:\tlearn: 0.0574278\ttotal: 39.9s\tremaining: 1m 25s\n",
      "317:\tlearn: 0.0573811\ttotal: 40s\tremaining: 1m 25s\n",
      "318:\tlearn: 0.0573477\ttotal: 40.2s\tremaining: 1m 25s\n",
      "319:\tlearn: 0.0573144\ttotal: 40.3s\tremaining: 1m 25s\n",
      "320:\tlearn: 0.0572944\ttotal: 40.4s\tremaining: 1m 25s\n",
      "321:\tlearn: 0.0572477\ttotal: 40.6s\tremaining: 1m 25s\n",
      "322:\tlearn: 0.0572143\ttotal: 40.7s\tremaining: 1m 25s\n",
      "323:\tlearn: 0.0571943\ttotal: 40.8s\tremaining: 1m 25s\n",
      "324:\tlearn: 0.0571876\ttotal: 40.9s\tremaining: 1m 25s\n",
      "325:\tlearn: 0.0571076\ttotal: 41.1s\tremaining: 1m 24s\n",
      "326:\tlearn: 0.0570809\ttotal: 41.2s\tremaining: 1m 24s\n",
      "327:\tlearn: 0.0570476\ttotal: 41.3s\tremaining: 1m 24s\n",
      "328:\tlearn: 0.0570009\ttotal: 41.5s\tremaining: 1m 24s\n",
      "329:\tlearn: 0.0570075\ttotal: 41.6s\tremaining: 1m 24s\n",
      "330:\tlearn: 0.0569809\ttotal: 41.7s\tremaining: 1m 24s\n",
      "331:\tlearn: 0.0569408\ttotal: 41.9s\tremaining: 1m 24s\n",
      "332:\tlearn: 0.0569075\ttotal: 42s\tremaining: 1m 24s\n",
      "333:\tlearn: 0.0568875\ttotal: 42.1s\tremaining: 1m 23s\n",
      "334:\tlearn: 0.0568274\ttotal: 42.2s\tremaining: 1m 23s\n",
      "335:\tlearn: 0.0567941\ttotal: 42.4s\tremaining: 1m 23s\n",
      "336:\tlearn: 0.0567941\ttotal: 42.5s\tremaining: 1m 23s\n",
      "337:\tlearn: 0.0567874\ttotal: 42.6s\tremaining: 1m 23s\n",
      "338:\tlearn: 0.0567474\ttotal: 42.7s\tremaining: 1m 23s\n",
      "339:\tlearn: 0.0566807\ttotal: 42.8s\tremaining: 1m 23s\n",
      "340:\tlearn: 0.0566673\ttotal: 43s\tremaining: 1m 23s\n",
      "341:\tlearn: 0.0565940\ttotal: 43.1s\tremaining: 1m 22s\n",
      "342:\tlearn: 0.0566206\ttotal: 43.2s\tremaining: 1m 22s\n",
      "343:\tlearn: 0.0565339\ttotal: 43.3s\tremaining: 1m 22s\n",
      "344:\tlearn: 0.0565473\ttotal: 43.4s\tremaining: 1m 22s\n",
      "345:\tlearn: 0.0564806\ttotal: 43.6s\tremaining: 1m 22s\n",
      "346:\tlearn: 0.0564005\ttotal: 43.7s\tremaining: 1m 22s\n",
      "347:\tlearn: 0.0563605\ttotal: 43.8s\tremaining: 1m 22s\n",
      "348:\tlearn: 0.0563471\ttotal: 43.9s\tremaining: 1m 21s\n",
      "349:\tlearn: 0.0563071\ttotal: 44s\tremaining: 1m 21s\n",
      "350:\tlearn: 0.0563071\ttotal: 44.1s\tremaining: 1m 21s\n",
      "351:\tlearn: 0.0562337\ttotal: 44.3s\tremaining: 1m 21s\n",
      "352:\tlearn: 0.0561870\ttotal: 44.4s\tremaining: 1m 21s\n",
      "353:\tlearn: 0.0561737\ttotal: 44.5s\tremaining: 1m 21s\n",
      "354:\tlearn: 0.0560670\ttotal: 44.6s\tremaining: 1m 21s\n",
      "355:\tlearn: 0.0560336\ttotal: 44.7s\tremaining: 1m 20s\n",
      "356:\tlearn: 0.0559869\ttotal: 44.9s\tremaining: 1m 20s\n",
      "357:\tlearn: 0.0560136\ttotal: 45s\tremaining: 1m 20s\n",
      "358:\tlearn: 0.0559869\ttotal: 45.1s\tremaining: 1m 20s\n",
      "359:\tlearn: 0.0559602\ttotal: 45.2s\tremaining: 1m 20s\n",
      "360:\tlearn: 0.0559135\ttotal: 45.3s\tremaining: 1m 20s\n",
      "361:\tlearn: 0.0558602\ttotal: 45.5s\tremaining: 1m 20s\n",
      "362:\tlearn: 0.0558935\ttotal: 45.6s\tremaining: 1m 19s\n",
      "363:\tlearn: 0.0558869\ttotal: 45.7s\tremaining: 1m 19s\n",
      "364:\tlearn: 0.0558669\ttotal: 45.8s\tremaining: 1m 19s\n",
      "365:\tlearn: 0.0558402\ttotal: 46s\tremaining: 1m 19s\n",
      "366:\tlearn: 0.0557601\ttotal: 46.1s\tremaining: 1m 19s\n",
      "367:\tlearn: 0.0557201\ttotal: 46.2s\tremaining: 1m 19s\n",
      "368:\tlearn: 0.0556734\ttotal: 46.3s\tremaining: 1m 19s\n",
      "369:\tlearn: 0.0556334\ttotal: 46.5s\tremaining: 1m 19s\n",
      "370:\tlearn: 0.0555867\ttotal: 46.6s\tremaining: 1m 19s\n",
      "371:\tlearn: 0.0555667\ttotal: 46.7s\tremaining: 1m 18s\n",
      "372:\tlearn: 0.0555066\ttotal: 46.9s\tremaining: 1m 18s\n",
      "373:\tlearn: 0.0554599\ttotal: 47s\tremaining: 1m 18s\n",
      "374:\tlearn: 0.0554333\ttotal: 47.1s\tremaining: 1m 18s\n",
      "375:\tlearn: 0.0553666\ttotal: 47.2s\tremaining: 1m 18s\n",
      "376:\tlearn: 0.0553666\ttotal: 47.4s\tremaining: 1m 18s\n",
      "377:\tlearn: 0.0553532\ttotal: 47.5s\tremaining: 1m 18s\n",
      "378:\tlearn: 0.0553599\ttotal: 47.7s\tremaining: 1m 18s\n",
      "379:\tlearn: 0.0552932\ttotal: 47.8s\tremaining: 1m 18s\n",
      "380:\tlearn: 0.0552065\ttotal: 47.9s\tremaining: 1m 17s\n",
      "381:\tlearn: 0.0552465\ttotal: 48.1s\tremaining: 1m 17s\n",
      "382:\tlearn: 0.0552398\ttotal: 48.2s\tremaining: 1m 17s\n",
      "383:\tlearn: 0.0551931\ttotal: 48.3s\tremaining: 1m 17s\n",
      "384:\tlearn: 0.0552065\ttotal: 48.5s\tremaining: 1m 17s\n",
      "385:\tlearn: 0.0551598\ttotal: 48.6s\tremaining: 1m 17s\n",
      "386:\tlearn: 0.0551197\ttotal: 48.7s\tremaining: 1m 17s\n",
      "387:\tlearn: 0.0550530\ttotal: 48.8s\tremaining: 1m 16s\n",
      "388:\tlearn: 0.0550530\ttotal: 48.9s\tremaining: 1m 16s\n",
      "389:\tlearn: 0.0550063\ttotal: 49s\tremaining: 1m 16s\n",
      "390:\tlearn: 0.0549596\ttotal: 49.2s\tremaining: 1m 16s\n",
      "391:\tlearn: 0.0549196\ttotal: 49.3s\tremaining: 1m 16s\n",
      "392:\tlearn: 0.0549196\ttotal: 49.4s\tremaining: 1m 16s\n",
      "393:\tlearn: 0.0548796\ttotal: 49.5s\tremaining: 1m 16s\n",
      "394:\tlearn: 0.0548129\ttotal: 49.7s\tremaining: 1m 16s\n",
      "395:\tlearn: 0.0547462\ttotal: 49.8s\tremaining: 1m 15s\n",
      "396:\tlearn: 0.0547062\ttotal: 49.9s\tremaining: 1m 15s\n",
      "397:\tlearn: 0.0546995\ttotal: 50s\tremaining: 1m 15s\n",
      "398:\tlearn: 0.0547195\ttotal: 50.1s\tremaining: 1m 15s\n",
      "399:\tlearn: 0.0546995\ttotal: 50.3s\tremaining: 1m 15s\n",
      "400:\tlearn: 0.0546728\ttotal: 50.4s\tremaining: 1m 15s\n",
      "401:\tlearn: 0.0546461\ttotal: 50.5s\tremaining: 1m 15s\n",
      "402:\tlearn: 0.0546595\ttotal: 50.6s\tremaining: 1m 14s\n",
      "403:\tlearn: 0.0546194\ttotal: 50.7s\tremaining: 1m 14s\n",
      "404:\tlearn: 0.0546061\ttotal: 50.8s\tremaining: 1m 14s\n",
      "405:\tlearn: 0.0545194\ttotal: 51s\tremaining: 1m 14s\n",
      "406:\tlearn: 0.0545327\ttotal: 51.1s\tremaining: 1m 14s\n",
      "407:\tlearn: 0.0545060\ttotal: 51.2s\tremaining: 1m 14s\n",
      "408:\tlearn: 0.0544794\ttotal: 51.3s\tremaining: 1m 14s\n",
      "409:\tlearn: 0.0544727\ttotal: 51.4s\tremaining: 1m 14s\n",
      "410:\tlearn: 0.0543926\ttotal: 51.6s\tremaining: 1m 13s\n",
      "411:\tlearn: 0.0543526\ttotal: 51.7s\tremaining: 1m 13s\n",
      "412:\tlearn: 0.0543193\ttotal: 51.8s\tremaining: 1m 13s\n",
      "413:\tlearn: 0.0542659\ttotal: 51.9s\tremaining: 1m 13s\n",
      "414:\tlearn: 0.0542526\ttotal: 52s\tremaining: 1m 13s\n",
      "415:\tlearn: 0.0542325\ttotal: 52.2s\tremaining: 1m 13s\n",
      "416:\tlearn: 0.0542059\ttotal: 52.3s\tremaining: 1m 13s\n",
      "417:\tlearn: 0.0541658\ttotal: 52.4s\tremaining: 1m 12s\n",
      "418:\tlearn: 0.0540991\ttotal: 52.5s\tremaining: 1m 12s\n",
      "419:\tlearn: 0.0540724\ttotal: 52.6s\tremaining: 1m 12s\n",
      "420:\tlearn: 0.0540391\ttotal: 52.8s\tremaining: 1m 12s\n",
      "421:\tlearn: 0.0539857\ttotal: 52.9s\tremaining: 1m 12s\n",
      "422:\tlearn: 0.0540124\ttotal: 53s\tremaining: 1m 12s\n",
      "423:\tlearn: 0.0540057\ttotal: 53.1s\tremaining: 1m 12s\n",
      "424:\tlearn: 0.0539657\ttotal: 53.2s\tremaining: 1m 12s\n",
      "425:\tlearn: 0.0538990\ttotal: 53.4s\tremaining: 1m 11s\n",
      "426:\tlearn: 0.0538390\ttotal: 53.5s\tremaining: 1m 11s\n",
      "427:\tlearn: 0.0538056\ttotal: 53.6s\tremaining: 1m 11s\n",
      "428:\tlearn: 0.0537589\ttotal: 53.7s\tremaining: 1m 11s\n",
      "429:\tlearn: 0.0537189\ttotal: 53.9s\tremaining: 1m 11s\n",
      "430:\tlearn: 0.0536789\ttotal: 54s\tremaining: 1m 11s\n",
      "431:\tlearn: 0.0536455\ttotal: 54.1s\tremaining: 1m 11s\n",
      "432:\tlearn: 0.0536055\ttotal: 54.2s\tremaining: 1m 10s\n",
      "433:\tlearn: 0.0535388\ttotal: 54.3s\tremaining: 1m 10s\n",
      "434:\tlearn: 0.0534788\ttotal: 54.4s\tremaining: 1m 10s\n",
      "435:\tlearn: 0.0534721\ttotal: 54.6s\tremaining: 1m 10s\n",
      "436:\tlearn: 0.0534387\ttotal: 54.7s\tremaining: 1m 10s\n",
      "437:\tlearn: 0.0534054\ttotal: 54.8s\tremaining: 1m 10s\n",
      "438:\tlearn: 0.0533720\ttotal: 54.9s\tremaining: 1m 10s\n",
      "439:\tlearn: 0.0533720\ttotal: 55s\tremaining: 1m 10s\n",
      "440:\tlearn: 0.0533654\ttotal: 55.1s\tremaining: 1m 9s\n",
      "441:\tlearn: 0.0533253\ttotal: 55.3s\tremaining: 1m 9s\n",
      "442:\tlearn: 0.0533120\ttotal: 55.4s\tremaining: 1m 9s\n",
      "443:\tlearn: 0.0532586\ttotal: 55.5s\tremaining: 1m 9s\n",
      "444:\tlearn: 0.0532520\ttotal: 55.6s\tremaining: 1m 9s\n",
      "445:\tlearn: 0.0532119\ttotal: 55.7s\tremaining: 1m 9s\n",
      "446:\tlearn: 0.0531786\ttotal: 55.9s\tremaining: 1m 9s\n",
      "447:\tlearn: 0.0531519\ttotal: 56s\tremaining: 1m 8s\n",
      "448:\tlearn: 0.0530919\ttotal: 56.1s\tremaining: 1m 8s\n",
      "449:\tlearn: 0.0530452\ttotal: 56.2s\tremaining: 1m 8s\n",
      "450:\tlearn: 0.0529851\ttotal: 56.3s\tremaining: 1m 8s\n",
      "451:\tlearn: 0.0529785\ttotal: 56.5s\tremaining: 1m 8s\n",
      "452:\tlearn: 0.0529584\ttotal: 56.6s\tremaining: 1m 8s\n",
      "453:\tlearn: 0.0529117\ttotal: 56.7s\tremaining: 1m 8s\n",
      "454:\tlearn: 0.0528917\ttotal: 56.8s\tremaining: 1m 8s\n",
      "455:\tlearn: 0.0528250\ttotal: 56.9s\tremaining: 1m 7s\n",
      "456:\tlearn: 0.0527917\ttotal: 57s\tremaining: 1m 7s\n",
      "457:\tlearn: 0.0527116\ttotal: 57.2s\tremaining: 1m 7s\n",
      "458:\tlearn: 0.0526849\ttotal: 57.3s\tremaining: 1m 7s\n",
      "459:\tlearn: 0.0526716\ttotal: 57.4s\tremaining: 1m 7s\n",
      "460:\tlearn: 0.0526449\ttotal: 57.6s\tremaining: 1m 7s\n",
      "461:\tlearn: 0.0526316\ttotal: 57.7s\tremaining: 1m 7s\n",
      "462:\tlearn: 0.0525515\ttotal: 57.8s\tremaining: 1m 7s\n",
      "463:\tlearn: 0.0525115\ttotal: 57.9s\tremaining: 1m 6s\n",
      "464:\tlearn: 0.0524515\ttotal: 58.1s\tremaining: 1m 6s\n",
      "465:\tlearn: 0.0524048\ttotal: 58.2s\tremaining: 1m 6s\n",
      "466:\tlearn: 0.0523714\ttotal: 58.3s\tremaining: 1m 6s\n",
      "467:\tlearn: 0.0523581\ttotal: 58.5s\tremaining: 1m 6s\n",
      "468:\tlearn: 0.0523447\ttotal: 58.6s\tremaining: 1m 6s\n",
      "469:\tlearn: 0.0522780\ttotal: 58.7s\tremaining: 1m 6s\n",
      "470:\tlearn: 0.0522313\ttotal: 58.8s\tremaining: 1m 6s\n",
      "471:\tlearn: 0.0521846\ttotal: 58.9s\tremaining: 1m 5s\n",
      "472:\tlearn: 0.0521313\ttotal: 59.1s\tremaining: 1m 5s\n",
      "473:\tlearn: 0.0521246\ttotal: 59.2s\tremaining: 1m 5s\n",
      "474:\tlearn: 0.0521046\ttotal: 59.3s\tremaining: 1m 5s\n",
      "475:\tlearn: 0.0520779\ttotal: 59.4s\tremaining: 1m 5s\n",
      "476:\tlearn: 0.0520312\ttotal: 59.6s\tremaining: 1m 5s\n",
      "477:\tlearn: 0.0520446\ttotal: 59.7s\tremaining: 1m 5s\n",
      "478:\tlearn: 0.0519645\ttotal: 59.8s\tremaining: 1m 5s\n",
      "479:\tlearn: 0.0519111\ttotal: 59.9s\tremaining: 1m 4s\n",
      "480:\tlearn: 0.0518778\ttotal: 1m\tremaining: 1m 4s\n",
      "481:\tlearn: 0.0518311\ttotal: 1m\tremaining: 1m 4s\n",
      "482:\tlearn: 0.0518244\ttotal: 1m\tremaining: 1m 4s\n",
      "483:\tlearn: 0.0518044\ttotal: 1m\tremaining: 1m 4s\n",
      "484:\tlearn: 0.0517577\ttotal: 1m\tremaining: 1m 4s\n",
      "485:\tlearn: 0.0516910\ttotal: 1m\tremaining: 1m 4s\n",
      "486:\tlearn: 0.0516710\ttotal: 1m\tremaining: 1m 3s\n",
      "487:\tlearn: 0.0516310\ttotal: 1m\tremaining: 1m 3s\n",
      "488:\tlearn: 0.0516443\ttotal: 1m\tremaining: 1m 3s\n",
      "489:\tlearn: 0.0516443\ttotal: 1m 1s\tremaining: 1m 3s\n",
      "490:\tlearn: 0.0516310\ttotal: 1m 1s\tremaining: 1m 3s\n",
      "491:\tlearn: 0.0515309\ttotal: 1m 1s\tremaining: 1m 3s\n",
      "492:\tlearn: 0.0515376\ttotal: 1m 1s\tremaining: 1m 3s\n",
      "493:\tlearn: 0.0515042\ttotal: 1m 1s\tremaining: 1m 3s\n",
      "494:\tlearn: 0.0514509\ttotal: 1m 1s\tremaining: 1m 2s\n",
      "495:\tlearn: 0.0514309\ttotal: 1m 1s\tremaining: 1m 2s\n",
      "496:\tlearn: 0.0514242\ttotal: 1m 1s\tremaining: 1m 2s\n",
      "497:\tlearn: 0.0513642\ttotal: 1m 2s\tremaining: 1m 2s\n",
      "498:\tlearn: 0.0513241\ttotal: 1m 2s\tremaining: 1m 2s\n",
      "499:\tlearn: 0.0512841\ttotal: 1m 2s\tremaining: 1m 2s\n",
      "500:\tlearn: 0.0512708\ttotal: 1m 2s\tremaining: 1m 2s\n",
      "501:\tlearn: 0.0512508\ttotal: 1m 2s\tremaining: 1m 2s\n",
      "502:\tlearn: 0.0511173\ttotal: 1m 2s\tremaining: 1m 1s\n",
      "503:\tlearn: 0.0511173\ttotal: 1m 2s\tremaining: 1m 1s\n",
      "504:\tlearn: 0.0510907\ttotal: 1m 2s\tremaining: 1m 1s\n",
      "505:\tlearn: 0.0510907\ttotal: 1m 3s\tremaining: 1m 1s\n",
      "506:\tlearn: 0.0510573\ttotal: 1m 3s\tremaining: 1m 1s\n",
      "507:\tlearn: 0.0510239\ttotal: 1m 3s\tremaining: 1m 1s\n",
      "508:\tlearn: 0.0509906\ttotal: 1m 3s\tremaining: 1m 1s\n",
      "509:\tlearn: 0.0509839\ttotal: 1m 3s\tremaining: 1m 1s\n",
      "510:\tlearn: 0.0509706\ttotal: 1m 3s\tremaining: 1m\n",
      "511:\tlearn: 0.0508905\ttotal: 1m 3s\tremaining: 1m\n",
      "512:\tlearn: 0.0508972\ttotal: 1m 3s\tremaining: 1m\n",
      "513:\tlearn: 0.0508438\ttotal: 1m 4s\tremaining: 1m\n",
      "514:\tlearn: 0.0508172\ttotal: 1m 4s\tremaining: 1m\n",
      "515:\tlearn: 0.0508172\ttotal: 1m 4s\tremaining: 1m\n",
      "516:\tlearn: 0.0507505\ttotal: 1m 4s\tremaining: 1m\n",
      "517:\tlearn: 0.0506837\ttotal: 1m 4s\tremaining: 1m\n",
      "518:\tlearn: 0.0506104\ttotal: 1m 4s\tremaining: 59.9s\n",
      "519:\tlearn: 0.0505904\ttotal: 1m 4s\tremaining: 59.8s\n",
      "520:\tlearn: 0.0505837\ttotal: 1m 4s\tremaining: 59.6s\n",
      "521:\tlearn: 0.0505703\ttotal: 1m 4s\tremaining: 59.5s\n",
      "522:\tlearn: 0.0504970\ttotal: 1m 5s\tremaining: 59.4s\n",
      "523:\tlearn: 0.0504703\ttotal: 1m 5s\tremaining: 59.2s\n",
      "524:\tlearn: 0.0503969\ttotal: 1m 5s\tremaining: 59.1s\n",
      "525:\tlearn: 0.0503569\ttotal: 1m 5s\tremaining: 59s\n",
      "526:\tlearn: 0.0503769\ttotal: 1m 5s\tremaining: 58.9s\n",
      "527:\tlearn: 0.0503636\ttotal: 1m 5s\tremaining: 58.8s\n",
      "528:\tlearn: 0.0502835\ttotal: 1m 5s\tremaining: 58.7s\n",
      "529:\tlearn: 0.0502435\ttotal: 1m 6s\tremaining: 58.5s\n",
      "530:\tlearn: 0.0501968\ttotal: 1m 6s\tremaining: 58.4s\n",
      "531:\tlearn: 0.0501568\ttotal: 1m 6s\tremaining: 58.3s\n",
      "532:\tlearn: 0.0501234\ttotal: 1m 6s\tremaining: 58.2s\n",
      "533:\tlearn: 0.0501301\ttotal: 1m 6s\tremaining: 58.1s\n",
      "534:\tlearn: 0.0501234\ttotal: 1m 6s\tremaining: 57.9s\n",
      "535:\tlearn: 0.0500634\ttotal: 1m 6s\tremaining: 57.8s\n",
      "536:\tlearn: 0.0500500\ttotal: 1m 6s\tremaining: 57.7s\n",
      "537:\tlearn: 0.0499900\ttotal: 1m 6s\tremaining: 57.5s\n",
      "538:\tlearn: 0.0499500\ttotal: 1m 7s\tremaining: 57.4s\n",
      "539:\tlearn: 0.0499500\ttotal: 1m 7s\tremaining: 57.3s\n",
      "540:\tlearn: 0.0499300\ttotal: 1m 7s\tremaining: 57.1s\n",
      "541:\tlearn: 0.0499099\ttotal: 1m 7s\tremaining: 57s\n",
      "542:\tlearn: 0.0498766\ttotal: 1m 7s\tremaining: 56.9s\n",
      "543:\tlearn: 0.0498633\ttotal: 1m 7s\tremaining: 56.8s\n",
      "544:\tlearn: 0.0497965\ttotal: 1m 7s\tremaining: 56.6s\n",
      "545:\tlearn: 0.0497432\ttotal: 1m 7s\tremaining: 56.5s\n",
      "546:\tlearn: 0.0497565\ttotal: 1m 8s\tremaining: 56.4s\n",
      "547:\tlearn: 0.0497365\ttotal: 1m 8s\tremaining: 56.3s\n",
      "548:\tlearn: 0.0496898\ttotal: 1m 8s\tremaining: 56.1s\n",
      "549:\tlearn: 0.0496831\ttotal: 1m 8s\tremaining: 56s\n",
      "550:\tlearn: 0.0496431\ttotal: 1m 8s\tremaining: 55.9s\n",
      "551:\tlearn: 0.0496364\ttotal: 1m 8s\tremaining: 55.7s\n",
      "552:\tlearn: 0.0495964\ttotal: 1m 8s\tremaining: 55.6s\n",
      "553:\tlearn: 0.0495831\ttotal: 1m 8s\tremaining: 55.5s\n",
      "554:\tlearn: 0.0495831\ttotal: 1m 9s\tremaining: 55.3s\n",
      "555:\tlearn: 0.0495431\ttotal: 1m 9s\tremaining: 55.2s\n",
      "556:\tlearn: 0.0495297\ttotal: 1m 9s\tremaining: 55.1s\n",
      "557:\tlearn: 0.0494964\ttotal: 1m 9s\tremaining: 55s\n",
      "558:\tlearn: 0.0494497\ttotal: 1m 9s\tremaining: 54.9s\n",
      "559:\tlearn: 0.0493563\ttotal: 1m 9s\tremaining: 54.7s\n",
      "560:\tlearn: 0.0493429\ttotal: 1m 9s\tremaining: 54.6s\n",
      "561:\tlearn: 0.0493096\ttotal: 1m 9s\tremaining: 54.5s\n",
      "562:\tlearn: 0.0492696\ttotal: 1m 10s\tremaining: 54.3s\n",
      "563:\tlearn: 0.0492362\ttotal: 1m 10s\tremaining: 54.2s\n",
      "564:\tlearn: 0.0492295\ttotal: 1m 10s\tremaining: 54.1s\n",
      "565:\tlearn: 0.0491962\ttotal: 1m 10s\tremaining: 54s\n",
      "566:\tlearn: 0.0491562\ttotal: 1m 10s\tremaining: 53.8s\n",
      "567:\tlearn: 0.0491161\ttotal: 1m 10s\tremaining: 53.7s\n",
      "568:\tlearn: 0.0490961\ttotal: 1m 10s\tremaining: 53.6s\n",
      "569:\tlearn: 0.0490628\ttotal: 1m 10s\tremaining: 53.4s\n",
      "570:\tlearn: 0.0490161\ttotal: 1m 10s\tremaining: 53.3s\n",
      "571:\tlearn: 0.0489627\ttotal: 1m 11s\tremaining: 53.2s\n",
      "572:\tlearn: 0.0489761\ttotal: 1m 11s\tremaining: 53.1s\n",
      "573:\tlearn: 0.0489494\ttotal: 1m 11s\tremaining: 52.9s\n",
      "574:\tlearn: 0.0489360\ttotal: 1m 11s\tremaining: 52.8s\n",
      "575:\tlearn: 0.0488693\ttotal: 1m 11s\tremaining: 52.7s\n",
      "576:\tlearn: 0.0488693\ttotal: 1m 11s\tremaining: 52.6s\n",
      "577:\tlearn: 0.0488493\ttotal: 1m 11s\tremaining: 52.4s\n",
      "578:\tlearn: 0.0488226\ttotal: 1m 11s\tremaining: 52.3s\n",
      "579:\tlearn: 0.0487626\ttotal: 1m 12s\tremaining: 52.2s\n",
      "580:\tlearn: 0.0487492\ttotal: 1m 12s\tremaining: 52s\n",
      "581:\tlearn: 0.0487359\ttotal: 1m 12s\tremaining: 51.9s\n",
      "582:\tlearn: 0.0487092\ttotal: 1m 12s\tremaining: 51.8s\n",
      "583:\tlearn: 0.0486692\ttotal: 1m 12s\tremaining: 51.7s\n",
      "584:\tlearn: 0.0486292\ttotal: 1m 12s\tremaining: 51.5s\n",
      "585:\tlearn: 0.0486225\ttotal: 1m 12s\tremaining: 51.4s\n",
      "586:\tlearn: 0.0486092\ttotal: 1m 12s\tremaining: 51.3s\n",
      "587:\tlearn: 0.0485892\ttotal: 1m 12s\tremaining: 51.1s\n",
      "588:\tlearn: 0.0485358\ttotal: 1m 13s\tremaining: 51s\n",
      "589:\tlearn: 0.0484557\ttotal: 1m 13s\tremaining: 50.9s\n",
      "590:\tlearn: 0.0484624\ttotal: 1m 13s\tremaining: 50.7s\n",
      "591:\tlearn: 0.0484624\ttotal: 1m 13s\tremaining: 50.6s\n",
      "592:\tlearn: 0.0484357\ttotal: 1m 13s\tremaining: 50.5s\n",
      "593:\tlearn: 0.0484357\ttotal: 1m 13s\tremaining: 50.4s\n",
      "594:\tlearn: 0.0483890\ttotal: 1m 13s\tremaining: 50.3s\n",
      "595:\tlearn: 0.0483157\ttotal: 1m 13s\tremaining: 50.1s\n",
      "596:\tlearn: 0.0482756\ttotal: 1m 14s\tremaining: 50s\n",
      "597:\tlearn: 0.0482089\ttotal: 1m 14s\tremaining: 49.9s\n",
      "598:\tlearn: 0.0482156\ttotal: 1m 14s\tremaining: 49.7s\n",
      "599:\tlearn: 0.0481489\ttotal: 1m 14s\tremaining: 49.6s\n",
      "600:\tlearn: 0.0481556\ttotal: 1m 14s\tremaining: 49.5s\n",
      "601:\tlearn: 0.0481155\ttotal: 1m 14s\tremaining: 49.4s\n",
      "602:\tlearn: 0.0481355\ttotal: 1m 14s\tremaining: 49.3s\n",
      "603:\tlearn: 0.0481022\ttotal: 1m 14s\tremaining: 49.2s\n",
      "604:\tlearn: 0.0480555\ttotal: 1m 15s\tremaining: 49.1s\n",
      "605:\tlearn: 0.0480355\ttotal: 1m 15s\tremaining: 48.9s\n",
      "606:\tlearn: 0.0479821\ttotal: 1m 15s\tremaining: 48.8s\n",
      "607:\tlearn: 0.0479488\ttotal: 1m 15s\tremaining: 48.7s\n",
      "608:\tlearn: 0.0479154\ttotal: 1m 15s\tremaining: 48.6s\n",
      "609:\tlearn: 0.0478754\ttotal: 1m 15s\tremaining: 48.5s\n",
      "610:\tlearn: 0.0478420\ttotal: 1m 15s\tremaining: 48.4s\n",
      "611:\tlearn: 0.0478220\ttotal: 1m 16s\tremaining: 48.3s\n",
      "612:\tlearn: 0.0478154\ttotal: 1m 16s\tremaining: 48.2s\n",
      "613:\tlearn: 0.0477953\ttotal: 1m 16s\tremaining: 48s\n",
      "614:\tlearn: 0.0477553\ttotal: 1m 16s\tremaining: 47.9s\n",
      "615:\tlearn: 0.0477420\ttotal: 1m 16s\tremaining: 47.8s\n",
      "616:\tlearn: 0.0477353\ttotal: 1m 16s\tremaining: 47.7s\n",
      "617:\tlearn: 0.0477086\ttotal: 1m 16s\tremaining: 47.6s\n",
      "618:\tlearn: 0.0477020\ttotal: 1m 17s\tremaining: 47.5s\n",
      "619:\tlearn: 0.0476419\ttotal: 1m 17s\tremaining: 47.3s\n",
      "620:\tlearn: 0.0476086\ttotal: 1m 17s\tremaining: 47.2s\n",
      "621:\tlearn: 0.0475819\ttotal: 1m 17s\tremaining: 47.1s\n",
      "622:\tlearn: 0.0475619\ttotal: 1m 17s\tremaining: 47s\n",
      "623:\tlearn: 0.0475218\ttotal: 1m 17s\tremaining: 46.9s\n",
      "624:\tlearn: 0.0474885\ttotal: 1m 18s\tremaining: 46.8s\n",
      "625:\tlearn: 0.0474752\ttotal: 1m 18s\tremaining: 46.7s\n",
      "626:\tlearn: 0.0474218\ttotal: 1m 18s\tremaining: 46.6s\n",
      "627:\tlearn: 0.0474485\ttotal: 1m 18s\tremaining: 46.5s\n",
      "628:\tlearn: 0.0473818\ttotal: 1m 18s\tremaining: 46.4s\n",
      "629:\tlearn: 0.0473284\ttotal: 1m 18s\tremaining: 46.2s\n",
      "630:\tlearn: 0.0473351\ttotal: 1m 18s\tremaining: 46.1s\n",
      "631:\tlearn: 0.0473284\ttotal: 1m 19s\tremaining: 46s\n",
      "632:\tlearn: 0.0473017\ttotal: 1m 19s\tremaining: 45.9s\n",
      "633:\tlearn: 0.0472884\ttotal: 1m 19s\tremaining: 45.8s\n",
      "634:\tlearn: 0.0472350\ttotal: 1m 19s\tremaining: 45.7s\n",
      "635:\tlearn: 0.0472017\ttotal: 1m 19s\tremaining: 45.6s\n",
      "636:\tlearn: 0.0471550\ttotal: 1m 19s\tremaining: 45.5s\n",
      "637:\tlearn: 0.0471283\ttotal: 1m 20s\tremaining: 45.4s\n",
      "638:\tlearn: 0.0471216\ttotal: 1m 20s\tremaining: 45.3s\n",
      "639:\tlearn: 0.0470816\ttotal: 1m 20s\tremaining: 45.2s\n",
      "640:\tlearn: 0.0470549\ttotal: 1m 20s\tremaining: 45.1s\n",
      "641:\tlearn: 0.0470282\ttotal: 1m 20s\tremaining: 45s\n",
      "642:\tlearn: 0.0470015\ttotal: 1m 20s\tremaining: 44.9s\n",
      "643:\tlearn: 0.0469749\ttotal: 1m 20s\tremaining: 44.7s\n",
      "644:\tlearn: 0.0469882\ttotal: 1m 21s\tremaining: 44.6s\n",
      "645:\tlearn: 0.0469482\ttotal: 1m 21s\tremaining: 44.5s\n",
      "646:\tlearn: 0.0469215\ttotal: 1m 21s\tremaining: 44.4s\n",
      "647:\tlearn: 0.0468481\ttotal: 1m 21s\tremaining: 44.2s\n",
      "648:\tlearn: 0.0468081\ttotal: 1m 21s\tremaining: 44.1s\n",
      "649:\tlearn: 0.0467881\ttotal: 1m 21s\tremaining: 44s\n",
      "650:\tlearn: 0.0467747\ttotal: 1m 21s\tremaining: 43.8s\n",
      "651:\tlearn: 0.0467347\ttotal: 1m 21s\tremaining: 43.7s\n",
      "652:\tlearn: 0.0467214\ttotal: 1m 22s\tremaining: 43.6s\n",
      "653:\tlearn: 0.0467147\ttotal: 1m 22s\tremaining: 43.5s\n",
      "654:\tlearn: 0.0467014\ttotal: 1m 22s\tremaining: 43.3s\n",
      "655:\tlearn: 0.0466613\ttotal: 1m 22s\tremaining: 43.2s\n",
      "656:\tlearn: 0.0466146\ttotal: 1m 22s\tremaining: 43.1s\n",
      "657:\tlearn: 0.0465546\ttotal: 1m 22s\tremaining: 43s\n",
      "658:\tlearn: 0.0465212\ttotal: 1m 22s\tremaining: 42.8s\n",
      "659:\tlearn: 0.0465012\ttotal: 1m 22s\tremaining: 42.7s\n",
      "660:\tlearn: 0.0464545\ttotal: 1m 23s\tremaining: 42.6s\n",
      "661:\tlearn: 0.0464078\ttotal: 1m 23s\tremaining: 42.4s\n",
      "662:\tlearn: 0.0463678\ttotal: 1m 23s\tremaining: 42.3s\n",
      "663:\tlearn: 0.0463545\ttotal: 1m 23s\tremaining: 42.2s\n",
      "664:\tlearn: 0.0463612\ttotal: 1m 23s\tremaining: 42.1s\n",
      "665:\tlearn: 0.0463345\ttotal: 1m 23s\tremaining: 41.9s\n",
      "666:\tlearn: 0.0463211\ttotal: 1m 23s\tremaining: 41.8s\n",
      "667:\tlearn: 0.0463011\ttotal: 1m 23s\tremaining: 41.7s\n",
      "668:\tlearn: 0.0462944\ttotal: 1m 23s\tremaining: 41.5s\n",
      "669:\tlearn: 0.0462477\ttotal: 1m 24s\tremaining: 41.4s\n",
      "670:\tlearn: 0.0461944\ttotal: 1m 24s\tremaining: 41.3s\n",
      "671:\tlearn: 0.0461410\ttotal: 1m 24s\tremaining: 41.2s\n",
      "672:\tlearn: 0.0461143\ttotal: 1m 24s\tremaining: 41s\n",
      "673:\tlearn: 0.0460943\ttotal: 1m 24s\tremaining: 40.9s\n",
      "674:\tlearn: 0.0460343\ttotal: 1m 24s\tremaining: 40.8s\n",
      "675:\tlearn: 0.0460476\ttotal: 1m 24s\tremaining: 40.6s\n",
      "676:\tlearn: 0.0460009\ttotal: 1m 24s\tremaining: 40.5s\n",
      "677:\tlearn: 0.0459743\ttotal: 1m 25s\tremaining: 40.4s\n",
      "678:\tlearn: 0.0459542\ttotal: 1m 25s\tremaining: 40.3s\n",
      "679:\tlearn: 0.0459476\ttotal: 1m 25s\tremaining: 40.1s\n",
      "680:\tlearn: 0.0458942\ttotal: 1m 25s\tremaining: 40s\n",
      "681:\tlearn: 0.0458608\ttotal: 1m 25s\tremaining: 39.9s\n",
      "682:\tlearn: 0.0458142\ttotal: 1m 25s\tremaining: 39.8s\n",
      "683:\tlearn: 0.0457741\ttotal: 1m 25s\tremaining: 39.6s\n",
      "684:\tlearn: 0.0457474\ttotal: 1m 25s\tremaining: 39.5s\n",
      "685:\tlearn: 0.0457274\ttotal: 1m 26s\tremaining: 39.4s\n",
      "686:\tlearn: 0.0457141\ttotal: 1m 26s\tremaining: 39.2s\n",
      "687:\tlearn: 0.0456541\ttotal: 1m 26s\tremaining: 39.1s\n",
      "688:\tlearn: 0.0456207\ttotal: 1m 26s\tremaining: 39s\n",
      "689:\tlearn: 0.0456140\ttotal: 1m 26s\tremaining: 38.9s\n",
      "690:\tlearn: 0.0456474\ttotal: 1m 26s\tremaining: 38.7s\n",
      "691:\tlearn: 0.0456407\ttotal: 1m 26s\tremaining: 38.6s\n",
      "692:\tlearn: 0.0456274\ttotal: 1m 26s\tremaining: 38.5s\n",
      "693:\tlearn: 0.0455607\ttotal: 1m 26s\tremaining: 38.3s\n",
      "694:\tlearn: 0.0455473\ttotal: 1m 27s\tremaining: 38.2s\n",
      "695:\tlearn: 0.0455273\ttotal: 1m 27s\tremaining: 38.1s\n",
      "696:\tlearn: 0.0455140\ttotal: 1m 27s\tremaining: 38s\n",
      "697:\tlearn: 0.0454873\ttotal: 1m 27s\tremaining: 37.8s\n",
      "698:\tlearn: 0.0454606\ttotal: 1m 27s\tremaining: 37.7s\n",
      "699:\tlearn: 0.0454473\ttotal: 1m 27s\tremaining: 37.6s\n",
      "700:\tlearn: 0.0454339\ttotal: 1m 27s\tremaining: 37.5s\n",
      "701:\tlearn: 0.0454539\ttotal: 1m 27s\tremaining: 37.3s\n",
      "702:\tlearn: 0.0453939\ttotal: 1m 28s\tremaining: 37.2s\n",
      "703:\tlearn: 0.0453339\ttotal: 1m 28s\tremaining: 37.1s\n",
      "704:\tlearn: 0.0453339\ttotal: 1m 28s\tremaining: 37s\n",
      "705:\tlearn: 0.0453072\ttotal: 1m 28s\tremaining: 36.8s\n",
      "706:\tlearn: 0.0452872\ttotal: 1m 28s\tremaining: 36.7s\n",
      "707:\tlearn: 0.0452271\ttotal: 1m 28s\tremaining: 36.6s\n",
      "708:\tlearn: 0.0452205\ttotal: 1m 28s\tremaining: 36.4s\n",
      "709:\tlearn: 0.0452471\ttotal: 1m 28s\tremaining: 36.3s\n",
      "710:\tlearn: 0.0451804\ttotal: 1m 29s\tremaining: 36.2s\n",
      "711:\tlearn: 0.0451471\ttotal: 1m 29s\tremaining: 36.1s\n",
      "712:\tlearn: 0.0451738\ttotal: 1m 29s\tremaining: 35.9s\n",
      "713:\tlearn: 0.0451538\ttotal: 1m 29s\tremaining: 35.8s\n",
      "714:\tlearn: 0.0451204\ttotal: 1m 29s\tremaining: 35.7s\n",
      "715:\tlearn: 0.0450737\ttotal: 1m 29s\tremaining: 35.6s\n",
      "716:\tlearn: 0.0450137\ttotal: 1m 29s\tremaining: 35.4s\n",
      "717:\tlearn: 0.0449470\ttotal: 1m 29s\tremaining: 35.3s\n",
      "718:\tlearn: 0.0449203\ttotal: 1m 29s\tremaining: 35.2s\n",
      "719:\tlearn: 0.0449069\ttotal: 1m 30s\tremaining: 35s\n",
      "720:\tlearn: 0.0448869\ttotal: 1m 30s\tremaining: 34.9s\n",
      "721:\tlearn: 0.0448803\ttotal: 1m 30s\tremaining: 34.8s\n",
      "722:\tlearn: 0.0448803\ttotal: 1m 30s\tremaining: 34.7s\n",
      "723:\tlearn: 0.0448069\ttotal: 1m 30s\tremaining: 34.5s\n",
      "724:\tlearn: 0.0447335\ttotal: 1m 30s\tremaining: 34.4s\n",
      "725:\tlearn: 0.0447268\ttotal: 1m 30s\tremaining: 34.3s\n",
      "726:\tlearn: 0.0446735\ttotal: 1m 30s\tremaining: 34.2s\n",
      "727:\tlearn: 0.0446601\ttotal: 1m 31s\tremaining: 34s\n",
      "728:\tlearn: 0.0446201\ttotal: 1m 31s\tremaining: 33.9s\n",
      "729:\tlearn: 0.0445934\ttotal: 1m 31s\tremaining: 33.8s\n",
      "730:\tlearn: 0.0445534\ttotal: 1m 31s\tremaining: 33.6s\n",
      "731:\tlearn: 0.0445000\ttotal: 1m 31s\tremaining: 33.5s\n",
      "732:\tlearn: 0.0444667\ttotal: 1m 31s\tremaining: 33.4s\n",
      "733:\tlearn: 0.0444600\ttotal: 1m 31s\tremaining: 33.3s\n",
      "734:\tlearn: 0.0444533\ttotal: 1m 31s\tremaining: 33.1s\n",
      "735:\tlearn: 0.0444533\ttotal: 1m 32s\tremaining: 33s\n",
      "736:\tlearn: 0.0444133\ttotal: 1m 32s\tremaining: 32.9s\n",
      "737:\tlearn: 0.0443800\ttotal: 1m 32s\tremaining: 32.8s\n",
      "738:\tlearn: 0.0443800\ttotal: 1m 32s\tremaining: 32.6s\n",
      "739:\tlearn: 0.0443466\ttotal: 1m 32s\tremaining: 32.5s\n",
      "740:\tlearn: 0.0443266\ttotal: 1m 32s\tremaining: 32.4s\n",
      "741:\tlearn: 0.0443199\ttotal: 1m 32s\tremaining: 32.3s\n",
      "742:\tlearn: 0.0442866\ttotal: 1m 32s\tremaining: 32.1s\n",
      "743:\tlearn: 0.0442599\ttotal: 1m 33s\tremaining: 32s\n",
      "744:\tlearn: 0.0442666\ttotal: 1m 33s\tremaining: 31.9s\n",
      "745:\tlearn: 0.0441999\ttotal: 1m 33s\tremaining: 31.8s\n",
      "746:\tlearn: 0.0441665\ttotal: 1m 33s\tremaining: 31.6s\n",
      "747:\tlearn: 0.0441532\ttotal: 1m 33s\tremaining: 31.5s\n",
      "748:\tlearn: 0.0441198\ttotal: 1m 33s\tremaining: 31.4s\n",
      "749:\tlearn: 0.0440798\ttotal: 1m 33s\tremaining: 31.3s\n",
      "750:\tlearn: 0.0440798\ttotal: 1m 33s\tremaining: 31.1s\n",
      "751:\tlearn: 0.0440598\ttotal: 1m 34s\tremaining: 31s\n",
      "752:\tlearn: 0.0440064\ttotal: 1m 34s\tremaining: 30.9s\n",
      "753:\tlearn: 0.0439330\ttotal: 1m 34s\tremaining: 30.8s\n",
      "754:\tlearn: 0.0438863\ttotal: 1m 34s\tremaining: 30.6s\n",
      "755:\tlearn: 0.0438730\ttotal: 1m 34s\tremaining: 30.5s\n",
      "756:\tlearn: 0.0438463\ttotal: 1m 34s\tremaining: 30.4s\n",
      "757:\tlearn: 0.0438263\ttotal: 1m 34s\tremaining: 30.3s\n",
      "758:\tlearn: 0.0437596\ttotal: 1m 34s\tremaining: 30.1s\n",
      "759:\tlearn: 0.0437196\ttotal: 1m 35s\tremaining: 30s\n",
      "760:\tlearn: 0.0437529\ttotal: 1m 35s\tremaining: 29.9s\n",
      "761:\tlearn: 0.0436862\ttotal: 1m 35s\tremaining: 29.7s\n",
      "762:\tlearn: 0.0436795\ttotal: 1m 35s\tremaining: 29.6s\n",
      "763:\tlearn: 0.0436795\ttotal: 1m 35s\tremaining: 29.5s\n",
      "764:\tlearn: 0.0436195\ttotal: 1m 35s\tremaining: 29.4s\n",
      "765:\tlearn: 0.0435928\ttotal: 1m 35s\tremaining: 29.2s\n",
      "766:\tlearn: 0.0436128\ttotal: 1m 35s\tremaining: 29.1s\n",
      "767:\tlearn: 0.0435728\ttotal: 1m 35s\tremaining: 29s\n",
      "768:\tlearn: 0.0435328\ttotal: 1m 36s\tremaining: 28.9s\n",
      "769:\tlearn: 0.0434728\ttotal: 1m 36s\tremaining: 28.7s\n",
      "770:\tlearn: 0.0434194\ttotal: 1m 36s\tremaining: 28.6s\n",
      "771:\tlearn: 0.0434060\ttotal: 1m 36s\tremaining: 28.5s\n",
      "772:\tlearn: 0.0433527\ttotal: 1m 36s\tremaining: 28.4s\n",
      "773:\tlearn: 0.0433727\ttotal: 1m 36s\tremaining: 28.2s\n",
      "774:\tlearn: 0.0433260\ttotal: 1m 36s\tremaining: 28.1s\n",
      "775:\tlearn: 0.0433260\ttotal: 1m 36s\tremaining: 28s\n",
      "776:\tlearn: 0.0432660\ttotal: 1m 37s\tremaining: 27.9s\n",
      "777:\tlearn: 0.0432926\ttotal: 1m 37s\tremaining: 27.7s\n",
      "778:\tlearn: 0.0432459\ttotal: 1m 37s\tremaining: 27.6s\n",
      "779:\tlearn: 0.0432193\ttotal: 1m 37s\tremaining: 27.5s\n",
      "780:\tlearn: 0.0432326\ttotal: 1m 37s\tremaining: 27.3s\n",
      "781:\tlearn: 0.0431859\ttotal: 1m 37s\tremaining: 27.2s\n",
      "782:\tlearn: 0.0431859\ttotal: 1m 37s\tremaining: 27.1s\n",
      "783:\tlearn: 0.0431726\ttotal: 1m 37s\tremaining: 27s\n",
      "784:\tlearn: 0.0431592\ttotal: 1m 37s\tremaining: 26.8s\n",
      "785:\tlearn: 0.0431325\ttotal: 1m 38s\tremaining: 26.7s\n",
      "786:\tlearn: 0.0431125\ttotal: 1m 38s\tremaining: 26.6s\n",
      "787:\tlearn: 0.0430392\ttotal: 1m 38s\tremaining: 26.5s\n",
      "788:\tlearn: 0.0430325\ttotal: 1m 38s\tremaining: 26.3s\n",
      "789:\tlearn: 0.0429791\ttotal: 1m 38s\tremaining: 26.2s\n",
      "790:\tlearn: 0.0429725\ttotal: 1m 38s\tremaining: 26.1s\n",
      "791:\tlearn: 0.0429391\ttotal: 1m 38s\tremaining: 26s\n",
      "792:\tlearn: 0.0429391\ttotal: 1m 38s\tremaining: 25.8s\n",
      "793:\tlearn: 0.0428924\ttotal: 1m 39s\tremaining: 25.7s\n",
      "794:\tlearn: 0.0428657\ttotal: 1m 39s\tremaining: 25.6s\n",
      "795:\tlearn: 0.0428524\ttotal: 1m 39s\tremaining: 25.5s\n",
      "796:\tlearn: 0.0427857\ttotal: 1m 39s\tremaining: 25.3s\n",
      "797:\tlearn: 0.0427923\ttotal: 1m 39s\tremaining: 25.2s\n",
      "798:\tlearn: 0.0427390\ttotal: 1m 39s\tremaining: 25.1s\n",
      "799:\tlearn: 0.0427590\ttotal: 1m 39s\tremaining: 24.9s\n",
      "800:\tlearn: 0.0427323\ttotal: 1m 39s\tremaining: 24.8s\n",
      "801:\tlearn: 0.0427056\ttotal: 1m 40s\tremaining: 24.7s\n",
      "802:\tlearn: 0.0427390\ttotal: 1m 40s\tremaining: 24.6s\n",
      "803:\tlearn: 0.0427256\ttotal: 1m 40s\tremaining: 24.4s\n",
      "804:\tlearn: 0.0426723\ttotal: 1m 40s\tremaining: 24.3s\n",
      "805:\tlearn: 0.0426189\ttotal: 1m 40s\tremaining: 24.2s\n",
      "806:\tlearn: 0.0425856\ttotal: 1m 40s\tremaining: 24.1s\n",
      "807:\tlearn: 0.0425589\ttotal: 1m 40s\tremaining: 23.9s\n",
      "808:\tlearn: 0.0425389\ttotal: 1m 40s\tremaining: 23.8s\n",
      "809:\tlearn: 0.0424655\ttotal: 1m 41s\tremaining: 23.7s\n",
      "810:\tlearn: 0.0424721\ttotal: 1m 41s\tremaining: 23.6s\n",
      "811:\tlearn: 0.0423988\ttotal: 1m 41s\tremaining: 23.4s\n",
      "812:\tlearn: 0.0423387\ttotal: 1m 41s\tremaining: 23.3s\n",
      "813:\tlearn: 0.0423654\ttotal: 1m 41s\tremaining: 23.2s\n",
      "814:\tlearn: 0.0423521\ttotal: 1m 41s\tremaining: 23.1s\n",
      "815:\tlearn: 0.0423321\ttotal: 1m 41s\tremaining: 22.9s\n",
      "816:\tlearn: 0.0423254\ttotal: 1m 41s\tremaining: 22.8s\n",
      "817:\tlearn: 0.0422920\ttotal: 1m 41s\tremaining: 22.7s\n",
      "818:\tlearn: 0.0422720\ttotal: 1m 42s\tremaining: 22.6s\n",
      "819:\tlearn: 0.0422787\ttotal: 1m 42s\tremaining: 22.4s\n",
      "820:\tlearn: 0.0422453\ttotal: 1m 42s\tremaining: 22.3s\n",
      "821:\tlearn: 0.0422520\ttotal: 1m 42s\tremaining: 22.2s\n",
      "822:\tlearn: 0.0422453\ttotal: 1m 42s\tremaining: 22.1s\n",
      "823:\tlearn: 0.0421920\ttotal: 1m 42s\tremaining: 21.9s\n",
      "824:\tlearn: 0.0421453\ttotal: 1m 42s\tremaining: 21.8s\n",
      "825:\tlearn: 0.0421386\ttotal: 1m 42s\tremaining: 21.7s\n",
      "826:\tlearn: 0.0420919\ttotal: 1m 43s\tremaining: 21.6s\n",
      "827:\tlearn: 0.0420452\ttotal: 1m 43s\tremaining: 21.4s\n",
      "828:\tlearn: 0.0420052\ttotal: 1m 43s\tremaining: 21.3s\n",
      "829:\tlearn: 0.0419652\ttotal: 1m 43s\tremaining: 21.2s\n",
      "830:\tlearn: 0.0419385\ttotal: 1m 43s\tremaining: 21.1s\n",
      "831:\tlearn: 0.0419051\ttotal: 1m 43s\tremaining: 20.9s\n",
      "832:\tlearn: 0.0418918\ttotal: 1m 43s\tremaining: 20.8s\n",
      "833:\tlearn: 0.0418851\ttotal: 1m 43s\tremaining: 20.7s\n",
      "834:\tlearn: 0.0418051\ttotal: 1m 44s\tremaining: 20.6s\n",
      "835:\tlearn: 0.0417784\ttotal: 1m 44s\tremaining: 20.4s\n",
      "836:\tlearn: 0.0417450\ttotal: 1m 44s\tremaining: 20.3s\n",
      "837:\tlearn: 0.0417517\ttotal: 1m 44s\tremaining: 20.2s\n",
      "838:\tlearn: 0.0417317\ttotal: 1m 44s\tremaining: 20.1s\n",
      "839:\tlearn: 0.0417117\ttotal: 1m 44s\tremaining: 19.9s\n",
      "840:\tlearn: 0.0417184\ttotal: 1m 44s\tremaining: 19.8s\n",
      "841:\tlearn: 0.0417317\ttotal: 1m 44s\tremaining: 19.7s\n",
      "842:\tlearn: 0.0416917\ttotal: 1m 45s\tremaining: 19.6s\n",
      "843:\tlearn: 0.0416917\ttotal: 1m 45s\tremaining: 19.4s\n",
      "844:\tlearn: 0.0416250\ttotal: 1m 45s\tremaining: 19.3s\n",
      "845:\tlearn: 0.0415850\ttotal: 1m 45s\tremaining: 19.2s\n",
      "846:\tlearn: 0.0415716\ttotal: 1m 45s\tremaining: 19.1s\n",
      "847:\tlearn: 0.0415649\ttotal: 1m 45s\tremaining: 18.9s\n",
      "848:\tlearn: 0.0415383\ttotal: 1m 45s\tremaining: 18.8s\n",
      "849:\tlearn: 0.0415049\ttotal: 1m 45s\tremaining: 18.7s\n",
      "850:\tlearn: 0.0414782\ttotal: 1m 46s\tremaining: 18.6s\n",
      "851:\tlearn: 0.0414649\ttotal: 1m 46s\tremaining: 18.4s\n",
      "852:\tlearn: 0.0414782\ttotal: 1m 46s\tremaining: 18.3s\n",
      "853:\tlearn: 0.0414582\ttotal: 1m 46s\tremaining: 18.2s\n",
      "854:\tlearn: 0.0414048\ttotal: 1m 46s\tremaining: 18.1s\n",
      "855:\tlearn: 0.0413782\ttotal: 1m 46s\tremaining: 17.9s\n",
      "856:\tlearn: 0.0413581\ttotal: 1m 46s\tremaining: 17.8s\n",
      "857:\tlearn: 0.0412981\ttotal: 1m 46s\tremaining: 17.7s\n",
      "858:\tlearn: 0.0412581\ttotal: 1m 47s\tremaining: 17.6s\n",
      "859:\tlearn: 0.0412381\ttotal: 1m 47s\tremaining: 17.4s\n",
      "860:\tlearn: 0.0412247\ttotal: 1m 47s\tremaining: 17.3s\n",
      "861:\tlearn: 0.0412114\ttotal: 1m 47s\tremaining: 17.2s\n",
      "862:\tlearn: 0.0411780\ttotal: 1m 47s\tremaining: 17.1s\n",
      "863:\tlearn: 0.0411180\ttotal: 1m 47s\tremaining: 16.9s\n",
      "864:\tlearn: 0.0411047\ttotal: 1m 47s\tremaining: 16.8s\n",
      "865:\tlearn: 0.0410313\ttotal: 1m 47s\tremaining: 16.7s\n",
      "866:\tlearn: 0.0410513\ttotal: 1m 48s\tremaining: 16.6s\n",
      "867:\tlearn: 0.0410380\ttotal: 1m 48s\tremaining: 16.5s\n",
      "868:\tlearn: 0.0409846\ttotal: 1m 48s\tremaining: 16.3s\n",
      "869:\tlearn: 0.0409579\ttotal: 1m 48s\tremaining: 16.2s\n",
      "870:\tlearn: 0.0409512\ttotal: 1m 48s\tremaining: 16.1s\n",
      "871:\tlearn: 0.0408779\ttotal: 1m 48s\tremaining: 16s\n",
      "872:\tlearn: 0.0408845\ttotal: 1m 48s\tremaining: 15.8s\n",
      "873:\tlearn: 0.0408045\ttotal: 1m 48s\tremaining: 15.7s\n",
      "874:\tlearn: 0.0408045\ttotal: 1m 49s\tremaining: 15.6s\n",
      "875:\tlearn: 0.0407978\ttotal: 1m 49s\tremaining: 15.5s\n",
      "876:\tlearn: 0.0407645\ttotal: 1m 49s\tremaining: 15.3s\n",
      "877:\tlearn: 0.0407578\ttotal: 1m 49s\tremaining: 15.2s\n",
      "878:\tlearn: 0.0407444\ttotal: 1m 49s\tremaining: 15.1s\n",
      "879:\tlearn: 0.0407044\ttotal: 1m 49s\tremaining: 15s\n",
      "880:\tlearn: 0.0406711\ttotal: 1m 49s\tremaining: 14.8s\n",
      "881:\tlearn: 0.0406711\ttotal: 1m 49s\tremaining: 14.7s\n",
      "882:\tlearn: 0.0406644\ttotal: 1m 50s\tremaining: 14.6s\n",
      "883:\tlearn: 0.0405977\ttotal: 1m 50s\tremaining: 14.4s\n",
      "884:\tlearn: 0.0405777\ttotal: 1m 50s\tremaining: 14.3s\n",
      "885:\tlearn: 0.0405643\ttotal: 1m 50s\tremaining: 14.2s\n",
      "886:\tlearn: 0.0405377\ttotal: 1m 50s\tremaining: 14.1s\n",
      "887:\tlearn: 0.0405176\ttotal: 1m 50s\tremaining: 14s\n",
      "888:\tlearn: 0.0404776\ttotal: 1m 50s\tremaining: 13.8s\n",
      "889:\tlearn: 0.0404776\ttotal: 1m 50s\tremaining: 13.7s\n",
      "890:\tlearn: 0.0404576\ttotal: 1m 50s\tremaining: 13.6s\n",
      "891:\tlearn: 0.0404309\ttotal: 1m 51s\tremaining: 13.5s\n",
      "892:\tlearn: 0.0404243\ttotal: 1m 51s\tremaining: 13.3s\n",
      "893:\tlearn: 0.0403776\ttotal: 1m 51s\tremaining: 13.2s\n",
      "894:\tlearn: 0.0403442\ttotal: 1m 51s\tremaining: 13.1s\n",
      "895:\tlearn: 0.0403442\ttotal: 1m 51s\tremaining: 13s\n",
      "896:\tlearn: 0.0403109\ttotal: 1m 51s\tremaining: 12.8s\n",
      "897:\tlearn: 0.0402775\ttotal: 1m 51s\tremaining: 12.7s\n",
      "898:\tlearn: 0.0402842\ttotal: 1m 51s\tremaining: 12.6s\n",
      "899:\tlearn: 0.0403042\ttotal: 1m 52s\tremaining: 12.5s\n",
      "900:\tlearn: 0.0402642\ttotal: 1m 52s\tremaining: 12.3s\n",
      "901:\tlearn: 0.0402575\ttotal: 1m 52s\tremaining: 12.2s\n",
      "902:\tlearn: 0.0402308\ttotal: 1m 52s\tremaining: 12.1s\n",
      "903:\tlearn: 0.0401975\ttotal: 1m 52s\tremaining: 12s\n",
      "904:\tlearn: 0.0402175\ttotal: 1m 52s\tremaining: 11.8s\n",
      "905:\tlearn: 0.0402041\ttotal: 1m 52s\tremaining: 11.7s\n",
      "906:\tlearn: 0.0401374\ttotal: 1m 52s\tremaining: 11.6s\n",
      "907:\tlearn: 0.0401441\ttotal: 1m 53s\tremaining: 11.5s\n",
      "908:\tlearn: 0.0401374\ttotal: 1m 53s\tremaining: 11.3s\n",
      "909:\tlearn: 0.0401174\ttotal: 1m 53s\tremaining: 11.2s\n",
      "910:\tlearn: 0.0401041\ttotal: 1m 53s\tremaining: 11.1s\n",
      "911:\tlearn: 0.0400974\ttotal: 1m 53s\tremaining: 11s\n",
      "912:\tlearn: 0.0400640\ttotal: 1m 53s\tremaining: 10.8s\n",
      "913:\tlearn: 0.0400374\ttotal: 1m 53s\tremaining: 10.7s\n",
      "914:\tlearn: 0.0400040\ttotal: 1m 53s\tremaining: 10.6s\n",
      "915:\tlearn: 0.0399840\ttotal: 1m 53s\tremaining: 10.5s\n",
      "916:\tlearn: 0.0399840\ttotal: 1m 54s\tremaining: 10.3s\n",
      "917:\tlearn: 0.0399240\ttotal: 1m 54s\tremaining: 10.2s\n",
      "918:\tlearn: 0.0399306\ttotal: 1m 54s\tremaining: 10.1s\n",
      "919:\tlearn: 0.0398973\ttotal: 1m 54s\tremaining: 9.95s\n",
      "920:\tlearn: 0.0398706\ttotal: 1m 54s\tremaining: 9.83s\n",
      "921:\tlearn: 0.0398506\ttotal: 1m 54s\tremaining: 9.7s\n",
      "922:\tlearn: 0.0398439\ttotal: 1m 54s\tremaining: 9.58s\n",
      "923:\tlearn: 0.0397705\ttotal: 1m 54s\tremaining: 9.45s\n",
      "924:\tlearn: 0.0397839\ttotal: 1m 55s\tremaining: 9.33s\n",
      "925:\tlearn: 0.0397238\ttotal: 1m 55s\tremaining: 9.2s\n",
      "926:\tlearn: 0.0396972\ttotal: 1m 55s\tremaining: 9.08s\n",
      "927:\tlearn: 0.0396771\ttotal: 1m 55s\tremaining: 8.96s\n",
      "928:\tlearn: 0.0396638\ttotal: 1m 55s\tremaining: 8.83s\n",
      "929:\tlearn: 0.0395971\ttotal: 1m 55s\tremaining: 8.71s\n",
      "930:\tlearn: 0.0396104\ttotal: 1m 55s\tremaining: 8.58s\n",
      "931:\tlearn: 0.0395704\ttotal: 1m 55s\tremaining: 8.46s\n",
      "932:\tlearn: 0.0395371\ttotal: 1m 56s\tremaining: 8.33s\n",
      "933:\tlearn: 0.0395571\ttotal: 1m 56s\tremaining: 8.21s\n",
      "934:\tlearn: 0.0395504\ttotal: 1m 56s\tremaining: 8.08s\n",
      "935:\tlearn: 0.0395237\ttotal: 1m 56s\tremaining: 7.96s\n",
      "936:\tlearn: 0.0394970\ttotal: 1m 56s\tremaining: 7.83s\n",
      "937:\tlearn: 0.0394970\ttotal: 1m 56s\tremaining: 7.71s\n",
      "938:\tlearn: 0.0394770\ttotal: 1m 56s\tremaining: 7.58s\n",
      "939:\tlearn: 0.0395037\ttotal: 1m 56s\tremaining: 7.46s\n",
      "940:\tlearn: 0.0394637\ttotal: 1m 57s\tremaining: 7.33s\n",
      "941:\tlearn: 0.0394503\ttotal: 1m 57s\tremaining: 7.21s\n",
      "942:\tlearn: 0.0394303\ttotal: 1m 57s\tremaining: 7.09s\n",
      "943:\tlearn: 0.0394036\ttotal: 1m 57s\tremaining: 6.96s\n",
      "944:\tlearn: 0.0393836\ttotal: 1m 57s\tremaining: 6.84s\n",
      "945:\tlearn: 0.0393636\ttotal: 1m 57s\tremaining: 6.71s\n",
      "946:\tlearn: 0.0393103\ttotal: 1m 57s\tremaining: 6.59s\n",
      "947:\tlearn: 0.0393436\ttotal: 1m 57s\tremaining: 6.46s\n",
      "948:\tlearn: 0.0393103\ttotal: 1m 57s\tremaining: 6.34s\n",
      "949:\tlearn: 0.0392435\ttotal: 1m 58s\tremaining: 6.21s\n",
      "950:\tlearn: 0.0392035\ttotal: 1m 58s\tremaining: 6.09s\n",
      "951:\tlearn: 0.0392169\ttotal: 1m 58s\tremaining: 5.97s\n",
      "952:\tlearn: 0.0392102\ttotal: 1m 58s\tremaining: 5.84s\n",
      "953:\tlearn: 0.0391635\ttotal: 1m 58s\tremaining: 5.72s\n",
      "954:\tlearn: 0.0391301\ttotal: 1m 58s\tremaining: 5.59s\n",
      "955:\tlearn: 0.0391035\ttotal: 1m 58s\tremaining: 5.47s\n",
      "956:\tlearn: 0.0390968\ttotal: 1m 58s\tremaining: 5.34s\n",
      "957:\tlearn: 0.0391168\ttotal: 1m 59s\tremaining: 5.22s\n",
      "958:\tlearn: 0.0390901\ttotal: 1m 59s\tremaining: 5.09s\n",
      "959:\tlearn: 0.0390634\ttotal: 1m 59s\tremaining: 4.97s\n",
      "960:\tlearn: 0.0390501\ttotal: 1m 59s\tremaining: 4.85s\n",
      "961:\tlearn: 0.0389901\ttotal: 1m 59s\tremaining: 4.72s\n",
      "962:\tlearn: 0.0389434\ttotal: 1m 59s\tremaining: 4.6s\n",
      "963:\tlearn: 0.0389367\ttotal: 1m 59s\tremaining: 4.47s\n",
      "964:\tlearn: 0.0388900\ttotal: 1m 59s\tremaining: 4.35s\n",
      "965:\tlearn: 0.0389100\ttotal: 2m\tremaining: 4.22s\n",
      "966:\tlearn: 0.0388700\ttotal: 2m\tremaining: 4.1s\n",
      "967:\tlearn: 0.0388633\ttotal: 2m\tremaining: 3.98s\n",
      "968:\tlearn: 0.0388566\ttotal: 2m\tremaining: 3.85s\n",
      "969:\tlearn: 0.0388433\ttotal: 2m\tremaining: 3.73s\n",
      "970:\tlearn: 0.0388767\ttotal: 2m\tremaining: 3.6s\n",
      "971:\tlearn: 0.0388500\ttotal: 2m\tremaining: 3.48s\n",
      "972:\tlearn: 0.0387833\ttotal: 2m\tremaining: 3.35s\n",
      "973:\tlearn: 0.0388100\ttotal: 2m 1s\tremaining: 3.23s\n",
      "974:\tlearn: 0.0387566\ttotal: 2m 1s\tremaining: 3.1s\n",
      "975:\tlearn: 0.0387566\ttotal: 2m 1s\tremaining: 2.98s\n",
      "976:\tlearn: 0.0387566\ttotal: 2m 1s\tremaining: 2.86s\n",
      "977:\tlearn: 0.0387499\ttotal: 2m 1s\tremaining: 2.73s\n",
      "978:\tlearn: 0.0387099\ttotal: 2m 1s\tremaining: 2.61s\n",
      "979:\tlearn: 0.0387099\ttotal: 2m 1s\tremaining: 2.48s\n",
      "980:\tlearn: 0.0386632\ttotal: 2m 1s\tremaining: 2.36s\n",
      "981:\tlearn: 0.0386432\ttotal: 2m 1s\tremaining: 2.23s\n",
      "982:\tlearn: 0.0386165\ttotal: 2m 2s\tremaining: 2.11s\n",
      "983:\tlearn: 0.0385898\ttotal: 2m 2s\tremaining: 1.99s\n",
      "984:\tlearn: 0.0385631\ttotal: 2m 2s\tremaining: 1.86s\n",
      "985:\tlearn: 0.0385698\ttotal: 2m 2s\tremaining: 1.74s\n",
      "986:\tlearn: 0.0385431\ttotal: 2m 2s\tremaining: 1.61s\n",
      "987:\tlearn: 0.0385098\ttotal: 2m 2s\tremaining: 1.49s\n",
      "988:\tlearn: 0.0384431\ttotal: 2m 2s\tremaining: 1.37s\n",
      "989:\tlearn: 0.0384631\ttotal: 2m 2s\tremaining: 1.24s\n",
      "990:\tlearn: 0.0384431\ttotal: 2m 3s\tremaining: 1.12s\n",
      "991:\tlearn: 0.0383897\ttotal: 2m 3s\tremaining: 994ms\n",
      "992:\tlearn: 0.0383964\ttotal: 2m 3s\tremaining: 870ms\n",
      "993:\tlearn: 0.0383830\ttotal: 2m 3s\tremaining: 745ms\n",
      "994:\tlearn: 0.0383497\ttotal: 2m 3s\tremaining: 621ms\n",
      "995:\tlearn: 0.0383830\ttotal: 2m 3s\tremaining: 497ms\n",
      "996:\tlearn: 0.0383563\ttotal: 2m 3s\tremaining: 373ms\n",
      "997:\tlearn: 0.0383163\ttotal: 2m 3s\tremaining: 248ms\n",
      "998:\tlearn: 0.0383097\ttotal: 2m 4s\tremaining: 124ms\n",
      "999:\tlearn: 0.0382963\ttotal: 2m 4s\tremaining: 0us\n",
      "Learning rate set to 0.024888\n",
      "0:\tlearn: 0.0846041\ttotal: 114ms\tremaining: 1m 53s\n",
      "1:\tlearn: 0.0857448\ttotal: 245ms\tremaining: 2m 2s\n",
      "2:\tlearn: 0.0858048\ttotal: 356ms\tremaining: 1m 58s\n",
      "3:\tlearn: 0.0858515\ttotal: 445ms\tremaining: 1m 50s\n",
      "4:\tlearn: 0.0858582\ttotal: 559ms\tremaining: 1m 51s\n",
      "5:\tlearn: 0.0858649\ttotal: 683ms\tremaining: 1m 53s\n",
      "6:\tlearn: 0.0858649\ttotal: 814ms\tremaining: 1m 55s\n",
      "7:\tlearn: 0.0858649\ttotal: 932ms\tremaining: 1m 55s\n",
      "8:\tlearn: 0.0858649\ttotal: 1.05s\tremaining: 1m 55s\n",
      "9:\tlearn: 0.0858649\ttotal: 1.16s\tremaining: 1m 55s\n",
      "10:\tlearn: 0.0858649\ttotal: 1.28s\tremaining: 1m 55s\n",
      "11:\tlearn: 0.0858649\ttotal: 1.4s\tremaining: 1m 55s\n",
      "12:\tlearn: 0.0858649\ttotal: 1.51s\tremaining: 1m 54s\n",
      "13:\tlearn: 0.0858649\ttotal: 1.63s\tremaining: 1m 54s\n",
      "14:\tlearn: 0.0858649\ttotal: 1.75s\tremaining: 1m 54s\n",
      "15:\tlearn: 0.0858382\ttotal: 1.87s\tremaining: 1m 55s\n",
      "16:\tlearn: 0.0858582\ttotal: 1.99s\tremaining: 1m 55s\n",
      "17:\tlearn: 0.0858649\ttotal: 2.11s\tremaining: 1m 54s\n",
      "18:\tlearn: 0.0858582\ttotal: 2.24s\tremaining: 1m 55s\n",
      "19:\tlearn: 0.0858582\ttotal: 2.35s\tremaining: 1m 55s\n",
      "20:\tlearn: 0.0858448\ttotal: 2.46s\tremaining: 1m 54s\n",
      "21:\tlearn: 0.0858515\ttotal: 2.58s\tremaining: 1m 54s\n",
      "22:\tlearn: 0.0858448\ttotal: 2.7s\tremaining: 1m 54s\n",
      "23:\tlearn: 0.0858315\ttotal: 2.76s\tremaining: 1m 52s\n",
      "24:\tlearn: 0.0857981\ttotal: 2.88s\tremaining: 1m 52s\n",
      "25:\tlearn: 0.0857715\ttotal: 3s\tremaining: 1m 52s\n",
      "26:\tlearn: 0.0857381\ttotal: 3.12s\tremaining: 1m 52s\n",
      "27:\tlearn: 0.0857314\ttotal: 3.23s\tremaining: 1m 52s\n",
      "28:\tlearn: 0.0856981\ttotal: 3.35s\tremaining: 1m 52s\n",
      "29:\tlearn: 0.0856981\ttotal: 3.51s\tremaining: 1m 53s\n",
      "30:\tlearn: 0.0856514\ttotal: 3.63s\tremaining: 1m 53s\n",
      "31:\tlearn: 0.0856047\ttotal: 3.76s\tremaining: 1m 53s\n",
      "32:\tlearn: 0.0855713\ttotal: 3.85s\tremaining: 1m 52s\n",
      "33:\tlearn: 0.0855447\ttotal: 3.97s\tremaining: 1m 52s\n",
      "34:\tlearn: 0.0855647\ttotal: 4.08s\tremaining: 1m 52s\n",
      "35:\tlearn: 0.0855647\ttotal: 4.2s\tremaining: 1m 52s\n",
      "36:\tlearn: 0.0854980\ttotal: 4.32s\tremaining: 1m 52s\n",
      "37:\tlearn: 0.0855046\ttotal: 4.43s\tremaining: 1m 52s\n",
      "38:\tlearn: 0.0854846\ttotal: 4.55s\tremaining: 1m 52s\n",
      "39:\tlearn: 0.0854646\ttotal: 4.67s\tremaining: 1m 52s\n",
      "40:\tlearn: 0.0852912\ttotal: 4.8s\tremaining: 1m 52s\n",
      "41:\tlearn: 0.0853112\ttotal: 4.92s\tremaining: 1m 52s\n",
      "42:\tlearn: 0.0852245\ttotal: 5.04s\tremaining: 1m 52s\n",
      "43:\tlearn: 0.0852045\ttotal: 5.16s\tremaining: 1m 52s\n",
      "44:\tlearn: 0.0852045\ttotal: 5.28s\tremaining: 1m 52s\n",
      "45:\tlearn: 0.0851244\ttotal: 5.39s\tremaining: 1m 51s\n",
      "46:\tlearn: 0.0850844\ttotal: 5.51s\tremaining: 1m 51s\n",
      "47:\tlearn: 0.0851111\ttotal: 5.64s\tremaining: 1m 51s\n",
      "48:\tlearn: 0.0850911\ttotal: 5.76s\tremaining: 1m 51s\n",
      "49:\tlearn: 0.0849843\ttotal: 5.88s\tremaining: 1m 51s\n",
      "50:\tlearn: 0.0849576\ttotal: 6.01s\tremaining: 1m 51s\n",
      "51:\tlearn: 0.0848442\ttotal: 6.13s\tremaining: 1m 51s\n",
      "52:\tlearn: 0.0848109\ttotal: 6.25s\tremaining: 1m 51s\n",
      "53:\tlearn: 0.0848442\ttotal: 6.36s\tremaining: 1m 51s\n",
      "54:\tlearn: 0.0848509\ttotal: 6.49s\tremaining: 1m 51s\n",
      "55:\tlearn: 0.0847442\ttotal: 6.63s\tremaining: 1m 51s\n",
      "56:\tlearn: 0.0846708\ttotal: 6.75s\tremaining: 1m 51s\n",
      "57:\tlearn: 0.0845908\ttotal: 6.87s\tremaining: 1m 51s\n",
      "58:\tlearn: 0.0845107\ttotal: 6.99s\tremaining: 1m 51s\n",
      "59:\tlearn: 0.0844774\ttotal: 7.11s\tremaining: 1m 51s\n",
      "60:\tlearn: 0.0844173\ttotal: 7.23s\tremaining: 1m 51s\n",
      "61:\tlearn: 0.0843640\ttotal: 7.35s\tremaining: 1m 51s\n",
      "62:\tlearn: 0.0842706\ttotal: 7.47s\tremaining: 1m 51s\n",
      "63:\tlearn: 0.0842239\ttotal: 7.59s\tremaining: 1m 50s\n",
      "64:\tlearn: 0.0841638\ttotal: 7.71s\tremaining: 1m 50s\n",
      "65:\tlearn: 0.0841238\ttotal: 7.83s\tremaining: 1m 50s\n",
      "66:\tlearn: 0.0841105\ttotal: 7.95s\tremaining: 1m 50s\n",
      "67:\tlearn: 0.0840171\ttotal: 8.07s\tremaining: 1m 50s\n",
      "68:\tlearn: 0.0838570\ttotal: 8.19s\tremaining: 1m 50s\n",
      "69:\tlearn: 0.0838036\ttotal: 8.3s\tremaining: 1m 50s\n",
      "70:\tlearn: 0.0836769\ttotal: 8.42s\tremaining: 1m 50s\n",
      "71:\tlearn: 0.0836168\ttotal: 8.54s\tremaining: 1m 50s\n",
      "72:\tlearn: 0.0834768\ttotal: 8.66s\tremaining: 1m 49s\n",
      "73:\tlearn: 0.0833967\ttotal: 8.78s\tremaining: 1m 49s\n",
      "74:\tlearn: 0.0833367\ttotal: 8.9s\tremaining: 1m 49s\n",
      "75:\tlearn: 0.0832633\ttotal: 9.03s\tremaining: 1m 49s\n",
      "76:\tlearn: 0.0831832\ttotal: 9.14s\tremaining: 1m 49s\n",
      "77:\tlearn: 0.0831699\ttotal: 9.26s\tremaining: 1m 49s\n",
      "78:\tlearn: 0.0830965\ttotal: 9.37s\tremaining: 1m 49s\n",
      "79:\tlearn: 0.0829965\ttotal: 9.49s\tremaining: 1m 49s\n",
      "80:\tlearn: 0.0828831\ttotal: 9.6s\tremaining: 1m 48s\n",
      "81:\tlearn: 0.0827697\ttotal: 9.73s\tremaining: 1m 48s\n",
      "82:\tlearn: 0.0826763\ttotal: 9.85s\tremaining: 1m 48s\n",
      "83:\tlearn: 0.0824895\ttotal: 9.96s\tremaining: 1m 48s\n",
      "84:\tlearn: 0.0824161\ttotal: 10.1s\tremaining: 1m 48s\n",
      "85:\tlearn: 0.0822427\ttotal: 10.2s\tremaining: 1m 48s\n",
      "86:\tlearn: 0.0821960\ttotal: 10.3s\tremaining: 1m 48s\n",
      "87:\tlearn: 0.0821159\ttotal: 10.4s\tremaining: 1m 48s\n",
      "88:\tlearn: 0.0820626\ttotal: 10.6s\tremaining: 1m 48s\n",
      "89:\tlearn: 0.0820092\ttotal: 10.7s\tremaining: 1m 47s\n",
      "90:\tlearn: 0.0819025\ttotal: 10.8s\tremaining: 1m 47s\n",
      "91:\tlearn: 0.0818091\ttotal: 10.9s\tremaining: 1m 48s\n",
      "92:\tlearn: 0.0816557\ttotal: 11.1s\tremaining: 1m 47s\n",
      "93:\tlearn: 0.0815089\ttotal: 11.2s\tremaining: 1m 47s\n",
      "94:\tlearn: 0.0814489\ttotal: 11.3s\tremaining: 1m 47s\n",
      "95:\tlearn: 0.0813221\ttotal: 11.4s\tremaining: 1m 47s\n",
      "96:\tlearn: 0.0811820\ttotal: 11.5s\tremaining: 1m 47s\n",
      "97:\tlearn: 0.0810486\ttotal: 11.7s\tremaining: 1m 47s\n",
      "98:\tlearn: 0.0809019\ttotal: 11.8s\tremaining: 1m 47s\n",
      "99:\tlearn: 0.0807951\ttotal: 11.9s\tremaining: 1m 47s\n",
      "100:\tlearn: 0.0806417\ttotal: 12s\tremaining: 1m 47s\n",
      "101:\tlearn: 0.0805083\ttotal: 12.2s\tremaining: 1m 47s\n",
      "102:\tlearn: 0.0803616\ttotal: 12.3s\tremaining: 1m 47s\n",
      "103:\tlearn: 0.0803349\ttotal: 12.4s\tremaining: 1m 47s\n",
      "104:\tlearn: 0.0802682\ttotal: 12.5s\tremaining: 1m 46s\n",
      "105:\tlearn: 0.0801548\ttotal: 12.7s\tremaining: 1m 46s\n",
      "106:\tlearn: 0.0799613\ttotal: 12.8s\tremaining: 1m 46s\n",
      "107:\tlearn: 0.0799146\ttotal: 13s\tremaining: 1m 46s\n",
      "108:\tlearn: 0.0798012\ttotal: 13.1s\tremaining: 1m 46s\n",
      "109:\tlearn: 0.0797212\ttotal: 13.2s\tremaining: 1m 46s\n",
      "110:\tlearn: 0.0796945\ttotal: 13.3s\tremaining: 1m 46s\n",
      "111:\tlearn: 0.0795811\ttotal: 13.5s\tremaining: 1m 46s\n",
      "112:\tlearn: 0.0794076\ttotal: 13.6s\tremaining: 1m 46s\n",
      "113:\tlearn: 0.0793009\ttotal: 13.7s\tremaining: 1m 46s\n",
      "114:\tlearn: 0.0791675\ttotal: 13.8s\tremaining: 1m 46s\n",
      "115:\tlearn: 0.0790474\ttotal: 14s\tremaining: 1m 46s\n",
      "116:\tlearn: 0.0789607\ttotal: 14.1s\tremaining: 1m 46s\n",
      "117:\tlearn: 0.0788406\ttotal: 14.2s\tremaining: 1m 46s\n",
      "118:\tlearn: 0.0786672\ttotal: 14.3s\tremaining: 1m 45s\n",
      "119:\tlearn: 0.0785405\ttotal: 14.4s\tremaining: 1m 45s\n",
      "120:\tlearn: 0.0784804\ttotal: 14.6s\tremaining: 1m 45s\n",
      "121:\tlearn: 0.0783737\ttotal: 14.7s\tremaining: 1m 45s\n",
      "122:\tlearn: 0.0782469\ttotal: 14.8s\tremaining: 1m 45s\n",
      "123:\tlearn: 0.0781936\ttotal: 14.9s\tremaining: 1m 45s\n",
      "124:\tlearn: 0.0781269\ttotal: 15.1s\tremaining: 1m 45s\n",
      "125:\tlearn: 0.0779735\ttotal: 15.2s\tremaining: 1m 45s\n",
      "126:\tlearn: 0.0779334\ttotal: 15.3s\tremaining: 1m 45s\n",
      "127:\tlearn: 0.0778467\ttotal: 15.4s\tremaining: 1m 44s\n",
      "128:\tlearn: 0.0777133\ttotal: 15.5s\tremaining: 1m 44s\n",
      "129:\tlearn: 0.0775465\ttotal: 15.7s\tremaining: 1m 44s\n",
      "130:\tlearn: 0.0774398\ttotal: 15.8s\tremaining: 1m 44s\n",
      "131:\tlearn: 0.0774198\ttotal: 15.9s\tremaining: 1m 44s\n",
      "132:\tlearn: 0.0772797\ttotal: 16s\tremaining: 1m 44s\n",
      "133:\tlearn: 0.0771997\ttotal: 16.1s\tremaining: 1m 44s\n",
      "134:\tlearn: 0.0771196\ttotal: 16.3s\tremaining: 1m 44s\n",
      "135:\tlearn: 0.0770929\ttotal: 16.4s\tremaining: 1m 44s\n",
      "136:\tlearn: 0.0770262\ttotal: 16.5s\tremaining: 1m 43s\n",
      "137:\tlearn: 0.0768995\ttotal: 16.6s\tremaining: 1m 43s\n",
      "138:\tlearn: 0.0767527\ttotal: 16.8s\tremaining: 1m 43s\n",
      "139:\tlearn: 0.0767194\ttotal: 16.9s\tremaining: 1m 43s\n",
      "140:\tlearn: 0.0765793\ttotal: 17s\tremaining: 1m 43s\n",
      "141:\tlearn: 0.0764525\ttotal: 17.1s\tremaining: 1m 43s\n",
      "142:\tlearn: 0.0763391\ttotal: 17.2s\tremaining: 1m 43s\n",
      "143:\tlearn: 0.0762724\ttotal: 17.4s\tremaining: 1m 43s\n",
      "144:\tlearn: 0.0761457\ttotal: 17.5s\tremaining: 1m 43s\n",
      "145:\tlearn: 0.0760456\ttotal: 17.6s\tremaining: 1m 42s\n",
      "146:\tlearn: 0.0759656\ttotal: 17.7s\tremaining: 1m 42s\n",
      "147:\tlearn: 0.0757921\ttotal: 17.9s\tremaining: 1m 42s\n",
      "148:\tlearn: 0.0757321\ttotal: 18s\tremaining: 1m 42s\n",
      "149:\tlearn: 0.0755587\ttotal: 18.1s\tremaining: 1m 42s\n",
      "150:\tlearn: 0.0754853\ttotal: 18.2s\tremaining: 1m 42s\n",
      "151:\tlearn: 0.0754319\ttotal: 18.3s\tremaining: 1m 42s\n",
      "152:\tlearn: 0.0753052\ttotal: 18.5s\tremaining: 1m 42s\n",
      "153:\tlearn: 0.0751718\ttotal: 18.6s\tremaining: 1m 42s\n",
      "154:\tlearn: 0.0750717\ttotal: 18.7s\tremaining: 1m 41s\n",
      "155:\tlearn: 0.0749650\ttotal: 18.8s\tremaining: 1m 41s\n",
      "156:\tlearn: 0.0749049\ttotal: 19s\tremaining: 1m 41s\n",
      "157:\tlearn: 0.0748582\ttotal: 19.1s\tremaining: 1m 41s\n",
      "158:\tlearn: 0.0747115\ttotal: 19.2s\tremaining: 1m 41s\n",
      "159:\tlearn: 0.0746515\ttotal: 19.3s\tremaining: 1m 41s\n",
      "160:\tlearn: 0.0745714\ttotal: 19.4s\tremaining: 1m 41s\n",
      "161:\tlearn: 0.0744447\ttotal: 19.5s\tremaining: 1m 41s\n",
      "162:\tlearn: 0.0743980\ttotal: 19.7s\tremaining: 1m 40s\n",
      "163:\tlearn: 0.0743313\ttotal: 19.8s\tremaining: 1m 40s\n",
      "164:\tlearn: 0.0742112\ttotal: 19.9s\tremaining: 1m 40s\n",
      "165:\tlearn: 0.0741045\ttotal: 20s\tremaining: 1m 40s\n",
      "166:\tlearn: 0.0740311\ttotal: 20.1s\tremaining: 1m 40s\n",
      "167:\tlearn: 0.0739444\ttotal: 20.3s\tremaining: 1m 40s\n",
      "168:\tlearn: 0.0738977\ttotal: 20.4s\tremaining: 1m 40s\n",
      "169:\tlearn: 0.0738376\ttotal: 20.5s\tremaining: 1m 40s\n",
      "170:\tlearn: 0.0737909\ttotal: 20.6s\tremaining: 1m 39s\n",
      "171:\tlearn: 0.0736108\ttotal: 20.7s\tremaining: 1m 39s\n",
      "172:\tlearn: 0.0735975\ttotal: 20.9s\tremaining: 1m 39s\n",
      "173:\tlearn: 0.0734908\ttotal: 21s\tremaining: 1m 39s\n",
      "174:\tlearn: 0.0734174\ttotal: 21.1s\tremaining: 1m 39s\n",
      "175:\tlearn: 0.0733173\ttotal: 21.2s\tremaining: 1m 39s\n",
      "176:\tlearn: 0.0732973\ttotal: 21.3s\tremaining: 1m 39s\n",
      "177:\tlearn: 0.0731839\ttotal: 21.5s\tremaining: 1m 39s\n",
      "178:\tlearn: 0.0730972\ttotal: 21.6s\tremaining: 1m 39s\n",
      "179:\tlearn: 0.0730038\ttotal: 21.7s\tremaining: 1m 38s\n",
      "180:\tlearn: 0.0729438\ttotal: 21.8s\tremaining: 1m 38s\n",
      "181:\tlearn: 0.0729371\ttotal: 22s\tremaining: 1m 38s\n",
      "182:\tlearn: 0.0727970\ttotal: 22.1s\tremaining: 1m 38s\n",
      "183:\tlearn: 0.0727303\ttotal: 22.2s\tremaining: 1m 38s\n",
      "184:\tlearn: 0.0726970\ttotal: 22.3s\tremaining: 1m 38s\n",
      "185:\tlearn: 0.0726102\ttotal: 22.4s\tremaining: 1m 38s\n",
      "186:\tlearn: 0.0725369\ttotal: 22.5s\tremaining: 1m 38s\n",
      "187:\tlearn: 0.0725035\ttotal: 22.7s\tremaining: 1m 37s\n",
      "188:\tlearn: 0.0724635\ttotal: 22.8s\tremaining: 1m 37s\n",
      "189:\tlearn: 0.0723701\ttotal: 22.9s\tremaining: 1m 37s\n",
      "190:\tlearn: 0.0722367\ttotal: 23s\tremaining: 1m 37s\n",
      "191:\tlearn: 0.0722167\ttotal: 23.2s\tremaining: 1m 37s\n",
      "192:\tlearn: 0.0722233\ttotal: 23.3s\tremaining: 1m 37s\n",
      "193:\tlearn: 0.0720966\ttotal: 23.4s\tremaining: 1m 37s\n",
      "194:\tlearn: 0.0719432\ttotal: 23.5s\tremaining: 1m 37s\n",
      "195:\tlearn: 0.0718498\ttotal: 23.6s\tremaining: 1m 36s\n",
      "196:\tlearn: 0.0717364\ttotal: 23.8s\tremaining: 1m 36s\n",
      "197:\tlearn: 0.0716163\ttotal: 23.9s\tremaining: 1m 36s\n",
      "198:\tlearn: 0.0715296\ttotal: 24s\tremaining: 1m 36s\n",
      "199:\tlearn: 0.0714362\ttotal: 24.1s\tremaining: 1m 36s\n",
      "200:\tlearn: 0.0713161\ttotal: 24.2s\tremaining: 1m 36s\n",
      "201:\tlearn: 0.0712494\ttotal: 24.4s\tremaining: 1m 36s\n",
      "202:\tlearn: 0.0711894\ttotal: 24.5s\tremaining: 1m 36s\n",
      "203:\tlearn: 0.0711760\ttotal: 24.6s\tremaining: 1m 36s\n",
      "204:\tlearn: 0.0711627\ttotal: 24.7s\tremaining: 1m 35s\n",
      "205:\tlearn: 0.0710760\ttotal: 24.9s\tremaining: 1m 35s\n",
      "206:\tlearn: 0.0709692\ttotal: 25s\tremaining: 1m 35s\n",
      "207:\tlearn: 0.0708558\ttotal: 25.1s\tremaining: 1m 35s\n",
      "208:\tlearn: 0.0707491\ttotal: 25.2s\tremaining: 1m 35s\n",
      "209:\tlearn: 0.0707358\ttotal: 25.3s\tremaining: 1m 35s\n",
      "210:\tlearn: 0.0706224\ttotal: 25.4s\tremaining: 1m 35s\n",
      "211:\tlearn: 0.0705357\ttotal: 25.6s\tremaining: 1m 34s\n",
      "212:\tlearn: 0.0704890\ttotal: 25.7s\tremaining: 1m 34s\n",
      "213:\tlearn: 0.0704489\ttotal: 25.8s\tremaining: 1m 34s\n",
      "214:\tlearn: 0.0704756\ttotal: 26s\tremaining: 1m 34s\n",
      "215:\tlearn: 0.0704223\ttotal: 26.1s\tremaining: 1m 34s\n",
      "216:\tlearn: 0.0704356\ttotal: 26.3s\tremaining: 1m 34s\n",
      "217:\tlearn: 0.0704022\ttotal: 26.5s\tremaining: 1m 34s\n",
      "218:\tlearn: 0.0703022\ttotal: 26.6s\tremaining: 1m 34s\n",
      "219:\tlearn: 0.0701888\ttotal: 26.7s\tremaining: 1m 34s\n",
      "220:\tlearn: 0.0701021\ttotal: 26.9s\tremaining: 1m 34s\n",
      "221:\tlearn: 0.0700087\ttotal: 27s\tremaining: 1m 34s\n",
      "222:\tlearn: 0.0699353\ttotal: 27.2s\tremaining: 1m 34s\n",
      "223:\tlearn: 0.0699486\ttotal: 27.3s\tremaining: 1m 34s\n",
      "224:\tlearn: 0.0698619\ttotal: 27.5s\tremaining: 1m 34s\n",
      "225:\tlearn: 0.0697752\ttotal: 27.6s\tremaining: 1m 34s\n",
      "226:\tlearn: 0.0697218\ttotal: 27.8s\tremaining: 1m 34s\n",
      "227:\tlearn: 0.0696685\ttotal: 27.9s\tremaining: 1m 34s\n",
      "228:\tlearn: 0.0696284\ttotal: 28.1s\tremaining: 1m 34s\n",
      "229:\tlearn: 0.0695284\ttotal: 28.2s\tremaining: 1m 34s\n",
      "230:\tlearn: 0.0694283\ttotal: 28.4s\tremaining: 1m 34s\n",
      "231:\tlearn: 0.0693883\ttotal: 28.5s\tremaining: 1m 34s\n",
      "232:\tlearn: 0.0693149\ttotal: 28.6s\tremaining: 1m 34s\n",
      "233:\tlearn: 0.0692549\ttotal: 28.8s\tremaining: 1m 34s\n",
      "234:\tlearn: 0.0692215\ttotal: 28.9s\tremaining: 1m 34s\n",
      "235:\tlearn: 0.0691148\ttotal: 29s\tremaining: 1m 34s\n",
      "236:\tlearn: 0.0690614\ttotal: 29.2s\tremaining: 1m 33s\n",
      "237:\tlearn: 0.0689881\ttotal: 29.3s\tremaining: 1m 33s\n",
      "238:\tlearn: 0.0689147\ttotal: 29.5s\tremaining: 1m 33s\n",
      "239:\tlearn: 0.0688813\ttotal: 29.6s\tremaining: 1m 33s\n",
      "240:\tlearn: 0.0688080\ttotal: 29.7s\tremaining: 1m 33s\n",
      "241:\tlearn: 0.0686879\ttotal: 29.9s\tremaining: 1m 33s\n",
      "242:\tlearn: 0.0686479\ttotal: 30s\tremaining: 1m 33s\n",
      "243:\tlearn: 0.0686212\ttotal: 30.2s\tremaining: 1m 33s\n",
      "244:\tlearn: 0.0684811\ttotal: 30.4s\tremaining: 1m 33s\n",
      "245:\tlearn: 0.0684010\ttotal: 30.6s\tremaining: 1m 33s\n",
      "246:\tlearn: 0.0683810\ttotal: 30.8s\tremaining: 1m 33s\n",
      "247:\tlearn: 0.0682876\ttotal: 31s\tremaining: 1m 33s\n",
      "248:\tlearn: 0.0682676\ttotal: 31.1s\tremaining: 1m 33s\n",
      "249:\tlearn: 0.0681676\ttotal: 31.3s\tremaining: 1m 33s\n",
      "250:\tlearn: 0.0681942\ttotal: 31.4s\tremaining: 1m 33s\n",
      "251:\tlearn: 0.0680542\ttotal: 31.6s\tremaining: 1m 33s\n",
      "252:\tlearn: 0.0680141\ttotal: 31.7s\tremaining: 1m 33s\n",
      "253:\tlearn: 0.0679875\ttotal: 31.9s\tremaining: 1m 33s\n",
      "254:\tlearn: 0.0679875\ttotal: 32.1s\tremaining: 1m 33s\n",
      "255:\tlearn: 0.0679007\ttotal: 32.2s\tremaining: 1m 33s\n",
      "256:\tlearn: 0.0678274\ttotal: 32.3s\tremaining: 1m 33s\n",
      "257:\tlearn: 0.0678074\ttotal: 32.5s\tremaining: 1m 33s\n",
      "258:\tlearn: 0.0677340\ttotal: 32.6s\tremaining: 1m 33s\n",
      "259:\tlearn: 0.0676806\ttotal: 32.7s\tremaining: 1m 33s\n",
      "260:\tlearn: 0.0676139\ttotal: 32.8s\tremaining: 1m 32s\n",
      "261:\tlearn: 0.0675672\ttotal: 32.9s\tremaining: 1m 32s\n",
      "262:\tlearn: 0.0675339\ttotal: 33.1s\tremaining: 1m 32s\n",
      "263:\tlearn: 0.0674738\ttotal: 33.2s\tremaining: 1m 32s\n",
      "264:\tlearn: 0.0674004\ttotal: 33.3s\tremaining: 1m 32s\n",
      "265:\tlearn: 0.0673337\ttotal: 33.4s\tremaining: 1m 32s\n",
      "266:\tlearn: 0.0672670\ttotal: 33.5s\tremaining: 1m 32s\n",
      "267:\tlearn: 0.0672737\ttotal: 33.6s\tremaining: 1m 31s\n",
      "268:\tlearn: 0.0672537\ttotal: 33.8s\tremaining: 1m 31s\n",
      "269:\tlearn: 0.0671670\ttotal: 33.9s\tremaining: 1m 31s\n",
      "270:\tlearn: 0.0671870\ttotal: 34s\tremaining: 1m 31s\n",
      "271:\tlearn: 0.0671536\ttotal: 34.1s\tremaining: 1m 31s\n",
      "272:\tlearn: 0.0670802\ttotal: 34.2s\tremaining: 1m 31s\n",
      "273:\tlearn: 0.0670736\ttotal: 34.4s\tremaining: 1m 31s\n",
      "274:\tlearn: 0.0669802\ttotal: 34.5s\tremaining: 1m 30s\n",
      "275:\tlearn: 0.0670069\ttotal: 34.6s\tremaining: 1m 30s\n",
      "276:\tlearn: 0.0670002\ttotal: 34.7s\tremaining: 1m 30s\n",
      "277:\tlearn: 0.0669668\ttotal: 34.8s\tremaining: 1m 30s\n",
      "278:\tlearn: 0.0668668\ttotal: 35s\tremaining: 1m 30s\n",
      "279:\tlearn: 0.0668401\ttotal: 35.1s\tremaining: 1m 30s\n",
      "280:\tlearn: 0.0668201\ttotal: 35.2s\tremaining: 1m 30s\n",
      "281:\tlearn: 0.0667867\ttotal: 35.3s\tremaining: 1m 29s\n",
      "282:\tlearn: 0.0667334\ttotal: 35.4s\tremaining: 1m 29s\n",
      "283:\tlearn: 0.0666467\ttotal: 35.6s\tremaining: 1m 29s\n",
      "284:\tlearn: 0.0666200\ttotal: 35.7s\tremaining: 1m 29s\n",
      "285:\tlearn: 0.0666133\ttotal: 35.8s\tremaining: 1m 29s\n",
      "286:\tlearn: 0.0665799\ttotal: 35.9s\tremaining: 1m 29s\n",
      "287:\tlearn: 0.0665799\ttotal: 36.1s\tremaining: 1m 29s\n",
      "288:\tlearn: 0.0665533\ttotal: 36.2s\tremaining: 1m 29s\n",
      "289:\tlearn: 0.0665666\ttotal: 36.3s\tremaining: 1m 28s\n",
      "290:\tlearn: 0.0665533\ttotal: 36.4s\tremaining: 1m 28s\n",
      "291:\tlearn: 0.0664866\ttotal: 36.6s\tremaining: 1m 28s\n",
      "292:\tlearn: 0.0664332\ttotal: 36.7s\tremaining: 1m 28s\n",
      "293:\tlearn: 0.0663998\ttotal: 36.8s\tremaining: 1m 28s\n",
      "294:\tlearn: 0.0664065\ttotal: 36.9s\tremaining: 1m 28s\n",
      "295:\tlearn: 0.0663598\ttotal: 37s\tremaining: 1m 28s\n",
      "296:\tlearn: 0.0662731\ttotal: 37.2s\tremaining: 1m 27s\n",
      "297:\tlearn: 0.0662264\ttotal: 37.3s\tremaining: 1m 27s\n",
      "298:\tlearn: 0.0661197\ttotal: 37.4s\tremaining: 1m 27s\n",
      "299:\tlearn: 0.0660730\ttotal: 37.5s\tremaining: 1m 27s\n",
      "300:\tlearn: 0.0660330\ttotal: 37.6s\tremaining: 1m 27s\n",
      "301:\tlearn: 0.0659662\ttotal: 37.8s\tremaining: 1m 27s\n",
      "302:\tlearn: 0.0659729\ttotal: 37.9s\tremaining: 1m 27s\n",
      "303:\tlearn: 0.0658862\ttotal: 38s\tremaining: 1m 27s\n",
      "304:\tlearn: 0.0658262\ttotal: 38.1s\tremaining: 1m 26s\n",
      "305:\tlearn: 0.0658262\ttotal: 38.2s\tremaining: 1m 26s\n",
      "306:\tlearn: 0.0657461\ttotal: 38.4s\tremaining: 1m 26s\n",
      "307:\tlearn: 0.0657461\ttotal: 38.5s\tremaining: 1m 26s\n",
      "308:\tlearn: 0.0656861\ttotal: 38.6s\tremaining: 1m 26s\n",
      "309:\tlearn: 0.0656394\ttotal: 38.7s\tremaining: 1m 26s\n",
      "310:\tlearn: 0.0655327\ttotal: 38.8s\tremaining: 1m 26s\n",
      "311:\tlearn: 0.0654593\ttotal: 39s\tremaining: 1m 25s\n",
      "312:\tlearn: 0.0653926\ttotal: 39.1s\tremaining: 1m 25s\n",
      "313:\tlearn: 0.0653192\ttotal: 39.2s\tremaining: 1m 25s\n",
      "314:\tlearn: 0.0653525\ttotal: 39.3s\tremaining: 1m 25s\n",
      "315:\tlearn: 0.0652725\ttotal: 39.4s\tremaining: 1m 25s\n",
      "316:\tlearn: 0.0651858\ttotal: 39.5s\tremaining: 1m 25s\n",
      "317:\tlearn: 0.0651458\ttotal: 39.7s\tremaining: 1m 25s\n",
      "318:\tlearn: 0.0651191\ttotal: 39.8s\tremaining: 1m 24s\n",
      "319:\tlearn: 0.0650390\ttotal: 39.9s\tremaining: 1m 24s\n",
      "320:\tlearn: 0.0650257\ttotal: 40.1s\tremaining: 1m 24s\n",
      "321:\tlearn: 0.0649857\ttotal: 40.2s\tremaining: 1m 24s\n",
      "322:\tlearn: 0.0649723\ttotal: 40.3s\tremaining: 1m 24s\n",
      "323:\tlearn: 0.0649190\ttotal: 40.4s\tremaining: 1m 24s\n",
      "324:\tlearn: 0.0648923\ttotal: 40.5s\tremaining: 1m 24s\n",
      "325:\tlearn: 0.0648189\ttotal: 40.7s\tremaining: 1m 24s\n",
      "326:\tlearn: 0.0647388\ttotal: 40.8s\tremaining: 1m 23s\n",
      "327:\tlearn: 0.0646855\ttotal: 40.9s\tremaining: 1m 23s\n",
      "328:\tlearn: 0.0646655\ttotal: 41s\tremaining: 1m 23s\n",
      "329:\tlearn: 0.0645721\ttotal: 41.2s\tremaining: 1m 23s\n",
      "330:\tlearn: 0.0645521\ttotal: 41.3s\tremaining: 1m 23s\n",
      "331:\tlearn: 0.0644987\ttotal: 41.4s\tremaining: 1m 23s\n",
      "332:\tlearn: 0.0644453\ttotal: 41.5s\tremaining: 1m 23s\n",
      "333:\tlearn: 0.0643986\ttotal: 41.6s\tremaining: 1m 23s\n",
      "334:\tlearn: 0.0643586\ttotal: 41.7s\tremaining: 1m 22s\n",
      "335:\tlearn: 0.0643253\ttotal: 41.9s\tremaining: 1m 22s\n",
      "336:\tlearn: 0.0642852\ttotal: 42s\tremaining: 1m 22s\n",
      "337:\tlearn: 0.0642586\ttotal: 42.1s\tremaining: 1m 22s\n",
      "338:\tlearn: 0.0641718\ttotal: 42.2s\tremaining: 1m 22s\n",
      "339:\tlearn: 0.0641718\ttotal: 42.3s\tremaining: 1m 22s\n",
      "340:\tlearn: 0.0641118\ttotal: 42.5s\tremaining: 1m 22s\n",
      "341:\tlearn: 0.0640651\ttotal: 42.6s\tremaining: 1m 21s\n",
      "342:\tlearn: 0.0640117\ttotal: 42.7s\tremaining: 1m 21s\n",
      "343:\tlearn: 0.0639250\ttotal: 42.9s\tremaining: 1m 21s\n",
      "344:\tlearn: 0.0638850\ttotal: 43s\tremaining: 1m 21s\n",
      "345:\tlearn: 0.0638917\ttotal: 43.1s\tremaining: 1m 21s\n",
      "346:\tlearn: 0.0638183\ttotal: 43.3s\tremaining: 1m 21s\n",
      "347:\tlearn: 0.0637716\ttotal: 43.4s\tremaining: 1m 21s\n",
      "348:\tlearn: 0.0637783\ttotal: 43.5s\tremaining: 1m 21s\n",
      "349:\tlearn: 0.0637649\ttotal: 43.7s\tremaining: 1m 21s\n",
      "350:\tlearn: 0.0637049\ttotal: 43.8s\tremaining: 1m 21s\n",
      "351:\tlearn: 0.0636649\ttotal: 44s\tremaining: 1m 20s\n",
      "352:\tlearn: 0.0636649\ttotal: 44.1s\tremaining: 1m 20s\n",
      "353:\tlearn: 0.0636115\ttotal: 44.2s\tremaining: 1m 20s\n",
      "354:\tlearn: 0.0635448\ttotal: 44.3s\tremaining: 1m 20s\n",
      "355:\tlearn: 0.0634781\ttotal: 44.4s\tremaining: 1m 20s\n",
      "356:\tlearn: 0.0634647\ttotal: 44.6s\tremaining: 1m 20s\n",
      "357:\tlearn: 0.0633780\ttotal: 44.7s\tremaining: 1m 20s\n",
      "358:\tlearn: 0.0633647\ttotal: 44.8s\tremaining: 1m 19s\n",
      "359:\tlearn: 0.0633513\ttotal: 44.9s\tremaining: 1m 19s\n",
      "360:\tlearn: 0.0633380\ttotal: 45s\tremaining: 1m 19s\n",
      "361:\tlearn: 0.0633247\ttotal: 45.2s\tremaining: 1m 19s\n",
      "362:\tlearn: 0.0632780\ttotal: 45.3s\tremaining: 1m 19s\n",
      "363:\tlearn: 0.0632580\ttotal: 45.5s\tremaining: 1m 19s\n",
      "364:\tlearn: 0.0631779\ttotal: 45.6s\tremaining: 1m 19s\n",
      "365:\tlearn: 0.0631446\ttotal: 45.7s\tremaining: 1m 19s\n",
      "366:\tlearn: 0.0630979\ttotal: 45.8s\tremaining: 1m 19s\n",
      "367:\tlearn: 0.0630378\ttotal: 46s\tremaining: 1m 18s\n",
      "368:\tlearn: 0.0630445\ttotal: 46.1s\tremaining: 1m 18s\n",
      "369:\tlearn: 0.0630445\ttotal: 46.2s\tremaining: 1m 18s\n",
      "370:\tlearn: 0.0629578\ttotal: 46.3s\tremaining: 1m 18s\n",
      "371:\tlearn: 0.0629178\ttotal: 46.4s\tremaining: 1m 18s\n",
      "372:\tlearn: 0.0628644\ttotal: 46.6s\tremaining: 1m 18s\n",
      "373:\tlearn: 0.0627910\ttotal: 46.7s\tremaining: 1m 18s\n",
      "374:\tlearn: 0.0627977\ttotal: 46.8s\tremaining: 1m 17s\n",
      "375:\tlearn: 0.0627577\ttotal: 46.9s\tremaining: 1m 17s\n",
      "376:\tlearn: 0.0626909\ttotal: 47s\tremaining: 1m 17s\n",
      "377:\tlearn: 0.0626909\ttotal: 47.2s\tremaining: 1m 17s\n",
      "378:\tlearn: 0.0626242\ttotal: 47.3s\tremaining: 1m 17s\n",
      "379:\tlearn: 0.0625842\ttotal: 47.4s\tremaining: 1m 17s\n",
      "380:\tlearn: 0.0625642\ttotal: 47.5s\tremaining: 1m 17s\n",
      "381:\tlearn: 0.0625242\ttotal: 47.7s\tremaining: 1m 17s\n",
      "382:\tlearn: 0.0624975\ttotal: 47.8s\tremaining: 1m 17s\n",
      "383:\tlearn: 0.0624641\ttotal: 47.9s\tremaining: 1m 16s\n",
      "384:\tlearn: 0.0624375\ttotal: 48.1s\tremaining: 1m 16s\n",
      "385:\tlearn: 0.0624441\ttotal: 48.2s\tremaining: 1m 16s\n",
      "386:\tlearn: 0.0623908\ttotal: 48.3s\tremaining: 1m 16s\n",
      "387:\tlearn: 0.0623641\ttotal: 48.4s\tremaining: 1m 16s\n",
      "388:\tlearn: 0.0622440\ttotal: 48.5s\tremaining: 1m 16s\n",
      "389:\tlearn: 0.0621906\ttotal: 48.6s\tremaining: 1m 16s\n",
      "390:\tlearn: 0.0621573\ttotal: 48.8s\tremaining: 1m 15s\n",
      "391:\tlearn: 0.0621106\ttotal: 48.9s\tremaining: 1m 15s\n",
      "392:\tlearn: 0.0620839\ttotal: 49s\tremaining: 1m 15s\n",
      "393:\tlearn: 0.0620506\ttotal: 49.2s\tremaining: 1m 15s\n",
      "394:\tlearn: 0.0619772\ttotal: 49.3s\tremaining: 1m 15s\n",
      "395:\tlearn: 0.0619438\ttotal: 49.4s\tremaining: 1m 15s\n",
      "396:\tlearn: 0.0618838\ttotal: 49.5s\tremaining: 1m 15s\n",
      "397:\tlearn: 0.0618504\ttotal: 49.7s\tremaining: 1m 15s\n",
      "398:\tlearn: 0.0617971\ttotal: 49.8s\tremaining: 1m 14s\n",
      "399:\tlearn: 0.0617437\ttotal: 49.9s\tremaining: 1m 14s\n",
      "400:\tlearn: 0.0617170\ttotal: 50s\tremaining: 1m 14s\n",
      "401:\tlearn: 0.0616770\ttotal: 50.1s\tremaining: 1m 14s\n",
      "402:\tlearn: 0.0616370\ttotal: 50.3s\tremaining: 1m 14s\n",
      "403:\tlearn: 0.0616170\ttotal: 50.4s\tremaining: 1m 14s\n",
      "404:\tlearn: 0.0615303\ttotal: 50.5s\tremaining: 1m 14s\n",
      "405:\tlearn: 0.0614902\ttotal: 50.6s\tremaining: 1m 14s\n",
      "406:\tlearn: 0.0614969\ttotal: 50.7s\tremaining: 1m 13s\n",
      "407:\tlearn: 0.0614169\ttotal: 50.9s\tremaining: 1m 13s\n",
      "408:\tlearn: 0.0613635\ttotal: 51s\tremaining: 1m 13s\n",
      "409:\tlearn: 0.0613568\ttotal: 51.1s\tremaining: 1m 13s\n",
      "410:\tlearn: 0.0613301\ttotal: 51.3s\tremaining: 1m 13s\n",
      "411:\tlearn: 0.0612701\ttotal: 51.4s\tremaining: 1m 13s\n",
      "412:\tlearn: 0.0612367\ttotal: 51.5s\tremaining: 1m 13s\n",
      "413:\tlearn: 0.0611567\ttotal: 51.6s\tremaining: 1m 13s\n",
      "414:\tlearn: 0.0611434\ttotal: 51.8s\tremaining: 1m 12s\n",
      "415:\tlearn: 0.0610366\ttotal: 51.9s\tremaining: 1m 12s\n",
      "416:\tlearn: 0.0609766\ttotal: 52s\tremaining: 1m 12s\n",
      "417:\tlearn: 0.0608965\ttotal: 52.1s\tremaining: 1m 12s\n",
      "418:\tlearn: 0.0608498\ttotal: 52.2s\tremaining: 1m 12s\n",
      "419:\tlearn: 0.0608031\ttotal: 52.4s\tremaining: 1m 12s\n",
      "420:\tlearn: 0.0607831\ttotal: 52.5s\tremaining: 1m 12s\n",
      "421:\tlearn: 0.0607231\ttotal: 52.6s\tremaining: 1m 12s\n",
      "422:\tlearn: 0.0607098\ttotal: 52.7s\tremaining: 1m 11s\n",
      "423:\tlearn: 0.0606897\ttotal: 52.8s\tremaining: 1m 11s\n",
      "424:\tlearn: 0.0606364\ttotal: 53s\tremaining: 1m 11s\n",
      "425:\tlearn: 0.0605563\ttotal: 53.1s\tremaining: 1m 11s\n",
      "426:\tlearn: 0.0604429\ttotal: 53.2s\tremaining: 1m 11s\n",
      "427:\tlearn: 0.0604429\ttotal: 53.3s\tremaining: 1m 11s\n",
      "428:\tlearn: 0.0604629\ttotal: 53.4s\tremaining: 1m 11s\n",
      "429:\tlearn: 0.0604563\ttotal: 53.6s\tremaining: 1m 11s\n",
      "430:\tlearn: 0.0603562\ttotal: 53.7s\tremaining: 1m 10s\n",
      "431:\tlearn: 0.0603229\ttotal: 53.8s\tremaining: 1m 10s\n",
      "432:\tlearn: 0.0603429\ttotal: 53.9s\tremaining: 1m 10s\n",
      "433:\tlearn: 0.0602828\ttotal: 54s\tremaining: 1m 10s\n",
      "434:\tlearn: 0.0602095\ttotal: 54.2s\tremaining: 1m 10s\n",
      "435:\tlearn: 0.0600961\ttotal: 54.3s\tremaining: 1m 10s\n",
      "436:\tlearn: 0.0600827\ttotal: 54.4s\tremaining: 1m 10s\n",
      "437:\tlearn: 0.0600694\ttotal: 54.5s\tremaining: 1m 9s\n",
      "438:\tlearn: 0.0600227\ttotal: 54.6s\tremaining: 1m 9s\n",
      "439:\tlearn: 0.0599760\ttotal: 54.8s\tremaining: 1m 9s\n",
      "440:\tlearn: 0.0599693\ttotal: 54.9s\tremaining: 1m 9s\n",
      "441:\tlearn: 0.0598893\ttotal: 55s\tremaining: 1m 9s\n",
      "442:\tlearn: 0.0598492\ttotal: 55.1s\tremaining: 1m 9s\n",
      "443:\tlearn: 0.0597959\ttotal: 55.3s\tremaining: 1m 9s\n",
      "444:\tlearn: 0.0598025\ttotal: 55.4s\tremaining: 1m 9s\n",
      "445:\tlearn: 0.0597759\ttotal: 55.5s\tremaining: 1m 8s\n",
      "446:\tlearn: 0.0597025\ttotal: 55.6s\tremaining: 1m 8s\n",
      "447:\tlearn: 0.0596891\ttotal: 55.7s\tremaining: 1m 8s\n",
      "448:\tlearn: 0.0596291\ttotal: 55.9s\tremaining: 1m 8s\n",
      "449:\tlearn: 0.0596158\ttotal: 56s\tremaining: 1m 8s\n",
      "450:\tlearn: 0.0595491\ttotal: 56.1s\tremaining: 1m 8s\n",
      "451:\tlearn: 0.0595357\ttotal: 56.2s\tremaining: 1m 8s\n",
      "452:\tlearn: 0.0595157\ttotal: 56.4s\tremaining: 1m 8s\n",
      "453:\tlearn: 0.0594623\ttotal: 56.5s\tremaining: 1m 7s\n",
      "454:\tlearn: 0.0594490\ttotal: 56.6s\tremaining: 1m 7s\n",
      "455:\tlearn: 0.0594357\ttotal: 56.7s\tremaining: 1m 7s\n",
      "456:\tlearn: 0.0594156\ttotal: 56.8s\tremaining: 1m 7s\n",
      "457:\tlearn: 0.0594023\ttotal: 57s\tremaining: 1m 7s\n",
      "458:\tlearn: 0.0593289\ttotal: 57.1s\tremaining: 1m 7s\n",
      "459:\tlearn: 0.0592689\ttotal: 57.2s\tremaining: 1m 7s\n",
      "460:\tlearn: 0.0592289\ttotal: 57.3s\tremaining: 1m 7s\n",
      "461:\tlearn: 0.0591822\ttotal: 57.4s\tremaining: 1m 6s\n",
      "462:\tlearn: 0.0591755\ttotal: 57.6s\tremaining: 1m 6s\n",
      "463:\tlearn: 0.0591555\ttotal: 57.7s\tremaining: 1m 6s\n",
      "464:\tlearn: 0.0591288\ttotal: 57.9s\tremaining: 1m 6s\n",
      "465:\tlearn: 0.0591021\ttotal: 58s\tremaining: 1m 6s\n",
      "466:\tlearn: 0.0590821\ttotal: 58.1s\tremaining: 1m 6s\n",
      "467:\tlearn: 0.0590621\ttotal: 58.2s\tremaining: 1m 6s\n",
      "468:\tlearn: 0.0589554\ttotal: 58.4s\tremaining: 1m 6s\n",
      "469:\tlearn: 0.0589754\ttotal: 58.5s\tremaining: 1m 5s\n",
      "470:\tlearn: 0.0589420\ttotal: 58.6s\tremaining: 1m 5s\n",
      "471:\tlearn: 0.0589153\ttotal: 58.7s\tremaining: 1m 5s\n",
      "472:\tlearn: 0.0588820\ttotal: 58.8s\tremaining: 1m 5s\n",
      "473:\tlearn: 0.0588220\ttotal: 58.9s\tremaining: 1m 5s\n",
      "474:\tlearn: 0.0588420\ttotal: 59.1s\tremaining: 1m 5s\n",
      "475:\tlearn: 0.0588220\ttotal: 59.2s\tremaining: 1m 5s\n",
      "476:\tlearn: 0.0587419\ttotal: 59.3s\tremaining: 1m 5s\n",
      "477:\tlearn: 0.0587152\ttotal: 59.4s\tremaining: 1m 4s\n",
      "478:\tlearn: 0.0586685\ttotal: 59.6s\tremaining: 1m 4s\n",
      "479:\tlearn: 0.0586419\ttotal: 59.7s\tremaining: 1m 4s\n",
      "480:\tlearn: 0.0586152\ttotal: 59.8s\tremaining: 1m 4s\n",
      "481:\tlearn: 0.0585885\ttotal: 59.9s\tremaining: 1m 4s\n",
      "482:\tlearn: 0.0585485\ttotal: 1m\tremaining: 1m 4s\n",
      "483:\tlearn: 0.0585151\ttotal: 1m\tremaining: 1m 4s\n",
      "484:\tlearn: 0.0585018\ttotal: 1m\tremaining: 1m 4s\n",
      "485:\tlearn: 0.0584617\ttotal: 1m\tremaining: 1m 3s\n",
      "486:\tlearn: 0.0584084\ttotal: 1m\tremaining: 1m 3s\n",
      "487:\tlearn: 0.0583750\ttotal: 1m\tremaining: 1m 3s\n",
      "488:\tlearn: 0.0583283\ttotal: 1m\tremaining: 1m 3s\n",
      "489:\tlearn: 0.0582283\ttotal: 1m\tremaining: 1m 3s\n",
      "490:\tlearn: 0.0581882\ttotal: 1m\tremaining: 1m 3s\n",
      "491:\tlearn: 0.0581616\ttotal: 1m 1s\tremaining: 1m 3s\n",
      "492:\tlearn: 0.0581349\ttotal: 1m 1s\tremaining: 1m 2s\n",
      "493:\tlearn: 0.0581215\ttotal: 1m 1s\tremaining: 1m 2s\n",
      "494:\tlearn: 0.0580949\ttotal: 1m 1s\tremaining: 1m 2s\n",
      "495:\tlearn: 0.0580282\ttotal: 1m 1s\tremaining: 1m 2s\n",
      "496:\tlearn: 0.0579748\ttotal: 1m 1s\tremaining: 1m 2s\n",
      "497:\tlearn: 0.0579481\ttotal: 1m 1s\tremaining: 1m 2s\n",
      "498:\tlearn: 0.0578747\ttotal: 1m 1s\tremaining: 1m 2s\n",
      "499:\tlearn: 0.0578347\ttotal: 1m 2s\tremaining: 1m 2s\n",
      "500:\tlearn: 0.0578013\ttotal: 1m 2s\tremaining: 1m 1s\n",
      "501:\tlearn: 0.0578280\ttotal: 1m 2s\tremaining: 1m 1s\n",
      "502:\tlearn: 0.0577947\ttotal: 1m 2s\tremaining: 1m 1s\n",
      "503:\tlearn: 0.0577280\ttotal: 1m 2s\tremaining: 1m 1s\n",
      "504:\tlearn: 0.0576879\ttotal: 1m 2s\tremaining: 1m 1s\n",
      "505:\tlearn: 0.0576613\ttotal: 1m 2s\tremaining: 1m 1s\n",
      "506:\tlearn: 0.0576146\ttotal: 1m 2s\tremaining: 1m 1s\n",
      "507:\tlearn: 0.0575345\ttotal: 1m 3s\tremaining: 1m 1s\n",
      "508:\tlearn: 0.0575279\ttotal: 1m 3s\tremaining: 1m\n",
      "509:\tlearn: 0.0574545\ttotal: 1m 3s\tremaining: 1m\n",
      "510:\tlearn: 0.0574411\ttotal: 1m 3s\tremaining: 1m\n",
      "511:\tlearn: 0.0573878\ttotal: 1m 3s\tremaining: 1m\n",
      "512:\tlearn: 0.0573678\ttotal: 1m 3s\tremaining: 1m\n",
      "513:\tlearn: 0.0573344\ttotal: 1m 3s\tremaining: 1m\n",
      "514:\tlearn: 0.0573477\ttotal: 1m 3s\tremaining: 1m\n",
      "515:\tlearn: 0.0572744\ttotal: 1m 3s\tremaining: 1m\n",
      "516:\tlearn: 0.0572477\ttotal: 1m 4s\tremaining: 59.9s\n",
      "517:\tlearn: 0.0572610\ttotal: 1m 4s\tremaining: 59.8s\n",
      "518:\tlearn: 0.0572077\ttotal: 1m 4s\tremaining: 59.7s\n",
      "519:\tlearn: 0.0571876\ttotal: 1m 4s\tremaining: 59.6s\n",
      "520:\tlearn: 0.0571343\ttotal: 1m 4s\tremaining: 59.4s\n",
      "521:\tlearn: 0.0571009\ttotal: 1m 4s\tremaining: 59.3s\n",
      "522:\tlearn: 0.0570142\ttotal: 1m 4s\tremaining: 59.2s\n",
      "523:\tlearn: 0.0570209\ttotal: 1m 4s\tremaining: 59s\n",
      "524:\tlearn: 0.0569875\ttotal: 1m 5s\tremaining: 58.9s\n",
      "525:\tlearn: 0.0569475\ttotal: 1m 5s\tremaining: 58.8s\n",
      "526:\tlearn: 0.0569008\ttotal: 1m 5s\tremaining: 58.7s\n",
      "527:\tlearn: 0.0568741\ttotal: 1m 5s\tremaining: 58.5s\n",
      "528:\tlearn: 0.0568608\ttotal: 1m 5s\tremaining: 58.4s\n",
      "529:\tlearn: 0.0568341\ttotal: 1m 5s\tremaining: 58.3s\n",
      "530:\tlearn: 0.0568608\ttotal: 1m 5s\tremaining: 58.1s\n",
      "531:\tlearn: 0.0568341\ttotal: 1m 5s\tremaining: 58s\n",
      "532:\tlearn: 0.0568007\ttotal: 1m 6s\tremaining: 57.9s\n",
      "533:\tlearn: 0.0567674\ttotal: 1m 6s\tremaining: 57.8s\n",
      "534:\tlearn: 0.0567340\ttotal: 1m 6s\tremaining: 57.6s\n",
      "535:\tlearn: 0.0566540\ttotal: 1m 6s\tremaining: 57.5s\n",
      "536:\tlearn: 0.0566473\ttotal: 1m 6s\tremaining: 57.4s\n",
      "537:\tlearn: 0.0566073\ttotal: 1m 6s\tremaining: 57.3s\n",
      "538:\tlearn: 0.0565673\ttotal: 1m 6s\tremaining: 57.1s\n",
      "539:\tlearn: 0.0565473\ttotal: 1m 6s\tremaining: 57s\n",
      "540:\tlearn: 0.0565006\ttotal: 1m 7s\tremaining: 56.9s\n",
      "541:\tlearn: 0.0564739\ttotal: 1m 7s\tremaining: 56.8s\n",
      "542:\tlearn: 0.0564138\ttotal: 1m 7s\tremaining: 56.6s\n",
      "543:\tlearn: 0.0563805\ttotal: 1m 7s\tremaining: 56.5s\n",
      "544:\tlearn: 0.0563672\ttotal: 1m 7s\tremaining: 56.4s\n",
      "545:\tlearn: 0.0563405\ttotal: 1m 7s\tremaining: 56.3s\n",
      "546:\tlearn: 0.0563471\ttotal: 1m 7s\tremaining: 56.1s\n",
      "547:\tlearn: 0.0563605\ttotal: 1m 7s\tremaining: 56s\n",
      "548:\tlearn: 0.0562804\ttotal: 1m 8s\tremaining: 55.9s\n",
      "549:\tlearn: 0.0561537\ttotal: 1m 8s\tremaining: 55.8s\n",
      "550:\tlearn: 0.0561270\ttotal: 1m 8s\tremaining: 55.6s\n",
      "551:\tlearn: 0.0560336\ttotal: 1m 8s\tremaining: 55.5s\n",
      "552:\tlearn: 0.0560336\ttotal: 1m 8s\tremaining: 55.4s\n",
      "553:\tlearn: 0.0559869\ttotal: 1m 8s\tremaining: 55.2s\n",
      "554:\tlearn: 0.0559469\ttotal: 1m 8s\tremaining: 55.1s\n",
      "555:\tlearn: 0.0559469\ttotal: 1m 8s\tremaining: 55s\n",
      "556:\tlearn: 0.0559069\ttotal: 1m 8s\tremaining: 54.9s\n",
      "557:\tlearn: 0.0558402\ttotal: 1m 9s\tremaining: 54.7s\n",
      "558:\tlearn: 0.0558001\ttotal: 1m 9s\tremaining: 54.6s\n",
      "559:\tlearn: 0.0557601\ttotal: 1m 9s\tremaining: 54.5s\n",
      "560:\tlearn: 0.0557535\ttotal: 1m 9s\tremaining: 54.3s\n",
      "561:\tlearn: 0.0556934\ttotal: 1m 9s\tremaining: 54.2s\n",
      "562:\tlearn: 0.0557001\ttotal: 1m 9s\tremaining: 54.1s\n",
      "563:\tlearn: 0.0556667\ttotal: 1m 9s\tremaining: 54s\n",
      "564:\tlearn: 0.0556401\ttotal: 1m 9s\tremaining: 53.8s\n",
      "565:\tlearn: 0.0556267\ttotal: 1m 10s\tremaining: 53.7s\n",
      "566:\tlearn: 0.0555733\ttotal: 1m 10s\tremaining: 53.6s\n",
      "567:\tlearn: 0.0555533\ttotal: 1m 10s\tremaining: 53.5s\n",
      "568:\tlearn: 0.0555333\ttotal: 1m 10s\tremaining: 53.3s\n",
      "569:\tlearn: 0.0555200\ttotal: 1m 10s\tremaining: 53.2s\n",
      "570:\tlearn: 0.0554733\ttotal: 1m 10s\tremaining: 53.1s\n",
      "571:\tlearn: 0.0554733\ttotal: 1m 10s\tremaining: 53s\n",
      "572:\tlearn: 0.0554533\ttotal: 1m 10s\tremaining: 52.8s\n",
      "573:\tlearn: 0.0553999\ttotal: 1m 11s\tremaining: 52.7s\n",
      "574:\tlearn: 0.0553599\ttotal: 1m 11s\tremaining: 52.6s\n",
      "575:\tlearn: 0.0553132\ttotal: 1m 11s\tremaining: 52.5s\n",
      "576:\tlearn: 0.0552732\ttotal: 1m 11s\tremaining: 52.3s\n",
      "577:\tlearn: 0.0552665\ttotal: 1m 11s\tremaining: 52.2s\n",
      "578:\tlearn: 0.0552265\ttotal: 1m 11s\tremaining: 52.1s\n",
      "579:\tlearn: 0.0551464\ttotal: 1m 11s\tremaining: 52s\n",
      "580:\tlearn: 0.0551331\ttotal: 1m 11s\tremaining: 51.9s\n",
      "581:\tlearn: 0.0550931\ttotal: 1m 12s\tremaining: 51.7s\n",
      "582:\tlearn: 0.0551064\ttotal: 1m 12s\tremaining: 51.6s\n",
      "583:\tlearn: 0.0550530\ttotal: 1m 12s\tremaining: 51.5s\n",
      "584:\tlearn: 0.0549930\ttotal: 1m 12s\tremaining: 51.4s\n",
      "585:\tlearn: 0.0549930\ttotal: 1m 12s\tremaining: 51.2s\n",
      "586:\tlearn: 0.0549530\ttotal: 1m 12s\tremaining: 51.1s\n",
      "587:\tlearn: 0.0549063\ttotal: 1m 12s\tremaining: 51s\n",
      "588:\tlearn: 0.0548863\ttotal: 1m 12s\tremaining: 50.9s\n",
      "589:\tlearn: 0.0548663\ttotal: 1m 13s\tremaining: 50.8s\n",
      "590:\tlearn: 0.0548062\ttotal: 1m 13s\tremaining: 50.6s\n",
      "591:\tlearn: 0.0547929\ttotal: 1m 13s\tremaining: 50.5s\n",
      "592:\tlearn: 0.0547662\ttotal: 1m 13s\tremaining: 50.4s\n",
      "593:\tlearn: 0.0547462\ttotal: 1m 13s\tremaining: 50.3s\n",
      "594:\tlearn: 0.0547328\ttotal: 1m 13s\tremaining: 50.1s\n",
      "595:\tlearn: 0.0546995\ttotal: 1m 13s\tremaining: 50s\n",
      "596:\tlearn: 0.0546995\ttotal: 1m 13s\tremaining: 49.9s\n",
      "597:\tlearn: 0.0546795\ttotal: 1m 14s\tremaining: 49.8s\n",
      "598:\tlearn: 0.0545994\ttotal: 1m 14s\tremaining: 49.6s\n",
      "599:\tlearn: 0.0546061\ttotal: 1m 14s\tremaining: 49.5s\n",
      "600:\tlearn: 0.0545461\ttotal: 1m 14s\tremaining: 49.4s\n",
      "601:\tlearn: 0.0545928\ttotal: 1m 14s\tremaining: 49.3s\n",
      "602:\tlearn: 0.0545527\ttotal: 1m 14s\tremaining: 49.1s\n",
      "603:\tlearn: 0.0544393\ttotal: 1m 14s\tremaining: 49s\n",
      "604:\tlearn: 0.0544527\ttotal: 1m 14s\tremaining: 48.9s\n",
      "605:\tlearn: 0.0544327\ttotal: 1m 15s\tremaining: 48.8s\n",
      "606:\tlearn: 0.0543193\ttotal: 1m 15s\tremaining: 48.6s\n",
      "607:\tlearn: 0.0543259\ttotal: 1m 15s\tremaining: 48.5s\n",
      "608:\tlearn: 0.0543326\ttotal: 1m 15s\tremaining: 48.4s\n",
      "609:\tlearn: 0.0542659\ttotal: 1m 15s\tremaining: 48.3s\n",
      "610:\tlearn: 0.0542259\ttotal: 1m 15s\tremaining: 48.1s\n",
      "611:\tlearn: 0.0542059\ttotal: 1m 15s\tremaining: 48s\n",
      "612:\tlearn: 0.0541592\ttotal: 1m 15s\tremaining: 47.9s\n",
      "613:\tlearn: 0.0541058\ttotal: 1m 15s\tremaining: 47.8s\n",
      "614:\tlearn: 0.0540658\ttotal: 1m 16s\tremaining: 47.6s\n",
      "615:\tlearn: 0.0540124\ttotal: 1m 16s\tremaining: 47.5s\n",
      "616:\tlearn: 0.0539657\ttotal: 1m 16s\tremaining: 47.4s\n",
      "617:\tlearn: 0.0538590\ttotal: 1m 16s\tremaining: 47.3s\n",
      "618:\tlearn: 0.0538657\ttotal: 1m 16s\tremaining: 47.1s\n",
      "619:\tlearn: 0.0539057\ttotal: 1m 16s\tremaining: 47s\n",
      "620:\tlearn: 0.0538857\ttotal: 1m 16s\tremaining: 46.9s\n",
      "621:\tlearn: 0.0538323\ttotal: 1m 16s\tremaining: 46.8s\n",
      "622:\tlearn: 0.0537789\ttotal: 1m 17s\tremaining: 46.6s\n",
      "623:\tlearn: 0.0537589\ttotal: 1m 17s\tremaining: 46.5s\n",
      "624:\tlearn: 0.0537122\ttotal: 1m 17s\tremaining: 46.4s\n",
      "625:\tlearn: 0.0537122\ttotal: 1m 17s\tremaining: 46.2s\n",
      "626:\tlearn: 0.0537322\ttotal: 1m 17s\tremaining: 46.1s\n",
      "627:\tlearn: 0.0536589\ttotal: 1m 17s\tremaining: 46s\n",
      "628:\tlearn: 0.0535988\ttotal: 1m 17s\tremaining: 45.9s\n",
      "629:\tlearn: 0.0536122\ttotal: 1m 17s\tremaining: 45.7s\n",
      "630:\tlearn: 0.0535588\ttotal: 1m 17s\tremaining: 45.6s\n",
      "631:\tlearn: 0.0535455\ttotal: 1m 18s\tremaining: 45.5s\n",
      "632:\tlearn: 0.0534721\ttotal: 1m 18s\tremaining: 45.4s\n",
      "633:\tlearn: 0.0534521\ttotal: 1m 18s\tremaining: 45.2s\n",
      "634:\tlearn: 0.0534187\ttotal: 1m 18s\tremaining: 45.1s\n",
      "635:\tlearn: 0.0533987\ttotal: 1m 18s\tremaining: 45s\n",
      "636:\tlearn: 0.0533587\ttotal: 1m 18s\tremaining: 44.9s\n",
      "637:\tlearn: 0.0533387\ttotal: 1m 18s\tremaining: 44.7s\n",
      "638:\tlearn: 0.0532853\ttotal: 1m 18s\tremaining: 44.6s\n",
      "639:\tlearn: 0.0532386\ttotal: 1m 19s\tremaining: 44.5s\n",
      "640:\tlearn: 0.0532319\ttotal: 1m 19s\tremaining: 44.4s\n",
      "641:\tlearn: 0.0532119\ttotal: 1m 19s\tremaining: 44.2s\n",
      "642:\tlearn: 0.0531852\ttotal: 1m 19s\tremaining: 44.1s\n",
      "643:\tlearn: 0.0531519\ttotal: 1m 19s\tremaining: 44s\n",
      "644:\tlearn: 0.0530785\ttotal: 1m 19s\tremaining: 43.9s\n",
      "645:\tlearn: 0.0530985\ttotal: 1m 19s\tremaining: 43.7s\n",
      "646:\tlearn: 0.0530251\ttotal: 1m 19s\tremaining: 43.6s\n",
      "647:\tlearn: 0.0529785\ttotal: 1m 20s\tremaining: 43.5s\n",
      "648:\tlearn: 0.0529985\ttotal: 1m 20s\tremaining: 43.4s\n",
      "649:\tlearn: 0.0529451\ttotal: 1m 20s\tremaining: 43.2s\n",
      "650:\tlearn: 0.0529117\ttotal: 1m 20s\tremaining: 43.1s\n",
      "651:\tlearn: 0.0528784\ttotal: 1m 20s\tremaining: 43s\n",
      "652:\tlearn: 0.0527917\ttotal: 1m 20s\tremaining: 42.9s\n",
      "653:\tlearn: 0.0527717\ttotal: 1m 20s\tremaining: 42.7s\n",
      "654:\tlearn: 0.0527250\ttotal: 1m 20s\tremaining: 42.6s\n",
      "655:\tlearn: 0.0527183\ttotal: 1m 21s\tremaining: 42.5s\n",
      "656:\tlearn: 0.0526249\ttotal: 1m 21s\tremaining: 42.4s\n",
      "657:\tlearn: 0.0525982\ttotal: 1m 21s\tremaining: 42.2s\n",
      "658:\tlearn: 0.0526583\ttotal: 1m 21s\tremaining: 42.1s\n",
      "659:\tlearn: 0.0526249\ttotal: 1m 21s\tremaining: 42s\n",
      "660:\tlearn: 0.0525382\ttotal: 1m 21s\tremaining: 41.9s\n",
      "661:\tlearn: 0.0525115\ttotal: 1m 21s\tremaining: 41.7s\n",
      "662:\tlearn: 0.0524848\ttotal: 1m 21s\tremaining: 41.6s\n",
      "663:\tlearn: 0.0524715\ttotal: 1m 21s\tremaining: 41.5s\n",
      "664:\tlearn: 0.0524648\ttotal: 1m 22s\tremaining: 41.4s\n",
      "665:\tlearn: 0.0523848\ttotal: 1m 22s\tremaining: 41.2s\n",
      "666:\tlearn: 0.0523247\ttotal: 1m 22s\tremaining: 41.1s\n",
      "667:\tlearn: 0.0522714\ttotal: 1m 22s\tremaining: 41s\n",
      "668:\tlearn: 0.0521846\ttotal: 1m 22s\tremaining: 40.9s\n",
      "669:\tlearn: 0.0521379\ttotal: 1m 22s\tremaining: 40.7s\n",
      "670:\tlearn: 0.0521580\ttotal: 1m 22s\tremaining: 40.6s\n",
      "671:\tlearn: 0.0521113\ttotal: 1m 22s\tremaining: 40.5s\n",
      "672:\tlearn: 0.0521046\ttotal: 1m 23s\tremaining: 40.4s\n",
      "673:\tlearn: 0.0520379\ttotal: 1m 23s\tremaining: 40.2s\n",
      "674:\tlearn: 0.0519645\ttotal: 1m 23s\tremaining: 40.1s\n",
      "675:\tlearn: 0.0519178\ttotal: 1m 23s\tremaining: 40s\n",
      "676:\tlearn: 0.0519245\ttotal: 1m 23s\tremaining: 39.9s\n",
      "677:\tlearn: 0.0518711\ttotal: 1m 23s\tremaining: 39.8s\n",
      "678:\tlearn: 0.0518178\ttotal: 1m 23s\tremaining: 39.6s\n",
      "679:\tlearn: 0.0518111\ttotal: 1m 23s\tremaining: 39.5s\n",
      "680:\tlearn: 0.0517911\ttotal: 1m 24s\tremaining: 39.4s\n",
      "681:\tlearn: 0.0517177\ttotal: 1m 24s\tremaining: 39.3s\n",
      "682:\tlearn: 0.0516843\ttotal: 1m 24s\tremaining: 39.1s\n",
      "683:\tlearn: 0.0515910\ttotal: 1m 24s\tremaining: 39s\n",
      "684:\tlearn: 0.0515576\ttotal: 1m 24s\tremaining: 38.9s\n",
      "685:\tlearn: 0.0515042\ttotal: 1m 24s\tremaining: 38.7s\n",
      "686:\tlearn: 0.0514642\ttotal: 1m 24s\tremaining: 38.6s\n",
      "687:\tlearn: 0.0514575\ttotal: 1m 24s\tremaining: 38.5s\n",
      "688:\tlearn: 0.0514242\ttotal: 1m 25s\tremaining: 38.4s\n",
      "689:\tlearn: 0.0513842\ttotal: 1m 25s\tremaining: 38.2s\n",
      "690:\tlearn: 0.0513908\ttotal: 1m 25s\tremaining: 38.1s\n",
      "691:\tlearn: 0.0513708\ttotal: 1m 25s\tremaining: 38s\n",
      "692:\tlearn: 0.0513241\ttotal: 1m 25s\tremaining: 37.9s\n",
      "693:\tlearn: 0.0513308\ttotal: 1m 25s\tremaining: 37.7s\n",
      "694:\tlearn: 0.0513041\ttotal: 1m 25s\tremaining: 37.6s\n",
      "695:\tlearn: 0.0512441\ttotal: 1m 25s\tremaining: 37.5s\n",
      "696:\tlearn: 0.0512174\ttotal: 1m 25s\tremaining: 37.4s\n",
      "697:\tlearn: 0.0511774\ttotal: 1m 26s\tremaining: 37.3s\n",
      "698:\tlearn: 0.0511574\ttotal: 1m 26s\tremaining: 37.1s\n",
      "699:\tlearn: 0.0511373\ttotal: 1m 26s\tremaining: 37s\n",
      "700:\tlearn: 0.0511240\ttotal: 1m 26s\tremaining: 36.9s\n",
      "701:\tlearn: 0.0511040\ttotal: 1m 26s\tremaining: 36.8s\n",
      "702:\tlearn: 0.0510506\ttotal: 1m 26s\tremaining: 36.6s\n",
      "703:\tlearn: 0.0510039\ttotal: 1m 26s\tremaining: 36.5s\n",
      "704:\tlearn: 0.0509506\ttotal: 1m 26s\tremaining: 36.4s\n",
      "705:\tlearn: 0.0509906\ttotal: 1m 27s\tremaining: 36.3s\n",
      "706:\tlearn: 0.0509439\ttotal: 1m 27s\tremaining: 36.1s\n",
      "707:\tlearn: 0.0509372\ttotal: 1m 27s\tremaining: 36s\n",
      "708:\tlearn: 0.0508905\ttotal: 1m 27s\tremaining: 35.9s\n",
      "709:\tlearn: 0.0507838\ttotal: 1m 27s\tremaining: 35.8s\n",
      "710:\tlearn: 0.0507905\ttotal: 1m 27s\tremaining: 35.7s\n",
      "711:\tlearn: 0.0507705\ttotal: 1m 27s\tremaining: 35.5s\n",
      "712:\tlearn: 0.0507905\ttotal: 1m 27s\tremaining: 35.4s\n",
      "713:\tlearn: 0.0507438\ttotal: 1m 28s\tremaining: 35.3s\n",
      "714:\tlearn: 0.0507171\ttotal: 1m 28s\tremaining: 35.2s\n",
      "715:\tlearn: 0.0506837\ttotal: 1m 28s\tremaining: 35s\n",
      "716:\tlearn: 0.0506837\ttotal: 1m 28s\tremaining: 34.9s\n",
      "717:\tlearn: 0.0506704\ttotal: 1m 28s\tremaining: 34.8s\n",
      "718:\tlearn: 0.0506571\ttotal: 1m 28s\tremaining: 34.7s\n",
      "719:\tlearn: 0.0505970\ttotal: 1m 28s\tremaining: 34.5s\n",
      "720:\tlearn: 0.0505437\ttotal: 1m 28s\tremaining: 34.4s\n",
      "721:\tlearn: 0.0505236\ttotal: 1m 29s\tremaining: 34.3s\n",
      "722:\tlearn: 0.0505036\ttotal: 1m 29s\tremaining: 34.2s\n",
      "723:\tlearn: 0.0504970\ttotal: 1m 29s\tremaining: 34s\n",
      "724:\tlearn: 0.0504436\ttotal: 1m 29s\tremaining: 33.9s\n",
      "725:\tlearn: 0.0504236\ttotal: 1m 29s\tremaining: 33.8s\n",
      "726:\tlearn: 0.0503435\ttotal: 1m 29s\tremaining: 33.7s\n",
      "727:\tlearn: 0.0502902\ttotal: 1m 29s\tremaining: 33.5s\n",
      "728:\tlearn: 0.0502768\ttotal: 1m 29s\tremaining: 33.4s\n",
      "729:\tlearn: 0.0502235\ttotal: 1m 30s\tremaining: 33.3s\n",
      "730:\tlearn: 0.0501768\ttotal: 1m 30s\tremaining: 33.2s\n",
      "731:\tlearn: 0.0501634\ttotal: 1m 30s\tremaining: 33s\n",
      "732:\tlearn: 0.0501234\ttotal: 1m 30s\tremaining: 32.9s\n",
      "733:\tlearn: 0.0501034\ttotal: 1m 30s\tremaining: 32.8s\n",
      "734:\tlearn: 0.0500634\ttotal: 1m 30s\tremaining: 32.7s\n",
      "735:\tlearn: 0.0500567\ttotal: 1m 30s\tremaining: 32.5s\n",
      "736:\tlearn: 0.0500367\ttotal: 1m 30s\tremaining: 32.4s\n",
      "737:\tlearn: 0.0500300\ttotal: 1m 30s\tremaining: 32.3s\n",
      "738:\tlearn: 0.0499967\ttotal: 1m 31s\tremaining: 32.2s\n",
      "739:\tlearn: 0.0499767\ttotal: 1m 31s\tremaining: 32s\n",
      "740:\tlearn: 0.0499833\ttotal: 1m 31s\tremaining: 31.9s\n",
      "741:\tlearn: 0.0499833\ttotal: 1m 31s\tremaining: 31.8s\n",
      "742:\tlearn: 0.0499833\ttotal: 1m 31s\tremaining: 31.7s\n",
      "743:\tlearn: 0.0498966\ttotal: 1m 31s\tremaining: 31.6s\n",
      "744:\tlearn: 0.0498966\ttotal: 1m 31s\tremaining: 31.4s\n",
      "745:\tlearn: 0.0498833\ttotal: 1m 31s\tremaining: 31.3s\n",
      "746:\tlearn: 0.0498566\ttotal: 1m 32s\tremaining: 31.2s\n",
      "747:\tlearn: 0.0498432\ttotal: 1m 32s\tremaining: 31.1s\n",
      "748:\tlearn: 0.0497498\ttotal: 1m 32s\tremaining: 30.9s\n",
      "749:\tlearn: 0.0497232\ttotal: 1m 32s\tremaining: 30.8s\n",
      "750:\tlearn: 0.0496831\ttotal: 1m 32s\tremaining: 30.7s\n",
      "751:\tlearn: 0.0496565\ttotal: 1m 32s\tremaining: 30.6s\n",
      "752:\tlearn: 0.0496364\ttotal: 1m 32s\tremaining: 30.4s\n",
      "753:\tlearn: 0.0495697\ttotal: 1m 32s\tremaining: 30.3s\n",
      "754:\tlearn: 0.0495697\ttotal: 1m 33s\tremaining: 30.2s\n",
      "755:\tlearn: 0.0495831\ttotal: 1m 33s\tremaining: 30.1s\n",
      "756:\tlearn: 0.0495230\ttotal: 1m 33s\tremaining: 30s\n",
      "757:\tlearn: 0.0495097\ttotal: 1m 33s\tremaining: 29.8s\n",
      "758:\tlearn: 0.0494630\ttotal: 1m 33s\tremaining: 29.7s\n",
      "759:\tlearn: 0.0494897\ttotal: 1m 33s\tremaining: 29.6s\n",
      "760:\tlearn: 0.0494764\ttotal: 1m 33s\tremaining: 29.5s\n",
      "761:\tlearn: 0.0494363\ttotal: 1m 34s\tremaining: 29.4s\n",
      "762:\tlearn: 0.0494163\ttotal: 1m 34s\tremaining: 29.3s\n",
      "763:\tlearn: 0.0493830\ttotal: 1m 34s\tremaining: 29.1s\n",
      "764:\tlearn: 0.0493630\ttotal: 1m 34s\tremaining: 29s\n",
      "765:\tlearn: 0.0492896\ttotal: 1m 34s\tremaining: 28.9s\n",
      "766:\tlearn: 0.0492495\ttotal: 1m 34s\tremaining: 28.8s\n",
      "767:\tlearn: 0.0492162\ttotal: 1m 34s\tremaining: 28.6s\n",
      "768:\tlearn: 0.0491628\ttotal: 1m 34s\tremaining: 28.5s\n",
      "769:\tlearn: 0.0491628\ttotal: 1m 35s\tremaining: 28.4s\n",
      "770:\tlearn: 0.0491428\ttotal: 1m 35s\tremaining: 28.3s\n",
      "771:\tlearn: 0.0491028\ttotal: 1m 35s\tremaining: 28.1s\n",
      "772:\tlearn: 0.0490761\ttotal: 1m 35s\tremaining: 28s\n",
      "773:\tlearn: 0.0490761\ttotal: 1m 35s\tremaining: 27.9s\n",
      "774:\tlearn: 0.0490628\ttotal: 1m 35s\tremaining: 27.8s\n",
      "775:\tlearn: 0.0490294\ttotal: 1m 35s\tremaining: 27.6s\n",
      "776:\tlearn: 0.0489961\ttotal: 1m 35s\tremaining: 27.5s\n",
      "777:\tlearn: 0.0489093\ttotal: 1m 36s\tremaining: 27.4s\n",
      "778:\tlearn: 0.0488693\ttotal: 1m 36s\tremaining: 27.3s\n",
      "779:\tlearn: 0.0488493\ttotal: 1m 36s\tremaining: 27.2s\n",
      "780:\tlearn: 0.0487893\ttotal: 1m 36s\tremaining: 27s\n",
      "781:\tlearn: 0.0488160\ttotal: 1m 36s\tremaining: 26.9s\n",
      "782:\tlearn: 0.0488426\ttotal: 1m 36s\tremaining: 26.8s\n",
      "783:\tlearn: 0.0488226\ttotal: 1m 36s\tremaining: 26.7s\n",
      "784:\tlearn: 0.0488226\ttotal: 1m 36s\tremaining: 26.5s\n",
      "785:\tlearn: 0.0487759\ttotal: 1m 37s\tremaining: 26.4s\n",
      "786:\tlearn: 0.0487426\ttotal: 1m 37s\tremaining: 26.3s\n",
      "787:\tlearn: 0.0486625\ttotal: 1m 37s\tremaining: 26.2s\n",
      "788:\tlearn: 0.0486358\ttotal: 1m 37s\tremaining: 26s\n",
      "789:\tlearn: 0.0485958\ttotal: 1m 37s\tremaining: 25.9s\n",
      "790:\tlearn: 0.0486559\ttotal: 1m 37s\tremaining: 25.8s\n",
      "791:\tlearn: 0.0486158\ttotal: 1m 37s\tremaining: 25.7s\n",
      "792:\tlearn: 0.0485625\ttotal: 1m 37s\tremaining: 25.6s\n",
      "793:\tlearn: 0.0485091\ttotal: 1m 38s\tremaining: 25.4s\n",
      "794:\tlearn: 0.0484491\ttotal: 1m 38s\tremaining: 25.3s\n",
      "795:\tlearn: 0.0484357\ttotal: 1m 38s\tremaining: 25.2s\n",
      "796:\tlearn: 0.0483557\ttotal: 1m 38s\tremaining: 25.1s\n",
      "797:\tlearn: 0.0483223\ttotal: 1m 38s\tremaining: 24.9s\n",
      "798:\tlearn: 0.0483090\ttotal: 1m 38s\tremaining: 24.8s\n",
      "799:\tlearn: 0.0482690\ttotal: 1m 38s\tremaining: 24.7s\n",
      "800:\tlearn: 0.0482623\ttotal: 1m 38s\tremaining: 24.6s\n",
      "801:\tlearn: 0.0482956\ttotal: 1m 38s\tremaining: 24.4s\n",
      "802:\tlearn: 0.0482756\ttotal: 1m 39s\tremaining: 24.3s\n",
      "803:\tlearn: 0.0482289\ttotal: 1m 39s\tremaining: 24.2s\n",
      "804:\tlearn: 0.0481956\ttotal: 1m 39s\tremaining: 24.1s\n",
      "805:\tlearn: 0.0481689\ttotal: 1m 39s\tremaining: 23.9s\n",
      "806:\tlearn: 0.0481355\ttotal: 1m 39s\tremaining: 23.8s\n",
      "807:\tlearn: 0.0480422\ttotal: 1m 39s\tremaining: 23.7s\n",
      "808:\tlearn: 0.0479955\ttotal: 1m 39s\tremaining: 23.6s\n",
      "809:\tlearn: 0.0479821\ttotal: 1m 40s\tremaining: 23.5s\n",
      "810:\tlearn: 0.0479421\ttotal: 1m 40s\tremaining: 23.3s\n",
      "811:\tlearn: 0.0479221\ttotal: 1m 40s\tremaining: 23.2s\n",
      "812:\tlearn: 0.0479087\ttotal: 1m 40s\tremaining: 23.1s\n",
      "813:\tlearn: 0.0478887\ttotal: 1m 40s\tremaining: 23s\n",
      "814:\tlearn: 0.0478821\ttotal: 1m 40s\tremaining: 22.8s\n",
      "815:\tlearn: 0.0478687\ttotal: 1m 40s\tremaining: 22.7s\n",
      "816:\tlearn: 0.0478287\ttotal: 1m 40s\tremaining: 22.6s\n",
      "817:\tlearn: 0.0478220\ttotal: 1m 41s\tremaining: 22.5s\n",
      "818:\tlearn: 0.0477887\ttotal: 1m 41s\tremaining: 22.3s\n",
      "819:\tlearn: 0.0477820\ttotal: 1m 41s\tremaining: 22.2s\n",
      "820:\tlearn: 0.0477486\ttotal: 1m 41s\tremaining: 22.1s\n",
      "821:\tlearn: 0.0477353\ttotal: 1m 41s\tremaining: 22s\n",
      "822:\tlearn: 0.0476686\ttotal: 1m 41s\tremaining: 21.9s\n",
      "823:\tlearn: 0.0475886\ttotal: 1m 41s\tremaining: 21.7s\n",
      "824:\tlearn: 0.0475819\ttotal: 1m 41s\tremaining: 21.6s\n",
      "825:\tlearn: 0.0475752\ttotal: 1m 42s\tremaining: 21.5s\n",
      "826:\tlearn: 0.0475819\ttotal: 1m 42s\tremaining: 21.4s\n",
      "827:\tlearn: 0.0475419\ttotal: 1m 42s\tremaining: 21.3s\n",
      "828:\tlearn: 0.0475218\ttotal: 1m 42s\tremaining: 21.1s\n",
      "829:\tlearn: 0.0475352\ttotal: 1m 42s\tremaining: 21s\n",
      "830:\tlearn: 0.0474618\ttotal: 1m 42s\tremaining: 20.9s\n",
      "831:\tlearn: 0.0474618\ttotal: 1m 43s\tremaining: 20.8s\n",
      "832:\tlearn: 0.0474285\ttotal: 1m 43s\tremaining: 20.7s\n",
      "833:\tlearn: 0.0474151\ttotal: 1m 43s\tremaining: 20.6s\n",
      "834:\tlearn: 0.0474218\ttotal: 1m 43s\tremaining: 20.4s\n",
      "835:\tlearn: 0.0473818\ttotal: 1m 43s\tremaining: 20.3s\n",
      "836:\tlearn: 0.0473151\ttotal: 1m 43s\tremaining: 20.2s\n",
      "837:\tlearn: 0.0472684\ttotal: 1m 43s\tremaining: 20.1s\n",
      "838:\tlearn: 0.0472684\ttotal: 1m 44s\tremaining: 20s\n",
      "839:\tlearn: 0.0472817\ttotal: 1m 44s\tremaining: 19.8s\n",
      "840:\tlearn: 0.0472217\ttotal: 1m 44s\tremaining: 19.7s\n",
      "841:\tlearn: 0.0471616\ttotal: 1m 44s\tremaining: 19.6s\n",
      "842:\tlearn: 0.0471216\ttotal: 1m 44s\tremaining: 19.5s\n",
      "843:\tlearn: 0.0471216\ttotal: 1m 44s\tremaining: 19.4s\n",
      "844:\tlearn: 0.0471349\ttotal: 1m 44s\tremaining: 19.2s\n",
      "845:\tlearn: 0.0471149\ttotal: 1m 45s\tremaining: 19.1s\n",
      "846:\tlearn: 0.0470682\ttotal: 1m 45s\tremaining: 19s\n",
      "847:\tlearn: 0.0470749\ttotal: 1m 45s\tremaining: 18.9s\n",
      "848:\tlearn: 0.0470015\ttotal: 1m 45s\tremaining: 18.8s\n",
      "849:\tlearn: 0.0469548\ttotal: 1m 45s\tremaining: 18.7s\n",
      "850:\tlearn: 0.0468948\ttotal: 1m 45s\tremaining: 18.5s\n",
      "851:\tlearn: 0.0468881\ttotal: 1m 46s\tremaining: 18.4s\n",
      "852:\tlearn: 0.0468414\ttotal: 1m 46s\tremaining: 18.3s\n",
      "853:\tlearn: 0.0468281\ttotal: 1m 46s\tremaining: 18.2s\n",
      "854:\tlearn: 0.0467414\ttotal: 1m 46s\tremaining: 18.1s\n",
      "855:\tlearn: 0.0467347\ttotal: 1m 46s\tremaining: 17.9s\n",
      "856:\tlearn: 0.0467214\ttotal: 1m 46s\tremaining: 17.8s\n",
      "857:\tlearn: 0.0466613\ttotal: 1m 46s\tremaining: 17.7s\n",
      "858:\tlearn: 0.0466613\ttotal: 1m 47s\tremaining: 17.6s\n",
      "859:\tlearn: 0.0466213\ttotal: 1m 47s\tremaining: 17.5s\n",
      "860:\tlearn: 0.0466013\ttotal: 1m 47s\tremaining: 17.3s\n",
      "861:\tlearn: 0.0466213\ttotal: 1m 47s\tremaining: 17.2s\n",
      "862:\tlearn: 0.0465880\ttotal: 1m 47s\tremaining: 17.1s\n",
      "863:\tlearn: 0.0465880\ttotal: 1m 47s\tremaining: 17s\n",
      "864:\tlearn: 0.0465880\ttotal: 1m 47s\tremaining: 16.8s\n",
      "865:\tlearn: 0.0465012\ttotal: 1m 48s\tremaining: 16.7s\n",
      "866:\tlearn: 0.0464946\ttotal: 1m 48s\tremaining: 16.6s\n",
      "867:\tlearn: 0.0464612\ttotal: 1m 48s\tremaining: 16.5s\n",
      "868:\tlearn: 0.0464345\ttotal: 1m 48s\tremaining: 16.3s\n",
      "869:\tlearn: 0.0463878\ttotal: 1m 48s\tremaining: 16.2s\n",
      "870:\tlearn: 0.0463745\ttotal: 1m 48s\tremaining: 16.1s\n",
      "871:\tlearn: 0.0463745\ttotal: 1m 48s\tremaining: 16s\n",
      "872:\tlearn: 0.0463478\ttotal: 1m 48s\tremaining: 15.8s\n",
      "873:\tlearn: 0.0463411\ttotal: 1m 48s\tremaining: 15.7s\n",
      "874:\tlearn: 0.0463211\ttotal: 1m 49s\tremaining: 15.6s\n",
      "875:\tlearn: 0.0462611\ttotal: 1m 49s\tremaining: 15.5s\n",
      "876:\tlearn: 0.0462477\ttotal: 1m 49s\tremaining: 15.3s\n",
      "877:\tlearn: 0.0461944\ttotal: 1m 49s\tremaining: 15.2s\n",
      "878:\tlearn: 0.0461610\ttotal: 1m 49s\tremaining: 15.1s\n",
      "879:\tlearn: 0.0461544\ttotal: 1m 49s\tremaining: 15s\n",
      "880:\tlearn: 0.0461477\ttotal: 1m 49s\tremaining: 14.8s\n",
      "881:\tlearn: 0.0461277\ttotal: 1m 49s\tremaining: 14.7s\n",
      "882:\tlearn: 0.0460743\ttotal: 1m 50s\tremaining: 14.6s\n",
      "883:\tlearn: 0.0460810\ttotal: 1m 50s\tremaining: 14.5s\n",
      "884:\tlearn: 0.0460076\ttotal: 1m 50s\tremaining: 14.3s\n",
      "885:\tlearn: 0.0459542\ttotal: 1m 50s\tremaining: 14.2s\n",
      "886:\tlearn: 0.0459542\ttotal: 1m 50s\tremaining: 14.1s\n",
      "887:\tlearn: 0.0459075\ttotal: 1m 50s\tremaining: 14s\n",
      "888:\tlearn: 0.0459276\ttotal: 1m 50s\tremaining: 13.8s\n",
      "889:\tlearn: 0.0458942\ttotal: 1m 50s\tremaining: 13.7s\n",
      "890:\tlearn: 0.0458742\ttotal: 1m 51s\tremaining: 13.6s\n",
      "891:\tlearn: 0.0458542\ttotal: 1m 51s\tremaining: 13.5s\n",
      "892:\tlearn: 0.0458608\ttotal: 1m 51s\tremaining: 13.3s\n",
      "893:\tlearn: 0.0458608\ttotal: 1m 51s\tremaining: 13.2s\n",
      "894:\tlearn: 0.0458275\ttotal: 1m 51s\tremaining: 13.1s\n",
      "895:\tlearn: 0.0457875\ttotal: 1m 51s\tremaining: 13s\n",
      "896:\tlearn: 0.0457675\ttotal: 1m 51s\tremaining: 12.8s\n",
      "897:\tlearn: 0.0456941\ttotal: 1m 51s\tremaining: 12.7s\n",
      "898:\tlearn: 0.0456941\ttotal: 1m 51s\tremaining: 12.6s\n",
      "899:\tlearn: 0.0456741\ttotal: 1m 52s\tremaining: 12.5s\n",
      "900:\tlearn: 0.0456007\ttotal: 1m 52s\tremaining: 12.3s\n",
      "901:\tlearn: 0.0456074\ttotal: 1m 52s\tremaining: 12.2s\n",
      "902:\tlearn: 0.0455473\ttotal: 1m 52s\tremaining: 12.1s\n",
      "903:\tlearn: 0.0455073\ttotal: 1m 52s\tremaining: 12s\n",
      "904:\tlearn: 0.0454539\ttotal: 1m 52s\tremaining: 11.8s\n",
      "905:\tlearn: 0.0454673\ttotal: 1m 52s\tremaining: 11.7s\n",
      "906:\tlearn: 0.0454606\ttotal: 1m 52s\tremaining: 11.6s\n",
      "907:\tlearn: 0.0454339\ttotal: 1m 53s\tremaining: 11.5s\n",
      "908:\tlearn: 0.0454473\ttotal: 1m 53s\tremaining: 11.3s\n",
      "909:\tlearn: 0.0454339\ttotal: 1m 53s\tremaining: 11.2s\n",
      "910:\tlearn: 0.0453872\ttotal: 1m 53s\tremaining: 11.1s\n",
      "911:\tlearn: 0.0453539\ttotal: 1m 53s\tremaining: 11s\n",
      "912:\tlearn: 0.0453005\ttotal: 1m 53s\tremaining: 10.8s\n",
      "913:\tlearn: 0.0453072\ttotal: 1m 53s\tremaining: 10.7s\n",
      "914:\tlearn: 0.0452672\ttotal: 1m 53s\tremaining: 10.6s\n",
      "915:\tlearn: 0.0452005\ttotal: 1m 54s\tremaining: 10.5s\n",
      "916:\tlearn: 0.0451804\ttotal: 1m 54s\tremaining: 10.3s\n",
      "917:\tlearn: 0.0451404\ttotal: 1m 54s\tremaining: 10.2s\n",
      "918:\tlearn: 0.0451938\ttotal: 1m 54s\tremaining: 10.1s\n",
      "919:\tlearn: 0.0451538\ttotal: 1m 54s\tremaining: 9.96s\n",
      "920:\tlearn: 0.0451538\ttotal: 1m 54s\tremaining: 9.84s\n",
      "921:\tlearn: 0.0451071\ttotal: 1m 54s\tremaining: 9.71s\n",
      "922:\tlearn: 0.0450470\ttotal: 1m 54s\tremaining: 9.59s\n",
      "923:\tlearn: 0.0450270\ttotal: 1m 55s\tremaining: 9.46s\n",
      "924:\tlearn: 0.0449937\ttotal: 1m 55s\tremaining: 9.34s\n",
      "925:\tlearn: 0.0449536\ttotal: 1m 55s\tremaining: 9.21s\n",
      "926:\tlearn: 0.0449336\ttotal: 1m 55s\tremaining: 9.09s\n",
      "927:\tlearn: 0.0448803\ttotal: 1m 55s\tremaining: 8.96s\n",
      "928:\tlearn: 0.0448803\ttotal: 1m 55s\tremaining: 8.84s\n",
      "929:\tlearn: 0.0448402\ttotal: 1m 55s\tremaining: 8.71s\n",
      "930:\tlearn: 0.0448269\ttotal: 1m 55s\tremaining: 8.59s\n",
      "931:\tlearn: 0.0448069\ttotal: 1m 56s\tremaining: 8.47s\n",
      "932:\tlearn: 0.0448002\ttotal: 1m 56s\tremaining: 8.34s\n",
      "933:\tlearn: 0.0447935\ttotal: 1m 56s\tremaining: 8.22s\n",
      "934:\tlearn: 0.0447135\ttotal: 1m 56s\tremaining: 8.09s\n",
      "935:\tlearn: 0.0447135\ttotal: 1m 56s\tremaining: 7.97s\n",
      "936:\tlearn: 0.0447135\ttotal: 1m 56s\tremaining: 7.85s\n",
      "937:\tlearn: 0.0447202\ttotal: 1m 56s\tremaining: 7.72s\n",
      "938:\tlearn: 0.0447202\ttotal: 1m 56s\tremaining: 7.6s\n",
      "939:\tlearn: 0.0446601\ttotal: 1m 57s\tremaining: 7.47s\n",
      "940:\tlearn: 0.0446201\ttotal: 1m 57s\tremaining: 7.35s\n",
      "941:\tlearn: 0.0446001\ttotal: 1m 57s\tremaining: 7.23s\n",
      "942:\tlearn: 0.0446001\ttotal: 1m 57s\tremaining: 7.1s\n",
      "943:\tlearn: 0.0445534\ttotal: 1m 57s\tremaining: 6.98s\n",
      "944:\tlearn: 0.0445534\ttotal: 1m 57s\tremaining: 6.86s\n",
      "945:\tlearn: 0.0445067\ttotal: 1m 58s\tremaining: 6.74s\n",
      "946:\tlearn: 0.0445267\ttotal: 1m 58s\tremaining: 6.61s\n",
      "947:\tlearn: 0.0445200\ttotal: 1m 58s\tremaining: 6.49s\n",
      "948:\tlearn: 0.0444934\ttotal: 1m 58s\tremaining: 6.36s\n",
      "949:\tlearn: 0.0444333\ttotal: 1m 58s\tremaining: 6.24s\n",
      "950:\tlearn: 0.0443866\ttotal: 1m 58s\tremaining: 6.11s\n",
      "951:\tlearn: 0.0443599\ttotal: 1m 58s\tremaining: 5.99s\n",
      "952:\tlearn: 0.0443266\ttotal: 1m 58s\tremaining: 5.86s\n",
      "953:\tlearn: 0.0443133\ttotal: 1m 58s\tremaining: 5.74s\n",
      "954:\tlearn: 0.0443199\ttotal: 1m 59s\tremaining: 5.61s\n",
      "955:\tlearn: 0.0442732\ttotal: 1m 59s\tremaining: 5.49s\n",
      "956:\tlearn: 0.0442732\ttotal: 1m 59s\tremaining: 5.37s\n",
      "957:\tlearn: 0.0442799\ttotal: 1m 59s\tremaining: 5.24s\n",
      "958:\tlearn: 0.0442465\ttotal: 1m 59s\tremaining: 5.12s\n",
      "959:\tlearn: 0.0442532\ttotal: 1m 59s\tremaining: 4.99s\n",
      "960:\tlearn: 0.0442532\ttotal: 1m 59s\tremaining: 4.87s\n",
      "961:\tlearn: 0.0442265\ttotal: 2m\tremaining: 4.74s\n",
      "962:\tlearn: 0.0441732\ttotal: 2m\tremaining: 4.62s\n",
      "963:\tlearn: 0.0441465\ttotal: 2m\tremaining: 4.49s\n",
      "964:\tlearn: 0.0440998\ttotal: 2m\tremaining: 4.37s\n",
      "965:\tlearn: 0.0440865\ttotal: 2m\tremaining: 4.24s\n",
      "966:\tlearn: 0.0440464\ttotal: 2m\tremaining: 4.12s\n",
      "967:\tlearn: 0.0440197\ttotal: 2m\tremaining: 4s\n",
      "968:\tlearn: 0.0440131\ttotal: 2m\tremaining: 3.87s\n",
      "969:\tlearn: 0.0440131\ttotal: 2m 1s\tremaining: 3.75s\n",
      "970:\tlearn: 0.0439464\ttotal: 2m 1s\tremaining: 3.62s\n",
      "971:\tlearn: 0.0439063\ttotal: 2m 1s\tremaining: 3.5s\n",
      "972:\tlearn: 0.0438930\ttotal: 2m 1s\tremaining: 3.37s\n",
      "973:\tlearn: 0.0438396\ttotal: 2m 1s\tremaining: 3.25s\n",
      "974:\tlearn: 0.0438330\ttotal: 2m 1s\tremaining: 3.12s\n",
      "975:\tlearn: 0.0437996\ttotal: 2m 1s\tremaining: 3s\n",
      "976:\tlearn: 0.0437996\ttotal: 2m 1s\tremaining: 2.87s\n",
      "977:\tlearn: 0.0437996\ttotal: 2m 2s\tremaining: 2.75s\n",
      "978:\tlearn: 0.0437863\ttotal: 2m 2s\tremaining: 2.62s\n",
      "979:\tlearn: 0.0437529\ttotal: 2m 2s\tremaining: 2.5s\n",
      "980:\tlearn: 0.0436662\ttotal: 2m 2s\tremaining: 2.37s\n",
      "981:\tlearn: 0.0436262\ttotal: 2m 2s\tremaining: 2.25s\n",
      "982:\tlearn: 0.0435928\ttotal: 2m 2s\tremaining: 2.12s\n",
      "983:\tlearn: 0.0436062\ttotal: 2m 2s\tremaining: 2s\n",
      "984:\tlearn: 0.0435528\ttotal: 2m 2s\tremaining: 1.87s\n",
      "985:\tlearn: 0.0435328\ttotal: 2m 3s\tremaining: 1.75s\n",
      "986:\tlearn: 0.0434728\ttotal: 2m 3s\tremaining: 1.62s\n",
      "987:\tlearn: 0.0434127\ttotal: 2m 3s\tremaining: 1.5s\n",
      "988:\tlearn: 0.0433794\ttotal: 2m 3s\tremaining: 1.37s\n",
      "989:\tlearn: 0.0433327\ttotal: 2m 3s\tremaining: 1.25s\n",
      "990:\tlearn: 0.0433193\ttotal: 2m 3s\tremaining: 1.12s\n",
      "991:\tlearn: 0.0432793\ttotal: 2m 3s\tremaining: 999ms\n",
      "992:\tlearn: 0.0432793\ttotal: 2m 4s\tremaining: 874ms\n",
      "993:\tlearn: 0.0432860\ttotal: 2m 4s\tremaining: 749ms\n",
      "994:\tlearn: 0.0432660\ttotal: 2m 4s\tremaining: 625ms\n",
      "995:\tlearn: 0.0432326\ttotal: 2m 4s\tremaining: 500ms\n",
      "996:\tlearn: 0.0431993\ttotal: 2m 4s\tremaining: 375ms\n",
      "997:\tlearn: 0.0431659\ttotal: 2m 4s\tremaining: 250ms\n",
      "998:\tlearn: 0.0432126\ttotal: 2m 4s\tremaining: 125ms\n",
      "999:\tlearn: 0.0431392\ttotal: 2m 4s\tremaining: 0us\n",
      "Learning rate set to 0.024888\n",
      "0:\tlearn: 0.1042959\ttotal: 124ms\tremaining: 2m 3s\n",
      "1:\tlearn: 0.1043559\ttotal: 246ms\tremaining: 2m 2s\n",
      "2:\tlearn: 0.1044760\ttotal: 360ms\tremaining: 1m 59s\n",
      "3:\tlearn: 0.1045227\ttotal: 454ms\tremaining: 1m 53s\n",
      "4:\tlearn: 0.1045361\ttotal: 591ms\tremaining: 1m 57s\n",
      "5:\tlearn: 0.1045361\ttotal: 703ms\tremaining: 1m 56s\n",
      "6:\tlearn: 0.1045227\ttotal: 828ms\tremaining: 1m 57s\n",
      "7:\tlearn: 0.1045361\ttotal: 949ms\tremaining: 1m 57s\n",
      "8:\tlearn: 0.1045361\ttotal: 1.08s\tremaining: 1m 58s\n",
      "9:\tlearn: 0.1045361\ttotal: 1.21s\tremaining: 1m 59s\n",
      "10:\tlearn: 0.1045361\ttotal: 1.32s\tremaining: 1m 59s\n",
      "11:\tlearn: 0.1045361\ttotal: 1.44s\tremaining: 1m 58s\n",
      "12:\tlearn: 0.1045361\ttotal: 1.57s\tremaining: 1m 59s\n",
      "13:\tlearn: 0.1045361\ttotal: 1.68s\tremaining: 1m 58s\n",
      "14:\tlearn: 0.1045361\ttotal: 1.81s\tremaining: 1m 58s\n",
      "15:\tlearn: 0.1045361\ttotal: 1.93s\tremaining: 1m 58s\n",
      "16:\tlearn: 0.1045361\ttotal: 2.05s\tremaining: 1m 58s\n",
      "17:\tlearn: 0.1045361\ttotal: 2.18s\tremaining: 1m 58s\n",
      "18:\tlearn: 0.1045361\ttotal: 2.31s\tremaining: 1m 59s\n",
      "19:\tlearn: 0.1045361\ttotal: 2.44s\tremaining: 1m 59s\n",
      "20:\tlearn: 0.1045361\ttotal: 2.57s\tremaining: 1m 59s\n",
      "21:\tlearn: 0.1045361\ttotal: 2.69s\tremaining: 1m 59s\n",
      "22:\tlearn: 0.1045361\ttotal: 2.82s\tremaining: 1m 59s\n",
      "23:\tlearn: 0.1045361\ttotal: 2.94s\tremaining: 1m 59s\n",
      "24:\tlearn: 0.1045361\ttotal: 3.06s\tremaining: 1m 59s\n",
      "25:\tlearn: 0.1045361\ttotal: 3.18s\tremaining: 1m 59s\n",
      "26:\tlearn: 0.1045361\ttotal: 3.31s\tremaining: 1m 59s\n",
      "27:\tlearn: 0.1045361\ttotal: 3.43s\tremaining: 1m 59s\n",
      "28:\tlearn: 0.1045361\ttotal: 3.56s\tremaining: 1m 59s\n",
      "29:\tlearn: 0.1045361\ttotal: 3.69s\tremaining: 1m 59s\n",
      "30:\tlearn: 0.1045361\ttotal: 3.82s\tremaining: 1m 59s\n",
      "31:\tlearn: 0.1045361\ttotal: 3.95s\tremaining: 1m 59s\n",
      "32:\tlearn: 0.1045361\ttotal: 4.07s\tremaining: 1m 59s\n",
      "33:\tlearn: 0.1045361\ttotal: 4.2s\tremaining: 1m 59s\n",
      "34:\tlearn: 0.1045361\ttotal: 4.33s\tremaining: 1m 59s\n",
      "35:\tlearn: 0.1045361\ttotal: 4.46s\tremaining: 1m 59s\n",
      "36:\tlearn: 0.1045361\ttotal: 4.59s\tremaining: 1m 59s\n",
      "37:\tlearn: 0.1045361\ttotal: 4.71s\tremaining: 1m 59s\n",
      "38:\tlearn: 0.1045361\ttotal: 4.85s\tremaining: 1m 59s\n",
      "39:\tlearn: 0.1045361\ttotal: 4.98s\tremaining: 1m 59s\n",
      "40:\tlearn: 0.1045227\ttotal: 5.11s\tremaining: 1m 59s\n",
      "41:\tlearn: 0.1045227\ttotal: 5.24s\tremaining: 1m 59s\n",
      "42:\tlearn: 0.1045227\ttotal: 5.36s\tremaining: 1m 59s\n",
      "43:\tlearn: 0.1045160\ttotal: 5.48s\tremaining: 1m 59s\n",
      "44:\tlearn: 0.1044960\ttotal: 5.63s\tremaining: 1m 59s\n",
      "45:\tlearn: 0.1044427\ttotal: 5.77s\tremaining: 1m 59s\n",
      "46:\tlearn: 0.1044227\ttotal: 5.91s\tremaining: 1m 59s\n",
      "47:\tlearn: 0.1043493\ttotal: 6.04s\tremaining: 1m 59s\n",
      "48:\tlearn: 0.1043159\ttotal: 6.17s\tremaining: 1m 59s\n",
      "49:\tlearn: 0.1042892\ttotal: 6.37s\tremaining: 2m\n",
      "50:\tlearn: 0.1042759\ttotal: 6.52s\tremaining: 2m 1s\n",
      "51:\tlearn: 0.1043026\ttotal: 6.64s\tremaining: 2m 1s\n",
      "52:\tlearn: 0.1042626\ttotal: 6.79s\tremaining: 2m 1s\n",
      "53:\tlearn: 0.1042559\ttotal: 6.93s\tremaining: 2m 1s\n",
      "54:\tlearn: 0.1042359\ttotal: 7.08s\tremaining: 2m 1s\n",
      "55:\tlearn: 0.1042425\ttotal: 7.23s\tremaining: 2m 1s\n",
      "56:\tlearn: 0.1042492\ttotal: 7.38s\tremaining: 2m 2s\n",
      "57:\tlearn: 0.1042359\ttotal: 7.52s\tremaining: 2m 2s\n",
      "58:\tlearn: 0.1042225\ttotal: 7.65s\tremaining: 2m 1s\n",
      "59:\tlearn: 0.1042025\ttotal: 7.79s\tremaining: 2m 2s\n",
      "60:\tlearn: 0.1041692\ttotal: 7.93s\tremaining: 2m 2s\n",
      "61:\tlearn: 0.1041225\ttotal: 8.05s\tremaining: 2m 1s\n",
      "62:\tlearn: 0.1040758\ttotal: 8.18s\tremaining: 2m 1s\n",
      "63:\tlearn: 0.1040424\ttotal: 8.31s\tremaining: 2m 1s\n",
      "64:\tlearn: 0.1040291\ttotal: 8.44s\tremaining: 2m 1s\n",
      "65:\tlearn: 0.1039624\ttotal: 8.57s\tremaining: 2m 1s\n",
      "66:\tlearn: 0.1038556\ttotal: 8.7s\tremaining: 2m 1s\n",
      "67:\tlearn: 0.1038090\ttotal: 8.83s\tremaining: 2m 1s\n",
      "68:\tlearn: 0.1037623\ttotal: 8.95s\tremaining: 2m\n",
      "69:\tlearn: 0.1037156\ttotal: 9.12s\tremaining: 2m 1s\n",
      "70:\tlearn: 0.1036489\ttotal: 9.27s\tremaining: 2m 1s\n",
      "71:\tlearn: 0.1035755\ttotal: 9.41s\tremaining: 2m 1s\n",
      "72:\tlearn: 0.1035888\ttotal: 9.59s\tremaining: 2m 1s\n",
      "73:\tlearn: 0.1035355\ttotal: 9.74s\tremaining: 2m 1s\n",
      "74:\tlearn: 0.1035288\ttotal: 9.9s\tremaining: 2m 2s\n",
      "75:\tlearn: 0.1034354\ttotal: 10s\tremaining: 2m 2s\n",
      "76:\tlearn: 0.1034087\ttotal: 10.2s\tremaining: 2m 2s\n",
      "77:\tlearn: 0.1033087\ttotal: 10.3s\tremaining: 2m 2s\n",
      "78:\tlearn: 0.1032086\ttotal: 10.5s\tremaining: 2m 1s\n",
      "79:\tlearn: 0.1031285\ttotal: 10.6s\tremaining: 2m 1s\n",
      "80:\tlearn: 0.1030085\ttotal: 10.7s\tremaining: 2m 1s\n",
      "81:\tlearn: 0.1029351\ttotal: 10.8s\tremaining: 2m 1s\n",
      "82:\tlearn: 0.1028150\ttotal: 11s\tremaining: 2m 1s\n",
      "83:\tlearn: 0.1026549\ttotal: 11.1s\tremaining: 2m 1s\n",
      "84:\tlearn: 0.1025282\ttotal: 11.3s\tremaining: 2m 1s\n",
      "85:\tlearn: 0.1024281\ttotal: 11.4s\tremaining: 2m 1s\n",
      "86:\tlearn: 0.1021947\ttotal: 11.6s\tremaining: 2m 1s\n",
      "87:\tlearn: 0.1021013\ttotal: 11.7s\tremaining: 2m 1s\n",
      "88:\tlearn: 0.1021213\ttotal: 11.8s\tremaining: 2m 1s\n",
      "89:\tlearn: 0.1018878\ttotal: 12s\tremaining: 2m 1s\n",
      "90:\tlearn: 0.1017944\ttotal: 12.1s\tremaining: 2m 1s\n",
      "91:\tlearn: 0.1016410\ttotal: 12.3s\tremaining: 2m 1s\n",
      "92:\tlearn: 0.1015876\ttotal: 12.4s\tremaining: 2m\n",
      "93:\tlearn: 0.1014876\ttotal: 12.6s\tremaining: 2m 1s\n",
      "94:\tlearn: 0.1013875\ttotal: 12.7s\tremaining: 2m 1s\n",
      "95:\tlearn: 0.1013541\ttotal: 12.8s\tremaining: 2m\n",
      "96:\tlearn: 0.1012541\ttotal: 13s\tremaining: 2m\n",
      "97:\tlearn: 0.1011474\ttotal: 13.1s\tremaining: 2m\n",
      "98:\tlearn: 0.1010406\ttotal: 13.2s\tremaining: 2m\n",
      "99:\tlearn: 0.1008739\ttotal: 13.4s\tremaining: 2m\n",
      "100:\tlearn: 0.1007071\ttotal: 13.5s\tremaining: 2m\n",
      "101:\tlearn: 0.1006337\ttotal: 13.6s\tremaining: 1m 59s\n",
      "102:\tlearn: 0.1004936\ttotal: 13.8s\tremaining: 1m 59s\n",
      "103:\tlearn: 0.1004803\ttotal: 13.9s\tremaining: 1m 59s\n",
      "104:\tlearn: 0.1004269\ttotal: 14s\tremaining: 1m 59s\n",
      "105:\tlearn: 0.1003402\ttotal: 14.1s\tremaining: 1m 59s\n",
      "106:\tlearn: 0.1002268\ttotal: 14.3s\tremaining: 1m 59s\n",
      "107:\tlearn: 0.1002068\ttotal: 14.4s\tremaining: 1m 59s\n",
      "108:\tlearn: 0.0999666\ttotal: 14.5s\tremaining: 1m 58s\n",
      "109:\tlearn: 0.0998799\ttotal: 14.7s\tremaining: 1m 58s\n",
      "110:\tlearn: 0.0997865\ttotal: 14.8s\tremaining: 1m 58s\n",
      "111:\tlearn: 0.0996264\ttotal: 15s\tremaining: 1m 58s\n",
      "112:\tlearn: 0.0995931\ttotal: 15.1s\tremaining: 1m 58s\n",
      "113:\tlearn: 0.0995264\ttotal: 15.2s\tremaining: 1m 58s\n",
      "114:\tlearn: 0.0994197\ttotal: 15.4s\tremaining: 1m 58s\n",
      "115:\tlearn: 0.0993396\ttotal: 15.5s\tremaining: 1m 58s\n",
      "116:\tlearn: 0.0992395\ttotal: 15.6s\tremaining: 1m 57s\n",
      "117:\tlearn: 0.0991128\ttotal: 15.8s\tremaining: 1m 57s\n",
      "118:\tlearn: 0.0990061\ttotal: 15.9s\tremaining: 1m 57s\n",
      "119:\tlearn: 0.0989794\ttotal: 16s\tremaining: 1m 57s\n",
      "120:\tlearn: 0.0988460\ttotal: 16.1s\tremaining: 1m 57s\n",
      "121:\tlearn: 0.0986859\ttotal: 16.3s\tremaining: 1m 57s\n",
      "122:\tlearn: 0.0985925\ttotal: 16.4s\tremaining: 1m 56s\n",
      "123:\tlearn: 0.0984191\ttotal: 16.5s\tremaining: 1m 56s\n",
      "124:\tlearn: 0.0983857\ttotal: 16.7s\tremaining: 1m 56s\n",
      "125:\tlearn: 0.0982590\ttotal: 16.8s\tremaining: 1m 56s\n",
      "126:\tlearn: 0.0981789\ttotal: 16.9s\tremaining: 1m 56s\n",
      "127:\tlearn: 0.0981589\ttotal: 17.1s\tremaining: 1m 56s\n",
      "128:\tlearn: 0.0980655\ttotal: 17.2s\tremaining: 1m 56s\n",
      "129:\tlearn: 0.0980388\ttotal: 17.4s\tremaining: 1m 56s\n",
      "130:\tlearn: 0.0979654\ttotal: 17.5s\tremaining: 1m 55s\n",
      "131:\tlearn: 0.0977987\ttotal: 17.6s\tremaining: 1m 55s\n",
      "132:\tlearn: 0.0976719\ttotal: 17.8s\tremaining: 1m 55s\n",
      "133:\tlearn: 0.0975185\ttotal: 17.9s\tremaining: 1m 55s\n",
      "134:\tlearn: 0.0973851\ttotal: 18.1s\tremaining: 1m 55s\n",
      "135:\tlearn: 0.0973384\ttotal: 18.2s\tremaining: 1m 55s\n",
      "136:\tlearn: 0.0972383\ttotal: 18.3s\tremaining: 1m 55s\n",
      "137:\tlearn: 0.0971316\ttotal: 18.5s\tremaining: 1m 55s\n",
      "138:\tlearn: 0.0970782\ttotal: 18.6s\tremaining: 1m 55s\n",
      "139:\tlearn: 0.0970249\ttotal: 18.7s\tremaining: 1m 55s\n",
      "140:\tlearn: 0.0969448\ttotal: 18.9s\tremaining: 1m 54s\n",
      "141:\tlearn: 0.0968381\ttotal: 19s\tremaining: 1m 54s\n",
      "142:\tlearn: 0.0967314\ttotal: 19.1s\tremaining: 1m 54s\n",
      "143:\tlearn: 0.0966513\ttotal: 19.3s\tremaining: 1m 54s\n",
      "144:\tlearn: 0.0965913\ttotal: 19.4s\tremaining: 1m 54s\n",
      "145:\tlearn: 0.0965046\ttotal: 19.5s\tremaining: 1m 54s\n",
      "146:\tlearn: 0.0964779\ttotal: 19.7s\tremaining: 1m 54s\n",
      "147:\tlearn: 0.0964112\ttotal: 19.8s\tremaining: 1m 54s\n",
      "148:\tlearn: 0.0963912\ttotal: 19.9s\tremaining: 1m 53s\n",
      "149:\tlearn: 0.0962778\ttotal: 20.1s\tremaining: 1m 53s\n",
      "150:\tlearn: 0.0962177\ttotal: 20.2s\tremaining: 1m 53s\n",
      "151:\tlearn: 0.0961444\ttotal: 20.3s\tremaining: 1m 53s\n",
      "152:\tlearn: 0.0960443\ttotal: 20.4s\tremaining: 1m 53s\n",
      "153:\tlearn: 0.0959642\ttotal: 20.6s\tremaining: 1m 53s\n",
      "154:\tlearn: 0.0958909\ttotal: 20.7s\tremaining: 1m 52s\n",
      "155:\tlearn: 0.0958375\ttotal: 20.8s\tremaining: 1m 52s\n",
      "156:\tlearn: 0.0956907\ttotal: 21s\tremaining: 1m 52s\n",
      "157:\tlearn: 0.0956307\ttotal: 21.1s\tremaining: 1m 52s\n",
      "158:\tlearn: 0.0955974\ttotal: 21.3s\tremaining: 1m 52s\n",
      "159:\tlearn: 0.0955307\ttotal: 21.4s\tremaining: 1m 52s\n",
      "160:\tlearn: 0.0954173\ttotal: 21.5s\tremaining: 1m 52s\n",
      "161:\tlearn: 0.0954039\ttotal: 21.7s\tremaining: 1m 52s\n",
      "162:\tlearn: 0.0953972\ttotal: 21.8s\tremaining: 1m 52s\n",
      "163:\tlearn: 0.0953706\ttotal: 22s\tremaining: 1m 51s\n",
      "164:\tlearn: 0.0952905\ttotal: 22.1s\tremaining: 1m 52s\n",
      "165:\tlearn: 0.0951704\ttotal: 22.3s\tremaining: 1m 51s\n",
      "166:\tlearn: 0.0951438\ttotal: 22.4s\tremaining: 1m 51s\n",
      "167:\tlearn: 0.0950770\ttotal: 22.5s\tremaining: 1m 51s\n",
      "168:\tlearn: 0.0949903\ttotal: 22.6s\tremaining: 1m 51s\n",
      "169:\tlearn: 0.0949970\ttotal: 22.8s\tremaining: 1m 51s\n",
      "170:\tlearn: 0.0948636\ttotal: 22.9s\tremaining: 1m 50s\n",
      "171:\tlearn: 0.0948436\ttotal: 23s\tremaining: 1m 50s\n",
      "172:\tlearn: 0.0947102\ttotal: 23.1s\tremaining: 1m 50s\n",
      "173:\tlearn: 0.0946234\ttotal: 23.3s\tremaining: 1m 50s\n",
      "174:\tlearn: 0.0946101\ttotal: 23.4s\tremaining: 1m 50s\n",
      "175:\tlearn: 0.0945767\ttotal: 23.5s\tremaining: 1m 50s\n",
      "176:\tlearn: 0.0944834\ttotal: 23.6s\tremaining: 1m 49s\n",
      "177:\tlearn: 0.0943833\ttotal: 23.8s\tremaining: 1m 49s\n",
      "178:\tlearn: 0.0943166\ttotal: 23.9s\tremaining: 1m 49s\n",
      "179:\tlearn: 0.0942966\ttotal: 24s\tremaining: 1m 49s\n",
      "180:\tlearn: 0.0942165\ttotal: 24.2s\tremaining: 1m 49s\n",
      "181:\tlearn: 0.0941965\ttotal: 24.3s\tremaining: 1m 49s\n",
      "182:\tlearn: 0.0941231\ttotal: 24.4s\tremaining: 1m 49s\n",
      "183:\tlearn: 0.0940698\ttotal: 24.6s\tremaining: 1m 49s\n",
      "184:\tlearn: 0.0940031\ttotal: 24.7s\tremaining: 1m 48s\n",
      "185:\tlearn: 0.0939831\ttotal: 24.8s\tremaining: 1m 48s\n",
      "186:\tlearn: 0.0938763\ttotal: 25s\tremaining: 1m 48s\n",
      "187:\tlearn: 0.0938363\ttotal: 25.1s\tremaining: 1m 48s\n",
      "188:\tlearn: 0.0936962\ttotal: 25.2s\tremaining: 1m 48s\n",
      "189:\tlearn: 0.0936429\ttotal: 25.4s\tremaining: 1m 48s\n",
      "190:\tlearn: 0.0935361\ttotal: 25.5s\tremaining: 1m 48s\n",
      "191:\tlearn: 0.0934828\ttotal: 25.6s\tremaining: 1m 47s\n",
      "192:\tlearn: 0.0933960\ttotal: 25.8s\tremaining: 1m 47s\n",
      "193:\tlearn: 0.0933227\ttotal: 25.9s\tremaining: 1m 47s\n",
      "194:\tlearn: 0.0932693\ttotal: 26s\tremaining: 1m 47s\n",
      "195:\tlearn: 0.0931492\ttotal: 26.1s\tremaining: 1m 47s\n",
      "196:\tlearn: 0.0931225\ttotal: 26.2s\tremaining: 1m 46s\n",
      "197:\tlearn: 0.0930758\ttotal: 26.4s\tremaining: 1m 46s\n",
      "198:\tlearn: 0.0929825\ttotal: 26.5s\tremaining: 1m 46s\n",
      "199:\tlearn: 0.0928957\ttotal: 26.6s\tremaining: 1m 46s\n",
      "200:\tlearn: 0.0928357\ttotal: 26.7s\tremaining: 1m 46s\n",
      "201:\tlearn: 0.0927823\ttotal: 26.8s\tremaining: 1m 46s\n",
      "202:\tlearn: 0.0926889\ttotal: 27s\tremaining: 1m 45s\n",
      "203:\tlearn: 0.0926022\ttotal: 27.1s\tremaining: 1m 45s\n",
      "204:\tlearn: 0.0924688\ttotal: 27.2s\tremaining: 1m 45s\n",
      "205:\tlearn: 0.0923888\ttotal: 27.3s\tremaining: 1m 45s\n",
      "206:\tlearn: 0.0923554\ttotal: 27.5s\tremaining: 1m 45s\n",
      "207:\tlearn: 0.0923020\ttotal: 27.6s\tremaining: 1m 45s\n",
      "208:\tlearn: 0.0922954\ttotal: 27.7s\tremaining: 1m 44s\n",
      "209:\tlearn: 0.0921286\ttotal: 27.8s\tremaining: 1m 44s\n",
      "210:\tlearn: 0.0920819\ttotal: 28s\tremaining: 1m 44s\n",
      "211:\tlearn: 0.0920619\ttotal: 28.1s\tremaining: 1m 44s\n",
      "212:\tlearn: 0.0919885\ttotal: 28.2s\tremaining: 1m 44s\n",
      "213:\tlearn: 0.0918818\ttotal: 28.3s\tremaining: 1m 44s\n",
      "214:\tlearn: 0.0917551\ttotal: 28.4s\tremaining: 1m 43s\n",
      "215:\tlearn: 0.0917417\ttotal: 28.6s\tremaining: 1m 43s\n",
      "216:\tlearn: 0.0916216\ttotal: 28.7s\tremaining: 1m 43s\n",
      "217:\tlearn: 0.0916016\ttotal: 28.8s\tremaining: 1m 43s\n",
      "218:\tlearn: 0.0915349\ttotal: 28.9s\tremaining: 1m 43s\n",
      "219:\tlearn: 0.0915283\ttotal: 29s\tremaining: 1m 42s\n",
      "220:\tlearn: 0.0914682\ttotal: 29.2s\tremaining: 1m 42s\n",
      "221:\tlearn: 0.0914882\ttotal: 29.3s\tremaining: 1m 42s\n",
      "222:\tlearn: 0.0914082\ttotal: 29.4s\tremaining: 1m 42s\n",
      "223:\tlearn: 0.0913682\ttotal: 29.5s\tremaining: 1m 42s\n",
      "224:\tlearn: 0.0912481\ttotal: 29.6s\tremaining: 1m 42s\n",
      "225:\tlearn: 0.0912014\ttotal: 29.8s\tremaining: 1m 41s\n",
      "226:\tlearn: 0.0911480\ttotal: 29.9s\tremaining: 1m 41s\n",
      "227:\tlearn: 0.0910813\ttotal: 30s\tremaining: 1m 41s\n",
      "228:\tlearn: 0.0910346\ttotal: 30.1s\tremaining: 1m 41s\n",
      "229:\tlearn: 0.0909079\ttotal: 30.3s\tremaining: 1m 41s\n",
      "230:\tlearn: 0.0909012\ttotal: 30.4s\tremaining: 1m 41s\n",
      "231:\tlearn: 0.0908345\ttotal: 30.5s\tremaining: 1m 41s\n",
      "232:\tlearn: 0.0908212\ttotal: 30.7s\tremaining: 1m 40s\n",
      "233:\tlearn: 0.0907278\ttotal: 30.8s\tremaining: 1m 40s\n",
      "234:\tlearn: 0.0906677\ttotal: 30.9s\tremaining: 1m 40s\n",
      "235:\tlearn: 0.0905743\ttotal: 31s\tremaining: 1m 40s\n",
      "236:\tlearn: 0.0905076\ttotal: 31.1s\tremaining: 1m 40s\n",
      "237:\tlearn: 0.0904209\ttotal: 31.3s\tremaining: 1m 40s\n",
      "238:\tlearn: 0.0903142\ttotal: 31.4s\tremaining: 1m 39s\n",
      "239:\tlearn: 0.0902742\ttotal: 31.5s\tremaining: 1m 39s\n",
      "240:\tlearn: 0.0902408\ttotal: 31.7s\tremaining: 1m 39s\n",
      "241:\tlearn: 0.0901141\ttotal: 31.8s\tremaining: 1m 39s\n",
      "242:\tlearn: 0.0900407\ttotal: 31.9s\tremaining: 1m 39s\n",
      "243:\tlearn: 0.0900407\ttotal: 32s\tremaining: 1m 39s\n",
      "244:\tlearn: 0.0900073\ttotal: 32.1s\tremaining: 1m 39s\n",
      "245:\tlearn: 0.0899073\ttotal: 32.3s\tremaining: 1m 38s\n",
      "246:\tlearn: 0.0899139\ttotal: 32.4s\tremaining: 1m 38s\n",
      "247:\tlearn: 0.0898739\ttotal: 32.5s\tremaining: 1m 38s\n",
      "248:\tlearn: 0.0897805\ttotal: 32.6s\tremaining: 1m 38s\n",
      "249:\tlearn: 0.0897405\ttotal: 32.7s\tremaining: 1m 38s\n",
      "250:\tlearn: 0.0896938\ttotal: 32.9s\tremaining: 1m 38s\n",
      "251:\tlearn: 0.0896538\ttotal: 33s\tremaining: 1m 37s\n",
      "252:\tlearn: 0.0895938\ttotal: 33.1s\tremaining: 1m 37s\n",
      "253:\tlearn: 0.0895604\ttotal: 33.2s\tremaining: 1m 37s\n",
      "254:\tlearn: 0.0895337\ttotal: 33.3s\tremaining: 1m 37s\n",
      "255:\tlearn: 0.0894870\ttotal: 33.5s\tremaining: 1m 37s\n",
      "256:\tlearn: 0.0894136\ttotal: 33.6s\tremaining: 1m 37s\n",
      "257:\tlearn: 0.0893870\ttotal: 33.7s\tremaining: 1m 36s\n",
      "258:\tlearn: 0.0893736\ttotal: 33.8s\tremaining: 1m 36s\n",
      "259:\tlearn: 0.0893603\ttotal: 34s\tremaining: 1m 36s\n",
      "260:\tlearn: 0.0893269\ttotal: 34.1s\tremaining: 1m 36s\n",
      "261:\tlearn: 0.0893069\ttotal: 34.2s\tremaining: 1m 36s\n",
      "262:\tlearn: 0.0893002\ttotal: 34.3s\tremaining: 1m 36s\n",
      "263:\tlearn: 0.0892469\ttotal: 34.4s\tremaining: 1m 35s\n",
      "264:\tlearn: 0.0891468\ttotal: 34.6s\tremaining: 1m 35s\n",
      "265:\tlearn: 0.0891868\ttotal: 34.7s\tremaining: 1m 35s\n",
      "266:\tlearn: 0.0891068\ttotal: 34.8s\tremaining: 1m 35s\n",
      "267:\tlearn: 0.0890734\ttotal: 34.9s\tremaining: 1m 35s\n",
      "268:\tlearn: 0.0890801\ttotal: 35.1s\tremaining: 1m 35s\n",
      "269:\tlearn: 0.0889600\ttotal: 35.2s\tremaining: 1m 35s\n",
      "270:\tlearn: 0.0890001\ttotal: 35.3s\tremaining: 1m 34s\n",
      "271:\tlearn: 0.0889334\ttotal: 35.4s\tremaining: 1m 34s\n",
      "272:\tlearn: 0.0888800\ttotal: 35.6s\tremaining: 1m 34s\n",
      "273:\tlearn: 0.0888333\ttotal: 35.7s\tremaining: 1m 34s\n",
      "274:\tlearn: 0.0887332\ttotal: 35.8s\tremaining: 1m 34s\n",
      "275:\tlearn: 0.0887132\ttotal: 35.9s\tremaining: 1m 34s\n",
      "276:\tlearn: 0.0886999\ttotal: 36s\tremaining: 1m 34s\n",
      "277:\tlearn: 0.0885998\ttotal: 36.2s\tremaining: 1m 33s\n",
      "278:\tlearn: 0.0885264\ttotal: 36.3s\tremaining: 1m 33s\n",
      "279:\tlearn: 0.0884397\ttotal: 36.4s\tremaining: 1m 33s\n",
      "280:\tlearn: 0.0883997\ttotal: 36.6s\tremaining: 1m 33s\n",
      "281:\tlearn: 0.0883730\ttotal: 36.7s\tremaining: 1m 33s\n",
      "282:\tlearn: 0.0883063\ttotal: 36.8s\tremaining: 1m 33s\n",
      "283:\tlearn: 0.0882396\ttotal: 37s\tremaining: 1m 33s\n",
      "284:\tlearn: 0.0882263\ttotal: 37.1s\tremaining: 1m 33s\n",
      "285:\tlearn: 0.0881729\ttotal: 37.2s\tremaining: 1m 32s\n",
      "286:\tlearn: 0.0881596\ttotal: 37.3s\tremaining: 1m 32s\n",
      "287:\tlearn: 0.0880795\ttotal: 37.5s\tremaining: 1m 32s\n",
      "288:\tlearn: 0.0880328\ttotal: 37.6s\tremaining: 1m 32s\n",
      "289:\tlearn: 0.0880261\ttotal: 37.7s\tremaining: 1m 32s\n",
      "290:\tlearn: 0.0879328\ttotal: 37.8s\tremaining: 1m 32s\n",
      "291:\tlearn: 0.0878927\ttotal: 37.9s\tremaining: 1m 32s\n",
      "292:\tlearn: 0.0878794\ttotal: 38.1s\tremaining: 1m 31s\n",
      "293:\tlearn: 0.0878327\ttotal: 38.2s\tremaining: 1m 31s\n",
      "294:\tlearn: 0.0877793\ttotal: 38.3s\tremaining: 1m 31s\n",
      "295:\tlearn: 0.0877326\ttotal: 38.5s\tremaining: 1m 31s\n",
      "296:\tlearn: 0.0876526\ttotal: 38.6s\tremaining: 1m 31s\n",
      "297:\tlearn: 0.0876259\ttotal: 38.7s\tremaining: 1m 31s\n",
      "298:\tlearn: 0.0876059\ttotal: 38.8s\tremaining: 1m 31s\n",
      "299:\tlearn: 0.0875258\ttotal: 38.9s\tremaining: 1m 30s\n",
      "300:\tlearn: 0.0874992\ttotal: 39.1s\tremaining: 1m 30s\n",
      "301:\tlearn: 0.0874124\ttotal: 39.2s\tremaining: 1m 30s\n",
      "302:\tlearn: 0.0873191\ttotal: 39.4s\tremaining: 1m 30s\n",
      "303:\tlearn: 0.0873191\ttotal: 39.5s\tremaining: 1m 30s\n",
      "304:\tlearn: 0.0872590\ttotal: 39.6s\tremaining: 1m 30s\n",
      "305:\tlearn: 0.0872457\ttotal: 39.7s\tremaining: 1m 30s\n",
      "306:\tlearn: 0.0871923\ttotal: 39.9s\tremaining: 1m 29s\n",
      "307:\tlearn: 0.0870656\ttotal: 40s\tremaining: 1m 29s\n",
      "308:\tlearn: 0.0869989\ttotal: 40.1s\tremaining: 1m 29s\n",
      "309:\tlearn: 0.0869322\ttotal: 40.2s\tremaining: 1m 29s\n",
      "310:\tlearn: 0.0869388\ttotal: 40.3s\tremaining: 1m 29s\n",
      "311:\tlearn: 0.0869655\ttotal: 40.5s\tremaining: 1m 29s\n",
      "312:\tlearn: 0.0868921\ttotal: 40.6s\tremaining: 1m 29s\n",
      "313:\tlearn: 0.0868054\ttotal: 40.7s\tremaining: 1m 28s\n",
      "314:\tlearn: 0.0868321\ttotal: 40.8s\tremaining: 1m 28s\n",
      "315:\tlearn: 0.0866920\ttotal: 40.9s\tremaining: 1m 28s\n",
      "316:\tlearn: 0.0866720\ttotal: 41.1s\tremaining: 1m 28s\n",
      "317:\tlearn: 0.0866787\ttotal: 41.2s\tremaining: 1m 28s\n",
      "318:\tlearn: 0.0866787\ttotal: 41.3s\tremaining: 1m 28s\n",
      "319:\tlearn: 0.0866320\ttotal: 41.4s\tremaining: 1m 28s\n",
      "320:\tlearn: 0.0865386\ttotal: 41.6s\tremaining: 1m 27s\n",
      "321:\tlearn: 0.0864986\ttotal: 41.7s\tremaining: 1m 27s\n",
      "322:\tlearn: 0.0865052\ttotal: 41.8s\tremaining: 1m 27s\n",
      "323:\tlearn: 0.0864252\ttotal: 41.9s\tremaining: 1m 27s\n",
      "324:\tlearn: 0.0863985\ttotal: 42s\tremaining: 1m 27s\n",
      "325:\tlearn: 0.0863718\ttotal: 42.2s\tremaining: 1m 27s\n",
      "326:\tlearn: 0.0863251\ttotal: 42.3s\tremaining: 1m 27s\n",
      "327:\tlearn: 0.0863185\ttotal: 42.4s\tremaining: 1m 26s\n",
      "328:\tlearn: 0.0862718\ttotal: 42.5s\tremaining: 1m 26s\n",
      "329:\tlearn: 0.0862317\ttotal: 42.7s\tremaining: 1m 26s\n",
      "330:\tlearn: 0.0862451\ttotal: 42.8s\tremaining: 1m 26s\n",
      "331:\tlearn: 0.0861717\ttotal: 42.9s\tremaining: 1m 26s\n",
      "332:\tlearn: 0.0861183\ttotal: 43s\tremaining: 1m 26s\n",
      "333:\tlearn: 0.0860650\ttotal: 43.2s\tremaining: 1m 26s\n",
      "334:\tlearn: 0.0860049\ttotal: 43.3s\tremaining: 1m 25s\n",
      "335:\tlearn: 0.0859582\ttotal: 43.5s\tremaining: 1m 25s\n",
      "336:\tlearn: 0.0860316\ttotal: 43.6s\tremaining: 1m 25s\n",
      "337:\tlearn: 0.0859182\ttotal: 43.7s\tremaining: 1m 25s\n",
      "338:\tlearn: 0.0858849\ttotal: 43.9s\tremaining: 1m 25s\n",
      "339:\tlearn: 0.0858248\ttotal: 44s\tremaining: 1m 25s\n",
      "340:\tlearn: 0.0857848\ttotal: 44.1s\tremaining: 1m 25s\n",
      "341:\tlearn: 0.0857448\ttotal: 44.3s\tremaining: 1m 25s\n",
      "342:\tlearn: 0.0857181\ttotal: 44.4s\tremaining: 1m 25s\n",
      "343:\tlearn: 0.0856447\ttotal: 44.5s\tremaining: 1m 24s\n",
      "344:\tlearn: 0.0856047\ttotal: 44.6s\tremaining: 1m 24s\n",
      "345:\tlearn: 0.0855914\ttotal: 44.7s\tremaining: 1m 24s\n",
      "346:\tlearn: 0.0855180\ttotal: 44.9s\tremaining: 1m 24s\n",
      "347:\tlearn: 0.0853979\ttotal: 45s\tremaining: 1m 24s\n",
      "348:\tlearn: 0.0853779\ttotal: 45.1s\tremaining: 1m 24s\n",
      "349:\tlearn: 0.0853512\ttotal: 45.2s\tremaining: 1m 24s\n",
      "350:\tlearn: 0.0853579\ttotal: 45.4s\tremaining: 1m 23s\n",
      "351:\tlearn: 0.0853112\ttotal: 45.5s\tremaining: 1m 23s\n",
      "352:\tlearn: 0.0852845\ttotal: 45.6s\tremaining: 1m 23s\n",
      "353:\tlearn: 0.0852645\ttotal: 45.8s\tremaining: 1m 23s\n",
      "354:\tlearn: 0.0852512\ttotal: 45.9s\tremaining: 1m 23s\n",
      "355:\tlearn: 0.0851177\ttotal: 46s\tremaining: 1m 23s\n",
      "356:\tlearn: 0.0850510\ttotal: 46.1s\tremaining: 1m 23s\n",
      "357:\tlearn: 0.0849777\ttotal: 46.2s\tremaining: 1m 22s\n",
      "358:\tlearn: 0.0849777\ttotal: 46.4s\tremaining: 1m 22s\n",
      "359:\tlearn: 0.0849243\ttotal: 46.5s\tremaining: 1m 22s\n",
      "360:\tlearn: 0.0849043\ttotal: 46.6s\tremaining: 1m 22s\n",
      "361:\tlearn: 0.0848509\ttotal: 46.7s\tremaining: 1m 22s\n",
      "362:\tlearn: 0.0847242\ttotal: 46.9s\tremaining: 1m 22s\n",
      "363:\tlearn: 0.0847108\ttotal: 47s\tremaining: 1m 22s\n",
      "364:\tlearn: 0.0847175\ttotal: 47.1s\tremaining: 1m 21s\n",
      "365:\tlearn: 0.0847308\ttotal: 47.2s\tremaining: 1m 21s\n",
      "366:\tlearn: 0.0846508\ttotal: 47.3s\tremaining: 1m 21s\n",
      "367:\tlearn: 0.0846108\ttotal: 47.5s\tremaining: 1m 21s\n",
      "368:\tlearn: 0.0845908\ttotal: 47.6s\tremaining: 1m 21s\n",
      "369:\tlearn: 0.0845441\ttotal: 47.7s\tremaining: 1m 21s\n",
      "370:\tlearn: 0.0845574\ttotal: 47.8s\tremaining: 1m 21s\n",
      "371:\tlearn: 0.0845441\ttotal: 48s\tremaining: 1m 20s\n",
      "372:\tlearn: 0.0844373\ttotal: 48.1s\tremaining: 1m 20s\n",
      "373:\tlearn: 0.0844106\ttotal: 48.2s\tremaining: 1m 20s\n",
      "374:\tlearn: 0.0843840\ttotal: 48.4s\tremaining: 1m 20s\n",
      "375:\tlearn: 0.0843906\ttotal: 48.5s\tremaining: 1m 20s\n",
      "376:\tlearn: 0.0843439\ttotal: 48.6s\tremaining: 1m 20s\n",
      "377:\tlearn: 0.0843306\ttotal: 48.8s\tremaining: 1m 20s\n",
      "378:\tlearn: 0.0842839\ttotal: 48.9s\tremaining: 1m 20s\n",
      "379:\tlearn: 0.0842572\ttotal: 49s\tremaining: 1m 19s\n",
      "380:\tlearn: 0.0841305\ttotal: 49.1s\tremaining: 1m 19s\n",
      "381:\tlearn: 0.0840571\ttotal: 49.2s\tremaining: 1m 19s\n",
      "382:\tlearn: 0.0838970\ttotal: 49.4s\tremaining: 1m 19s\n",
      "383:\tlearn: 0.0838770\ttotal: 49.5s\tremaining: 1m 19s\n",
      "384:\tlearn: 0.0837969\ttotal: 49.6s\tremaining: 1m 19s\n",
      "385:\tlearn: 0.0837436\ttotal: 49.7s\tremaining: 1m 19s\n",
      "386:\tlearn: 0.0836702\ttotal: 49.8s\tremaining: 1m 18s\n",
      "387:\tlearn: 0.0836635\ttotal: 50s\tremaining: 1m 18s\n",
      "388:\tlearn: 0.0836235\ttotal: 50.1s\tremaining: 1m 18s\n",
      "389:\tlearn: 0.0835968\ttotal: 50.2s\tremaining: 1m 18s\n",
      "390:\tlearn: 0.0835635\ttotal: 50.3s\tremaining: 1m 18s\n",
      "391:\tlearn: 0.0834434\ttotal: 50.5s\tremaining: 1m 18s\n",
      "392:\tlearn: 0.0834234\ttotal: 50.6s\tremaining: 1m 18s\n",
      "393:\tlearn: 0.0834434\ttotal: 50.7s\tremaining: 1m 17s\n",
      "394:\tlearn: 0.0833367\ttotal: 50.8s\tremaining: 1m 17s\n",
      "395:\tlearn: 0.0832700\ttotal: 50.9s\tremaining: 1m 17s\n",
      "396:\tlearn: 0.0832366\ttotal: 51.1s\tremaining: 1m 17s\n",
      "397:\tlearn: 0.0832033\ttotal: 51.2s\tremaining: 1m 17s\n",
      "398:\tlearn: 0.0831299\ttotal: 51.3s\tremaining: 1m 17s\n",
      "399:\tlearn: 0.0830765\ttotal: 51.4s\tremaining: 1m 17s\n",
      "400:\tlearn: 0.0829965\ttotal: 51.6s\tremaining: 1m 17s\n",
      "401:\tlearn: 0.0828831\ttotal: 51.7s\tremaining: 1m 16s\n",
      "402:\tlearn: 0.0828097\ttotal: 51.9s\tremaining: 1m 16s\n",
      "403:\tlearn: 0.0827563\ttotal: 52s\tremaining: 1m 16s\n",
      "404:\tlearn: 0.0827496\ttotal: 52.2s\tremaining: 1m 16s\n",
      "405:\tlearn: 0.0826896\ttotal: 52.3s\tremaining: 1m 16s\n",
      "406:\tlearn: 0.0826429\ttotal: 52.5s\tremaining: 1m 16s\n",
      "407:\tlearn: 0.0825762\ttotal: 52.6s\tremaining: 1m 16s\n",
      "408:\tlearn: 0.0824895\ttotal: 52.8s\tremaining: 1m 16s\n",
      "409:\tlearn: 0.0824828\ttotal: 52.9s\tremaining: 1m 16s\n",
      "410:\tlearn: 0.0824495\ttotal: 53.1s\tremaining: 1m 16s\n",
      "411:\tlearn: 0.0824094\ttotal: 53.2s\tremaining: 1m 15s\n",
      "412:\tlearn: 0.0823628\ttotal: 53.4s\tremaining: 1m 15s\n",
      "413:\tlearn: 0.0823027\ttotal: 53.5s\tremaining: 1m 15s\n",
      "414:\tlearn: 0.0822894\ttotal: 53.6s\tremaining: 1m 15s\n",
      "415:\tlearn: 0.0822827\ttotal: 53.8s\tremaining: 1m 15s\n",
      "416:\tlearn: 0.0822493\ttotal: 53.9s\tremaining: 1m 15s\n",
      "417:\tlearn: 0.0822227\ttotal: 54s\tremaining: 1m 15s\n",
      "418:\tlearn: 0.0821960\ttotal: 54.2s\tremaining: 1m 15s\n",
      "419:\tlearn: 0.0821359\ttotal: 54.3s\tremaining: 1m 15s\n",
      "420:\tlearn: 0.0821026\ttotal: 54.5s\tremaining: 1m 14s\n",
      "421:\tlearn: 0.0820626\ttotal: 54.6s\tremaining: 1m 14s\n",
      "422:\tlearn: 0.0819825\ttotal: 54.8s\tremaining: 1m 14s\n",
      "423:\tlearn: 0.0819558\ttotal: 54.9s\tremaining: 1m 14s\n",
      "424:\tlearn: 0.0819158\ttotal: 55.1s\tremaining: 1m 14s\n",
      "425:\tlearn: 0.0818758\ttotal: 55.2s\tremaining: 1m 14s\n",
      "426:\tlearn: 0.0818558\ttotal: 55.3s\tremaining: 1m 14s\n",
      "427:\tlearn: 0.0817957\ttotal: 55.5s\tremaining: 1m 14s\n",
      "428:\tlearn: 0.0817290\ttotal: 55.6s\tremaining: 1m 14s\n",
      "429:\tlearn: 0.0816423\ttotal: 55.8s\tremaining: 1m 13s\n",
      "430:\tlearn: 0.0816557\ttotal: 55.9s\tremaining: 1m 13s\n",
      "431:\tlearn: 0.0816223\ttotal: 56.1s\tremaining: 1m 13s\n",
      "432:\tlearn: 0.0815623\ttotal: 56.3s\tremaining: 1m 13s\n",
      "433:\tlearn: 0.0814022\ttotal: 56.5s\tremaining: 1m 13s\n",
      "434:\tlearn: 0.0813555\ttotal: 56.7s\tremaining: 1m 13s\n",
      "435:\tlearn: 0.0812354\ttotal: 56.8s\tremaining: 1m 13s\n",
      "436:\tlearn: 0.0811220\ttotal: 57s\tremaining: 1m 13s\n",
      "437:\tlearn: 0.0811087\ttotal: 57.2s\tremaining: 1m 13s\n",
      "438:\tlearn: 0.0811153\ttotal: 57.3s\tremaining: 1m 13s\n",
      "439:\tlearn: 0.0811153\ttotal: 57.5s\tremaining: 1m 13s\n",
      "440:\tlearn: 0.0810486\ttotal: 57.6s\tremaining: 1m 13s\n",
      "441:\tlearn: 0.0810086\ttotal: 57.8s\tremaining: 1m 12s\n",
      "442:\tlearn: 0.0809219\ttotal: 57.9s\tremaining: 1m 12s\n",
      "443:\tlearn: 0.0809486\ttotal: 58.1s\tremaining: 1m 12s\n",
      "444:\tlearn: 0.0808685\ttotal: 58.2s\tremaining: 1m 12s\n",
      "445:\tlearn: 0.0808152\ttotal: 58.4s\tremaining: 1m 12s\n",
      "446:\tlearn: 0.0807551\ttotal: 58.5s\tremaining: 1m 12s\n",
      "447:\tlearn: 0.0806617\ttotal: 58.6s\tremaining: 1m 12s\n",
      "448:\tlearn: 0.0805817\ttotal: 58.7s\tremaining: 1m 12s\n",
      "449:\tlearn: 0.0805817\ttotal: 58.9s\tremaining: 1m 11s\n",
      "450:\tlearn: 0.0805483\ttotal: 59s\tremaining: 1m 11s\n",
      "451:\tlearn: 0.0805016\ttotal: 59.1s\tremaining: 1m 11s\n",
      "452:\tlearn: 0.0804750\ttotal: 59.2s\tremaining: 1m 11s\n",
      "453:\tlearn: 0.0804283\ttotal: 59.3s\tremaining: 1m 11s\n",
      "454:\tlearn: 0.0803682\ttotal: 59.5s\tremaining: 1m 11s\n",
      "455:\tlearn: 0.0803415\ttotal: 59.6s\tremaining: 1m 11s\n",
      "456:\tlearn: 0.0803015\ttotal: 59.7s\tremaining: 1m 10s\n",
      "457:\tlearn: 0.0802081\ttotal: 59.8s\tremaining: 1m 10s\n",
      "458:\tlearn: 0.0801414\ttotal: 60s\tremaining: 1m 10s\n",
      "459:\tlearn: 0.0800213\ttotal: 1m\tremaining: 1m 10s\n",
      "460:\tlearn: 0.0799813\ttotal: 1m\tremaining: 1m 10s\n",
      "461:\tlearn: 0.0799280\ttotal: 1m\tremaining: 1m 10s\n",
      "462:\tlearn: 0.0799013\ttotal: 1m\tremaining: 1m 10s\n",
      "463:\tlearn: 0.0799146\ttotal: 1m\tremaining: 1m 9s\n",
      "464:\tlearn: 0.0799146\ttotal: 1m\tremaining: 1m 9s\n",
      "465:\tlearn: 0.0798412\ttotal: 1m\tremaining: 1m 9s\n",
      "466:\tlearn: 0.0798146\ttotal: 1m\tremaining: 1m 9s\n",
      "467:\tlearn: 0.0797478\ttotal: 1m 1s\tremaining: 1m 9s\n",
      "468:\tlearn: 0.0796878\ttotal: 1m 1s\tremaining: 1m 9s\n",
      "469:\tlearn: 0.0796478\ttotal: 1m 1s\tremaining: 1m 9s\n",
      "470:\tlearn: 0.0795811\ttotal: 1m 1s\tremaining: 1m 8s\n",
      "471:\tlearn: 0.0795277\ttotal: 1m 1s\tremaining: 1m 8s\n",
      "472:\tlearn: 0.0795344\ttotal: 1m 1s\tremaining: 1m 8s\n",
      "473:\tlearn: 0.0794877\ttotal: 1m 1s\tremaining: 1m 8s\n",
      "474:\tlearn: 0.0794076\ttotal: 1m 1s\tremaining: 1m 8s\n",
      "475:\tlearn: 0.0793743\ttotal: 1m 2s\tremaining: 1m 8s\n",
      "476:\tlearn: 0.0792409\ttotal: 1m 2s\tremaining: 1m 8s\n",
      "477:\tlearn: 0.0792275\ttotal: 1m 2s\tremaining: 1m 8s\n",
      "478:\tlearn: 0.0791675\ttotal: 1m 2s\tremaining: 1m 7s\n",
      "479:\tlearn: 0.0790875\ttotal: 1m 2s\tremaining: 1m 7s\n",
      "480:\tlearn: 0.0790474\ttotal: 1m 2s\tremaining: 1m 7s\n",
      "481:\tlearn: 0.0790074\ttotal: 1m 2s\tremaining: 1m 7s\n",
      "482:\tlearn: 0.0789274\ttotal: 1m 2s\tremaining: 1m 7s\n",
      "483:\tlearn: 0.0789140\ttotal: 1m 3s\tremaining: 1m 7s\n",
      "484:\tlearn: 0.0788807\ttotal: 1m 3s\tremaining: 1m 7s\n",
      "485:\tlearn: 0.0788606\ttotal: 1m 3s\tremaining: 1m 7s\n",
      "486:\tlearn: 0.0788340\ttotal: 1m 3s\tremaining: 1m 6s\n",
      "487:\tlearn: 0.0786872\ttotal: 1m 3s\tremaining: 1m 6s\n",
      "488:\tlearn: 0.0786672\ttotal: 1m 3s\tremaining: 1m 6s\n",
      "489:\tlearn: 0.0786539\ttotal: 1m 3s\tremaining: 1m 6s\n",
      "490:\tlearn: 0.0786005\ttotal: 1m 3s\tremaining: 1m 6s\n",
      "491:\tlearn: 0.0785004\ttotal: 1m 4s\tremaining: 1m 6s\n",
      "492:\tlearn: 0.0784137\ttotal: 1m 4s\tremaining: 1m 6s\n",
      "493:\tlearn: 0.0783670\ttotal: 1m 4s\tremaining: 1m 5s\n",
      "494:\tlearn: 0.0783470\ttotal: 1m 4s\tremaining: 1m 5s\n",
      "495:\tlearn: 0.0783537\ttotal: 1m 4s\tremaining: 1m 5s\n",
      "496:\tlearn: 0.0782069\ttotal: 1m 4s\tremaining: 1m 5s\n",
      "497:\tlearn: 0.0782003\ttotal: 1m 4s\tremaining: 1m 5s\n",
      "498:\tlearn: 0.0781469\ttotal: 1m 5s\tremaining: 1m 5s\n",
      "499:\tlearn: 0.0780802\ttotal: 1m 5s\tremaining: 1m 5s\n",
      "500:\tlearn: 0.0780735\ttotal: 1m 5s\tremaining: 1m 5s\n",
      "501:\tlearn: 0.0780268\ttotal: 1m 5s\tremaining: 1m 4s\n",
      "502:\tlearn: 0.0779668\ttotal: 1m 5s\tremaining: 1m 4s\n",
      "503:\tlearn: 0.0779334\ttotal: 1m 5s\tremaining: 1m 4s\n",
      "504:\tlearn: 0.0779001\ttotal: 1m 5s\tremaining: 1m 4s\n",
      "505:\tlearn: 0.0778467\ttotal: 1m 6s\tremaining: 1m 4s\n",
      "506:\tlearn: 0.0778067\ttotal: 1m 6s\tremaining: 1m 4s\n",
      "507:\tlearn: 0.0777933\ttotal: 1m 6s\tremaining: 1m 4s\n",
      "508:\tlearn: 0.0777600\ttotal: 1m 6s\tremaining: 1m 4s\n",
      "509:\tlearn: 0.0776799\ttotal: 1m 6s\tremaining: 1m 3s\n",
      "510:\tlearn: 0.0776733\ttotal: 1m 6s\tremaining: 1m 3s\n",
      "511:\tlearn: 0.0776466\ttotal: 1m 6s\tremaining: 1m 3s\n",
      "512:\tlearn: 0.0775532\ttotal: 1m 7s\tremaining: 1m 3s\n",
      "513:\tlearn: 0.0774998\ttotal: 1m 7s\tremaining: 1m 3s\n",
      "514:\tlearn: 0.0774398\ttotal: 1m 7s\tremaining: 1m 3s\n",
      "515:\tlearn: 0.0773597\ttotal: 1m 7s\tremaining: 1m 3s\n",
      "516:\tlearn: 0.0773397\ttotal: 1m 7s\tremaining: 1m 3s\n",
      "517:\tlearn: 0.0773131\ttotal: 1m 7s\tremaining: 1m 3s\n",
      "518:\tlearn: 0.0772730\ttotal: 1m 7s\tremaining: 1m 2s\n",
      "519:\tlearn: 0.0772597\ttotal: 1m 8s\tremaining: 1m 2s\n",
      "520:\tlearn: 0.0772263\ttotal: 1m 8s\tremaining: 1m 2s\n",
      "521:\tlearn: 0.0771530\ttotal: 1m 8s\tremaining: 1m 2s\n",
      "522:\tlearn: 0.0771463\ttotal: 1m 8s\tremaining: 1m 2s\n",
      "523:\tlearn: 0.0770195\ttotal: 1m 8s\tremaining: 1m 2s\n",
      "524:\tlearn: 0.0769328\ttotal: 1m 8s\tremaining: 1m 2s\n",
      "525:\tlearn: 0.0769328\ttotal: 1m 8s\tremaining: 1m 1s\n",
      "526:\tlearn: 0.0768861\ttotal: 1m 8s\tremaining: 1m 1s\n",
      "527:\tlearn: 0.0767794\ttotal: 1m 9s\tremaining: 1m 1s\n",
      "528:\tlearn: 0.0767527\ttotal: 1m 9s\tremaining: 1m 1s\n",
      "529:\tlearn: 0.0767260\ttotal: 1m 9s\tremaining: 1m 1s\n",
      "530:\tlearn: 0.0767394\ttotal: 1m 9s\tremaining: 1m 1s\n",
      "531:\tlearn: 0.0766727\ttotal: 1m 9s\tremaining: 1m 1s\n",
      "532:\tlearn: 0.0766527\ttotal: 1m 9s\tremaining: 1m 1s\n",
      "533:\tlearn: 0.0765993\ttotal: 1m 9s\tremaining: 1m\n",
      "534:\tlearn: 0.0765593\ttotal: 1m 9s\tremaining: 1m\n",
      "535:\tlearn: 0.0765126\ttotal: 1m 10s\tremaining: 1m\n",
      "536:\tlearn: 0.0764659\ttotal: 1m 10s\tremaining: 1m\n",
      "537:\tlearn: 0.0764392\ttotal: 1m 10s\tremaining: 1m\n",
      "538:\tlearn: 0.0763792\ttotal: 1m 10s\tremaining: 1m\n",
      "539:\tlearn: 0.0763058\ttotal: 1m 10s\tremaining: 1m\n",
      "540:\tlearn: 0.0761857\ttotal: 1m 10s\tremaining: 59.9s\n",
      "541:\tlearn: 0.0761590\ttotal: 1m 10s\tremaining: 59.8s\n",
      "542:\tlearn: 0.0761457\ttotal: 1m 10s\tremaining: 59.6s\n",
      "543:\tlearn: 0.0760990\ttotal: 1m 10s\tremaining: 59.5s\n",
      "544:\tlearn: 0.0760323\ttotal: 1m 11s\tremaining: 59.4s\n",
      "545:\tlearn: 0.0759789\ttotal: 1m 11s\tremaining: 59.2s\n",
      "546:\tlearn: 0.0759256\ttotal: 1m 11s\tremaining: 59.1s\n",
      "547:\tlearn: 0.0758722\ttotal: 1m 11s\tremaining: 59s\n",
      "548:\tlearn: 0.0758322\ttotal: 1m 11s\tremaining: 58.8s\n",
      "549:\tlearn: 0.0757655\ttotal: 1m 11s\tremaining: 58.7s\n",
      "550:\tlearn: 0.0757388\ttotal: 1m 11s\tremaining: 58.5s\n",
      "551:\tlearn: 0.0756721\ttotal: 1m 11s\tremaining: 58.4s\n",
      "552:\tlearn: 0.0756587\ttotal: 1m 12s\tremaining: 58.2s\n",
      "553:\tlearn: 0.0756587\ttotal: 1m 12s\tremaining: 58.1s\n",
      "554:\tlearn: 0.0756054\ttotal: 1m 12s\tremaining: 58s\n",
      "555:\tlearn: 0.0755120\ttotal: 1m 12s\tremaining: 57.8s\n",
      "556:\tlearn: 0.0754653\ttotal: 1m 12s\tremaining: 57.7s\n",
      "557:\tlearn: 0.0754453\ttotal: 1m 12s\tremaining: 57.6s\n",
      "558:\tlearn: 0.0753852\ttotal: 1m 12s\tremaining: 57.4s\n",
      "559:\tlearn: 0.0753452\ttotal: 1m 12s\tremaining: 57.3s\n",
      "560:\tlearn: 0.0752918\ttotal: 1m 13s\tremaining: 57.2s\n",
      "561:\tlearn: 0.0753052\ttotal: 1m 13s\tremaining: 57s\n",
      "562:\tlearn: 0.0751918\ttotal: 1m 13s\tremaining: 56.9s\n",
      "563:\tlearn: 0.0751784\ttotal: 1m 13s\tremaining: 56.8s\n",
      "564:\tlearn: 0.0751184\ttotal: 1m 13s\tremaining: 56.6s\n",
      "565:\tlearn: 0.0751251\ttotal: 1m 13s\tremaining: 56.5s\n",
      "566:\tlearn: 0.0751051\ttotal: 1m 13s\tremaining: 56.3s\n",
      "567:\tlearn: 0.0750917\ttotal: 1m 13s\tremaining: 56.2s\n",
      "568:\tlearn: 0.0749917\ttotal: 1m 14s\tremaining: 56.1s\n",
      "569:\tlearn: 0.0749716\ttotal: 1m 14s\tremaining: 56s\n",
      "570:\tlearn: 0.0749183\ttotal: 1m 14s\tremaining: 55.8s\n",
      "571:\tlearn: 0.0748649\ttotal: 1m 14s\tremaining: 55.7s\n",
      "572:\tlearn: 0.0748116\ttotal: 1m 14s\tremaining: 55.6s\n",
      "573:\tlearn: 0.0747248\ttotal: 1m 14s\tremaining: 55.4s\n",
      "574:\tlearn: 0.0746781\ttotal: 1m 14s\tremaining: 55.3s\n",
      "575:\tlearn: 0.0746515\ttotal: 1m 14s\tremaining: 55.2s\n",
      "576:\tlearn: 0.0746048\ttotal: 1m 15s\tremaining: 55s\n",
      "577:\tlearn: 0.0745714\ttotal: 1m 15s\tremaining: 54.9s\n",
      "578:\tlearn: 0.0745114\ttotal: 1m 15s\tremaining: 54.8s\n",
      "579:\tlearn: 0.0744180\ttotal: 1m 15s\tremaining: 54.6s\n",
      "580:\tlearn: 0.0744180\ttotal: 1m 15s\tremaining: 54.5s\n",
      "581:\tlearn: 0.0743846\ttotal: 1m 15s\tremaining: 54.4s\n",
      "582:\tlearn: 0.0743713\ttotal: 1m 15s\tremaining: 54.2s\n",
      "583:\tlearn: 0.0743179\ttotal: 1m 15s\tremaining: 54.1s\n",
      "584:\tlearn: 0.0742979\ttotal: 1m 16s\tremaining: 53.9s\n",
      "585:\tlearn: 0.0743113\ttotal: 1m 16s\tremaining: 53.8s\n",
      "586:\tlearn: 0.0742245\ttotal: 1m 16s\tremaining: 53.7s\n",
      "587:\tlearn: 0.0741912\ttotal: 1m 16s\tremaining: 53.5s\n",
      "588:\tlearn: 0.0741378\ttotal: 1m 16s\tremaining: 53.4s\n",
      "589:\tlearn: 0.0741111\ttotal: 1m 16s\tremaining: 53.3s\n",
      "590:\tlearn: 0.0740578\ttotal: 1m 16s\tremaining: 53.1s\n",
      "591:\tlearn: 0.0739844\ttotal: 1m 16s\tremaining: 53s\n",
      "592:\tlearn: 0.0739710\ttotal: 1m 17s\tremaining: 52.9s\n",
      "593:\tlearn: 0.0739244\ttotal: 1m 17s\tremaining: 52.7s\n",
      "594:\tlearn: 0.0738777\ttotal: 1m 17s\tremaining: 52.6s\n",
      "595:\tlearn: 0.0738243\ttotal: 1m 17s\tremaining: 52.5s\n",
      "596:\tlearn: 0.0737576\ttotal: 1m 17s\tremaining: 52.3s\n",
      "597:\tlearn: 0.0737576\ttotal: 1m 17s\tremaining: 52.2s\n",
      "598:\tlearn: 0.0737176\ttotal: 1m 17s\tremaining: 52.1s\n",
      "599:\tlearn: 0.0736509\ttotal: 1m 17s\tremaining: 51.9s\n",
      "600:\tlearn: 0.0736308\ttotal: 1m 18s\tremaining: 51.8s\n",
      "601:\tlearn: 0.0736242\ttotal: 1m 18s\tremaining: 51.7s\n",
      "602:\tlearn: 0.0735308\ttotal: 1m 18s\tremaining: 51.5s\n",
      "603:\tlearn: 0.0735041\ttotal: 1m 18s\tremaining: 51.4s\n",
      "604:\tlearn: 0.0734374\ttotal: 1m 18s\tremaining: 51.3s\n",
      "605:\tlearn: 0.0733307\ttotal: 1m 18s\tremaining: 51.2s\n",
      "606:\tlearn: 0.0733040\ttotal: 1m 18s\tremaining: 51s\n",
      "607:\tlearn: 0.0732106\ttotal: 1m 18s\tremaining: 50.9s\n",
      "608:\tlearn: 0.0731239\ttotal: 1m 19s\tremaining: 50.8s\n",
      "609:\tlearn: 0.0730839\ttotal: 1m 19s\tremaining: 50.7s\n",
      "610:\tlearn: 0.0730905\ttotal: 1m 19s\tremaining: 50.6s\n",
      "611:\tlearn: 0.0730638\ttotal: 1m 19s\tremaining: 50.4s\n",
      "612:\tlearn: 0.0730171\ttotal: 1m 19s\tremaining: 50.3s\n",
      "613:\tlearn: 0.0730305\ttotal: 1m 19s\tremaining: 50.2s\n",
      "614:\tlearn: 0.0729905\ttotal: 1m 19s\tremaining: 50.1s\n",
      "615:\tlearn: 0.0729438\ttotal: 1m 20s\tremaining: 50s\n",
      "616:\tlearn: 0.0728971\ttotal: 1m 20s\tremaining: 49.8s\n",
      "617:\tlearn: 0.0728104\ttotal: 1m 20s\tremaining: 49.7s\n",
      "618:\tlearn: 0.0727637\ttotal: 1m 20s\tremaining: 49.6s\n",
      "619:\tlearn: 0.0726836\ttotal: 1m 20s\tremaining: 49.4s\n",
      "620:\tlearn: 0.0727036\ttotal: 1m 20s\tremaining: 49.3s\n",
      "621:\tlearn: 0.0726436\ttotal: 1m 20s\tremaining: 49.2s\n",
      "622:\tlearn: 0.0726569\ttotal: 1m 21s\tremaining: 49s\n",
      "623:\tlearn: 0.0726236\ttotal: 1m 21s\tremaining: 48.9s\n",
      "624:\tlearn: 0.0725569\ttotal: 1m 21s\tremaining: 48.8s\n",
      "625:\tlearn: 0.0725769\ttotal: 1m 21s\tremaining: 48.6s\n",
      "626:\tlearn: 0.0724835\ttotal: 1m 21s\tremaining: 48.5s\n",
      "627:\tlearn: 0.0724635\ttotal: 1m 21s\tremaining: 48.4s\n",
      "628:\tlearn: 0.0724501\ttotal: 1m 21s\tremaining: 48.3s\n",
      "629:\tlearn: 0.0724301\ttotal: 1m 22s\tremaining: 48.2s\n",
      "630:\tlearn: 0.0723768\ttotal: 1m 22s\tremaining: 48.1s\n",
      "631:\tlearn: 0.0723434\ttotal: 1m 22s\tremaining: 48s\n",
      "632:\tlearn: 0.0722634\ttotal: 1m 22s\tremaining: 48s\n",
      "633:\tlearn: 0.0722500\ttotal: 1m 23s\tremaining: 47.9s\n",
      "634:\tlearn: 0.0721500\ttotal: 1m 23s\tremaining: 47.8s\n",
      "635:\tlearn: 0.0721166\ttotal: 1m 23s\tremaining: 47.7s\n",
      "636:\tlearn: 0.0720832\ttotal: 1m 23s\tremaining: 47.6s\n",
      "637:\tlearn: 0.0720966\ttotal: 1m 23s\tremaining: 47.5s\n",
      "638:\tlearn: 0.0720566\ttotal: 1m 23s\tremaining: 47.3s\n",
      "639:\tlearn: 0.0719965\ttotal: 1m 23s\tremaining: 47.2s\n",
      "640:\tlearn: 0.0719232\ttotal: 1m 24s\tremaining: 47.1s\n",
      "641:\tlearn: 0.0719298\ttotal: 1m 24s\tremaining: 47s\n",
      "642:\tlearn: 0.0718431\ttotal: 1m 24s\tremaining: 46.9s\n",
      "643:\tlearn: 0.0717831\ttotal: 1m 24s\tremaining: 46.8s\n",
      "644:\tlearn: 0.0716697\ttotal: 1m 24s\tremaining: 46.7s\n",
      "645:\tlearn: 0.0716897\ttotal: 1m 25s\tremaining: 46.6s\n",
      "646:\tlearn: 0.0716230\ttotal: 1m 25s\tremaining: 46.5s\n",
      "647:\tlearn: 0.0715963\ttotal: 1m 25s\tremaining: 46.4s\n",
      "648:\tlearn: 0.0715496\ttotal: 1m 25s\tremaining: 46.3s\n",
      "649:\tlearn: 0.0715096\ttotal: 1m 25s\tremaining: 46.2s\n",
      "650:\tlearn: 0.0714695\ttotal: 1m 26s\tremaining: 46.2s\n",
      "651:\tlearn: 0.0714495\ttotal: 1m 26s\tremaining: 46.1s\n",
      "652:\tlearn: 0.0713695\ttotal: 1m 26s\tremaining: 46.1s\n",
      "653:\tlearn: 0.0713828\ttotal: 1m 26s\tremaining: 46s\n",
      "654:\tlearn: 0.0713095\ttotal: 1m 27s\tremaining: 45.9s\n",
      "655:\tlearn: 0.0713361\ttotal: 1m 27s\tremaining: 45.9s\n",
      "656:\tlearn: 0.0712761\ttotal: 1m 27s\tremaining: 45.8s\n",
      "657:\tlearn: 0.0712628\ttotal: 1m 27s\tremaining: 45.7s\n",
      "658:\tlearn: 0.0712427\ttotal: 1m 28s\tremaining: 45.6s\n",
      "659:\tlearn: 0.0711961\ttotal: 1m 28s\tremaining: 45.6s\n",
      "660:\tlearn: 0.0711894\ttotal: 1m 28s\tremaining: 45.5s\n",
      "661:\tlearn: 0.0711293\ttotal: 1m 28s\tremaining: 45.4s\n",
      "662:\tlearn: 0.0710360\ttotal: 1m 29s\tremaining: 45.3s\n",
      "663:\tlearn: 0.0709359\ttotal: 1m 29s\tremaining: 45.3s\n",
      "664:\tlearn: 0.0708759\ttotal: 1m 29s\tremaining: 45.2s\n",
      "665:\tlearn: 0.0708892\ttotal: 1m 30s\tremaining: 45.2s\n",
      "666:\tlearn: 0.0708425\ttotal: 1m 30s\tremaining: 45.1s\n",
      "667:\tlearn: 0.0708292\ttotal: 1m 30s\tremaining: 45s\n",
      "668:\tlearn: 0.0707891\ttotal: 1m 30s\tremaining: 45s\n",
      "669:\tlearn: 0.0707491\ttotal: 1m 31s\tremaining: 44.9s\n",
      "670:\tlearn: 0.0707358\ttotal: 1m 31s\tremaining: 44.9s\n",
      "671:\tlearn: 0.0707291\ttotal: 1m 31s\tremaining: 44.8s\n",
      "672:\tlearn: 0.0707358\ttotal: 1m 32s\tremaining: 44.8s\n",
      "673:\tlearn: 0.0707358\ttotal: 1m 32s\tremaining: 44.8s\n",
      "674:\tlearn: 0.0706624\ttotal: 1m 32s\tremaining: 44.7s\n",
      "675:\tlearn: 0.0705823\ttotal: 1m 33s\tremaining: 44.6s\n",
      "676:\tlearn: 0.0705623\ttotal: 1m 33s\tremaining: 44.5s\n",
      "677:\tlearn: 0.0705423\ttotal: 1m 33s\tremaining: 44.4s\n",
      "678:\tlearn: 0.0704823\ttotal: 1m 33s\tremaining: 44.4s\n",
      "679:\tlearn: 0.0704156\ttotal: 1m 34s\tremaining: 44.3s\n",
      "680:\tlearn: 0.0703889\ttotal: 1m 34s\tremaining: 44.2s\n",
      "681:\tlearn: 0.0703889\ttotal: 1m 34s\tremaining: 44.1s\n",
      "682:\tlearn: 0.0702822\ttotal: 1m 34s\tremaining: 44s\n",
      "683:\tlearn: 0.0702355\ttotal: 1m 35s\tremaining: 44s\n",
      "684:\tlearn: 0.0702088\ttotal: 1m 35s\tremaining: 43.9s\n",
      "685:\tlearn: 0.0701821\ttotal: 1m 35s\tremaining: 43.7s\n",
      "686:\tlearn: 0.0700887\ttotal: 1m 35s\tremaining: 43.6s\n",
      "687:\tlearn: 0.0700820\ttotal: 1m 35s\tremaining: 43.5s\n",
      "688:\tlearn: 0.0700887\ttotal: 1m 36s\tremaining: 43.4s\n",
      "689:\tlearn: 0.0700220\ttotal: 1m 36s\tremaining: 43.2s\n",
      "690:\tlearn: 0.0699086\ttotal: 1m 36s\tremaining: 43.1s\n",
      "691:\tlearn: 0.0699086\ttotal: 1m 36s\tremaining: 43s\n",
      "692:\tlearn: 0.0698619\ttotal: 1m 36s\tremaining: 42.9s\n",
      "693:\tlearn: 0.0698352\ttotal: 1m 37s\tremaining: 42.8s\n",
      "694:\tlearn: 0.0697619\ttotal: 1m 37s\tremaining: 42.7s\n",
      "695:\tlearn: 0.0697152\ttotal: 1m 37s\tremaining: 42.6s\n",
      "696:\tlearn: 0.0696151\ttotal: 1m 37s\tremaining: 42.5s\n",
      "697:\tlearn: 0.0695617\ttotal: 1m 37s\tremaining: 42.4s\n",
      "698:\tlearn: 0.0694950\ttotal: 1m 38s\tremaining: 42.3s\n",
      "699:\tlearn: 0.0694350\ttotal: 1m 38s\tremaining: 42.2s\n",
      "700:\tlearn: 0.0694217\ttotal: 1m 38s\tremaining: 42s\n",
      "701:\tlearn: 0.0693750\ttotal: 1m 38s\tremaining: 41.9s\n",
      "702:\tlearn: 0.0693616\ttotal: 1m 38s\tremaining: 41.8s\n",
      "703:\tlearn: 0.0693149\ttotal: 1m 39s\tremaining: 41.7s\n",
      "704:\tlearn: 0.0692816\ttotal: 1m 39s\tremaining: 41.5s\n",
      "705:\tlearn: 0.0692215\ttotal: 1m 39s\tremaining: 41.4s\n",
      "706:\tlearn: 0.0692282\ttotal: 1m 39s\tremaining: 41.3s\n",
      "707:\tlearn: 0.0691615\ttotal: 1m 39s\tremaining: 41.2s\n",
      "708:\tlearn: 0.0690748\ttotal: 1m 40s\tremaining: 41.1s\n",
      "709:\tlearn: 0.0690548\ttotal: 1m 40s\tremaining: 40.9s\n",
      "710:\tlearn: 0.0690147\ttotal: 1m 40s\tremaining: 40.8s\n",
      "711:\tlearn: 0.0690081\ttotal: 1m 40s\tremaining: 40.6s\n",
      "712:\tlearn: 0.0690147\ttotal: 1m 40s\tremaining: 40.5s\n",
      "713:\tlearn: 0.0689614\ttotal: 1m 40s\tremaining: 40.4s\n",
      "714:\tlearn: 0.0689013\ttotal: 1m 40s\tremaining: 40.2s\n",
      "715:\tlearn: 0.0688947\ttotal: 1m 41s\tremaining: 40.1s\n",
      "716:\tlearn: 0.0688680\ttotal: 1m 41s\tremaining: 39.9s\n",
      "717:\tlearn: 0.0688280\ttotal: 1m 41s\tremaining: 39.8s\n",
      "718:\tlearn: 0.0688213\ttotal: 1m 41s\tremaining: 39.6s\n",
      "719:\tlearn: 0.0687279\ttotal: 1m 41s\tremaining: 39.5s\n",
      "720:\tlearn: 0.0687279\ttotal: 1m 41s\tremaining: 39.3s\n",
      "721:\tlearn: 0.0686145\ttotal: 1m 41s\tremaining: 39.2s\n",
      "722:\tlearn: 0.0685611\ttotal: 1m 41s\tremaining: 39s\n",
      "723:\tlearn: 0.0685011\ttotal: 1m 42s\tremaining: 38.9s\n",
      "724:\tlearn: 0.0684811\ttotal: 1m 42s\tremaining: 38.8s\n",
      "725:\tlearn: 0.0684344\ttotal: 1m 42s\tremaining: 38.6s\n",
      "726:\tlearn: 0.0684277\ttotal: 1m 42s\tremaining: 38.5s\n",
      "727:\tlearn: 0.0683543\ttotal: 1m 42s\tremaining: 38.4s\n",
      "728:\tlearn: 0.0682610\ttotal: 1m 42s\tremaining: 38.2s\n",
      "729:\tlearn: 0.0682543\ttotal: 1m 42s\tremaining: 38.1s\n",
      "730:\tlearn: 0.0682009\ttotal: 1m 43s\tremaining: 37.9s\n",
      "731:\tlearn: 0.0681075\ttotal: 1m 43s\tremaining: 37.8s\n",
      "732:\tlearn: 0.0681075\ttotal: 1m 43s\tremaining: 37.6s\n",
      "733:\tlearn: 0.0680675\ttotal: 1m 43s\tremaining: 37.5s\n",
      "734:\tlearn: 0.0680075\ttotal: 1m 43s\tremaining: 37.3s\n",
      "735:\tlearn: 0.0679608\ttotal: 1m 43s\tremaining: 37.2s\n",
      "736:\tlearn: 0.0679541\ttotal: 1m 43s\tremaining: 37.1s\n",
      "737:\tlearn: 0.0679208\ttotal: 1m 43s\tremaining: 36.9s\n",
      "738:\tlearn: 0.0678607\ttotal: 1m 44s\tremaining: 36.8s\n",
      "739:\tlearn: 0.0678874\ttotal: 1m 44s\tremaining: 36.6s\n",
      "740:\tlearn: 0.0678274\ttotal: 1m 44s\tremaining: 36.5s\n",
      "741:\tlearn: 0.0677406\ttotal: 1m 44s\tremaining: 36.3s\n",
      "742:\tlearn: 0.0676739\ttotal: 1m 44s\tremaining: 36.2s\n",
      "743:\tlearn: 0.0676539\ttotal: 1m 44s\tremaining: 36s\n",
      "744:\tlearn: 0.0676206\ttotal: 1m 44s\tremaining: 35.9s\n",
      "745:\tlearn: 0.0675739\ttotal: 1m 44s\tremaining: 35.7s\n",
      "746:\tlearn: 0.0675072\ttotal: 1m 45s\tremaining: 35.6s\n",
      "747:\tlearn: 0.0674938\ttotal: 1m 45s\tremaining: 35.5s\n",
      "748:\tlearn: 0.0674338\ttotal: 1m 45s\tremaining: 35.3s\n",
      "749:\tlearn: 0.0673871\ttotal: 1m 45s\tremaining: 35.2s\n",
      "750:\tlearn: 0.0673871\ttotal: 1m 45s\tremaining: 35s\n",
      "751:\tlearn: 0.0674004\ttotal: 1m 45s\tremaining: 34.9s\n",
      "752:\tlearn: 0.0673738\ttotal: 1m 45s\tremaining: 34.7s\n",
      "753:\tlearn: 0.0673004\ttotal: 1m 46s\tremaining: 34.6s\n",
      "754:\tlearn: 0.0673137\ttotal: 1m 46s\tremaining: 34.4s\n",
      "755:\tlearn: 0.0672003\ttotal: 1m 46s\tremaining: 34.3s\n",
      "756:\tlearn: 0.0670802\ttotal: 1m 46s\tremaining: 34.2s\n",
      "757:\tlearn: 0.0670602\ttotal: 1m 46s\tremaining: 34s\n",
      "758:\tlearn: 0.0670269\ttotal: 1m 46s\tremaining: 33.9s\n",
      "759:\tlearn: 0.0669602\ttotal: 1m 46s\tremaining: 33.7s\n",
      "760:\tlearn: 0.0669001\ttotal: 1m 46s\tremaining: 33.6s\n",
      "761:\tlearn: 0.0668735\ttotal: 1m 47s\tremaining: 33.4s\n",
      "762:\tlearn: 0.0668468\ttotal: 1m 47s\tremaining: 33.3s\n",
      "763:\tlearn: 0.0667467\ttotal: 1m 47s\tremaining: 33.1s\n",
      "764:\tlearn: 0.0667000\ttotal: 1m 47s\tremaining: 33s\n",
      "765:\tlearn: 0.0666533\ttotal: 1m 47s\tremaining: 32.9s\n",
      "766:\tlearn: 0.0666667\ttotal: 1m 47s\tremaining: 32.7s\n",
      "767:\tlearn: 0.0666266\ttotal: 1m 47s\tremaining: 32.6s\n",
      "768:\tlearn: 0.0665466\ttotal: 1m 47s\tremaining: 32.4s\n",
      "769:\tlearn: 0.0664866\ttotal: 1m 48s\tremaining: 32.3s\n",
      "770:\tlearn: 0.0664532\ttotal: 1m 48s\tremaining: 32.1s\n",
      "771:\tlearn: 0.0663598\ttotal: 1m 48s\tremaining: 32s\n",
      "772:\tlearn: 0.0663665\ttotal: 1m 48s\tremaining: 31.8s\n",
      "773:\tlearn: 0.0663465\ttotal: 1m 48s\tremaining: 31.7s\n",
      "774:\tlearn: 0.0662931\ttotal: 1m 48s\tremaining: 31.6s\n",
      "775:\tlearn: 0.0662864\ttotal: 1m 48s\tremaining: 31.4s\n",
      "776:\tlearn: 0.0662131\ttotal: 1m 49s\tremaining: 31.3s\n",
      "777:\tlearn: 0.0661597\ttotal: 1m 49s\tremaining: 31.1s\n",
      "778:\tlearn: 0.0661397\ttotal: 1m 49s\tremaining: 31s\n",
      "779:\tlearn: 0.0660663\ttotal: 1m 49s\tremaining: 30.9s\n",
      "780:\tlearn: 0.0660530\ttotal: 1m 49s\tremaining: 30.7s\n",
      "781:\tlearn: 0.0659796\ttotal: 1m 49s\tremaining: 30.6s\n",
      "782:\tlearn: 0.0659729\ttotal: 1m 49s\tremaining: 30.4s\n",
      "783:\tlearn: 0.0659596\ttotal: 1m 49s\tremaining: 30.3s\n",
      "784:\tlearn: 0.0659729\ttotal: 1m 50s\tremaining: 30.1s\n",
      "785:\tlearn: 0.0659396\ttotal: 1m 50s\tremaining: 30s\n",
      "786:\tlearn: 0.0659662\ttotal: 1m 50s\tremaining: 29.9s\n",
      "787:\tlearn: 0.0659396\ttotal: 1m 50s\tremaining: 29.7s\n",
      "788:\tlearn: 0.0658929\ttotal: 1m 50s\tremaining: 29.6s\n",
      "789:\tlearn: 0.0658128\ttotal: 1m 50s\tremaining: 29.4s\n",
      "790:\tlearn: 0.0657928\ttotal: 1m 50s\tremaining: 29.3s\n",
      "791:\tlearn: 0.0658128\ttotal: 1m 50s\tremaining: 29.1s\n",
      "792:\tlearn: 0.0657595\ttotal: 1m 51s\tremaining: 29s\n",
      "793:\tlearn: 0.0656794\ttotal: 1m 51s\tremaining: 28.8s\n",
      "794:\tlearn: 0.0656594\ttotal: 1m 51s\tremaining: 28.7s\n",
      "795:\tlearn: 0.0656461\ttotal: 1m 51s\tremaining: 28.6s\n",
      "796:\tlearn: 0.0656594\ttotal: 1m 51s\tremaining: 28.4s\n",
      "797:\tlearn: 0.0655727\ttotal: 1m 51s\tremaining: 28.3s\n",
      "798:\tlearn: 0.0654926\ttotal: 1m 51s\tremaining: 28.1s\n",
      "799:\tlearn: 0.0655060\ttotal: 1m 51s\tremaining: 28s\n",
      "800:\tlearn: 0.0654593\ttotal: 1m 52s\tremaining: 27.8s\n",
      "801:\tlearn: 0.0654326\ttotal: 1m 52s\tremaining: 27.7s\n",
      "802:\tlearn: 0.0654126\ttotal: 1m 52s\tremaining: 27.6s\n",
      "803:\tlearn: 0.0653726\ttotal: 1m 52s\tremaining: 27.4s\n",
      "804:\tlearn: 0.0653659\ttotal: 1m 52s\tremaining: 27.3s\n",
      "805:\tlearn: 0.0653059\ttotal: 1m 52s\tremaining: 27.1s\n",
      "806:\tlearn: 0.0652258\ttotal: 1m 52s\tremaining: 27s\n",
      "807:\tlearn: 0.0651858\ttotal: 1m 52s\tremaining: 26.8s\n",
      "808:\tlearn: 0.0651658\ttotal: 1m 53s\tremaining: 26.7s\n",
      "809:\tlearn: 0.0651057\ttotal: 1m 53s\tremaining: 26.6s\n",
      "810:\tlearn: 0.0650991\ttotal: 1m 53s\tremaining: 26.4s\n",
      "811:\tlearn: 0.0650524\ttotal: 1m 53s\tremaining: 26.3s\n",
      "812:\tlearn: 0.0649523\ttotal: 1m 53s\tremaining: 26.1s\n",
      "813:\tlearn: 0.0649456\ttotal: 1m 53s\tremaining: 26s\n",
      "814:\tlearn: 0.0649590\ttotal: 1m 53s\tremaining: 25.8s\n",
      "815:\tlearn: 0.0649190\ttotal: 1m 53s\tremaining: 25.7s\n",
      "816:\tlearn: 0.0648989\ttotal: 1m 54s\tremaining: 25.6s\n",
      "817:\tlearn: 0.0648923\ttotal: 1m 54s\tremaining: 25.4s\n",
      "818:\tlearn: 0.0648589\ttotal: 1m 54s\tremaining: 25.3s\n",
      "819:\tlearn: 0.0648055\ttotal: 1m 54s\tremaining: 25.1s\n",
      "820:\tlearn: 0.0647388\ttotal: 1m 54s\tremaining: 25s\n",
      "821:\tlearn: 0.0646521\ttotal: 1m 54s\tremaining: 24.9s\n",
      "822:\tlearn: 0.0646721\ttotal: 1m 54s\tremaining: 24.7s\n",
      "823:\tlearn: 0.0646254\ttotal: 1m 55s\tremaining: 24.6s\n",
      "824:\tlearn: 0.0645387\ttotal: 1m 55s\tremaining: 24.4s\n",
      "825:\tlearn: 0.0644987\ttotal: 1m 55s\tremaining: 24.3s\n",
      "826:\tlearn: 0.0645254\ttotal: 1m 55s\tremaining: 24.1s\n",
      "827:\tlearn: 0.0644320\ttotal: 1m 55s\tremaining: 24s\n",
      "828:\tlearn: 0.0643986\ttotal: 1m 55s\tremaining: 23.9s\n",
      "829:\tlearn: 0.0644520\ttotal: 1m 55s\tremaining: 23.7s\n",
      "830:\tlearn: 0.0643519\ttotal: 1m 55s\tremaining: 23.6s\n",
      "831:\tlearn: 0.0643453\ttotal: 1m 56s\tremaining: 23.4s\n",
      "832:\tlearn: 0.0642652\ttotal: 1m 56s\tremaining: 23.3s\n",
      "833:\tlearn: 0.0642319\ttotal: 1m 56s\tremaining: 23.2s\n",
      "834:\tlearn: 0.0641985\ttotal: 1m 56s\tremaining: 23s\n",
      "835:\tlearn: 0.0642586\ttotal: 1m 56s\tremaining: 22.9s\n",
      "836:\tlearn: 0.0641918\ttotal: 1m 56s\tremaining: 22.7s\n",
      "837:\tlearn: 0.0642052\ttotal: 1m 56s\tremaining: 22.6s\n",
      "838:\tlearn: 0.0642052\ttotal: 1m 56s\tremaining: 22.4s\n",
      "839:\tlearn: 0.0641852\ttotal: 1m 57s\tremaining: 22.3s\n",
      "840:\tlearn: 0.0641251\ttotal: 1m 57s\tremaining: 22.2s\n",
      "841:\tlearn: 0.0641318\ttotal: 1m 57s\tremaining: 22s\n",
      "842:\tlearn: 0.0640918\ttotal: 1m 57s\tremaining: 21.9s\n",
      "843:\tlearn: 0.0640451\ttotal: 1m 57s\tremaining: 21.7s\n",
      "844:\tlearn: 0.0639317\ttotal: 1m 57s\tremaining: 21.6s\n",
      "845:\tlearn: 0.0638850\ttotal: 1m 57s\tremaining: 21.5s\n",
      "846:\tlearn: 0.0638583\ttotal: 1m 58s\tremaining: 21.3s\n",
      "847:\tlearn: 0.0639050\ttotal: 1m 58s\tremaining: 21.2s\n",
      "848:\tlearn: 0.0638850\ttotal: 1m 58s\tremaining: 21s\n",
      "849:\tlearn: 0.0638316\ttotal: 1m 58s\tremaining: 20.9s\n",
      "850:\tlearn: 0.0637716\ttotal: 1m 58s\tremaining: 20.8s\n",
      "851:\tlearn: 0.0637249\ttotal: 1m 58s\tremaining: 20.6s\n",
      "852:\tlearn: 0.0636715\ttotal: 1m 58s\tremaining: 20.5s\n",
      "853:\tlearn: 0.0636182\ttotal: 1m 58s\tremaining: 20.3s\n",
      "854:\tlearn: 0.0636115\ttotal: 1m 59s\tremaining: 20.2s\n",
      "855:\tlearn: 0.0635781\ttotal: 1m 59s\tremaining: 20s\n",
      "856:\tlearn: 0.0635515\ttotal: 1m 59s\tremaining: 19.9s\n",
      "857:\tlearn: 0.0634981\ttotal: 1m 59s\tremaining: 19.8s\n",
      "858:\tlearn: 0.0634581\ttotal: 1m 59s\tremaining: 19.6s\n",
      "859:\tlearn: 0.0634581\ttotal: 1m 59s\tremaining: 19.5s\n",
      "860:\tlearn: 0.0634447\ttotal: 1m 59s\tremaining: 19.3s\n",
      "861:\tlearn: 0.0633847\ttotal: 1m 59s\tremaining: 19.2s\n",
      "862:\tlearn: 0.0633380\ttotal: 2m\tremaining: 19.1s\n",
      "863:\tlearn: 0.0633447\ttotal: 2m\tremaining: 18.9s\n",
      "864:\tlearn: 0.0632646\ttotal: 2m\tremaining: 18.8s\n",
      "865:\tlearn: 0.0632379\ttotal: 2m\tremaining: 18.7s\n",
      "866:\tlearn: 0.0631912\ttotal: 2m\tremaining: 18.5s\n",
      "867:\tlearn: 0.0631112\ttotal: 2m\tremaining: 18.4s\n",
      "868:\tlearn: 0.0631179\ttotal: 2m\tremaining: 18.2s\n",
      "869:\tlearn: 0.0630712\ttotal: 2m 1s\tremaining: 18.1s\n",
      "870:\tlearn: 0.0630178\ttotal: 2m 1s\tremaining: 18s\n",
      "871:\tlearn: 0.0629511\ttotal: 2m 1s\tremaining: 17.8s\n",
      "872:\tlearn: 0.0629311\ttotal: 2m 1s\tremaining: 17.7s\n",
      "873:\tlearn: 0.0629845\ttotal: 2m 1s\tremaining: 17.5s\n",
      "874:\tlearn: 0.0629311\ttotal: 2m 1s\tremaining: 17.4s\n",
      "875:\tlearn: 0.0629044\ttotal: 2m 1s\tremaining: 17.3s\n",
      "876:\tlearn: 0.0628444\ttotal: 2m 2s\tremaining: 17.1s\n",
      "877:\tlearn: 0.0627977\ttotal: 2m 2s\tremaining: 17s\n",
      "878:\tlearn: 0.0627710\ttotal: 2m 2s\tremaining: 16.8s\n",
      "879:\tlearn: 0.0626709\ttotal: 2m 2s\tremaining: 16.7s\n",
      "880:\tlearn: 0.0626176\ttotal: 2m 2s\tremaining: 16.6s\n",
      "881:\tlearn: 0.0625442\ttotal: 2m 2s\tremaining: 16.4s\n",
      "882:\tlearn: 0.0625575\ttotal: 2m 2s\tremaining: 16.3s\n",
      "883:\tlearn: 0.0625042\ttotal: 2m 2s\tremaining: 16.1s\n",
      "884:\tlearn: 0.0625108\ttotal: 2m 3s\tremaining: 16s\n",
      "885:\tlearn: 0.0624975\ttotal: 2m 3s\tremaining: 15.9s\n",
      "886:\tlearn: 0.0624575\ttotal: 2m 3s\tremaining: 15.7s\n",
      "887:\tlearn: 0.0624441\ttotal: 2m 3s\tremaining: 15.6s\n",
      "888:\tlearn: 0.0623841\ttotal: 2m 3s\tremaining: 15.4s\n",
      "889:\tlearn: 0.0623174\ttotal: 2m 3s\tremaining: 15.3s\n",
      "890:\tlearn: 0.0623441\ttotal: 2m 3s\tremaining: 15.2s\n",
      "891:\tlearn: 0.0623174\ttotal: 2m 4s\tremaining: 15s\n",
      "892:\tlearn: 0.0622974\ttotal: 2m 4s\tremaining: 14.9s\n",
      "893:\tlearn: 0.0621773\ttotal: 2m 4s\tremaining: 14.7s\n",
      "894:\tlearn: 0.0621773\ttotal: 2m 4s\tremaining: 14.6s\n",
      "895:\tlearn: 0.0620772\ttotal: 2m 4s\tremaining: 14.5s\n",
      "896:\tlearn: 0.0619905\ttotal: 2m 4s\tremaining: 14.3s\n",
      "897:\tlearn: 0.0619772\ttotal: 2m 4s\tremaining: 14.2s\n",
      "898:\tlearn: 0.0619572\ttotal: 2m 4s\tremaining: 14s\n",
      "899:\tlearn: 0.0619372\ttotal: 2m 5s\tremaining: 13.9s\n",
      "900:\tlearn: 0.0619238\ttotal: 2m 5s\tremaining: 13.8s\n",
      "901:\tlearn: 0.0619305\ttotal: 2m 5s\tremaining: 13.6s\n",
      "902:\tlearn: 0.0618838\ttotal: 2m 5s\tremaining: 13.5s\n",
      "903:\tlearn: 0.0618304\ttotal: 2m 5s\tremaining: 13.3s\n",
      "904:\tlearn: 0.0618171\ttotal: 2m 5s\tremaining: 13.2s\n",
      "905:\tlearn: 0.0617571\ttotal: 2m 5s\tremaining: 13.1s\n",
      "906:\tlearn: 0.0616837\ttotal: 2m 5s\tremaining: 12.9s\n",
      "907:\tlearn: 0.0615769\ttotal: 2m 6s\tremaining: 12.8s\n",
      "908:\tlearn: 0.0615369\ttotal: 2m 6s\tremaining: 12.6s\n",
      "909:\tlearn: 0.0614635\ttotal: 2m 6s\tremaining: 12.5s\n",
      "910:\tlearn: 0.0614635\ttotal: 2m 6s\tremaining: 12.4s\n",
      "911:\tlearn: 0.0614369\ttotal: 2m 6s\tremaining: 12.2s\n",
      "912:\tlearn: 0.0613435\ttotal: 2m 6s\tremaining: 12.1s\n",
      "913:\tlearn: 0.0613435\ttotal: 2m 6s\tremaining: 11.9s\n",
      "914:\tlearn: 0.0613368\ttotal: 2m 7s\tremaining: 11.8s\n",
      "915:\tlearn: 0.0612568\ttotal: 2m 7s\tremaining: 11.7s\n",
      "916:\tlearn: 0.0612234\ttotal: 2m 7s\tremaining: 11.5s\n",
      "917:\tlearn: 0.0611834\ttotal: 2m 7s\tremaining: 11.4s\n",
      "918:\tlearn: 0.0611100\ttotal: 2m 7s\tremaining: 11.2s\n",
      "919:\tlearn: 0.0610900\ttotal: 2m 7s\tremaining: 11.1s\n",
      "920:\tlearn: 0.0610700\ttotal: 2m 7s\tremaining: 11s\n",
      "921:\tlearn: 0.0610366\ttotal: 2m 8s\tremaining: 10.8s\n",
      "922:\tlearn: 0.0610166\ttotal: 2m 8s\tremaining: 10.7s\n",
      "923:\tlearn: 0.0609366\ttotal: 2m 8s\tremaining: 10.6s\n",
      "924:\tlearn: 0.0609165\ttotal: 2m 8s\tremaining: 10.4s\n",
      "925:\tlearn: 0.0608899\ttotal: 2m 8s\tremaining: 10.3s\n",
      "926:\tlearn: 0.0608565\ttotal: 2m 8s\tremaining: 10.1s\n",
      "927:\tlearn: 0.0607498\ttotal: 2m 9s\tremaining: 10s\n",
      "928:\tlearn: 0.0607031\ttotal: 2m 9s\tremaining: 9.87s\n",
      "929:\tlearn: 0.0606497\ttotal: 2m 9s\tremaining: 9.73s\n",
      "930:\tlearn: 0.0606097\ttotal: 2m 9s\tremaining: 9.59s\n",
      "931:\tlearn: 0.0605964\ttotal: 2m 9s\tremaining: 9.46s\n",
      "932:\tlearn: 0.0606230\ttotal: 2m 9s\tremaining: 9.32s\n",
      "933:\tlearn: 0.0606030\ttotal: 2m 9s\tremaining: 9.18s\n",
      "934:\tlearn: 0.0605763\ttotal: 2m 10s\tremaining: 9.04s\n",
      "935:\tlearn: 0.0605497\ttotal: 2m 10s\tremaining: 8.9s\n",
      "936:\tlearn: 0.0605163\ttotal: 2m 10s\tremaining: 8.76s\n",
      "937:\tlearn: 0.0605096\ttotal: 2m 10s\tremaining: 8.62s\n",
      "938:\tlearn: 0.0604763\ttotal: 2m 10s\tremaining: 8.48s\n",
      "939:\tlearn: 0.0604496\ttotal: 2m 10s\tremaining: 8.34s\n",
      "940:\tlearn: 0.0603896\ttotal: 2m 10s\tremaining: 8.2s\n",
      "941:\tlearn: 0.0604363\ttotal: 2m 10s\tremaining: 8.06s\n",
      "942:\tlearn: 0.0603829\ttotal: 2m 11s\tremaining: 7.93s\n",
      "943:\tlearn: 0.0603229\ttotal: 2m 11s\tremaining: 7.79s\n",
      "944:\tlearn: 0.0602428\ttotal: 2m 11s\tremaining: 7.65s\n",
      "945:\tlearn: 0.0601961\ttotal: 2m 11s\tremaining: 7.51s\n",
      "946:\tlearn: 0.0601694\ttotal: 2m 11s\tremaining: 7.37s\n",
      "947:\tlearn: 0.0601294\ttotal: 2m 11s\tremaining: 7.24s\n",
      "948:\tlearn: 0.0601227\ttotal: 2m 12s\tremaining: 7.1s\n",
      "949:\tlearn: 0.0600093\ttotal: 2m 12s\tremaining: 6.96s\n",
      "950:\tlearn: 0.0600227\ttotal: 2m 12s\tremaining: 6.83s\n",
      "951:\tlearn: 0.0600093\ttotal: 2m 12s\tremaining: 6.69s\n",
      "952:\tlearn: 0.0599493\ttotal: 2m 12s\tremaining: 6.55s\n",
      "953:\tlearn: 0.0599159\ttotal: 2m 12s\tremaining: 6.41s\n",
      "954:\tlearn: 0.0598693\ttotal: 2m 13s\tremaining: 6.27s\n",
      "955:\tlearn: 0.0598292\ttotal: 2m 13s\tremaining: 6.14s\n",
      "956:\tlearn: 0.0597292\ttotal: 2m 13s\tremaining: 6s\n",
      "957:\tlearn: 0.0597358\ttotal: 2m 13s\tremaining: 5.86s\n",
      "958:\tlearn: 0.0596958\ttotal: 2m 13s\tremaining: 5.72s\n",
      "959:\tlearn: 0.0596358\ttotal: 2m 14s\tremaining: 5.58s\n",
      "960:\tlearn: 0.0596425\ttotal: 2m 14s\tremaining: 5.45s\n",
      "961:\tlearn: 0.0596224\ttotal: 2m 14s\tremaining: 5.3s\n",
      "962:\tlearn: 0.0595958\ttotal: 2m 14s\tremaining: 5.16s\n",
      "963:\tlearn: 0.0595491\ttotal: 2m 14s\tremaining: 5.02s\n",
      "964:\tlearn: 0.0595157\ttotal: 2m 14s\tremaining: 4.88s\n",
      "965:\tlearn: 0.0594290\ttotal: 2m 14s\tremaining: 4.74s\n",
      "966:\tlearn: 0.0594357\ttotal: 2m 14s\tremaining: 4.6s\n",
      "967:\tlearn: 0.0593690\ttotal: 2m 15s\tremaining: 4.46s\n",
      "968:\tlearn: 0.0593289\ttotal: 2m 15s\tremaining: 4.32s\n",
      "969:\tlearn: 0.0592689\ttotal: 2m 15s\tremaining: 4.18s\n",
      "970:\tlearn: 0.0592022\ttotal: 2m 15s\tremaining: 4.04s\n",
      "971:\tlearn: 0.0591355\ttotal: 2m 15s\tremaining: 3.9s\n",
      "972:\tlearn: 0.0591488\ttotal: 2m 15s\tremaining: 3.77s\n",
      "973:\tlearn: 0.0591155\ttotal: 2m 15s\tremaining: 3.63s\n",
      "974:\tlearn: 0.0590888\ttotal: 2m 15s\tremaining: 3.49s\n",
      "975:\tlearn: 0.0591021\ttotal: 2m 16s\tremaining: 3.35s\n",
      "976:\tlearn: 0.0590488\ttotal: 2m 16s\tremaining: 3.21s\n",
      "977:\tlearn: 0.0590421\ttotal: 2m 16s\tremaining: 3.07s\n",
      "978:\tlearn: 0.0590421\ttotal: 2m 16s\tremaining: 2.93s\n",
      "979:\tlearn: 0.0589687\ttotal: 2m 16s\tremaining: 2.79s\n",
      "980:\tlearn: 0.0589020\ttotal: 2m 16s\tremaining: 2.65s\n",
      "981:\tlearn: 0.0588753\ttotal: 2m 16s\tremaining: 2.51s\n",
      "982:\tlearn: 0.0588620\ttotal: 2m 16s\tremaining: 2.37s\n",
      "983:\tlearn: 0.0588153\ttotal: 2m 17s\tremaining: 2.23s\n",
      "984:\tlearn: 0.0587953\ttotal: 2m 17s\tremaining: 2.09s\n",
      "985:\tlearn: 0.0587686\ttotal: 2m 17s\tremaining: 1.95s\n",
      "986:\tlearn: 0.0587219\ttotal: 2m 17s\tremaining: 1.81s\n",
      "987:\tlearn: 0.0586885\ttotal: 2m 17s\tremaining: 1.67s\n",
      "988:\tlearn: 0.0586218\ttotal: 2m 17s\tremaining: 1.53s\n",
      "989:\tlearn: 0.0585885\ttotal: 2m 17s\tremaining: 1.39s\n",
      "990:\tlearn: 0.0585218\ttotal: 2m 18s\tremaining: 1.25s\n",
      "991:\tlearn: 0.0585351\ttotal: 2m 18s\tremaining: 1.11s\n",
      "992:\tlearn: 0.0585018\ttotal: 2m 18s\tremaining: 975ms\n",
      "993:\tlearn: 0.0584884\ttotal: 2m 18s\tremaining: 836ms\n",
      "994:\tlearn: 0.0584684\ttotal: 2m 18s\tremaining: 697ms\n",
      "995:\tlearn: 0.0584617\ttotal: 2m 18s\tremaining: 557ms\n",
      "996:\tlearn: 0.0584217\ttotal: 2m 18s\tremaining: 418ms\n",
      "997:\tlearn: 0.0584017\ttotal: 2m 19s\tremaining: 279ms\n",
      "998:\tlearn: 0.0583550\ttotal: 2m 19s\tremaining: 139ms\n",
      "999:\tlearn: 0.0583417\ttotal: 2m 19s\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "# cross_validate the baseline model on the accuracy, precision, recall and f1\n",
    "cat_clf_scores = cross_validate(cat_clf,x_train,y_train, cv=3, scoring =calculate_scores_multi_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "049e9460-fc48-4e74-b6d0-38e0bf279c44",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_accuracy': 91.19,\n",
       " 'test_precision': 73.24,\n",
       " 'test_recall': 62.05,\n",
       " 'test_f1': 60.59}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = ['test_accuracy', 'test_precision','test_recall', 'test_f1']\n",
    "validation_scores = {}\n",
    "for score in scores:\n",
    "    validation_scores[score] = round(cat_clf_scores[score].mean(), 2)\n",
    "validation_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fde5795-028c-441d-851b-81570f30e207",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Log Cat Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5339e0fb-bf03-4160-97c0-f3b02847b910",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Log the model's dataset train and test indices\n",
    "log_data(x_train,y_train,x_test,y_test)\n",
    "# Log the model, model description\n",
    "model = log_model(cat_clf,'Cat Boost, multilabel, Data resampled')\n",
    "# Log the model's train and test scores\n",
    "log_metrics(train_scores, validation_scores)\n",
    "# track the model artifacts, validation scores with mlflow \n",
    "track_model(model,validation_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ca91a1-0a3d-4acf-ad3d-df0d4e700ccb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Hyperparameter Tuning Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1ecc8f98-817d-48ac-b3ac-a209c0fd1de1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['memory',\n",
       " 'steps',\n",
       " 'verbose',\n",
       " 'randomforestclassifier',\n",
       " 'randomforestclassifier__bootstrap',\n",
       " 'randomforestclassifier__ccp_alpha',\n",
       " 'randomforestclassifier__class_weight',\n",
       " 'randomforestclassifier__criterion',\n",
       " 'randomforestclassifier__max_depth',\n",
       " 'randomforestclassifier__max_features',\n",
       " 'randomforestclassifier__max_leaf_nodes',\n",
       " 'randomforestclassifier__max_samples',\n",
       " 'randomforestclassifier__min_impurity_decrease',\n",
       " 'randomforestclassifier__min_samples_leaf',\n",
       " 'randomforestclassifier__min_samples_split',\n",
       " 'randomforestclassifier__min_weight_fraction_leaf',\n",
       " 'randomforestclassifier__n_estimators',\n",
       " 'randomforestclassifier__n_jobs',\n",
       " 'randomforestclassifier__oob_score',\n",
       " 'randomforestclassifier__random_state',\n",
       " 'randomforestclassifier__verbose',\n",
       " 'randomforestclassifier__warm_start']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(rf_clf.get_params().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "77ee3cd1-8385-4758-8dc8-b43a63e0add0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=50, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=9, randomforestclassifier__min_samples_split=6, randomforestclassifier__n_estimators=100, randomforestclassifier__verbose=0; total time=   4.4s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=50, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=9, randomforestclassifier__min_samples_split=6, randomforestclassifier__n_estimators=100, randomforestclassifier__verbose=0; total time=   1.3s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=50, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=9, randomforestclassifier__min_samples_split=6, randomforestclassifier__n_estimators=100, randomforestclassifier__verbose=0; total time=   1.3s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=50, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=7, randomforestclassifier__min_samples_split=8, randomforestclassifier__n_estimators=120, randomforestclassifier__verbose=0; total time=   1.8s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=50, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=7, randomforestclassifier__min_samples_split=8, randomforestclassifier__n_estimators=120, randomforestclassifier__verbose=0; total time=   1.7s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=50, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=7, randomforestclassifier__min_samples_split=8, randomforestclassifier__n_estimators=120, randomforestclassifier__verbose=0; total time=   1.8s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=30, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=9, randomforestclassifier__min_samples_split=4, randomforestclassifier__n_estimators=90, randomforestclassifier__verbose=0; total time=   1.3s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=30, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=9, randomforestclassifier__min_samples_split=4, randomforestclassifier__n_estimators=90, randomforestclassifier__verbose=0; total time=   1.3s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=30, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=9, randomforestclassifier__min_samples_split=4, randomforestclassifier__n_estimators=90, randomforestclassifier__verbose=0; total time=   1.5s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=45, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=1, randomforestclassifier__min_samples_split=3, randomforestclassifier__n_estimators=100, randomforestclassifier__verbose=0; total time=   2.5s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=45, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=1, randomforestclassifier__min_samples_split=3, randomforestclassifier__n_estimators=100, randomforestclassifier__verbose=0; total time=   2.5s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=45, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=1, randomforestclassifier__min_samples_split=3, randomforestclassifier__n_estimators=100, randomforestclassifier__verbose=0; total time=   2.6s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=50, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=1, randomforestclassifier__min_samples_split=7, randomforestclassifier__n_estimators=130, randomforestclassifier__verbose=0; total time=   2.2s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=50, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=1, randomforestclassifier__min_samples_split=7, randomforestclassifier__n_estimators=130, randomforestclassifier__verbose=0; total time=   2.2s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=50, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=1, randomforestclassifier__min_samples_split=7, randomforestclassifier__n_estimators=130, randomforestclassifier__verbose=0; total time=   2.1s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=35, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=1, randomforestclassifier__min_samples_split=8, randomforestclassifier__n_estimators=90, randomforestclassifier__verbose=0; total time=   1.7s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=35, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=1, randomforestclassifier__min_samples_split=8, randomforestclassifier__n_estimators=90, randomforestclassifier__verbose=0; total time=   1.7s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=35, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=1, randomforestclassifier__min_samples_split=8, randomforestclassifier__n_estimators=90, randomforestclassifier__verbose=0; total time=   1.8s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=30, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=5, randomforestclassifier__min_samples_split=8, randomforestclassifier__n_estimators=110, randomforestclassifier__verbose=0; total time=   1.7s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=30, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=5, randomforestclassifier__min_samples_split=8, randomforestclassifier__n_estimators=110, randomforestclassifier__verbose=0; total time=   1.8s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=30, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=5, randomforestclassifier__min_samples_split=8, randomforestclassifier__n_estimators=110, randomforestclassifier__verbose=0; total time=   1.5s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=40, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=1, randomforestclassifier__min_samples_split=3, randomforestclassifier__n_estimators=120, randomforestclassifier__verbose=0; total time=   2.4s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=40, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=1, randomforestclassifier__min_samples_split=3, randomforestclassifier__n_estimators=120, randomforestclassifier__verbose=0; total time=   2.5s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=40, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=1, randomforestclassifier__min_samples_split=3, randomforestclassifier__n_estimators=120, randomforestclassifier__verbose=0; total time=   2.5s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=35, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=9, randomforestclassifier__min_samples_split=3, randomforestclassifier__n_estimators=100, randomforestclassifier__verbose=0; total time=   1.3s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=35, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=9, randomforestclassifier__min_samples_split=3, randomforestclassifier__n_estimators=100, randomforestclassifier__verbose=0; total time=   1.3s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=35, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=9, randomforestclassifier__min_samples_split=3, randomforestclassifier__n_estimators=100, randomforestclassifier__verbose=0; total time=   1.3s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=35, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=5, randomforestclassifier__min_samples_split=4, randomforestclassifier__n_estimators=90, randomforestclassifier__verbose=0; total time=   1.6s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=35, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=5, randomforestclassifier__min_samples_split=4, randomforestclassifier__n_estimators=90, randomforestclassifier__verbose=0; total time=   1.6s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=35, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=5, randomforestclassifier__min_samples_split=4, randomforestclassifier__n_estimators=90, randomforestclassifier__verbose=0; total time=   1.8s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=45, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=5, randomforestclassifier__min_samples_split=7, randomforestclassifier__n_estimators=100, randomforestclassifier__verbose=0; total time=   1.6s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=45, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=5, randomforestclassifier__min_samples_split=7, randomforestclassifier__n_estimators=100, randomforestclassifier__verbose=0; total time=   1.5s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=45, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=5, randomforestclassifier__min_samples_split=7, randomforestclassifier__n_estimators=100, randomforestclassifier__verbose=0; total time=   1.5s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=30, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=7, randomforestclassifier__min_samples_split=3, randomforestclassifier__n_estimators=130, randomforestclassifier__verbose=0; total time=   1.8s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=30, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=7, randomforestclassifier__min_samples_split=3, randomforestclassifier__n_estimators=130, randomforestclassifier__verbose=0; total time=   1.9s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=30, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=7, randomforestclassifier__min_samples_split=3, randomforestclassifier__n_estimators=130, randomforestclassifier__verbose=0; total time=   2.0s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=30, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=5, randomforestclassifier__min_samples_split=6, randomforestclassifier__n_estimators=90, randomforestclassifier__verbose=0; total time=   1.6s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=30, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=5, randomforestclassifier__min_samples_split=6, randomforestclassifier__n_estimators=90, randomforestclassifier__verbose=0; total time=   1.6s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=30, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=5, randomforestclassifier__min_samples_split=6, randomforestclassifier__n_estimators=90, randomforestclassifier__verbose=0; total time=   1.6s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=30, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=5, randomforestclassifier__min_samples_split=4, randomforestclassifier__n_estimators=110, randomforestclassifier__verbose=0; total time=   1.7s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=30, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=5, randomforestclassifier__min_samples_split=4, randomforestclassifier__n_estimators=110, randomforestclassifier__verbose=0; total time=   1.8s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=30, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=5, randomforestclassifier__min_samples_split=4, randomforestclassifier__n_estimators=110, randomforestclassifier__verbose=0; total time=   1.7s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=30, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=5, randomforestclassifier__min_samples_split=8, randomforestclassifier__n_estimators=90, randomforestclassifier__verbose=0; total time=   1.3s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=30, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=5, randomforestclassifier__min_samples_split=8, randomforestclassifier__n_estimators=90, randomforestclassifier__verbose=0; total time=   1.4s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=30, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=5, randomforestclassifier__min_samples_split=8, randomforestclassifier__n_estimators=90, randomforestclassifier__verbose=0; total time=   1.3s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=40, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=9, randomforestclassifier__min_samples_split=8, randomforestclassifier__n_estimators=110, randomforestclassifier__verbose=0; total time=   1.5s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=40, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=9, randomforestclassifier__min_samples_split=8, randomforestclassifier__n_estimators=110, randomforestclassifier__verbose=0; total time=   1.3s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=40, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=9, randomforestclassifier__min_samples_split=8, randomforestclassifier__n_estimators=110, randomforestclassifier__verbose=0; total time=   1.5s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=40, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=7, randomforestclassifier__min_samples_split=8, randomforestclassifier__n_estimators=110, randomforestclassifier__verbose=0; total time=   1.5s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=40, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=7, randomforestclassifier__min_samples_split=8, randomforestclassifier__n_estimators=110, randomforestclassifier__verbose=0; total time=   1.4s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=40, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=7, randomforestclassifier__min_samples_split=8, randomforestclassifier__n_estimators=110, randomforestclassifier__verbose=0; total time=   1.6s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=35, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=7, randomforestclassifier__min_samples_split=2, randomforestclassifier__n_estimators=130, randomforestclassifier__verbose=0; total time=   1.6s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=35, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=7, randomforestclassifier__min_samples_split=2, randomforestclassifier__n_estimators=130, randomforestclassifier__verbose=0; total time=   1.7s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=35, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=7, randomforestclassifier__min_samples_split=2, randomforestclassifier__n_estimators=130, randomforestclassifier__verbose=0; total time=   1.8s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=50, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=9, randomforestclassifier__min_samples_split=7, randomforestclassifier__n_estimators=120, randomforestclassifier__verbose=0; total time=   1.6s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=50, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=9, randomforestclassifier__min_samples_split=7, randomforestclassifier__n_estimators=120, randomforestclassifier__verbose=0; total time=   1.5s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=50, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=9, randomforestclassifier__min_samples_split=7, randomforestclassifier__n_estimators=120, randomforestclassifier__verbose=0; total time=   1.5s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=30, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=7, randomforestclassifier__min_samples_split=7, randomforestclassifier__n_estimators=90, randomforestclassifier__verbose=0; total time=   1.2s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=30, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=7, randomforestclassifier__min_samples_split=7, randomforestclassifier__n_estimators=90, randomforestclassifier__verbose=0; total time=   1.2s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=30, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=7, randomforestclassifier__min_samples_split=7, randomforestclassifier__n_estimators=90, randomforestclassifier__verbose=0; total time=   1.2s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=30, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=3, randomforestclassifier__min_samples_split=7, randomforestclassifier__n_estimators=100, randomforestclassifier__verbose=0; total time=   1.9s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=30, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=3, randomforestclassifier__min_samples_split=7, randomforestclassifier__n_estimators=100, randomforestclassifier__verbose=0; total time=   2.2s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=30, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=3, randomforestclassifier__min_samples_split=7, randomforestclassifier__n_estimators=100, randomforestclassifier__verbose=0; total time=   1.8s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=50, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=1, randomforestclassifier__min_samples_split=5, randomforestclassifier__n_estimators=110, randomforestclassifier__verbose=0; total time=   2.3s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=50, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=1, randomforestclassifier__min_samples_split=5, randomforestclassifier__n_estimators=110, randomforestclassifier__verbose=0; total time=   2.5s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=50, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=1, randomforestclassifier__min_samples_split=5, randomforestclassifier__n_estimators=110, randomforestclassifier__verbose=0; total time=   2.4s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=30, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=5, randomforestclassifier__min_samples_split=2, randomforestclassifier__n_estimators=110, randomforestclassifier__verbose=0; total time=   1.8s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=30, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=5, randomforestclassifier__min_samples_split=2, randomforestclassifier__n_estimators=110, randomforestclassifier__verbose=0; total time=   1.9s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=30, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=5, randomforestclassifier__min_samples_split=2, randomforestclassifier__n_estimators=110, randomforestclassifier__verbose=0; total time=   1.8s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=40, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=5, randomforestclassifier__min_samples_split=2, randomforestclassifier__n_estimators=100, randomforestclassifier__verbose=0; total time=   1.5s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=40, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=5, randomforestclassifier__min_samples_split=2, randomforestclassifier__n_estimators=100, randomforestclassifier__verbose=0; total time=   1.6s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=40, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=5, randomforestclassifier__min_samples_split=2, randomforestclassifier__n_estimators=100, randomforestclassifier__verbose=0; total time=   1.6s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=45, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=9, randomforestclassifier__min_samples_split=3, randomforestclassifier__n_estimators=80, randomforestclassifier__verbose=0; total time=   1.2s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=45, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=9, randomforestclassifier__min_samples_split=3, randomforestclassifier__n_estimators=80, randomforestclassifier__verbose=0; total time=   1.3s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=45, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=9, randomforestclassifier__min_samples_split=3, randomforestclassifier__n_estimators=80, randomforestclassifier__verbose=0; total time=   1.2s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=40, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=1, randomforestclassifier__min_samples_split=7, randomforestclassifier__n_estimators=120, randomforestclassifier__verbose=0; total time=   2.0s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=40, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=1, randomforestclassifier__min_samples_split=7, randomforestclassifier__n_estimators=120, randomforestclassifier__verbose=0; total time=   1.9s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=40, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=1, randomforestclassifier__min_samples_split=7, randomforestclassifier__n_estimators=120, randomforestclassifier__verbose=0; total time=   2.0s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=30, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=9, randomforestclassifier__min_samples_split=4, randomforestclassifier__n_estimators=90, randomforestclassifier__verbose=0; total time=   1.2s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=30, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=9, randomforestclassifier__min_samples_split=4, randomforestclassifier__n_estimators=90, randomforestclassifier__verbose=0; total time=   1.2s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=30, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=9, randomforestclassifier__min_samples_split=4, randomforestclassifier__n_estimators=90, randomforestclassifier__verbose=0; total time=   1.4s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=50, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=5, randomforestclassifier__min_samples_split=5, randomforestclassifier__n_estimators=110, randomforestclassifier__verbose=0; total time=   1.5s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=50, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=5, randomforestclassifier__min_samples_split=5, randomforestclassifier__n_estimators=110, randomforestclassifier__verbose=0; total time=   1.6s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=50, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=5, randomforestclassifier__min_samples_split=5, randomforestclassifier__n_estimators=110, randomforestclassifier__verbose=0; total time=   1.7s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=40, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=9, randomforestclassifier__min_samples_split=8, randomforestclassifier__n_estimators=120, randomforestclassifier__verbose=0; total time=   1.9s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=40, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=9, randomforestclassifier__min_samples_split=8, randomforestclassifier__n_estimators=120, randomforestclassifier__verbose=0; total time=   2.0s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=40, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=9, randomforestclassifier__min_samples_split=8, randomforestclassifier__n_estimators=120, randomforestclassifier__verbose=0; total time=   1.7s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=30, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=1, randomforestclassifier__min_samples_split=4, randomforestclassifier__n_estimators=120, randomforestclassifier__verbose=0; total time=   2.7s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=30, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=1, randomforestclassifier__min_samples_split=4, randomforestclassifier__n_estimators=120, randomforestclassifier__verbose=0; total time=   2.8s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=30, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=1, randomforestclassifier__min_samples_split=4, randomforestclassifier__n_estimators=120, randomforestclassifier__verbose=0; total time=   3.2s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=40, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=3, randomforestclassifier__min_samples_split=6, randomforestclassifier__n_estimators=130, randomforestclassifier__verbose=0; total time=   2.5s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=40, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=3, randomforestclassifier__min_samples_split=6, randomforestclassifier__n_estimators=130, randomforestclassifier__verbose=0; total time=   2.4s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=40, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=3, randomforestclassifier__min_samples_split=6, randomforestclassifier__n_estimators=130, randomforestclassifier__verbose=0; total time=   2.5s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=40, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=5, randomforestclassifier__min_samples_split=6, randomforestclassifier__n_estimators=110, randomforestclassifier__verbose=0; total time=   1.7s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=40, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=5, randomforestclassifier__min_samples_split=6, randomforestclassifier__n_estimators=110, randomforestclassifier__verbose=0; total time=   1.6s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=40, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=5, randomforestclassifier__min_samples_split=6, randomforestclassifier__n_estimators=110, randomforestclassifier__verbose=0; total time=   1.6s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=30, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=5, randomforestclassifier__min_samples_split=2, randomforestclassifier__n_estimators=80, randomforestclassifier__verbose=0; total time=   1.2s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=30, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=5, randomforestclassifier__min_samples_split=2, randomforestclassifier__n_estimators=80, randomforestclassifier__verbose=0; total time=   1.2s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=30, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=5, randomforestclassifier__min_samples_split=2, randomforestclassifier__n_estimators=80, randomforestclassifier__verbose=0; total time=   1.2s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=40, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=7, randomforestclassifier__min_samples_split=2, randomforestclassifier__n_estimators=100, randomforestclassifier__verbose=0; total time=   1.4s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=40, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=7, randomforestclassifier__min_samples_split=2, randomforestclassifier__n_estimators=100, randomforestclassifier__verbose=0; total time=   1.5s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=40, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=7, randomforestclassifier__min_samples_split=2, randomforestclassifier__n_estimators=100, randomforestclassifier__verbose=0; total time=   1.4s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=45, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=3, randomforestclassifier__min_samples_split=4, randomforestclassifier__n_estimators=100, randomforestclassifier__verbose=0; total time=   1.8s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=45, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=3, randomforestclassifier__min_samples_split=4, randomforestclassifier__n_estimators=100, randomforestclassifier__verbose=0; total time=   1.9s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=45, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=3, randomforestclassifier__min_samples_split=4, randomforestclassifier__n_estimators=100, randomforestclassifier__verbose=0; total time=   1.9s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=50, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=1, randomforestclassifier__min_samples_split=4, randomforestclassifier__n_estimators=110, randomforestclassifier__verbose=0; total time=   2.1s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=50, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=1, randomforestclassifier__min_samples_split=4, randomforestclassifier__n_estimators=110, randomforestclassifier__verbose=0; total time=   2.1s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=50, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=1, randomforestclassifier__min_samples_split=4, randomforestclassifier__n_estimators=110, randomforestclassifier__verbose=0; total time=   2.1s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=40, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=9, randomforestclassifier__min_samples_split=3, randomforestclassifier__n_estimators=130, randomforestclassifier__verbose=0; total time=   1.9s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=40, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=9, randomforestclassifier__min_samples_split=3, randomforestclassifier__n_estimators=130, randomforestclassifier__verbose=0; total time=   1.9s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=40, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=9, randomforestclassifier__min_samples_split=3, randomforestclassifier__n_estimators=130, randomforestclassifier__verbose=0; total time=   2.0s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=50, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=9, randomforestclassifier__min_samples_split=3, randomforestclassifier__n_estimators=120, randomforestclassifier__verbose=0; total time=   1.5s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=50, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=9, randomforestclassifier__min_samples_split=3, randomforestclassifier__n_estimators=120, randomforestclassifier__verbose=0; total time=   1.7s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=50, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=9, randomforestclassifier__min_samples_split=3, randomforestclassifier__n_estimators=120, randomforestclassifier__verbose=0; total time=   1.8s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=45, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=3, randomforestclassifier__min_samples_split=8, randomforestclassifier__n_estimators=110, randomforestclassifier__verbose=0; total time=   1.7s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=45, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=3, randomforestclassifier__min_samples_split=8, randomforestclassifier__n_estimators=110, randomforestclassifier__verbose=0; total time=   1.9s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=45, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=3, randomforestclassifier__min_samples_split=8, randomforestclassifier__n_estimators=110, randomforestclassifier__verbose=0; total time=   1.8s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=50, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=3, randomforestclassifier__min_samples_split=8, randomforestclassifier__n_estimators=100, randomforestclassifier__verbose=0; total time=   1.6s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=50, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=3, randomforestclassifier__min_samples_split=8, randomforestclassifier__n_estimators=100, randomforestclassifier__verbose=0; total time=   1.6s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=50, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=3, randomforestclassifier__min_samples_split=8, randomforestclassifier__n_estimators=100, randomforestclassifier__verbose=0; total time=   1.7s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=45, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=1, randomforestclassifier__min_samples_split=5, randomforestclassifier__n_estimators=110, randomforestclassifier__verbose=0; total time=   2.2s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=45, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=1, randomforestclassifier__min_samples_split=5, randomforestclassifier__n_estimators=110, randomforestclassifier__verbose=0; total time=   2.4s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=45, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=1, randomforestclassifier__min_samples_split=5, randomforestclassifier__n_estimators=110, randomforestclassifier__verbose=0; total time=   2.3s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=50, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=5, randomforestclassifier__min_samples_split=4, randomforestclassifier__n_estimators=80, randomforestclassifier__verbose=0; total time=   1.1s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=50, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=5, randomforestclassifier__min_samples_split=4, randomforestclassifier__n_estimators=80, randomforestclassifier__verbose=0; total time=   1.2s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=50, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=5, randomforestclassifier__min_samples_split=4, randomforestclassifier__n_estimators=80, randomforestclassifier__verbose=0; total time=   1.3s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=35, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=7, randomforestclassifier__min_samples_split=3, randomforestclassifier__n_estimators=90, randomforestclassifier__verbose=0; total time=   1.6s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=35, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=7, randomforestclassifier__min_samples_split=3, randomforestclassifier__n_estimators=90, randomforestclassifier__verbose=0; total time=   1.5s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=35, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=7, randomforestclassifier__min_samples_split=3, randomforestclassifier__n_estimators=90, randomforestclassifier__verbose=0; total time=   1.7s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=45, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=5, randomforestclassifier__min_samples_split=4, randomforestclassifier__n_estimators=80, randomforestclassifier__verbose=0; total time=   1.5s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=45, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=5, randomforestclassifier__min_samples_split=4, randomforestclassifier__n_estimators=80, randomforestclassifier__verbose=0; total time=   1.5s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=45, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=5, randomforestclassifier__min_samples_split=4, randomforestclassifier__n_estimators=80, randomforestclassifier__verbose=0; total time=   1.4s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=40, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=7, randomforestclassifier__min_samples_split=7, randomforestclassifier__n_estimators=110, randomforestclassifier__verbose=0; total time=   1.5s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=40, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=7, randomforestclassifier__min_samples_split=7, randomforestclassifier__n_estimators=110, randomforestclassifier__verbose=0; total time=   1.6s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=40, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=7, randomforestclassifier__min_samples_split=7, randomforestclassifier__n_estimators=110, randomforestclassifier__verbose=0; total time=   1.6s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=40, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=7, randomforestclassifier__min_samples_split=4, randomforestclassifier__n_estimators=100, randomforestclassifier__verbose=0; total time=   1.8s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=40, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=7, randomforestclassifier__min_samples_split=4, randomforestclassifier__n_estimators=100, randomforestclassifier__verbose=0; total time=   1.7s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=40, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=7, randomforestclassifier__min_samples_split=4, randomforestclassifier__n_estimators=100, randomforestclassifier__verbose=0; total time=   1.7s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=35, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=7, randomforestclassifier__min_samples_split=3, randomforestclassifier__n_estimators=130, randomforestclassifier__verbose=0; total time=   2.0s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=35, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=7, randomforestclassifier__min_samples_split=3, randomforestclassifier__n_estimators=130, randomforestclassifier__verbose=0; total time=   2.1s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=35, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=7, randomforestclassifier__min_samples_split=3, randomforestclassifier__n_estimators=130, randomforestclassifier__verbose=0; total time=   2.2s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=30, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=7, randomforestclassifier__min_samples_split=8, randomforestclassifier__n_estimators=100, randomforestclassifier__verbose=0; total time=   1.6s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=30, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=7, randomforestclassifier__min_samples_split=8, randomforestclassifier__n_estimators=100, randomforestclassifier__verbose=0; total time=   1.6s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=30, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=7, randomforestclassifier__min_samples_split=8, randomforestclassifier__n_estimators=100, randomforestclassifier__verbose=0; total time=   1.7s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=30, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=3, randomforestclassifier__min_samples_split=4, randomforestclassifier__n_estimators=90, randomforestclassifier__verbose=0; total time=   2.0s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=30, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=3, randomforestclassifier__min_samples_split=4, randomforestclassifier__n_estimators=90, randomforestclassifier__verbose=0; total time=   1.8s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=30, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=3, randomforestclassifier__min_samples_split=4, randomforestclassifier__n_estimators=90, randomforestclassifier__verbose=0; total time=   1.8s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=50, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=9, randomforestclassifier__min_samples_split=8, randomforestclassifier__n_estimators=90, randomforestclassifier__verbose=0; total time=   1.2s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=50, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=9, randomforestclassifier__min_samples_split=8, randomforestclassifier__n_estimators=90, randomforestclassifier__verbose=0; total time=   1.3s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=50, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=9, randomforestclassifier__min_samples_split=8, randomforestclassifier__n_estimators=90, randomforestclassifier__verbose=0; total time=   1.5s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=35, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=9, randomforestclassifier__min_samples_split=2, randomforestclassifier__n_estimators=100, randomforestclassifier__verbose=0; total time=   1.4s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=35, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=9, randomforestclassifier__min_samples_split=2, randomforestclassifier__n_estimators=100, randomforestclassifier__verbose=0; total time=   1.6s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=35, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=9, randomforestclassifier__min_samples_split=2, randomforestclassifier__n_estimators=100, randomforestclassifier__verbose=0; total time=   1.6s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=30, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=1, randomforestclassifier__min_samples_split=4, randomforestclassifier__n_estimators=110, randomforestclassifier__verbose=0; total time=   2.1s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=30, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=1, randomforestclassifier__min_samples_split=4, randomforestclassifier__n_estimators=110, randomforestclassifier__verbose=0; total time=   2.2s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=30, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=1, randomforestclassifier__min_samples_split=4, randomforestclassifier__n_estimators=110, randomforestclassifier__verbose=0; total time=   2.1s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=45, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=1, randomforestclassifier__min_samples_split=4, randomforestclassifier__n_estimators=130, randomforestclassifier__verbose=0; total time=   2.5s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=45, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=1, randomforestclassifier__min_samples_split=4, randomforestclassifier__n_estimators=130, randomforestclassifier__verbose=0; total time=   2.5s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=45, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=1, randomforestclassifier__min_samples_split=4, randomforestclassifier__n_estimators=130, randomforestclassifier__verbose=0; total time=   2.5s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=30, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=5, randomforestclassifier__min_samples_split=7, randomforestclassifier__n_estimators=90, randomforestclassifier__verbose=0; total time=   1.5s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=30, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=5, randomforestclassifier__min_samples_split=7, randomforestclassifier__n_estimators=90, randomforestclassifier__verbose=0; total time=   1.6s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=30, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=5, randomforestclassifier__min_samples_split=7, randomforestclassifier__n_estimators=90, randomforestclassifier__verbose=0; total time=   1.5s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=50, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=5, randomforestclassifier__min_samples_split=8, randomforestclassifier__n_estimators=120, randomforestclassifier__verbose=0; total time=   1.9s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=50, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=5, randomforestclassifier__min_samples_split=8, randomforestclassifier__n_estimators=120, randomforestclassifier__verbose=0; total time=   1.9s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=50, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=5, randomforestclassifier__min_samples_split=8, randomforestclassifier__n_estimators=120, randomforestclassifier__verbose=0; total time=   1.8s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=35, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=1, randomforestclassifier__min_samples_split=8, randomforestclassifier__n_estimators=90, randomforestclassifier__verbose=0; total time=   2.0s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=35, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=1, randomforestclassifier__min_samples_split=8, randomforestclassifier__n_estimators=90, randomforestclassifier__verbose=0; total time=   2.2s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=35, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=1, randomforestclassifier__min_samples_split=8, randomforestclassifier__n_estimators=90, randomforestclassifier__verbose=0; total time=   1.9s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=35, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=7, randomforestclassifier__min_samples_split=2, randomforestclassifier__n_estimators=80, randomforestclassifier__verbose=0; total time=   1.4s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=35, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=7, randomforestclassifier__min_samples_split=2, randomforestclassifier__n_estimators=80, randomforestclassifier__verbose=0; total time=   1.5s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=35, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=7, randomforestclassifier__min_samples_split=2, randomforestclassifier__n_estimators=80, randomforestclassifier__verbose=0; total time=   1.5s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=35, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=3, randomforestclassifier__min_samples_split=4, randomforestclassifier__n_estimators=100, randomforestclassifier__verbose=0; total time=   1.8s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=35, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=3, randomforestclassifier__min_samples_split=4, randomforestclassifier__n_estimators=100, randomforestclassifier__verbose=0; total time=   1.7s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=35, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=3, randomforestclassifier__min_samples_split=4, randomforestclassifier__n_estimators=100, randomforestclassifier__verbose=0; total time=   1.7s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=30, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=9, randomforestclassifier__min_samples_split=5, randomforestclassifier__n_estimators=80, randomforestclassifier__verbose=0; total time=   1.3s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=30, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=9, randomforestclassifier__min_samples_split=5, randomforestclassifier__n_estimators=80, randomforestclassifier__verbose=0; total time=   1.3s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=30, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=9, randomforestclassifier__min_samples_split=5, randomforestclassifier__n_estimators=80, randomforestclassifier__verbose=0; total time=   1.2s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=40, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=1, randomforestclassifier__min_samples_split=4, randomforestclassifier__n_estimators=80, randomforestclassifier__verbose=0; total time=   1.8s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=40, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=1, randomforestclassifier__min_samples_split=4, randomforestclassifier__n_estimators=80, randomforestclassifier__verbose=0; total time=   2.0s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=40, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=1, randomforestclassifier__min_samples_split=4, randomforestclassifier__n_estimators=80, randomforestclassifier__verbose=0; total time=   1.9s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=45, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=5, randomforestclassifier__min_samples_split=3, randomforestclassifier__n_estimators=90, randomforestclassifier__verbose=0; total time=   1.3s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=45, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=5, randomforestclassifier__min_samples_split=3, randomforestclassifier__n_estimators=90, randomforestclassifier__verbose=0; total time=   1.4s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=45, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=5, randomforestclassifier__min_samples_split=3, randomforestclassifier__n_estimators=90, randomforestclassifier__verbose=0; total time=   1.3s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=45, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=9, randomforestclassifier__min_samples_split=8, randomforestclassifier__n_estimators=130, randomforestclassifier__verbose=0; total time=   1.8s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=45, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=9, randomforestclassifier__min_samples_split=8, randomforestclassifier__n_estimators=130, randomforestclassifier__verbose=0; total time=   1.8s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=45, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=9, randomforestclassifier__min_samples_split=8, randomforestclassifier__n_estimators=130, randomforestclassifier__verbose=0; total time=   1.7s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=40, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=3, randomforestclassifier__min_samples_split=8, randomforestclassifier__n_estimators=80, randomforestclassifier__verbose=0; total time=   1.2s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=40, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=3, randomforestclassifier__min_samples_split=8, randomforestclassifier__n_estimators=80, randomforestclassifier__verbose=0; total time=   1.3s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=40, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=3, randomforestclassifier__min_samples_split=8, randomforestclassifier__n_estimators=80, randomforestclassifier__verbose=0; total time=   1.3s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=50, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=1, randomforestclassifier__min_samples_split=5, randomforestclassifier__n_estimators=110, randomforestclassifier__verbose=0; total time=   2.6s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=50, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=1, randomforestclassifier__min_samples_split=5, randomforestclassifier__n_estimators=110, randomforestclassifier__verbose=0; total time=   2.9s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=50, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=1, randomforestclassifier__min_samples_split=5, randomforestclassifier__n_estimators=110, randomforestclassifier__verbose=0; total time=   2.4s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=50, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=9, randomforestclassifier__min_samples_split=2, randomforestclassifier__n_estimators=80, randomforestclassifier__verbose=0; total time=   1.2s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=50, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=9, randomforestclassifier__min_samples_split=2, randomforestclassifier__n_estimators=80, randomforestclassifier__verbose=0; total time=   1.1s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=50, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=9, randomforestclassifier__min_samples_split=2, randomforestclassifier__n_estimators=80, randomforestclassifier__verbose=0; total time=   1.1s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=45, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=1, randomforestclassifier__min_samples_split=6, randomforestclassifier__n_estimators=80, randomforestclassifier__verbose=0; total time=   1.5s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=45, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=1, randomforestclassifier__min_samples_split=6, randomforestclassifier__n_estimators=80, randomforestclassifier__verbose=0; total time=   1.6s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=45, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=1, randomforestclassifier__min_samples_split=6, randomforestclassifier__n_estimators=80, randomforestclassifier__verbose=0; total time=   1.6s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=40, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=9, randomforestclassifier__min_samples_split=3, randomforestclassifier__n_estimators=100, randomforestclassifier__verbose=0; total time=   1.6s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=40, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=9, randomforestclassifier__min_samples_split=3, randomforestclassifier__n_estimators=100, randomforestclassifier__verbose=0; total time=   1.3s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=40, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=9, randomforestclassifier__min_samples_split=3, randomforestclassifier__n_estimators=100, randomforestclassifier__verbose=0; total time=   1.4s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=45, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=1, randomforestclassifier__min_samples_split=8, randomforestclassifier__n_estimators=120, randomforestclassifier__verbose=0; total time=   2.1s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=45, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=1, randomforestclassifier__min_samples_split=8, randomforestclassifier__n_estimators=120, randomforestclassifier__verbose=0; total time=   2.0s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=45, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=1, randomforestclassifier__min_samples_split=8, randomforestclassifier__n_estimators=120, randomforestclassifier__verbose=0; total time=   2.0s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=30, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=7, randomforestclassifier__min_samples_split=7, randomforestclassifier__n_estimators=100, randomforestclassifier__verbose=0; total time=   1.6s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=30, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=7, randomforestclassifier__min_samples_split=7, randomforestclassifier__n_estimators=100, randomforestclassifier__verbose=0; total time=   1.5s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=30, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=7, randomforestclassifier__min_samples_split=7, randomforestclassifier__n_estimators=100, randomforestclassifier__verbose=0; total time=   1.3s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=30, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=1, randomforestclassifier__min_samples_split=5, randomforestclassifier__n_estimators=80, randomforestclassifier__verbose=0; total time=   1.8s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=30, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=1, randomforestclassifier__min_samples_split=5, randomforestclassifier__n_estimators=80, randomforestclassifier__verbose=0; total time=   1.8s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=30, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=1, randomforestclassifier__min_samples_split=5, randomforestclassifier__n_estimators=80, randomforestclassifier__verbose=0; total time=   1.9s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=50, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=3, randomforestclassifier__min_samples_split=2, randomforestclassifier__n_estimators=80, randomforestclassifier__verbose=0; total time=   1.3s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=50, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=3, randomforestclassifier__min_samples_split=2, randomforestclassifier__n_estimators=80, randomforestclassifier__verbose=0; total time=   1.4s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=50, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=3, randomforestclassifier__min_samples_split=2, randomforestclassifier__n_estimators=80, randomforestclassifier__verbose=0; total time=   1.8s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=50, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=7, randomforestclassifier__min_samples_split=6, randomforestclassifier__n_estimators=90, randomforestclassifier__verbose=0; total time=   1.6s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=50, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=7, randomforestclassifier__min_samples_split=6, randomforestclassifier__n_estimators=90, randomforestclassifier__verbose=0; total time=   1.6s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=50, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=7, randomforestclassifier__min_samples_split=6, randomforestclassifier__n_estimators=90, randomforestclassifier__verbose=0; total time=   1.6s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=40, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=7, randomforestclassifier__min_samples_split=5, randomforestclassifier__n_estimators=110, randomforestclassifier__verbose=0; total time=   1.8s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=40, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=7, randomforestclassifier__min_samples_split=5, randomforestclassifier__n_estimators=110, randomforestclassifier__verbose=0; total time=   1.8s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=40, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=7, randomforestclassifier__min_samples_split=5, randomforestclassifier__n_estimators=110, randomforestclassifier__verbose=0; total time=   1.8s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=30, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=3, randomforestclassifier__min_samples_split=7, randomforestclassifier__n_estimators=120, randomforestclassifier__verbose=0; total time=   1.9s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=30, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=3, randomforestclassifier__min_samples_split=7, randomforestclassifier__n_estimators=120, randomforestclassifier__verbose=0; total time=   1.9s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=30, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=3, randomforestclassifier__min_samples_split=7, randomforestclassifier__n_estimators=120, randomforestclassifier__verbose=0; total time=   1.8s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=45, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=1, randomforestclassifier__min_samples_split=7, randomforestclassifier__n_estimators=120, randomforestclassifier__verbose=0; total time=   2.2s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=45, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=1, randomforestclassifier__min_samples_split=7, randomforestclassifier__n_estimators=120, randomforestclassifier__verbose=0; total time=   2.2s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=45, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=1, randomforestclassifier__min_samples_split=7, randomforestclassifier__n_estimators=120, randomforestclassifier__verbose=0; total time=   2.1s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=30, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=3, randomforestclassifier__min_samples_split=3, randomforestclassifier__n_estimators=110, randomforestclassifier__verbose=0; total time=   1.9s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=30, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=3, randomforestclassifier__min_samples_split=3, randomforestclassifier__n_estimators=110, randomforestclassifier__verbose=0; total time=   1.8s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=30, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=3, randomforestclassifier__min_samples_split=3, randomforestclassifier__n_estimators=110, randomforestclassifier__verbose=0; total time=   1.9s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=30, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=9, randomforestclassifier__min_samples_split=8, randomforestclassifier__n_estimators=120, randomforestclassifier__verbose=0; total time=   2.0s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=30, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=9, randomforestclassifier__min_samples_split=8, randomforestclassifier__n_estimators=120, randomforestclassifier__verbose=0; total time=   1.8s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=30, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=9, randomforestclassifier__min_samples_split=8, randomforestclassifier__n_estimators=120, randomforestclassifier__verbose=0; total time=   1.9s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=40, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=5, randomforestclassifier__min_samples_split=8, randomforestclassifier__n_estimators=110, randomforestclassifier__verbose=0; total time=   1.6s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=40, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=5, randomforestclassifier__min_samples_split=8, randomforestclassifier__n_estimators=110, randomforestclassifier__verbose=0; total time=   1.4s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=40, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=5, randomforestclassifier__min_samples_split=8, randomforestclassifier__n_estimators=110, randomforestclassifier__verbose=0; total time=   1.6s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=45, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=3, randomforestclassifier__min_samples_split=4, randomforestclassifier__n_estimators=120, randomforestclassifier__verbose=0; total time=   1.8s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=45, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=3, randomforestclassifier__min_samples_split=4, randomforestclassifier__n_estimators=120, randomforestclassifier__verbose=0; total time=   1.9s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=45, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=3, randomforestclassifier__min_samples_split=4, randomforestclassifier__n_estimators=120, randomforestclassifier__verbose=0; total time=   2.1s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=35, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=5, randomforestclassifier__min_samples_split=2, randomforestclassifier__n_estimators=120, randomforestclassifier__verbose=0; total time=   2.3s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=35, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=5, randomforestclassifier__min_samples_split=2, randomforestclassifier__n_estimators=120, randomforestclassifier__verbose=0; total time=   1.7s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=35, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=5, randomforestclassifier__min_samples_split=2, randomforestclassifier__n_estimators=120, randomforestclassifier__verbose=0; total time=   2.0s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=30, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=9, randomforestclassifier__min_samples_split=5, randomforestclassifier__n_estimators=120, randomforestclassifier__verbose=0; total time=   1.6s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=30, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=9, randomforestclassifier__min_samples_split=5, randomforestclassifier__n_estimators=120, randomforestclassifier__verbose=0; total time=   1.9s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=30, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=9, randomforestclassifier__min_samples_split=5, randomforestclassifier__n_estimators=120, randomforestclassifier__verbose=0; total time=   1.6s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=50, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=7, randomforestclassifier__min_samples_split=8, randomforestclassifier__n_estimators=80, randomforestclassifier__verbose=0; total time=   1.3s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=50, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=7, randomforestclassifier__min_samples_split=8, randomforestclassifier__n_estimators=80, randomforestclassifier__verbose=0; total time=   1.3s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=50, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=7, randomforestclassifier__min_samples_split=8, randomforestclassifier__n_estimators=80, randomforestclassifier__verbose=0; total time=   1.2s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=40, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=5, randomforestclassifier__min_samples_split=3, randomforestclassifier__n_estimators=90, randomforestclassifier__verbose=0; total time=   1.6s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=40, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=5, randomforestclassifier__min_samples_split=3, randomforestclassifier__n_estimators=90, randomforestclassifier__verbose=0; total time=   1.6s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=40, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=5, randomforestclassifier__min_samples_split=3, randomforestclassifier__n_estimators=90, randomforestclassifier__verbose=0; total time=   1.6s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=45, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=3, randomforestclassifier__min_samples_split=4, randomforestclassifier__n_estimators=90, randomforestclassifier__verbose=0; total time=   1.8s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=45, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=3, randomforestclassifier__min_samples_split=4, randomforestclassifier__n_estimators=90, randomforestclassifier__verbose=0; total time=   2.0s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=45, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=3, randomforestclassifier__min_samples_split=4, randomforestclassifier__n_estimators=90, randomforestclassifier__verbose=0; total time=   1.9s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=40, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=7, randomforestclassifier__min_samples_split=6, randomforestclassifier__n_estimators=110, randomforestclassifier__verbose=0; total time=   1.8s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=40, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=7, randomforestclassifier__min_samples_split=6, randomforestclassifier__n_estimators=110, randomforestclassifier__verbose=0; total time=   1.9s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=40, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=7, randomforestclassifier__min_samples_split=6, randomforestclassifier__n_estimators=110, randomforestclassifier__verbose=0; total time=   1.5s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=50, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=9, randomforestclassifier__min_samples_split=3, randomforestclassifier__n_estimators=90, randomforestclassifier__verbose=0; total time=   1.3s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=50, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=9, randomforestclassifier__min_samples_split=3, randomforestclassifier__n_estimators=90, randomforestclassifier__verbose=0; total time=   1.3s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=50, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=9, randomforestclassifier__min_samples_split=3, randomforestclassifier__n_estimators=90, randomforestclassifier__verbose=0; total time=   1.3s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=45, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=1, randomforestclassifier__min_samples_split=3, randomforestclassifier__n_estimators=130, randomforestclassifier__verbose=0; total time=   2.6s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=45, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=1, randomforestclassifier__min_samples_split=3, randomforestclassifier__n_estimators=130, randomforestclassifier__verbose=0; total time=   2.6s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=45, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=1, randomforestclassifier__min_samples_split=3, randomforestclassifier__n_estimators=130, randomforestclassifier__verbose=0; total time=   2.7s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=40, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=5, randomforestclassifier__min_samples_split=7, randomforestclassifier__n_estimators=110, randomforestclassifier__verbose=0; total time=   1.6s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=40, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=5, randomforestclassifier__min_samples_split=7, randomforestclassifier__n_estimators=110, randomforestclassifier__verbose=0; total time=   1.5s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=40, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=5, randomforestclassifier__min_samples_split=7, randomforestclassifier__n_estimators=110, randomforestclassifier__verbose=0; total time=   1.6s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=45, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=9, randomforestclassifier__min_samples_split=4, randomforestclassifier__n_estimators=110, randomforestclassifier__verbose=0; total time=   1.6s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=45, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=9, randomforestclassifier__min_samples_split=4, randomforestclassifier__n_estimators=110, randomforestclassifier__verbose=0; total time=   1.7s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=45, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=9, randomforestclassifier__min_samples_split=4, randomforestclassifier__n_estimators=110, randomforestclassifier__verbose=0; total time=   1.6s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=45, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=5, randomforestclassifier__min_samples_split=5, randomforestclassifier__n_estimators=120, randomforestclassifier__verbose=0; total time=   1.8s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=45, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=5, randomforestclassifier__min_samples_split=5, randomforestclassifier__n_estimators=120, randomforestclassifier__verbose=0; total time=   1.7s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=45, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=5, randomforestclassifier__min_samples_split=5, randomforestclassifier__n_estimators=120, randomforestclassifier__verbose=0; total time=   1.6s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=35, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=1, randomforestclassifier__min_samples_split=7, randomforestclassifier__n_estimators=90, randomforestclassifier__verbose=0; total time=   2.0s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=35, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=1, randomforestclassifier__min_samples_split=7, randomforestclassifier__n_estimators=90, randomforestclassifier__verbose=0; total time=   2.0s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=35, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=1, randomforestclassifier__min_samples_split=7, randomforestclassifier__n_estimators=90, randomforestclassifier__verbose=0; total time=   2.2s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=50, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=9, randomforestclassifier__min_samples_split=4, randomforestclassifier__n_estimators=130, randomforestclassifier__verbose=0; total time=   2.3s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=50, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=9, randomforestclassifier__min_samples_split=4, randomforestclassifier__n_estimators=130, randomforestclassifier__verbose=0; total time=   2.4s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=50, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=9, randomforestclassifier__min_samples_split=4, randomforestclassifier__n_estimators=130, randomforestclassifier__verbose=0; total time=   2.0s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=50, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=3, randomforestclassifier__min_samples_split=5, randomforestclassifier__n_estimators=100, randomforestclassifier__verbose=0; total time=   2.1s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=50, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=3, randomforestclassifier__min_samples_split=5, randomforestclassifier__n_estimators=100, randomforestclassifier__verbose=0; total time=   2.0s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=50, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=3, randomforestclassifier__min_samples_split=5, randomforestclassifier__n_estimators=100, randomforestclassifier__verbose=0; total time=   1.9s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=40, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=3, randomforestclassifier__min_samples_split=6, randomforestclassifier__n_estimators=80, randomforestclassifier__verbose=0; total time=   1.7s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=40, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=3, randomforestclassifier__min_samples_split=6, randomforestclassifier__n_estimators=80, randomforestclassifier__verbose=0; total time=   1.6s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=40, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=3, randomforestclassifier__min_samples_split=6, randomforestclassifier__n_estimators=80, randomforestclassifier__verbose=0; total time=   1.7s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=35, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=3, randomforestclassifier__min_samples_split=5, randomforestclassifier__n_estimators=100, randomforestclassifier__verbose=0; total time=   1.8s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=35, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=3, randomforestclassifier__min_samples_split=5, randomforestclassifier__n_estimators=100, randomforestclassifier__verbose=0; total time=   1.8s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=35, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=3, randomforestclassifier__min_samples_split=5, randomforestclassifier__n_estimators=100, randomforestclassifier__verbose=0; total time=   1.8s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=40, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=7, randomforestclassifier__min_samples_split=8, randomforestclassifier__n_estimators=130, randomforestclassifier__verbose=0; total time=   2.2s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=40, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=7, randomforestclassifier__min_samples_split=8, randomforestclassifier__n_estimators=130, randomforestclassifier__verbose=0; total time=   2.4s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=40, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=7, randomforestclassifier__min_samples_split=8, randomforestclassifier__n_estimators=130, randomforestclassifier__verbose=0; total time=   2.2s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=50, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=1, randomforestclassifier__min_samples_split=4, randomforestclassifier__n_estimators=80, randomforestclassifier__verbose=0; total time=   1.7s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=50, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=1, randomforestclassifier__min_samples_split=4, randomforestclassifier__n_estimators=80, randomforestclassifier__verbose=0; total time=   1.6s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=50, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=1, randomforestclassifier__min_samples_split=4, randomforestclassifier__n_estimators=80, randomforestclassifier__verbose=0; total time=   1.7s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=40, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=5, randomforestclassifier__min_samples_split=7, randomforestclassifier__n_estimators=80, randomforestclassifier__verbose=0; total time=   1.5s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=40, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=5, randomforestclassifier__min_samples_split=7, randomforestclassifier__n_estimators=80, randomforestclassifier__verbose=0; total time=   1.3s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=40, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=5, randomforestclassifier__min_samples_split=7, randomforestclassifier__n_estimators=80, randomforestclassifier__verbose=0; total time=   1.6s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=35, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=1, randomforestclassifier__min_samples_split=8, randomforestclassifier__n_estimators=100, randomforestclassifier__verbose=0; total time=   1.8s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=35, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=1, randomforestclassifier__min_samples_split=8, randomforestclassifier__n_estimators=100, randomforestclassifier__verbose=0; total time=   1.8s\n",
      "[CV] END randomforestclassifier__class_weight=None, randomforestclassifier__max_depth=35, randomforestclassifier__max_features=log2, randomforestclassifier__min_samples_leaf=1, randomforestclassifier__min_samples_split=8, randomforestclassifier__n_estimators=100, randomforestclassifier__verbose=0; total time=   1.7s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=35, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=9, randomforestclassifier__min_samples_split=5, randomforestclassifier__n_estimators=130, randomforestclassifier__verbose=0; total time=   2.2s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=35, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=9, randomforestclassifier__min_samples_split=5, randomforestclassifier__n_estimators=130, randomforestclassifier__verbose=0; total time=   2.0s\n",
      "[CV] END randomforestclassifier__class_weight=balanced, randomforestclassifier__max_depth=35, randomforestclassifier__max_features=sqrt, randomforestclassifier__min_samples_leaf=9, randomforestclassifier__min_samples_split=5, randomforestclassifier__n_estimators=130, randomforestclassifier__verbose=0; total time=   2.1s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=3,\n",
       "                   estimator=Pipeline(steps=[(&#x27;randomforestclassifier&#x27;,\n",
       "                                              RandomForestClassifier(n_jobs=-1,\n",
       "                                                                     random_state=42,\n",
       "                                                                     verbose=1))]),\n",
       "                   n_iter=100,\n",
       "                   param_distributions=[{&#x27;randomforestclassifier__class_weight&#x27;: [&#x27;balanced&#x27;,\n",
       "                                                                                  None],\n",
       "                                         &#x27;randomforestclassifier__max_depth&#x27;: [30,\n",
       "                                                                               35,\n",
       "                                                                               40,\n",
       "                                                                               45,\n",
       "                                                                               50],\n",
       "                                         &#x27;randomforestclassifier__max_features&#x27;: [&#x27;sqrt&#x27;,\n",
       "                                                                                  &#x27;log2&#x27;],\n",
       "                                         &#x27;randomforestclassifier__min_samples_leaf&#x27;: [1,\n",
       "                                                                                      3,\n",
       "                                                                                      5,\n",
       "                                                                                      7,\n",
       "                                                                                      9],\n",
       "                                         &#x27;randomforestclassifier__min_samples_split&#x27;: [2,\n",
       "                                                                                       3,\n",
       "                                                                                       4,\n",
       "                                                                                       5,\n",
       "                                                                                       6,\n",
       "                                                                                       7,\n",
       "                                                                                       8],\n",
       "                                         &#x27;randomforestclassifier__n_estimators&#x27;: [80,\n",
       "                                                                                  90,\n",
       "                                                                                  100,\n",
       "                                                                                  110,\n",
       "                                                                                  120,\n",
       "                                                                                  130],\n",
       "                                         &#x27;randomforestclassifier__verbose&#x27;: [0]}],\n",
       "                   return_train_score=True,\n",
       "                   scoring=&lt;function precision_score_multi_label at 0x0000021C62062C00&gt;,\n",
       "                   verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=3,\n",
       "                   estimator=Pipeline(steps=[(&#x27;randomforestclassifier&#x27;,\n",
       "                                              RandomForestClassifier(n_jobs=-1,\n",
       "                                                                     random_state=42,\n",
       "                                                                     verbose=1))]),\n",
       "                   n_iter=100,\n",
       "                   param_distributions=[{&#x27;randomforestclassifier__class_weight&#x27;: [&#x27;balanced&#x27;,\n",
       "                                                                                  None],\n",
       "                                         &#x27;randomforestclassifier__max_depth&#x27;: [30,\n",
       "                                                                               35,\n",
       "                                                                               40,\n",
       "                                                                               45,\n",
       "                                                                               50],\n",
       "                                         &#x27;randomforestclassifier__max_features&#x27;: [&#x27;sqrt&#x27;,\n",
       "                                                                                  &#x27;log2&#x27;],\n",
       "                                         &#x27;randomforestclassifier__min_samples_leaf&#x27;: [1,\n",
       "                                                                                      3,\n",
       "                                                                                      5,\n",
       "                                                                                      7,\n",
       "                                                                                      9],\n",
       "                                         &#x27;randomforestclassifier__min_samples_split&#x27;: [2,\n",
       "                                                                                       3,\n",
       "                                                                                       4,\n",
       "                                                                                       5,\n",
       "                                                                                       6,\n",
       "                                                                                       7,\n",
       "                                                                                       8],\n",
       "                                         &#x27;randomforestclassifier__n_estimators&#x27;: [80,\n",
       "                                                                                  90,\n",
       "                                                                                  100,\n",
       "                                                                                  110,\n",
       "                                                                                  120,\n",
       "                                                                                  130],\n",
       "                                         &#x27;randomforestclassifier__verbose&#x27;: [0]}],\n",
       "                   return_train_score=True,\n",
       "                   scoring=&lt;function precision_score_multi_label at 0x0000021C62062C00&gt;,\n",
       "                   verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;randomforestclassifier&#x27;,\n",
       "                 RandomForestClassifier(n_jobs=-1, random_state=42,\n",
       "                                        verbose=1))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_jobs=-1, random_state=42, verbose=1)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=Pipeline(steps=[('randomforestclassifier',\n",
       "                                              RandomForestClassifier(n_jobs=-1,\n",
       "                                                                     random_state=42,\n",
       "                                                                     verbose=1))]),\n",
       "                   n_iter=100,\n",
       "                   param_distributions=[{'randomforestclassifier__class_weight': ['balanced',\n",
       "                                                                                  None],\n",
       "                                         'randomforestclassifier__max_depth': [30,\n",
       "                                                                               35,\n",
       "                                                                               40,\n",
       "                                                                               45,\n",
       "                                                                               50],\n",
       "                                         'randomforestclassifier__max_features': ['sqrt',\n",
       "                                                                                  'log2'],\n",
       "                                         'randomforestclassifier__min_samples_leaf': [1,\n",
       "                                                                                      3,\n",
       "                                                                                      5,\n",
       "                                                                                      7,\n",
       "                                                                                      9],\n",
       "                                         'randomforestclassifier__min_samples_split': [2,\n",
       "                                                                                       3,\n",
       "                                                                                       4,\n",
       "                                                                                       5,\n",
       "                                                                                       6,\n",
       "                                                                                       7,\n",
       "                                                                                       8],\n",
       "                                         'randomforestclassifier__n_estimators': [80,\n",
       "                                                                                  90,\n",
       "                                                                                  100,\n",
       "                                                                                  110,\n",
       "                                                                                  120,\n",
       "                                                                                  130],\n",
       "                                         'randomforestclassifier__verbose': [0]}],\n",
       "                   return_train_score=True,\n",
       "                   scoring=<function precision_score_multi_label at 0x0000021C62062C00>,\n",
       "                   verbose=2)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "rf_param_grid = [\n",
    "    {'randomforestclassifier__n_estimators':[80,90,100,110,120,130],\n",
    "     'randomforestclassifier__max_depth':[30,35,40,45,50],\n",
    "     'randomforestclassifier__min_samples_split':[2,3,4,5,6,7,8],\n",
    "     'randomforestclassifier__min_samples_leaf':[1,3,5,7,9],\n",
    "     'randomforestclassifier__class_weight':['balanced',None],\n",
    "     'randomforestclassifier__max_features':['sqrt','log2'],\n",
    "     'randomforestclassifier__verbose': [0],\n",
    "    }]\n",
    "    \n",
    "\n",
    "rf_clf_grid_search = RandomizedSearchCV(rf_clf, rf_param_grid,cv= 3,n_iter=100, scoring=precision_score_multi_label, return_train_score=True,refit=True,verbose=2)\n",
    "\n",
    "rf_clf_grid_search.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1ce35df1-3cda-4018-9573-5d58d39c6b74",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;randomforestclassifier&#x27;,\n",
       "                 RandomForestClassifier(class_weight=&#x27;balanced&#x27;, max_depth=40,\n",
       "                                        max_features=&#x27;log2&#x27;,\n",
       "                                        min_samples_split=3, n_estimators=120,\n",
       "                                        n_jobs=-1, random_state=42))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" ><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;randomforestclassifier&#x27;,\n",
       "                 RandomForestClassifier(class_weight=&#x27;balanced&#x27;, max_depth=40,\n",
       "                                        max_features=&#x27;log2&#x27;,\n",
       "                                        min_samples_split=3, n_estimators=120,\n",
       "                                        n_jobs=-1, random_state=42))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" ><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, max_depth=40,\n",
       "                       max_features=&#x27;log2&#x27;, min_samples_split=3,\n",
       "                       n_estimators=120, n_jobs=-1, random_state=42)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('randomforestclassifier',\n",
       "                 RandomForestClassifier(class_weight='balanced', max_depth=40,\n",
       "                                        max_features='log2',\n",
       "                                        min_samples_split=3, n_estimators=120,\n",
       "                                        n_jobs=-1, random_state=42))])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_clf_grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8327729f-ad56-471e-8f23-27fc9cdf497f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score     99.104211\n",
      "precision_score    99.457368\n",
      "recall_score       94.907368\n",
      "f1_score           96.981579\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Developer, desktop or enterprise applications</th>\n",
       "      <td>97.63</td>\n",
       "      <td>98.61</td>\n",
       "      <td>88.09</td>\n",
       "      <td>92.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, back-end</th>\n",
       "      <td>98.00</td>\n",
       "      <td>98.74</td>\n",
       "      <td>94.99</td>\n",
       "      <td>96.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, QA or test</th>\n",
       "      <td>98.32</td>\n",
       "      <td>99.12</td>\n",
       "      <td>86.59</td>\n",
       "      <td>91.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, full-stack</th>\n",
       "      <td>98.78</td>\n",
       "      <td>99.27</td>\n",
       "      <td>96.68</td>\n",
       "      <td>97.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Academic researcher</th>\n",
       "      <td>98.81</td>\n",
       "      <td>99.30</td>\n",
       "      <td>93.97</td>\n",
       "      <td>96.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Engineer, data</th>\n",
       "      <td>98.84</td>\n",
       "      <td>99.38</td>\n",
       "      <td>92.83</td>\n",
       "      <td>95.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, front-end</th>\n",
       "      <td>98.98</td>\n",
       "      <td>99.39</td>\n",
       "      <td>93.61</td>\n",
       "      <td>96.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Security professional</th>\n",
       "      <td>99.26</td>\n",
       "      <td>99.42</td>\n",
       "      <td>92.60</td>\n",
       "      <td>95.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, embedded applications or devices</th>\n",
       "      <td>99.01</td>\n",
       "      <td>99.47</td>\n",
       "      <td>93.10</td>\n",
       "      <td>96.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>System administrator</th>\n",
       "      <td>99.07</td>\n",
       "      <td>99.50</td>\n",
       "      <td>94.49</td>\n",
       "      <td>96.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, mobile</th>\n",
       "      <td>99.65</td>\n",
       "      <td>99.55</td>\n",
       "      <td>97.97</td>\n",
       "      <td>98.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data or business analyst</th>\n",
       "      <td>99.23</td>\n",
       "      <td>99.59</td>\n",
       "      <td>94.90</td>\n",
       "      <td>97.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DevOps specialist</th>\n",
       "      <td>99.37</td>\n",
       "      <td>99.66</td>\n",
       "      <td>96.66</td>\n",
       "      <td>98.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Database administrator</th>\n",
       "      <td>99.59</td>\n",
       "      <td>99.67</td>\n",
       "      <td>97.27</td>\n",
       "      <td>98.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cloud infrastructure engineer</th>\n",
       "      <td>99.53</td>\n",
       "      <td>99.74</td>\n",
       "      <td>97.29</td>\n",
       "      <td>98.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scientist</th>\n",
       "      <td>99.66</td>\n",
       "      <td>99.76</td>\n",
       "      <td>97.79</td>\n",
       "      <td>98.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, game or graphics</th>\n",
       "      <td>99.75</td>\n",
       "      <td>99.80</td>\n",
       "      <td>97.98</td>\n",
       "      <td>98.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data scientist or machine learning specialist</th>\n",
       "      <td>99.65</td>\n",
       "      <td>99.80</td>\n",
       "      <td>98.16</td>\n",
       "      <td>98.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blockchain</th>\n",
       "      <td>99.85</td>\n",
       "      <td>99.92</td>\n",
       "      <td>98.27</td>\n",
       "      <td>99.08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               accuracy_score  \\\n",
       "Developer, desktop or enterprise applications           97.63   \n",
       "Developer, back-end                                     98.00   \n",
       "Developer, QA or test                                   98.32   \n",
       "Developer, full-stack                                   98.78   \n",
       "Academic researcher                                     98.81   \n",
       "Engineer, data                                          98.84   \n",
       "Developer, front-end                                    98.98   \n",
       "Security professional                                   99.26   \n",
       "Developer, embedded applications or devices             99.01   \n",
       "System administrator                                    99.07   \n",
       "Developer, mobile                                       99.65   \n",
       "Data or business analyst                                99.23   \n",
       "DevOps specialist                                       99.37   \n",
       "Database administrator                                  99.59   \n",
       "Cloud infrastructure engineer                           99.53   \n",
       "Scientist                                               99.66   \n",
       "Developer, game or graphics                             99.75   \n",
       "Data scientist or machine learning specialist           99.65   \n",
       "Blockchain                                              99.85   \n",
       "\n",
       "                                               precision_score  recall_score  \\\n",
       "Developer, desktop or enterprise applications            98.61         88.09   \n",
       "Developer, back-end                                      98.74         94.99   \n",
       "Developer, QA or test                                    99.12         86.59   \n",
       "Developer, full-stack                                    99.27         96.68   \n",
       "Academic researcher                                      99.30         93.97   \n",
       "Engineer, data                                           99.38         92.83   \n",
       "Developer, front-end                                     99.39         93.61   \n",
       "Security professional                                    99.42         92.60   \n",
       "Developer, embedded applications or devices              99.47         93.10   \n",
       "System administrator                                     99.50         94.49   \n",
       "Developer, mobile                                        99.55         97.97   \n",
       "Data or business analyst                                 99.59         94.90   \n",
       "DevOps specialist                                        99.66         96.66   \n",
       "Database administrator                                   99.67         97.27   \n",
       "Cloud infrastructure engineer                            99.74         97.29   \n",
       "Scientist                                                99.76         97.79   \n",
       "Developer, game or graphics                              99.80         97.98   \n",
       "Data scientist or machine learning specialist            99.80         98.16   \n",
       "Blockchain                                               99.92         98.27   \n",
       "\n",
       "                                               f1_score  \n",
       "Developer, desktop or enterprise applications     92.55  \n",
       "Developer, back-end                               96.73  \n",
       "Developer, QA or test                             91.81  \n",
       "Developer, full-stack                             97.91  \n",
       "Academic researcher                               96.44  \n",
       "Engineer, data                                    95.82  \n",
       "Developer, front-end                              96.28  \n",
       "Security professional                             95.73  \n",
       "Developer, embedded applications or devices       96.03  \n",
       "System administrator                              96.83  \n",
       "Developer, mobile                                 98.74  \n",
       "Data or business analyst                          97.11  \n",
       "DevOps specialist                                 98.10  \n",
       "Database administrator                            98.43  \n",
       "Cloud infrastructure engineer                     98.48  \n",
       "Scientist                                         98.75  \n",
       "Developer, game or graphics                       98.87  \n",
       "Data scientist or machine learning specialist     98.96  \n",
       "Blockchain                                        99.08  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics=[accuracy_score, precision_score, recall_score, f1_score]\n",
    "train_scores, mean_train_scores= calculate_metrics(rf_clf_grid_search.best_estimator_,x_train,y_train, metrics)\n",
    "\n",
    "print(mean_train_scores)\n",
    "train_scores.sort_values(\"precision_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "fcf8f631-b4e7-4380-b3cf-e352ff09011b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cross_validate the baseline model on the accuracy, precision, recall and f1\n",
    "rf_clf_scores = cross_validate(rf_clf_grid_search.best_estimator_,x_train,y_train, cv=3, scoring =calculate_scores_multi_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "11227b3a-10cf-4baa-950f-638ca4e9e61b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_accuracy': 91.97,\n",
       " 'test_precision': 84.98,\n",
       " 'test_recall': 65.35,\n",
       " 'test_f1': 65.8}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = ['test_accuracy', 'test_precision','test_recall', 'test_f1']\n",
    "validation_scores = {}\n",
    "for score in scores:\n",
    "    validation_scores[score] = round(rf_clf_scores[score].mean(), 2)\n",
    "validation_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a28f5ae6-92cf-45ac-927a-0931b7b47bbb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Log the model's dataset train and test indices\n",
    "log_data(x_train,y_train,x_test,y_test)\n",
    "# Log the model, model description\n",
    "model = log_model(rf_clf_grid_search.best_estimator_,'Random Forest, Tuned, multilabel, Data resampled')\n",
    "# Log the model's train and test scores\n",
    "log_metrics(train_scores, validation_scores)\n",
    "# track the model artifacts, validation scores with mlflow \n",
    "track_model(model,validation_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a25a7e-1c05-4884-9b28-1e0ff397fedf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "61f7a726",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultiOutputClassifier(estimator=VotingClassifier(estimators=[(&#x27;rf&#x27;,\n",
       "                                                              RandomForestClassifier(class_weight=&#x27;balanced&#x27;,\n",
       "                                                                                     max_depth=40,\n",
       "                                                                                     max_features=&#x27;log2&#x27;,\n",
       "                                                                                     min_samples_split=3,\n",
       "                                                                                     n_estimators=120,\n",
       "                                                                                     n_jobs=-1,\n",
       "                                                                                     random_state=42)),\n",
       "                                                             (&#x27;gd&#x27;,\n",
       "                                                              GradientBoostingClassifier(max_features=&#x27;sqrt&#x27;,\n",
       "                                                                                         random_state=42)),\n",
       "                                                             (&#x27;cat&#x27;,\n",
       "                                                              &lt;catboost.core.CatBoostClassifier object at 0x000001A73D0F63D0&gt;)],\n",
       "                                                 voting=&#x27;soft&#x27;))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultiOutputClassifier</label><div class=\"sk-toggleable__content\"><pre>MultiOutputClassifier(estimator=VotingClassifier(estimators=[(&#x27;rf&#x27;,\n",
       "                                                              RandomForestClassifier(class_weight=&#x27;balanced&#x27;,\n",
       "                                                                                     max_depth=40,\n",
       "                                                                                     max_features=&#x27;log2&#x27;,\n",
       "                                                                                     min_samples_split=3,\n",
       "                                                                                     n_estimators=120,\n",
       "                                                                                     n_jobs=-1,\n",
       "                                                                                     random_state=42)),\n",
       "                                                             (&#x27;gd&#x27;,\n",
       "                                                              GradientBoostingClassifier(max_features=&#x27;sqrt&#x27;,\n",
       "                                                                                         random_state=42)),\n",
       "                                                             (&#x27;cat&#x27;,\n",
       "                                                              &lt;catboost.core.CatBoostClassifier object at 0x000001A73D0F63D0&gt;)],\n",
       "                                                 voting=&#x27;soft&#x27;))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: VotingClassifier</label><div class=\"sk-toggleable__content\"><pre>VotingClassifier(estimators=[(&#x27;rf&#x27;,\n",
       "                              RandomForestClassifier(class_weight=&#x27;balanced&#x27;,\n",
       "                                                     max_depth=40,\n",
       "                                                     max_features=&#x27;log2&#x27;,\n",
       "                                                     min_samples_split=3,\n",
       "                                                     n_estimators=120,\n",
       "                                                     n_jobs=-1,\n",
       "                                                     random_state=42)),\n",
       "                             (&#x27;gd&#x27;,\n",
       "                              GradientBoostingClassifier(max_features=&#x27;sqrt&#x27;,\n",
       "                                                         random_state=42)),\n",
       "                             (&#x27;cat&#x27;,\n",
       "                              &lt;catboost.core.CatBoostClassifier object at 0x000001A73D0F63D0&gt;)],\n",
       "                 voting=&#x27;soft&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>rf</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, max_depth=40,\n",
       "                       max_features=&#x27;log2&#x27;, min_samples_split=3,\n",
       "                       n_estimators=120, n_jobs=-1, random_state=42)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>gd</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(max_features=&#x27;sqrt&#x27;, random_state=42)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>cat</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CatBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>&lt;catboost.core.CatBoostClassifier object at 0x000001A73D0F63D0&gt;</pre></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultiOutputClassifier(estimator=VotingClassifier(estimators=[('rf',\n",
       "                                                              RandomForestClassifier(class_weight='balanced',\n",
       "                                                                                     max_depth=40,\n",
       "                                                                                     max_features='log2',\n",
       "                                                                                     min_samples_split=3,\n",
       "                                                                                     n_estimators=120,\n",
       "                                                                                     n_jobs=-1,\n",
       "                                                                                     random_state=42)),\n",
       "                                                             ('gd',\n",
       "                                                              GradientBoostingClassifier(max_features='sqrt',\n",
       "                                                                                         random_state=42)),\n",
       "                                                             ('cat',\n",
       "                                                              <catboost.core.CatBoostClassifier object at 0x000001A73D0F63D0>)],\n",
       "                                                 voting='soft'))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_clf = make_pipeline(StandardScaler(),\n",
    "                    LogisticRegression(max_iter=1000))\n",
    "\n",
    "gd_clf = GradientBoostingClassifier(n_estimators=100,\n",
    "                                    max_depth=3,\n",
    "                                    random_state=42,\n",
    "                                    verbose=0)\n",
    "\n",
    "rf_clf = RandomForestClassifier(class_weight='balanced', max_depth=40,\n",
    "                       max_features='log2', min_samples_split=3,\n",
    "                       n_estimators=120, n_jobs=-1, random_state=42)\n",
    "\n",
    "cat_clf = CatBoostClassifier(verbose=0)\n",
    "\n",
    "voting_clf = MultiOutputClassifier(VotingClassifier(\n",
    "    estimators=[\n",
    "        # ('log', log_clf),\n",
    "        ('rf', rf_clf),\n",
    "        ('gd', gd_clf),\n",
    "        ('cat', cat_clf)\n",
    "    ] \n",
    ",voting = \"soft\"))\n",
    "\n",
    "\n",
    "voting_clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9506fee5-2e5e-4022-80cc-c7215c1f9671",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Evaluate Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "87cfb64b-1f89-47c5-b7b7-86917d430b8d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score     96.398947\n",
      "precision_score    97.438421\n",
      "recall_score       79.192632\n",
      "f1_score           85.015263\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Developer, back-end</th>\n",
       "      <td>91.78</td>\n",
       "      <td>94.81</td>\n",
       "      <td>79.59</td>\n",
       "      <td>84.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, desktop or enterprise applications</th>\n",
       "      <td>95.01</td>\n",
       "      <td>95.57</td>\n",
       "      <td>75.74</td>\n",
       "      <td>82.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, full-stack</th>\n",
       "      <td>94.63</td>\n",
       "      <td>96.53</td>\n",
       "      <td>85.59</td>\n",
       "      <td>89.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Academic researcher</th>\n",
       "      <td>96.65</td>\n",
       "      <td>97.05</td>\n",
       "      <td>83.67</td>\n",
       "      <td>88.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DevOps specialist</th>\n",
       "      <td>96.27</td>\n",
       "      <td>97.07</td>\n",
       "      <td>80.62</td>\n",
       "      <td>86.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, front-end</th>\n",
       "      <td>97.46</td>\n",
       "      <td>97.14</td>\n",
       "      <td>85.04</td>\n",
       "      <td>90.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Engineer, data</th>\n",
       "      <td>95.93</td>\n",
       "      <td>97.19</td>\n",
       "      <td>75.10</td>\n",
       "      <td>82.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, QA or test</th>\n",
       "      <td>94.93</td>\n",
       "      <td>97.43</td>\n",
       "      <td>59.57</td>\n",
       "      <td>64.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>System administrator</th>\n",
       "      <td>95.54</td>\n",
       "      <td>97.68</td>\n",
       "      <td>73.55</td>\n",
       "      <td>80.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Database administrator</th>\n",
       "      <td>95.49</td>\n",
       "      <td>97.68</td>\n",
       "      <td>68.40</td>\n",
       "      <td>75.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data scientist or machine learning specialist</th>\n",
       "      <td>98.04</td>\n",
       "      <td>97.70</td>\n",
       "      <td>90.84</td>\n",
       "      <td>93.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, mobile</th>\n",
       "      <td>98.76</td>\n",
       "      <td>97.83</td>\n",
       "      <td>93.13</td>\n",
       "      <td>95.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data or business analyst</th>\n",
       "      <td>96.70</td>\n",
       "      <td>97.90</td>\n",
       "      <td>78.37</td>\n",
       "      <td>85.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, embedded applications or devices</th>\n",
       "      <td>97.58</td>\n",
       "      <td>97.91</td>\n",
       "      <td>83.68</td>\n",
       "      <td>89.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, game or graphics</th>\n",
       "      <td>97.90</td>\n",
       "      <td>98.08</td>\n",
       "      <td>82.65</td>\n",
       "      <td>88.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cloud infrastructure engineer</th>\n",
       "      <td>96.68</td>\n",
       "      <td>98.17</td>\n",
       "      <td>81.06</td>\n",
       "      <td>87.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scientist</th>\n",
       "      <td>97.36</td>\n",
       "      <td>98.21</td>\n",
       "      <td>82.59</td>\n",
       "      <td>88.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Security professional</th>\n",
       "      <td>96.87</td>\n",
       "      <td>98.41</td>\n",
       "      <td>68.21</td>\n",
       "      <td>75.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blockchain</th>\n",
       "      <td>98.00</td>\n",
       "      <td>98.97</td>\n",
       "      <td>77.26</td>\n",
       "      <td>84.76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               accuracy_score  \\\n",
       "Developer, back-end                                     91.78   \n",
       "Developer, desktop or enterprise applications           95.01   \n",
       "Developer, full-stack                                   94.63   \n",
       "Academic researcher                                     96.65   \n",
       "DevOps specialist                                       96.27   \n",
       "Developer, front-end                                    97.46   \n",
       "Engineer, data                                          95.93   \n",
       "Developer, QA or test                                   94.93   \n",
       "System administrator                                    95.54   \n",
       "Database administrator                                  95.49   \n",
       "Data scientist or machine learning specialist           98.04   \n",
       "Developer, mobile                                       98.76   \n",
       "Data or business analyst                                96.70   \n",
       "Developer, embedded applications or devices             97.58   \n",
       "Developer, game or graphics                             97.90   \n",
       "Cloud infrastructure engineer                           96.68   \n",
       "Scientist                                               97.36   \n",
       "Security professional                                   96.87   \n",
       "Blockchain                                              98.00   \n",
       "\n",
       "                                               precision_score  recall_score  \\\n",
       "Developer, back-end                                      94.81         79.59   \n",
       "Developer, desktop or enterprise applications            95.57         75.74   \n",
       "Developer, full-stack                                    96.53         85.59   \n",
       "Academic researcher                                      97.05         83.67   \n",
       "DevOps specialist                                        97.07         80.62   \n",
       "Developer, front-end                                     97.14         85.04   \n",
       "Engineer, data                                           97.19         75.10   \n",
       "Developer, QA or test                                    97.43         59.57   \n",
       "System administrator                                     97.68         73.55   \n",
       "Database administrator                                   97.68         68.40   \n",
       "Data scientist or machine learning specialist            97.70         90.84   \n",
       "Developer, mobile                                        97.83         93.13   \n",
       "Data or business analyst                                 97.90         78.37   \n",
       "Developer, embedded applications or devices              97.91         83.68   \n",
       "Developer, game or graphics                              98.08         82.65   \n",
       "Cloud infrastructure engineer                            98.17         81.06   \n",
       "Scientist                                                98.21         82.59   \n",
       "Security professional                                    98.41         68.21   \n",
       "Blockchain                                               98.97         77.26   \n",
       "\n",
       "                                               f1_score  \n",
       "Developer, back-end                               84.63  \n",
       "Developer, desktop or enterprise applications     82.28  \n",
       "Developer, full-stack                             89.88  \n",
       "Academic researcher                               88.98  \n",
       "DevOps specialist                                 86.73  \n",
       "Developer, front-end                              90.03  \n",
       "Engineer, data                                    82.20  \n",
       "Developer, QA or test                             64.75  \n",
       "System administrator                              80.83  \n",
       "Database administrator                            75.72  \n",
       "Data scientist or machine learning specialist     93.94  \n",
       "Developer, mobile                                 95.33  \n",
       "Data or business analyst                          85.24  \n",
       "Developer, embedded applications or devices       89.36  \n",
       "Developer, game or graphics                       88.70  \n",
       "Cloud infrastructure engineer                     87.40  \n",
       "Scientist                                         88.64  \n",
       "Security professional                             75.89  \n",
       "Blockchain                                        84.76  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics=[accuracy_score, precision_score, recall_score, f1_score]\n",
    "train_scores, mean_train_scores= calculate_metrics(voting_clf,x_train,y_train, metrics)\n",
    "\n",
    "print(mean_train_scores)\n",
    "train_scores.sort_values(\"precision_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "187d15ce-c682-4adc-a6d3-b40e4cfd420b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cross_validate the baseline model on the accuracy, precision, recall and f1\n",
    "voting_clf_scores = cross_validate(voting_clf,x_train,y_train, cv=3, scoring =calculate_scores_multi_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8009c2fb-9094-4436-83c2-9dc31fa0e90c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_accuracy': 91.43,\n",
       " 'test_precision': 74.62,\n",
       " 'test_recall': 63.04,\n",
       " 'test_f1': 61.57}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = ['test_accuracy', 'test_precision','test_recall', 'test_f1']\n",
    "validation_scores = {}\n",
    "for score in scores:\n",
    "    validation_scores[score] = round(voting_clf_scores[score].mean(), 2)\n",
    "validation_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e7cd83-9a0c-4d18-a4ce-829a0cfdce40",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Log voting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "62f39767",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Log the model's dataset train and test indices\n",
    "log_data(x_train,y_train,x_test,y_test)\n",
    "# Log the model, model description\n",
    "model = log_model(voting_clf,'Voting Classifier')\n",
    "# Log the model's train and test scores\n",
    "log_metrics(train_scores, validation_scores)\n",
    "# track the model artifacts, validation scores with mlflow \n",
    "track_model(model,validation_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b948782-b3bf-4fcf-b1d8-15837748adec",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Retrieve Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e2c5e639-1225-474d-b9e6-7c0f76947f7f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>tags.mlflow.runName</th>\n",
       "      <th>metrics.test_precision</th>\n",
       "      <th>metrics.test_recall</th>\n",
       "      <th>metrics.test_f1</th>\n",
       "      <th>metrics.test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d6010e9458eb4fd5aab149b76df44e1a</td>\n",
       "      <td>Baseline model: Logistic Regression, multilabe...</td>\n",
       "      <td>66.03</td>\n",
       "      <td>61.00</td>\n",
       "      <td>58.93</td>\n",
       "      <td>90.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>366b3b40b46344edb0a8d00c95a3884c</td>\n",
       "      <td>Random Forest, Tuned, multilabel, Data resampled</td>\n",
       "      <td>84.98</td>\n",
       "      <td>65.35</td>\n",
       "      <td>65.80</td>\n",
       "      <td>91.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d9a069fe4f2a490cad7b4d811be222bb</td>\n",
       "      <td>Voting Classifier</td>\n",
       "      <td>74.62</td>\n",
       "      <td>63.04</td>\n",
       "      <td>61.57</td>\n",
       "      <td>91.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>352deeb893cd40ef8fd55216a1b3004d</td>\n",
       "      <td>Cat Boost, multilabel, Data resampled</td>\n",
       "      <td>73.24</td>\n",
       "      <td>62.05</td>\n",
       "      <td>60.59</td>\n",
       "      <td>91.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5b6f02d285554e1ebd30a9c07435f817</td>\n",
       "      <td>Gradient Boost, multilabel, Data resampled</td>\n",
       "      <td>68.63</td>\n",
       "      <td>59.93</td>\n",
       "      <td>58.44</td>\n",
       "      <td>90.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>f33f70dd5d0c48d48136e8d3e89a3271</td>\n",
       "      <td>Random Forest, multilabel, Data resampled</td>\n",
       "      <td>80.84</td>\n",
       "      <td>66.31</td>\n",
       "      <td>65.28</td>\n",
       "      <td>91.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ffeeca910ef342959dc27b9a1edb024c</td>\n",
       "      <td>Baseline model: Logistic Regression, multilabe...</td>\n",
       "      <td>65.89</td>\n",
       "      <td>60.99</td>\n",
       "      <td>58.87</td>\n",
       "      <td>90.47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             run_id  \\\n",
       "0  d6010e9458eb4fd5aab149b76df44e1a   \n",
       "1  366b3b40b46344edb0a8d00c95a3884c   \n",
       "2  d9a069fe4f2a490cad7b4d811be222bb   \n",
       "3  352deeb893cd40ef8fd55216a1b3004d   \n",
       "4  5b6f02d285554e1ebd30a9c07435f817   \n",
       "5  f33f70dd5d0c48d48136e8d3e89a3271   \n",
       "6  ffeeca910ef342959dc27b9a1edb024c   \n",
       "\n",
       "                                 tags.mlflow.runName  metrics.test_precision  \\\n",
       "0  Baseline model: Logistic Regression, multilabe...                   66.03   \n",
       "1   Random Forest, Tuned, multilabel, Data resampled                   84.98   \n",
       "2                                  Voting Classifier                   74.62   \n",
       "3              Cat Boost, multilabel, Data resampled                   73.24   \n",
       "4         Gradient Boost, multilabel, Data resampled                   68.63   \n",
       "5          Random Forest, multilabel, Data resampled                   80.84   \n",
       "6  Baseline model: Logistic Regression, multilabe...                   65.89   \n",
       "\n",
       "   metrics.test_recall  metrics.test_f1  metrics.test_accuracy  \n",
       "0                61.00            58.93                  90.50  \n",
       "1                65.35            65.80                  91.97  \n",
       "2                63.04            61.57                  91.43  \n",
       "3                62.05            60.59                  91.19  \n",
       "4                59.93            58.44                  90.98  \n",
       "5                66.31            65.28                  91.80  \n",
       "6                60.99            58.87                  90.47  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runs = mlflow.search_runs([exp.experiment_id])\n",
    "runs[['run_id','tags.mlflow.runName','metrics.test_precision','metrics.test_recall','metrics.test_f1','metrics.test_accuracy']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd41423-dae5-4619-9fed-2be04783669d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Evaluate best models on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "5f964e82-ba47-4656-9903-70cdc497a29e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score     92.931579\n",
      "precision_score    91.562105\n",
      "recall_score       62.690526\n",
      "f1_score           67.615789\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Developer, full-stack</th>\n",
       "      <td>83.05</td>\n",
       "      <td>77.65</td>\n",
       "      <td>56.23</td>\n",
       "      <td>56.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, desktop or enterprise applications</th>\n",
       "      <td>90.94</td>\n",
       "      <td>83.58</td>\n",
       "      <td>56.75</td>\n",
       "      <td>59.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, back-end</th>\n",
       "      <td>82.71</td>\n",
       "      <td>85.23</td>\n",
       "      <td>57.80</td>\n",
       "      <td>58.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data scientist or machine learning specialist</th>\n",
       "      <td>93.03</td>\n",
       "      <td>85.37</td>\n",
       "      <td>69.69</td>\n",
       "      <td>74.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, front-end</th>\n",
       "      <td>92.93</td>\n",
       "      <td>86.16</td>\n",
       "      <td>57.90</td>\n",
       "      <td>61.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scientist</th>\n",
       "      <td>94.77</td>\n",
       "      <td>88.11</td>\n",
       "      <td>69.75</td>\n",
       "      <td>75.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Academic researcher</th>\n",
       "      <td>93.37</td>\n",
       "      <td>88.83</td>\n",
       "      <td>70.08</td>\n",
       "      <td>75.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, game or graphics</th>\n",
       "      <td>95.35</td>\n",
       "      <td>89.75</td>\n",
       "      <td>63.34</td>\n",
       "      <td>69.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, embedded applications or devices</th>\n",
       "      <td>93.95</td>\n",
       "      <td>90.65</td>\n",
       "      <td>59.56</td>\n",
       "      <td>64.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DevOps specialist</th>\n",
       "      <td>92.89</td>\n",
       "      <td>93.82</td>\n",
       "      <td>63.10</td>\n",
       "      <td>68.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cloud infrastructure engineer</th>\n",
       "      <td>93.44</td>\n",
       "      <td>94.04</td>\n",
       "      <td>63.63</td>\n",
       "      <td>69.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, mobile</th>\n",
       "      <td>95.66</td>\n",
       "      <td>95.92</td>\n",
       "      <td>72.47</td>\n",
       "      <td>79.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data or business analyst</th>\n",
       "      <td>94.12</td>\n",
       "      <td>96.08</td>\n",
       "      <td>61.64</td>\n",
       "      <td>67.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Engineer, data</th>\n",
       "      <td>93.20</td>\n",
       "      <td>96.55</td>\n",
       "      <td>58.37</td>\n",
       "      <td>62.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>System administrator</th>\n",
       "      <td>93.95</td>\n",
       "      <td>96.90</td>\n",
       "      <td>64.60</td>\n",
       "      <td>71.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Database administrator</th>\n",
       "      <td>94.67</td>\n",
       "      <td>97.28</td>\n",
       "      <td>63.03</td>\n",
       "      <td>69.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, QA or test</th>\n",
       "      <td>94.81</td>\n",
       "      <td>97.37</td>\n",
       "      <td>59.14</td>\n",
       "      <td>64.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Security professional</th>\n",
       "      <td>96.41</td>\n",
       "      <td>98.18</td>\n",
       "      <td>64.04</td>\n",
       "      <td>71.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blockchain</th>\n",
       "      <td>96.45</td>\n",
       "      <td>98.21</td>\n",
       "      <td>60.00</td>\n",
       "      <td>65.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               accuracy_score  \\\n",
       "Developer, full-stack                                   83.05   \n",
       "Developer, desktop or enterprise applications           90.94   \n",
       "Developer, back-end                                     82.71   \n",
       "Data scientist or machine learning specialist           93.03   \n",
       "Developer, front-end                                    92.93   \n",
       "Scientist                                               94.77   \n",
       "Academic researcher                                     93.37   \n",
       "Developer, game or graphics                             95.35   \n",
       "Developer, embedded applications or devices             93.95   \n",
       "DevOps specialist                                       92.89   \n",
       "Cloud infrastructure engineer                           93.44   \n",
       "Developer, mobile                                       95.66   \n",
       "Data or business analyst                                94.12   \n",
       "Engineer, data                                          93.20   \n",
       "System administrator                                    93.95   \n",
       "Database administrator                                  94.67   \n",
       "Developer, QA or test                                   94.81   \n",
       "Security professional                                   96.41   \n",
       "Blockchain                                              96.45   \n",
       "\n",
       "                                               precision_score  recall_score  \\\n",
       "Developer, full-stack                                    77.65         56.23   \n",
       "Developer, desktop or enterprise applications            83.58         56.75   \n",
       "Developer, back-end                                      85.23         57.80   \n",
       "Data scientist or machine learning specialist            85.37         69.69   \n",
       "Developer, front-end                                     86.16         57.90   \n",
       "Scientist                                                88.11         69.75   \n",
       "Academic researcher                                      88.83         70.08   \n",
       "Developer, game or graphics                              89.75         63.34   \n",
       "Developer, embedded applications or devices              90.65         59.56   \n",
       "DevOps specialist                                        93.82         63.10   \n",
       "Cloud infrastructure engineer                            94.04         63.63   \n",
       "Developer, mobile                                        95.92         72.47   \n",
       "Data or business analyst                                 96.08         61.64   \n",
       "Engineer, data                                           96.55         58.37   \n",
       "System administrator                                     96.90         64.60   \n",
       "Database administrator                                   97.28         63.03   \n",
       "Developer, QA or test                                    97.37         59.14   \n",
       "Security professional                                    98.18         64.04   \n",
       "Blockchain                                               98.21         60.00   \n",
       "\n",
       "                                               f1_score  \n",
       "Developer, full-stack                             56.73  \n",
       "Developer, desktop or enterprise applications     59.41  \n",
       "Developer, back-end                               58.74  \n",
       "Data scientist or machine learning specialist     74.72  \n",
       "Developer, front-end                              61.57  \n",
       "Scientist                                         75.50  \n",
       "Academic researcher                               75.76  \n",
       "Developer, game or graphics                       69.23  \n",
       "Developer, embedded applications or devices       64.25  \n",
       "DevOps specialist                                 68.73  \n",
       "Cloud infrastructure engineer                     69.52  \n",
       "Developer, mobile                                 79.55  \n",
       "Data or business analyst                          67.30  \n",
       "Engineer, data                                    62.55  \n",
       "System administrator                              71.00  \n",
       "Database administrator                            69.28  \n",
       "Developer, QA or test                             64.11  \n",
       "Security professional                             71.00  \n",
       "Blockchain                                        65.75  "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate Random Forest on the test set\n",
    "metrics=[accuracy_score, precision_score, recall_score, f1_score]\n",
    "test_scores, mean_test_scores= calculate_metrics(rf_clf_grid_search.best_estimator_,x_test,y_test, metrics)\n",
    "\n",
    "print(mean_test_scores)\n",
    "test_scores.sort_values(\"precision_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "61ecc489-f4ed-43e9-bda3-9bb4662fb055",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score     92.235789\n",
      "precision_score    79.986842\n",
      "recall_score       62.434737\n",
      "f1_score           65.455789\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Database administrator</th>\n",
       "      <td>92.75</td>\n",
       "      <td>69.56</td>\n",
       "      <td>51.29</td>\n",
       "      <td>50.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, QA or test</th>\n",
       "      <td>93.64</td>\n",
       "      <td>71.87</td>\n",
       "      <td>50.75</td>\n",
       "      <td>49.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scientist</th>\n",
       "      <td>92.45</td>\n",
       "      <td>72.19</td>\n",
       "      <td>63.30</td>\n",
       "      <td>66.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, full-stack</th>\n",
       "      <td>83.60</td>\n",
       "      <td>73.65</td>\n",
       "      <td>62.93</td>\n",
       "      <td>65.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, back-end</th>\n",
       "      <td>82.13</td>\n",
       "      <td>75.78</td>\n",
       "      <td>59.03</td>\n",
       "      <td>60.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cloud infrastructure engineer</th>\n",
       "      <td>91.70</td>\n",
       "      <td>75.99</td>\n",
       "      <td>59.19</td>\n",
       "      <td>62.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, desktop or enterprise applications</th>\n",
       "      <td>90.74</td>\n",
       "      <td>76.81</td>\n",
       "      <td>59.06</td>\n",
       "      <td>62.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data scientist or machine learning specialist</th>\n",
       "      <td>91.73</td>\n",
       "      <td>76.82</td>\n",
       "      <td>72.88</td>\n",
       "      <td>74.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Engineer, data</th>\n",
       "      <td>92.45</td>\n",
       "      <td>78.01</td>\n",
       "      <td>58.72</td>\n",
       "      <td>62.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>System administrator</th>\n",
       "      <td>91.97</td>\n",
       "      <td>78.58</td>\n",
       "      <td>56.26</td>\n",
       "      <td>58.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DevOps specialist</th>\n",
       "      <td>91.93</td>\n",
       "      <td>79.74</td>\n",
       "      <td>64.19</td>\n",
       "      <td>68.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Academic researcher</th>\n",
       "      <td>92.55</td>\n",
       "      <td>82.11</td>\n",
       "      <td>70.55</td>\n",
       "      <td>74.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, game or graphics</th>\n",
       "      <td>95.32</td>\n",
       "      <td>82.64</td>\n",
       "      <td>68.71</td>\n",
       "      <td>73.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data or business analyst</th>\n",
       "      <td>93.34</td>\n",
       "      <td>82.85</td>\n",
       "      <td>59.98</td>\n",
       "      <td>64.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, front-end</th>\n",
       "      <td>93.75</td>\n",
       "      <td>83.35</td>\n",
       "      <td>67.47</td>\n",
       "      <td>72.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blockchain</th>\n",
       "      <td>96.21</td>\n",
       "      <td>84.33</td>\n",
       "      <td>61.71</td>\n",
       "      <td>66.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, embedded applications or devices</th>\n",
       "      <td>94.46</td>\n",
       "      <td>85.57</td>\n",
       "      <td>66.79</td>\n",
       "      <td>72.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, mobile</th>\n",
       "      <td>96.65</td>\n",
       "      <td>92.35</td>\n",
       "      <td>82.42</td>\n",
       "      <td>86.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Security professional</th>\n",
       "      <td>95.11</td>\n",
       "      <td>97.55</td>\n",
       "      <td>51.03</td>\n",
       "      <td>50.76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               accuracy_score  \\\n",
       "Database administrator                                  92.75   \n",
       "Developer, QA or test                                   93.64   \n",
       "Scientist                                               92.45   \n",
       "Developer, full-stack                                   83.60   \n",
       "Developer, back-end                                     82.13   \n",
       "Cloud infrastructure engineer                           91.70   \n",
       "Developer, desktop or enterprise applications           90.74   \n",
       "Data scientist or machine learning specialist           91.73   \n",
       "Engineer, data                                          92.45   \n",
       "System administrator                                    91.97   \n",
       "DevOps specialist                                       91.93   \n",
       "Academic researcher                                     92.55   \n",
       "Developer, game or graphics                             95.32   \n",
       "Data or business analyst                                93.34   \n",
       "Developer, front-end                                    93.75   \n",
       "Blockchain                                              96.21   \n",
       "Developer, embedded applications or devices             94.46   \n",
       "Developer, mobile                                       96.65   \n",
       "Security professional                                   95.11   \n",
       "\n",
       "                                               precision_score  recall_score  \\\n",
       "Database administrator                                   69.56         51.29   \n",
       "Developer, QA or test                                    71.87         50.75   \n",
       "Scientist                                                72.19         63.30   \n",
       "Developer, full-stack                                    73.65         62.93   \n",
       "Developer, back-end                                      75.78         59.03   \n",
       "Cloud infrastructure engineer                            75.99         59.19   \n",
       "Developer, desktop or enterprise applications            76.81         59.06   \n",
       "Data scientist or machine learning specialist            76.82         72.88   \n",
       "Engineer, data                                           78.01         58.72   \n",
       "System administrator                                     78.58         56.26   \n",
       "DevOps specialist                                        79.74         64.19   \n",
       "Academic researcher                                      82.11         70.55   \n",
       "Developer, game or graphics                              82.64         68.71   \n",
       "Data or business analyst                                 82.85         59.98   \n",
       "Developer, front-end                                     83.35         67.47   \n",
       "Blockchain                                               84.33         61.71   \n",
       "Developer, embedded applications or devices              85.57         66.79   \n",
       "Developer, mobile                                        92.35         82.42   \n",
       "Security professional                                    97.55         51.03   \n",
       "\n",
       "                                               f1_score  \n",
       "Database administrator                            50.80  \n",
       "Developer, QA or test                             49.92  \n",
       "Scientist                                         66.33  \n",
       "Developer, full-stack                             65.47  \n",
       "Developer, back-end                               60.59  \n",
       "Cloud infrastructure engineer                     62.58  \n",
       "Developer, desktop or enterprise applications     62.33  \n",
       "Data scientist or machine learning specialist     74.64  \n",
       "Engineer, data                                    62.25  \n",
       "System administrator                              58.85  \n",
       "DevOps specialist                                 68.48  \n",
       "Academic researcher                               74.68  \n",
       "Developer, game or graphics                       73.50  \n",
       "Data or business analyst                          64.28  \n",
       "Developer, front-end                              72.42  \n",
       "Blockchain                                        66.94  \n",
       "Developer, embedded applications or devices       72.24  \n",
       "Developer, mobile                                 86.60  \n",
       "Security professional                             50.76  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate Gradient Boost on the test set\n",
    "metrics=[accuracy_score, precision_score, recall_score, f1_score]\n",
    "test_scores, mean_test_scores= calculate_metrics(gd_clf,x_test,y_test, metrics)\n",
    "\n",
    "print(mean_test_scores)\n",
    "test_scores.sort_values(\"precision_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5957bc39-fc21-4f46-a35b-0bcc61b7dc2f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score     92.601579\n",
      "precision_score    82.148947\n",
      "recall_score       63.180000\n",
      "f1_score           66.665789\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Developer, QA or test</th>\n",
       "      <td>93.64</td>\n",
       "      <td>46.82</td>\n",
       "      <td>50.00</td>\n",
       "      <td>48.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, full-stack</th>\n",
       "      <td>84.04</td>\n",
       "      <td>74.63</td>\n",
       "      <td>64.41</td>\n",
       "      <td>67.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scientist</th>\n",
       "      <td>92.86</td>\n",
       "      <td>74.85</td>\n",
       "      <td>63.10</td>\n",
       "      <td>66.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, back-end</th>\n",
       "      <td>83.15</td>\n",
       "      <td>77.32</td>\n",
       "      <td>62.47</td>\n",
       "      <td>65.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, desktop or enterprise applications</th>\n",
       "      <td>90.81</td>\n",
       "      <td>77.94</td>\n",
       "      <td>58.65</td>\n",
       "      <td>61.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data scientist or machine learning specialist</th>\n",
       "      <td>92.65</td>\n",
       "      <td>80.06</td>\n",
       "      <td>74.96</td>\n",
       "      <td>77.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cloud infrastructure engineer</th>\n",
       "      <td>92.28</td>\n",
       "      <td>80.98</td>\n",
       "      <td>61.08</td>\n",
       "      <td>65.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data or business analyst</th>\n",
       "      <td>93.23</td>\n",
       "      <td>82.79</td>\n",
       "      <td>58.90</td>\n",
       "      <td>62.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DevOps specialist</th>\n",
       "      <td>92.52</td>\n",
       "      <td>83.73</td>\n",
       "      <td>65.48</td>\n",
       "      <td>70.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Academic researcher</th>\n",
       "      <td>92.72</td>\n",
       "      <td>83.73</td>\n",
       "      <td>69.87</td>\n",
       "      <td>74.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Engineer, data</th>\n",
       "      <td>92.75</td>\n",
       "      <td>83.82</td>\n",
       "      <td>58.32</td>\n",
       "      <td>62.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, embedded applications or devices</th>\n",
       "      <td>94.60</td>\n",
       "      <td>85.86</td>\n",
       "      <td>67.95</td>\n",
       "      <td>73.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>System administrator</th>\n",
       "      <td>92.58</td>\n",
       "      <td>86.41</td>\n",
       "      <td>58.59</td>\n",
       "      <td>62.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, front-end</th>\n",
       "      <td>94.36</td>\n",
       "      <td>86.44</td>\n",
       "      <td>70.33</td>\n",
       "      <td>75.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, game or graphics</th>\n",
       "      <td>95.56</td>\n",
       "      <td>86.78</td>\n",
       "      <td>67.49</td>\n",
       "      <td>73.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Database administrator</th>\n",
       "      <td>93.13</td>\n",
       "      <td>87.22</td>\n",
       "      <td>53.03</td>\n",
       "      <td>53.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blockchain</th>\n",
       "      <td>96.27</td>\n",
       "      <td>89.13</td>\n",
       "      <td>60.28</td>\n",
       "      <td>65.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, mobile</th>\n",
       "      <td>97.06</td>\n",
       "      <td>94.72</td>\n",
       "      <td>83.46</td>\n",
       "      <td>88.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Security professional</th>\n",
       "      <td>95.22</td>\n",
       "      <td>97.60</td>\n",
       "      <td>52.05</td>\n",
       "      <td>52.72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               accuracy_score  \\\n",
       "Developer, QA or test                                   93.64   \n",
       "Developer, full-stack                                   84.04   \n",
       "Scientist                                               92.86   \n",
       "Developer, back-end                                     83.15   \n",
       "Developer, desktop or enterprise applications           90.81   \n",
       "Data scientist or machine learning specialist           92.65   \n",
       "Cloud infrastructure engineer                           92.28   \n",
       "Data or business analyst                                93.23   \n",
       "DevOps specialist                                       92.52   \n",
       "Academic researcher                                     92.72   \n",
       "Engineer, data                                          92.75   \n",
       "Developer, embedded applications or devices             94.60   \n",
       "System administrator                                    92.58   \n",
       "Developer, front-end                                    94.36   \n",
       "Developer, game or graphics                             95.56   \n",
       "Database administrator                                  93.13   \n",
       "Blockchain                                              96.27   \n",
       "Developer, mobile                                       97.06   \n",
       "Security professional                                   95.22   \n",
       "\n",
       "                                               precision_score  recall_score  \\\n",
       "Developer, QA or test                                    46.82         50.00   \n",
       "Developer, full-stack                                    74.63         64.41   \n",
       "Scientist                                                74.85         63.10   \n",
       "Developer, back-end                                      77.32         62.47   \n",
       "Developer, desktop or enterprise applications            77.94         58.65   \n",
       "Data scientist or machine learning specialist            80.06         74.96   \n",
       "Cloud infrastructure engineer                            80.98         61.08   \n",
       "Data or business analyst                                 82.79         58.90   \n",
       "DevOps specialist                                        83.73         65.48   \n",
       "Academic researcher                                      83.73         69.87   \n",
       "Engineer, data                                           83.82         58.32   \n",
       "Developer, embedded applications or devices              85.86         67.95   \n",
       "System administrator                                     86.41         58.59   \n",
       "Developer, front-end                                     86.44         70.33   \n",
       "Developer, game or graphics                              86.78         67.49   \n",
       "Database administrator                                   87.22         53.03   \n",
       "Blockchain                                               89.13         60.28   \n",
       "Developer, mobile                                        94.72         83.46   \n",
       "Security professional                                    97.60         52.05   \n",
       "\n",
       "                                               f1_score  \n",
       "Developer, QA or test                             48.36  \n",
       "Developer, full-stack                             67.12  \n",
       "Scientist                                         66.73  \n",
       "Developer, back-end                               65.08  \n",
       "Developer, desktop or enterprise applications     61.87  \n",
       "Data scientist or machine learning specialist     77.19  \n",
       "Cloud infrastructure engineer                     65.29  \n",
       "Data or business analyst                          62.87  \n",
       "DevOps specialist                                 70.41  \n",
       "Academic researcher                               74.52  \n",
       "Engineer, data                                    62.04  \n",
       "Developer, embedded applications or devices       73.41  \n",
       "System administrator                              62.47  \n",
       "Developer, front-end                              75.64  \n",
       "Developer, game or graphics                       73.25  \n",
       "Database administrator                            53.94  \n",
       "Blockchain                                        65.61  \n",
       "Developer, mobile                                 88.13  \n",
       "Security professional                             52.72  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate Cat Boost on the Test set\n",
    "metrics=[accuracy_score, precision_score, recall_score, f1_score]\n",
    "test_scores, mean_test_scores= calculate_metrics(cat_clf,x_test,y_test, metrics)\n",
    "\n",
    "print(mean_test_scores)\n",
    "test_scores.sort_values(\"precision_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eaef5ff3-1152-4a34-8fd2-845fa92b2e01",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score     92.765789\n",
      "precision_score    86.688947\n",
      "recall_score       63.718947\n",
      "f1_score           67.487895\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Developer, back-end</th>\n",
       "      <td>82.47</td>\n",
       "      <td>75.69</td>\n",
       "      <td>60.71</td>\n",
       "      <td>62.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, full-stack</th>\n",
       "      <td>84.22</td>\n",
       "      <td>76.00</td>\n",
       "      <td>63.23</td>\n",
       "      <td>66.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, desktop or enterprise applications</th>\n",
       "      <td>91.08</td>\n",
       "      <td>79.45</td>\n",
       "      <td>60.16</td>\n",
       "      <td>63.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data scientist or machine learning specialist</th>\n",
       "      <td>92.89</td>\n",
       "      <td>80.90</td>\n",
       "      <td>75.56</td>\n",
       "      <td>77.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scientist</th>\n",
       "      <td>93.78</td>\n",
       "      <td>81.05</td>\n",
       "      <td>66.51</td>\n",
       "      <td>71.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, game or graphics</th>\n",
       "      <td>95.42</td>\n",
       "      <td>83.75</td>\n",
       "      <td>68.76</td>\n",
       "      <td>73.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Academic researcher</th>\n",
       "      <td>93.03</td>\n",
       "      <td>84.58</td>\n",
       "      <td>71.43</td>\n",
       "      <td>76.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cloud infrastructure engineer</th>\n",
       "      <td>92.69</td>\n",
       "      <td>85.45</td>\n",
       "      <td>61.82</td>\n",
       "      <td>66.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data or business analyst</th>\n",
       "      <td>93.68</td>\n",
       "      <td>86.41</td>\n",
       "      <td>61.40</td>\n",
       "      <td>66.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Engineer, data</th>\n",
       "      <td>92.93</td>\n",
       "      <td>86.96</td>\n",
       "      <td>58.60</td>\n",
       "      <td>62.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, embedded applications or devices</th>\n",
       "      <td>94.77</td>\n",
       "      <td>87.27</td>\n",
       "      <td>68.48</td>\n",
       "      <td>74.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DevOps specialist</th>\n",
       "      <td>92.76</td>\n",
       "      <td>87.36</td>\n",
       "      <td>64.80</td>\n",
       "      <td>70.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, front-end</th>\n",
       "      <td>94.26</td>\n",
       "      <td>88.03</td>\n",
       "      <td>68.14</td>\n",
       "      <td>73.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>System administrator</th>\n",
       "      <td>92.76</td>\n",
       "      <td>89.04</td>\n",
       "      <td>59.05</td>\n",
       "      <td>63.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blockchain</th>\n",
       "      <td>96.24</td>\n",
       "      <td>89.85</td>\n",
       "      <td>59.53</td>\n",
       "      <td>64.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, mobile</th>\n",
       "      <td>97.13</td>\n",
       "      <td>94.11</td>\n",
       "      <td>84.53</td>\n",
       "      <td>88.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Database administrator</th>\n",
       "      <td>93.34</td>\n",
       "      <td>96.65</td>\n",
       "      <td>53.79</td>\n",
       "      <td>55.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer, QA or test</th>\n",
       "      <td>93.78</td>\n",
       "      <td>96.89</td>\n",
       "      <td>51.08</td>\n",
       "      <td>50.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Security professional</th>\n",
       "      <td>95.32</td>\n",
       "      <td>97.65</td>\n",
       "      <td>53.08</td>\n",
       "      <td>54.60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               accuracy_score  \\\n",
       "Developer, back-end                                     82.47   \n",
       "Developer, full-stack                                   84.22   \n",
       "Developer, desktop or enterprise applications           91.08   \n",
       "Data scientist or machine learning specialist           92.89   \n",
       "Scientist                                               93.78   \n",
       "Developer, game or graphics                             95.42   \n",
       "Academic researcher                                     93.03   \n",
       "Cloud infrastructure engineer                           92.69   \n",
       "Data or business analyst                                93.68   \n",
       "Engineer, data                                          92.93   \n",
       "Developer, embedded applications or devices             94.77   \n",
       "DevOps specialist                                       92.76   \n",
       "Developer, front-end                                    94.26   \n",
       "System administrator                                    92.76   \n",
       "Blockchain                                              96.24   \n",
       "Developer, mobile                                       97.13   \n",
       "Database administrator                                  93.34   \n",
       "Developer, QA or test                                   93.78   \n",
       "Security professional                                   95.32   \n",
       "\n",
       "                                               precision_score  recall_score  \\\n",
       "Developer, back-end                                      75.69         60.71   \n",
       "Developer, full-stack                                    76.00         63.23   \n",
       "Developer, desktop or enterprise applications            79.45         60.16   \n",
       "Data scientist or machine learning specialist            80.90         75.56   \n",
       "Scientist                                                81.05         66.51   \n",
       "Developer, game or graphics                              83.75         68.76   \n",
       "Academic researcher                                      84.58         71.43   \n",
       "Cloud infrastructure engineer                            85.45         61.82   \n",
       "Data or business analyst                                 86.41         61.40   \n",
       "Engineer, data                                           86.96         58.60   \n",
       "Developer, embedded applications or devices              87.27         68.48   \n",
       "DevOps specialist                                        87.36         64.80   \n",
       "Developer, front-end                                     88.03         68.14   \n",
       "System administrator                                     89.04         59.05   \n",
       "Blockchain                                               89.85         59.53   \n",
       "Developer, mobile                                        94.11         84.53   \n",
       "Database administrator                                   96.65         53.79   \n",
       "Developer, QA or test                                    96.89         51.08   \n",
       "Security professional                                    97.65         53.08   \n",
       "\n",
       "                                               f1_score  \n",
       "Developer, back-end                               62.82  \n",
       "Developer, full-stack                             66.05  \n",
       "Developer, desktop or enterprise applications     63.89  \n",
       "Data scientist or machine learning specialist     77.90  \n",
       "Scientist                                         71.11  \n",
       "Developer, game or graphics                       73.80  \n",
       "Academic researcher                               76.03  \n",
       "Cloud infrastructure engineer                     66.59  \n",
       "Data or business analyst                          66.33  \n",
       "Engineer, data                                    62.57  \n",
       "Developer, embedded applications or devices       74.18  \n",
       "DevOps specialist                                 70.17  \n",
       "Developer, front-end                              73.91  \n",
       "System administrator                              63.22  \n",
       "Blockchain                                        64.66  \n",
       "Developer, mobile                                 88.62  \n",
       "Database administrator                            55.32  \n",
       "Developer, QA or test                             50.50  \n",
       "Security professional                             54.60  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the Voting Classifier on the Test set\n",
    "metrics=[accuracy_score, precision_score, recall_score, f1_score]\n",
    "test_scores, mean_test_scores= calculate_metrics(voting_clf,x_test,y_test, metrics)\n",
    "\n",
    "print(mean_test_scores)\n",
    "test_scores.sort_values(\"precision_score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7386d0e7-452f-4d88-a9af-108bfdb4a4fd",
   "metadata": {},
   "source": [
    "## Retrieve Best Run Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "ac1499ba-f70b-4df3-b7bf-38fa6037681f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_run= runs[runs['run_id'] == '366b3b40b46344edb0a8d00c95a3884c'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "215caf8b-5637-4df1-8522-edc9bf2ece4b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "run_id                                      366b3b40b46344edb0a8d00c95a3884c\n",
       "experiment_id                                             996200319116358272\n",
       "status                                                              FINISHED\n",
       "artifact_uri               file:///C:/Users/Ali/Desktop/DS Projects/Tech ...\n",
       "start_time                                  2024-01-31 11:31:20.708000+00:00\n",
       "end_time                                    2024-01-31 11:31:34.513000+00:00\n",
       "metrics.test_recall                                                    65.35\n",
       "metrics.test_f1                                                         65.8\n",
       "metrics.test_precision                                                 84.98\n",
       "metrics.test_accuracy                                                  91.97\n",
       "tags.mlflow.runName         Random Forest, Tuned, multilabel, Data resampled\n",
       "tags.mlflow.user                                                         Ali\n",
       "tags.mlflow.source.name    C:\\Users\\Ali\\mambaforge-pypy3\\envs\\env1\\Lib\\si...\n",
       "tags.mlflow.source.type                                                LOCAL\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "5eab144d-3849-4cea-9546-e4f568606dfd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "artifact_path = best_run[\"artifact_uri\"].replace(\"file:///\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "c08f9997-e4ce-47e8-b862-61bbd3365228",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-14 {color: black;}#sk-container-id-14 pre{padding: 0;}#sk-container-id-14 div.sk-toggleable {background-color: white;}#sk-container-id-14 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-14 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-14 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-14 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-14 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-14 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-14 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-14 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-14 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-14 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-14 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-14 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-14 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-14 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-14 div.sk-item {position: relative;z-index: 1;}#sk-container-id-14 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-14 div.sk-item::before, #sk-container-id-14 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-14 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-14 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-14 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-14 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-14 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-14 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-14 div.sk-label-container {text-align: center;}#sk-container-id-14 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-14 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-14\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;randomforestclassifier&#x27;,\n",
       "                 RandomForestClassifier(class_weight=&#x27;balanced&#x27;, max_depth=40,\n",
       "                                        max_features=&#x27;log2&#x27;,\n",
       "                                        min_samples_split=3, n_estimators=120,\n",
       "                                        n_jobs=-1, random_state=42))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-40\" type=\"checkbox\" ><label for=\"sk-estimator-id-40\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;randomforestclassifier&#x27;,\n",
       "                 RandomForestClassifier(class_weight=&#x27;balanced&#x27;, max_depth=40,\n",
       "                                        max_features=&#x27;log2&#x27;,\n",
       "                                        min_samples_split=3, n_estimators=120,\n",
       "                                        n_jobs=-1, random_state=42))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-41\" type=\"checkbox\" ><label for=\"sk-estimator-id-41\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, max_depth=40,\n",
       "                       max_features=&#x27;log2&#x27;, min_samples_split=3,\n",
       "                       n_estimators=120, n_jobs=-1, random_state=42)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('randomforestclassifier',\n",
       "                 RandomForestClassifier(class_weight='balanced', max_depth=40,\n",
       "                                        max_features='log2',\n",
       "                                        min_samples_split=3, n_estimators=120,\n",
       "                                        n_jobs=-1, random_state=42))])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pkl = os.path.join(artifact_path, LOG_MODEL_PKL)\n",
    "with open(model_pkl, \"rb\") as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "model['model_object']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
